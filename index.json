[{"categories":["API Style"],"content":" 来自字节Kitex文档 ","date":"2022-06-10 09:28:10","objectID":"/kitex/:0:0","tags":["API style"],"title":"Kitex","uri":"/kitex/"},{"categories":["API Style"],"content":"准备 Golang 开发环境 如果您之前未搭建 Golang 开发环境， 可以参考 Golang 安装 推荐使用最新版本的 Golang，我们保证最新三个正式版本的兼容性(现在 \u003e= v1.16)。 确保打开 go mod 支持 (Golang \u003e= 1.15时，默认开启) kitex 暂时没有针对 Windows 做支持，如果本地开发环境是 Windows 建议使用 WSL2 ","date":"2022-06-10 09:28:10","objectID":"/kitex/:1:0","tags":["API style"],"title":"Kitex","uri":"/kitex/"},{"categories":["API Style"],"content":"快速上手 在完成环境准备后，本章节将帮助你快速上手 Kitex ","date":"2022-06-10 09:28:10","objectID":"/kitex/:2:0","tags":["API style"],"title":"Kitex","uri":"/kitex/"},{"categories":["API Style"],"content":"安装代码生成工具 首先，我们需要安装使用本示例所需要的命令行代码生成工具： 确保 GOPATH 环境变量已经被正确地定义（例如 export GOPATH=~/go）并且将$GOPATH/bin添加到 PATH 环境变量之中（例如 export PATH=$GOPATH/bin:$PATH）；请勿将 GOPATH 设置为当前用户没有读写权限的目录 安装 kitex：go install github.com/cloudwego/kitex/tool/cmd/kitex@latest 安装 thriftgo：go install github.com/cloudwego/thriftgo@latest 安装成功后，执行 kitex --version 和 thriftgo --version 应该能够看到具体版本号的输出（版本号有差异，以 x.x.x 示例）： $ kitex --version vx.x.x $ thriftgo --version thriftgo x.x.x 如果在安装阶段发生问题，可能主要是由于对 Golang 的不当使用造成，请依照报错信息进行检索 ","date":"2022-06-10 09:28:10","objectID":"/kitex/:2:1","tags":["API style"],"title":"Kitex","uri":"/kitex/"},{"categories":["API Style"],"content":"确定代码放置位置 若将代码放置于 $GOPATH/src 下，需在 $GOPATH/src 下创建额外目录，进入该目录后再获取代码： mkdir -p $(go env GOPATH)/src/github.com/cloudwego cd $(go env GOPATH)/src/github.com/cloudwego 若将代码放置于 GOPATH 之外，可直接获取 ","date":"2022-06-10 09:28:10","objectID":"/kitex/:2:2","tags":["API style"],"title":"Kitex","uri":"/kitex/"},{"categories":["API Style"],"content":"获取示例代码 你可以直接点击 此处 下载示例仓库 也可以克隆该示例仓库到本地 git clone https://github.com/cloudwego/kitex-examples.git ","date":"2022-06-10 09:28:10","objectID":"/kitex/:2:3","tags":["API style"],"title":"Kitex","uri":"/kitex/"},{"categories":["API Style"],"content":"运行示例代码 方式一：直接启动 进入示例仓库的 hello 目录 cd kitex-examples/hello 运行 server go run . 运行 client 另起一个终端后，go run ./client 方式二：使用 Docker 快速启动 进入示例仓库目录 cd kitex-examples 编译项目 docker build -t kitex-examples . 运行 server docker run --network host kitex-examples ./hello-server 运行 client 另起一个终端后，docker run --network host kitex-examples ./hello-client 恭喜你，你现在成功通过 Kitex 发起了 RPC 调用。 ","date":"2022-06-10 09:28:10","objectID":"/kitex/:2:4","tags":["API style"],"title":"Kitex","uri":"/kitex/"},{"categories":["API Style"],"content":"增加一个新的方法 打开 hello.thrift，你会看到如下内容： namespacegoapistructRequest{1:stringmessage}structResponse{1:stringmessage}serviceHello{Responseecho(1:Requestreq)} 现在让我们为新方法分别定义一个新的请求和响应，AddRequest 和 AddResponse，并在 service Hello 中增加 add 方法： namespacegoapistructRequest{1:stringmessage}structResponse{1:stringmessage}structAddRequest{1:i64first2:i64second}structAddResponse{1:i64sum}serviceHello{Responseecho(1:Requestreq)AddResponseadd(1:AddRequestreq)} 完成之后 hello.thrift 的内容应该和上面一样。 ","date":"2022-06-10 09:28:10","objectID":"/kitex/:2:5","tags":["API style"],"title":"Kitex","uri":"/kitex/"},{"categories":["API Style"],"content":"重新生成代码 运行如下命令后，kitex 工具将根据 hello.thrift 更新代码文件。 kitex -service a.b.c hello.thrift # 若当前目录不在 $GOPATH/src 下，需要加上 -module 参数，一般为 go.mod 下的名字 kitex -module \"your_module_name\" -service a.b.c hello.thrift 执行完上述命令后，kitex 工具将更新下述文件 更新 ./handler.go，在里面增加一个 Add 方法的基本实现 更新 ./kitex_gen，里面有框架运行所必须的代码文件 ","date":"2022-06-10 09:28:10","objectID":"/kitex/:2:6","tags":["API style"],"title":"Kitex","uri":"/kitex/"},{"categories":["API Style"],"content":"更新服务端处理逻辑 上述步骤完成后，./handler.go 中会自动补全一个 Add 方法的基本实现，类似如下代码： // Add implements the HelloImpl interface. func (s *HelloImpl) Add(ctx context.Context, req *api.AddRequest) (resp *api.AddResponse, err error) { // TODO: Your code here... return } 让我们在里面增加我们所需要的逻辑，类似如下代码： // Add implements the HelloImpl interface. func (s *HelloImpl) Add(ctx context.Context, req *api.AddRequest) (resp *api.AddResponse, err error) { // TODO: Your code here... resp = \u0026api.AddResponse{Sum: req.First + req.Second} return } ","date":"2022-06-10 09:28:10","objectID":"/kitex/:2:7","tags":["API style"],"title":"Kitex","uri":"/kitex/"},{"categories":["API Style"],"content":"增加客户端调用 服务端已经有了 Add 方法的处理，现在让我们在客户端增加对 Add 方法的调用。 在 ./client/main.go 中你会看到类似如下的 for 循环： for { req := \u0026api.Request{Message: \"my request\"} resp, err := client.Echo(context.Background(), req) if err != nil { log.Fatal(err) } log.Println(resp) time.Sleep(time.Second) } 现在让我们在里面增加 Add 方法的调用： for { req := \u0026api.Request{Message: \"my request\"} resp, err := client.Echo(context.Background(), req) if err != nil { log.Fatal(err) } log.Println(resp) time.Sleep(time.Second) addReq := \u0026api.AddRequest{First: 512, Second: 512} addResp, err := client.Add(context.Background(), addReq) if err != nil { log.Fatal(err) } log.Println(addResp) time.Sleep(time.Second) } ","date":"2022-06-10 09:28:10","objectID":"/kitex/:2:8","tags":["API style"],"title":"Kitex","uri":"/kitex/"},{"categories":["API Style"],"content":"重新运行示例代码 关闭之前运行的客户端和服务端之后 运行 server go run . 运行 client 另起一个终端后，go run ./client 现在，你应该能看到客户端在调用 Add 方法了。 ","date":"2022-06-10 09:28:10","objectID":"/kitex/:2:9","tags":["API style"],"title":"Kitex","uri":"/kitex/"},{"categories":["API Style"],"content":"基础教程 ","date":"2022-06-10 09:28:10","objectID":"/kitex/:3:0","tags":["API style"],"title":"Kitex","uri":"/kitex/"},{"categories":["API Style"],"content":"关于 Kitex Kitex 是一个 RPC 框架，既然是 RPC，底层就需要两大功能： Serialization 序列化 Transport 传输 Kitex 框架及命令行工具，默认支持 thrift 和 proto3 两种 IDL，对应的 Kitex 支持 thrift 和 protobuf 两种序列化协议。传输上 Kitex 使用扩展的 thrift 作为底层的传输协议（注：thrift 既是 IDL 格式，同时也是序列化协议和传输协议）。IDL 全称是 Interface Definition Language，接口定义语言。 ","date":"2022-06-10 09:28:10","objectID":"/kitex/:3:1","tags":["API style"],"title":"Kitex","uri":"/kitex/"},{"categories":["API Style"],"content":"为什么要使用 IDL 如果我们要进行 RPC，就需要知道对方的接口是什么，需要传什么参数，同时也需要知道返回值是什么样的，（即使我们的接口并没有真正实现调通，也可以通过IDL生成调用的代码，不会阻塞对方的开发）就好比两个人之间交流，需要保证在说的是同一个语言、同一件事。这时候，就需要通过 IDL 来约定双方的协议，就像在写代码的时候需要调用某个函数，我们需要知道函数签名一样。 Thrift IDL 语法可参考：Thrift interface description language。 proto3 语法可参考：Language Guide(proto3)。 ","date":"2022-06-10 09:28:10","objectID":"/kitex/:3:2","tags":["API style"],"title":"Kitex","uri":"/kitex/"},{"categories":["API Style"],"content":"创建项目目录 在开始后续的步骤之前，先让我们创建一个项目目录用于后续的教程。 $ mkdir example 然后让我们进入项目目录 $ cd example ","date":"2022-06-10 09:28:10","objectID":"/kitex/:3:3","tags":["API style"],"title":"Kitex","uri":"/kitex/"},{"categories":["API Style"],"content":"Kitex 命令行工具 Kitex 自带了一个同名的命令行工具 kitex，用来帮助大家很方便地生成代码，新项目的生成以及之后我们会学到的 server、client 代码的生成都是通过 kitex 工具进行。 安装 可以使用以下命令来安装或者更新 kitex： $ go install github.com/cloudwego/kitex/tool/cmd/kitex 完成后，可以通过执行 kitex 来检测是否安装成功。 $ kitex 如果出现如下输出，则安装成功。 $ kitex No IDL file found. 如果出现 command not found 错误，可能是因为没有把 $GOPATH/bin 加入到 $PATH 中，详见环境准备一章。 使用 kitex 的具体使用请参考代码生成工具 ","date":"2022-06-10 09:28:10","objectID":"/kitex/:3:4","tags":["API style"],"title":"Kitex","uri":"/kitex/"},{"categories":["API Style"],"content":"编写 IDL 首先我们需要编写一个 IDL，这里以 thrift IDL 为例。 首先创建一个名为 echo.thrift 的 thrift IDL 文件。 然后在里面定义我们的服务 namespacegoapistructRequest{1:stringmessage}structResponse{1:stringmessage}serviceEcho{Responseecho(1:Requestreq)} ","date":"2022-06-10 09:28:10","objectID":"/kitex/:3:5","tags":["API style"],"title":"Kitex","uri":"/kitex/"},{"categories":["API Style"],"content":"生成 echo 服务代码 有了 IDL 以后我们便可以通过 kitex 工具生成项目代码了，执行如下命令： $ kitex -module example -service example echo.thrift 上述命令中，-module 表示生成的该项目的 go module 名，-service 表明我们要生成一个服务端项目，后面紧跟的 example 为该服务的名字。最后一个参数则为该服务的 IDL 文件。 生成后的项目结构如下： . |-- build.sh |-- echo.thrift |-- handler.go |-- kitex_gen | `-- api | |-- echo | | |-- client.go | | |-- echo.go | | |-- invoker.go | | `-- server.go | |-- echo.go | `-- k-echo.go |-- main.go `-- script |-- bootstrap.sh `-- settings.py ","date":"2022-06-10 09:28:10","objectID":"/kitex/:3:6","tags":["API style"],"title":"Kitex","uri":"/kitex/"},{"categories":["API Style"],"content":"获取最新的 Kitex 框架 由于 kitex 要求使用 go mod 进行依赖管理，所以我们要升级 kitex 框架会很容易，只需要执行以下命令即可： $ go get github.com/cloudwego/kitex@latest $ go mod tidy 如果遇到类似如下报错： github.com/apache/thrift/lib/go/thrift: ambiguous import: found package github.com/apache/thrift/lib/go/thrift in multiple modules 先执行一遍下述命令，再继续操作： go mod edit -droprequire=github.com/apache/thrift/lib/go/thrift go mod edit -replace=github.com/apache/thrift=github.com/apache/thrift@v0.13.0 ","date":"2022-06-10 09:28:10","objectID":"/kitex/:3:7","tags":["API style"],"title":"Kitex","uri":"/kitex/"},{"categories":["API Style"],"content":"编写 echo 服务逻辑 我们需要编写的服务端逻辑都在 handler.go 这个文件中，现在这个文件应该如下所示： package main import ( \"context\" \"example/kitex_gen/api\" ) // EchoImpl implements the last service interface defined in the IDL. type EchoImpl struct{} // Echo implements the EchoImpl interface. func (s *EchoImpl) Echo(ctx context.Context, req *api.Request) (resp *api.Response, err error) { // TODO: Your code here... return } 这里的 Echo 函数就对应了我们之前在 IDL 中定义的 echo 方法。 现在让我们修改一下服务端逻辑，让 Echo 服务名副其实。 修改 Echo 函数为下述代码： func (s *EchoImpl) Echo(ctx context.Context, req *api.Request) (resp *api.Response, err error) { return \u0026api.Response{Message: req.Message}, nil } ","date":"2022-06-10 09:28:10","objectID":"/kitex/:3:8","tags":["API style"],"title":"Kitex","uri":"/kitex/"},{"categories":["API Style"],"content":"编译运行 kitex 工具已经帮我们生成好了编译和运行所需的脚本： 编译： $ sh build.sh 执行上述命令后，会生成一个 output 目录，里面含有我们的编译产物。 运行： $ sh output/bootstrap.sh 执行上述命令后，Echo 服务就开始运行啦！ ","date":"2022-06-10 09:28:10","objectID":"/kitex/:3:9","tags":["API style"],"title":"Kitex","uri":"/kitex/"},{"categories":["API Style"],"content":"编写客户端 有了服务端后，接下来就让我们编写一个客户端用于调用刚刚运行起来的服务端。 首先，同样的，先创建一个目录用于存放我们的客户端代码： $ mkdir client 进入目录： $ cd client 创建一个 main.go 文件，然后就开始编写客户端代码了。 创建 client 首先让我们创建一个调用所需的 client： import \"example/kitex_gen/api/echo\" import \"github.com/cloudwego/kitex/client\" ... c, err := echo.NewClient(\"example\", client.WithHostPorts(\"0.0.0.0:8888\")) if err != nil { log.Fatal(err) } 上述代码中，echo.NewClient 用于创建 client，其第一个参数为调用的 服务名，第二个参数为 options，用于传入参数，此处的 client.WithHostPorts 用于指定服务端的地址，更多参数可参考基本特性一节。 发起调用 接下来让我们编写用于发起调用的代码： import \"example/kitex_gen/api\" ... req := \u0026api.Request{Message: \"my request\"} resp, err := c.Echo(context.Background(), req, callopt.WithRPCTimeout(3*time.Second)) if err != nil { log.Fatal(err) } log.Println(resp) 上述代码中，我们首先创建了一个请求 req , 然后通过 c.Echo 发起了调用。 其第一个参数为 context.Context，通过通常用其传递信息或者控制本次调用的一些行为，你可以在后续章节中找到如何使用它。 其第二个参数为本次调用的请求。 其第三个参数为本次调用的 options ，Kitex 提供了一种 callopt 机制，顾名思义——调用参数 ，有别于创建 client 时传入的参数，这里传入的参数仅对此次生效。 此处的 callopt.WithRPCTimeout 用于指定此次调用的超时（通常不需要指定，此处仅作演示之用）同样的，你可以在基本特性一节中找到更多的参数。 ","date":"2022-06-10 09:28:10","objectID":"/kitex/:3:10","tags":["API style"],"title":"Kitex","uri":"/kitex/"},{"categories":["API Style"],"content":"发起调用 在编写完一个简单的客户端后，我们终于可以发起调用了。 你可以通过下述命令来完成这一步骤： $ go run main.go 如果不出意外，你可以看到类似如下输出： 2021/05/20 16:51:35 Response({Message:my request}) 恭喜你！至此你成功编写了一个 Kitex 的服务端和客户端，并完成了一次调用！ ","date":"2022-06-10 09:28:10","objectID":"/kitex/:3:11","tags":["API style"],"title":"Kitex","uri":"/kitex/"},{"categories":["Graduation project"],"content":" Hsiang-Fu Yu, Nikhil Rao, Inderjit S. Dhillon, 2016. Temporal regularized matrix factorization for high-dimensional time series prediction. 笔记中部分公式未渲染出来，文末截图可见 Temporal Regularized Matrix Factorization(TRMF) for High-dimensional Time Series Prediction ","date":"2022-05-13 09:33:30","objectID":"/nips16_trmf/:0:0","tags":["papers"],"title":"NIPS16_TRMF","uri":"/nips16_trmf/"},{"categories":["Graduation project"],"content":"摘要 现代应用程序需要具有高度可扩展性的方法，并且可以处理有噪声的或有缺失值的数据。 本文提出了一个支持数据驱动的时态学习和预测的时态正则化矩阵分解（TRMF）框架。我们在学习自回归模型中的依赖关系的背景下，与图正则化方法建立了有趣的联系框架。 实验结果表明：TRMF在维数为50000的问题上比其他方法快两个数量级，并能对现实世界的数据集（如沃尔玛电子商务数据集）生成更好的预测。 ","date":"2022-05-13 09:33:30","objectID":"/nips16_trmf/:1:0","tags":["papers"],"title":"NIPS16_TRMF","uri":"/nips16_trmf/"},{"categories":["Graduation project"],"content":"1. 介绍 现代时间序列应用程序给从业者带来了两个挑战：处理大n（数字）和T（时间帧）的可伸缩性，以及处理缺失值的灵活性。 AR和DLM侧重于低维时间序列数据，而没有处理上述两个问题。 对高维时间序列数据建模的一种自然方式是以矩阵的形式，行对应于每个一维时间序列，列对应于时间点。 鉴于n个时间序列通常高度相关，有人尝试应用低秩矩阵分解（MF）或矩阵完成（MC）技术来分析高维时间序列[2,14,16,23,26]。与上面的AR和DLM模型不同，最先进的MF方法以n为单位线性扩展，因此可以处理大型数据集。 在MF中，观测到的n维时间序列数据被组织在矩阵 $\\mathcal{Y} \\in \\mathbb{R}^{n \\times T}$ 中，矩阵 y 由维度特性矩阵 $W \\in \\mathbb{R}^{n \\times r}$ 与时间特性矩阵 $X \\in \\mathbb{R}^{r \\times T}$ 的组合进行低秩逼近，从而修补缺失数据。 $$ \\mathcal{Y} \\approx W X $$ 使用最小二乘法、梯度下降等方法求解下述最小化问题，从而对矩阵 W 与矩阵 X 进行逼近： $$ \\min {W X} \\sum{(i, t) \\in \\Omega}\\left(\\mathcal{Y}{i t}-w{i}^{T} x_{t}\\right)^{2}+\\lambda_{w} \\mathcal{R}_{w}(W)+\\lambda_{x} \\mathcal{R}_{x}(X) $$ 其中， $\\Omega$ 是原矩阵 $\\mathcal{Y} \\in \\mathbb{R}^{n \\times T}$ 中非零元所处位置的集合； $\\sum_{(i, t) \\in \\Omega}\\left(\\mathcal{Y}_{i t}-w_{i}^{T} x_{t}\\right)^{2}$ 为残差矩阵F范数的平方，用来描述 W X 矩阵 与原矩阵 Y 的差异；$R_w$ 与 $R_x$ 分别是 W 与 X 的正则项，用来防止过拟合。 $$ \\mathcal{R}_{w}(W)=|W|_{F}^{2}=\\sum_{i=1}^{n}\\left|\\boldsymbol{w}_{i}\\right|^{2}=\\sum_{i=1}^{n} w_{i}^{T} w_{i} $$ $$ \\mathcal{R}{x}(X)=|X|{F}^{2}=\\sum_{t=1}^{T}\\left|\\boldsymbol{x}_{t}\\right|^{2}=\\sum_{t=1}^{T} x_{t}^{T} x_{t} $$ 大多数现有的MF方法采用基于图（这个图指的是同一个特征的时序关系拼接成图，也就是X矩阵的一行）的方法来处理时间依赖性。具体来说，依赖关系由加权相似图描述，并通过拉普拉斯正则项进行约束。 图1：多重时间序列的矩阵分解模型。F捕捉矩阵Y中每个时间序列的特征，X捕捉潜在和时变变量 MF方法可以对缺失数据进行修复，但是对于预测问题则无能为力。此外，由于MF方法并没有考虑数据的时序特性，对上述的交通与天气数据的修复效果并不理想。 本文提出了一个新的时间正则化矩阵分解框架(TRMF)用于高维时间序列分析。 在TRMF中，我们考虑了一种原则性的方法来描述潜在时间嵌入之间的时间依赖性结构{$x_t$}，并设计了一个时间正则化器来将这种时间依赖性结构纳入标准MF公式。 与大多数现有的MF方法不同，我们的TRMF方法支持数据驱动的时间依赖性学习，并为矩阵分解方法带来预测未来值的能力。此外，TRMF方法继承了MF方法的属性，即使在存在许多缺失值的情况下，TRMF也可以轻松处理高维时间序列数据。 作为一个具体的例子，我们展示了一种新的自回归时间正则化器，它鼓励时间嵌入{$x_t$}之间的AR（autoregressive）结构。 我们还将提出的正则化框架与基于图的方法联系起来，其中甚至可以解释负相关。 这种连接不仅有助于更好地理解我们的框架所包含的依赖结构，而且还有助于使用现成的高效求解器(如GRALS)直接求解TRMF。 ","date":"2022-05-13 09:33:30","objectID":"/nips16_trmf/:2:0","tags":["papers"],"title":"NIPS16_TRMF","uri":"/nips16_trmf/"},{"categories":["Graduation project"],"content":"2. 具有时间依赖性的数据的现有矩阵分解方法 标准MF公式对列的排列保持不变（列不管怎么变，权重矩阵保持不变），这不适用于具有时间依赖性的数据。 因此，对于时间依赖性{$x_t$}，大多数现有的时间MF方法都转向基于图的正则化框架，并用图编码时间依赖性。 ","date":"2022-05-13 09:33:30","objectID":"/nips16_trmf/:3:0","tags":["papers"],"title":"NIPS16_TRMF","uri":"/nips16_trmf/"},{"categories":["Graduation project"],"content":"时间依赖性的图正则化 图2：时态依赖的基于图的正则化。 令G是一个时间依赖性{$x_t$}的图，$G_{ts}$是第t个点和第s个点之间的边权重。一种常见的正则化方式如下公式： $$ \\mathcal{R}_{x}(X)=\\mathcal{G}(X \\mid G, \\eta):=\\frac{1}{2} \\sum_{t \\sim s} G_{t s}\\left|\\boldsymbol{x}_{t}-\\boldsymbol{x}_{s}\\right|^{2}+\\frac{\\eta}{2} \\sum_{t}\\left|\\boldsymbol{x}_{t}\\right|^{2}(2) $$ 其中t~s代表了第t个点和第s个点之间的边；第二个正则化项是用来保证强凸性 一个很大的$G_{ts}$可以保证$x_t$和$x_s$在欧几里得距离上很接近 为了保证$\\mathcal{G}(X \\mid G, \\eta)$的凸性，我们让$G_{ts}$≥0 为了将基于图的正则化应用于时间依赖关系上，我们需要通过滞后集L和权值向量w重复地指定各个点之间的依赖模式，以便距离L的所有边t ~ s共享相同的权值 于是上面的公式可以改写成： $$ \\mathcal{G}(X \\mid G, \\eta)=\\frac{1}{2} \\sum_{l \\in \\mathcal{L}} \\sum_{t: t\u003el} w_{l}\\left(\\boldsymbol{x}_{t}-\\boldsymbol{x}_{t-l}\\right)^{2}+\\frac{\\eta}{2} \\sum_{t}\\left|\\boldsymbol{x}_{t}\\right|^{2}(3) $$ 这种直接使用基于图的方法虽然很直观，但有两个问题: 两个时间点之间可能存在负相关依赖关系; 显式的时态依赖结构通常不可用，必须使用者进行推断。 于是，很多现有的这种正则化的模型只能考虑很简单的时间依赖关系（比如滞后集L很小，L={1}），和统一的权重（比如不管两个点之间距离是多少，权重统一设置为1） 这导致现有MF方法对大规模时间序列的预测能力较差。 ","date":"2022-05-13 09:33:30","objectID":"/nips16_trmf/:3:1","tags":["papers"],"title":"NIPS16_TRMF","uri":"/nips16_trmf/"},{"categories":["Graduation project"],"content":"学习时间依赖性的挑战 也许有人会想：那我权重参数w让机器自己学不就好了吗？ 在这种假设下，我们有了以下的优化方程： $$ \\min {F, X, \\boldsymbol{w} \\geq \\mathbf{0}} \\sum{(i, t) \\in \\Omega}\\left(Y_{i t}-\\boldsymbol{f}_{i}^{\\top} \\boldsymbol{x}_{t}\\right)^{2}+\\lambda_{f} \\mathcal{R}_{f}(F)+\\frac{\\lambda_{x}}{2} \\sum_{l \\in \\mathcal{L}} \\sum_{t: t-l\u003e0} w_{l}\\left(\\boldsymbol{x}_{t}-\\boldsymbol{x}_{t-l}\\right)^{2}+\\frac{\\lambda_{x} \\eta}{2} \\sum_{t}\\left|\\boldsymbol{x}_{t}\\right|^{2} (4)$$ 我们不难发现，最终的优化结果，是所有的w都是0，意为没有空间依赖关系的时候，目标函数达到最小值。 为了避免让所有的w都是0，有人想到可以给w的和加上一个限制，比如$\\sum_{l \\in \\mathcal{L}} w_{l}=1$ 同样地，我们不难发现，最终的优化结果是$l^{}=\\arg \\min {l \\in \\mathcal{L}} \\sum{t: t\u003el}\\left|\\boldsymbol{x}{t}-\\boldsymbol{x}{t-l}\\right|^{2}$，对应的wl是1，其他的w是0 因此，通过简单地在MF公式中插入正则化器来自动学习权重并不是一个可行的选择。 ","date":"2022-05-13 09:33:30","objectID":"/nips16_trmf/:3:2","tags":["papers"],"title":"NIPS16_TRMF","uri":"/nips16_trmf/"},{"categories":["Graduation project"],"content":"3. TRMF 为了解决前面提到的限制，本文提出了时间正则化矩阵分解(TRMF)框架，这是一种将时间依赖性纳入矩阵分解模型的新方法。 与前面提到的基于图的方法不同，我们建议使用经过充分研究的时间序列模型来明确地描述{$x_t$}之间的时间依赖性。 $$\\boldsymbol{x}{t}=M{\\Theta}\\left(\\left{\\boldsymbol{x}{t-l}: l \\in \\mathcal{L}\\right}\\right)+\\boldsymbol{\\epsilon}{t} (5)$$ $\\boldsymbol{\\epsilon}_{t}$是一个高斯噪声向量 $M_{\\Theta}$是一个时间序列模型，参数是Θ和滞后集L L是一个包含滞后指标L的集合，表示t和t-l时间点之间的相关性 Θ捕捉时间相关性的权重信息(如AR模型中的转移矩阵) 基于此，我们提出了一个新的正则化项$\\mathcal{T}{\\mathrm{M}}(X \\mid \\Theta)$，这可以鼓励模型依照时间序列$M{\\Theta}$。 我们令： $$ \\mathcal{T}{\\mathrm{M}}(X \\mid \\Theta)=-\\log \\mathbb{P}\\left(\\boldsymbol{x}{1}, \\ldots, \\boldsymbol{x}_{T} \\mid \\Theta\\right) (6) $$ 当θ给定的时候，我们令$\\mathcal{T}_{\\mathrm{M}}(X \\mid \\Theta)$为矩阵分解的一个正则化项；当θ未知的时候，我们令θ为另外一部分参数，并且设计$R_θ$以作为另一个正则化项。 $$ \\min {F, X, \\Theta} \\sum{(i, t) \\in \\Omega}\\left(Y_{i t}-\\boldsymbol{f}_{i}^{\\top} \\boldsymbol{x}_{t}\\right)^{2}+\\lambda_{f} \\mathcal{R}_{f}(F)+\\lambda_{x} \\mathcal{T}_{\\mathrm{M}}(X \\mid \\Theta)+\\lambda_{\\theta} \\mathcal{R}_{\\theta}(\\Theta) (7) $$ 通过交替地优化更新F,X,Θ，可以解决上面的优化方程。 ","date":"2022-05-13 09:33:30","objectID":"/nips16_trmf/:4:0","tags":["papers"],"title":"NIPS16_TRMF","uri":"/nips16_trmf/"},{"categories":["Graduation project"],"content":"TRMF中数据驱动的时间依赖性学习 在TRMF中，当F和X是固定的时候，式（7）可以简化为： $$ \\min {\\Theta} \\lambda{x} \\mathcal{T}{M}(X \\mid \\Theta)+\\lambda{\\theta} \\mathcal{R}_{\\theta}(\\Theta) (8)$$ 其中第一项可以看成：$\\min _{\\Theta} -\\log{P}(X_1,…X_T \\mid \\Theta)$，即$\\max _{\\Theta}{P}(X_1,…X_T \\mid \\Theta)$ 也就是说，后一项可以看成最大后验概率 ","date":"2022-05-13 09:33:30","objectID":"/nips16_trmf/:4:1","tags":["papers"],"title":"NIPS16_TRMF","uri":"/nips16_trmf/"},{"categories":["Graduation project"],"content":"TRMF时间序列分析 我们可以看到，TRMF可以无缝地处理在分析具有时间依赖性的数据时经常遇到的各种任务: 时间序列预测 一旦我们有了潜在的嵌入{$x_t:1,…T$}的$M_{\\Theta}$，我们可以预测未来的嵌入{$x_t:t\u003eT$}，然后使用来预测结果 缺失值补全 我们可以使用$\\boldsymbol{f}{i}^{\\top} \\boldsymbol{x}{t}$来对这些缺失的条目进行插补，就像标准矩阵补全，在推荐系统和传感器网络中很有用。 ","date":"2022-05-13 09:33:30","objectID":"/nips16_trmf/:4:2","tags":["papers"],"title":"NIPS16_TRMF","uri":"/nips16_trmf/"},{"categories":["Graduation project"],"content":"4. 一种新的自回归时间正则化算法 在小节3中，我们大致介绍了TRMF的框架：正则项$\\mathcal{T}{M}(X \\mid \\Theta)$（有时间序列模型$M{\\Theta}$确定） 在这一小节中，我们将介绍一种TRMF框架：自回归模型，参数为滞后集L和权重 我们令xt是以下形式: $$ \\boldsymbol{x}{t}=\\sum{l \\in \\mathcal{L}} W^{(l)} \\boldsymbol{x}{t-l}+\\boldsymbol{\\epsilon}{t} $$ $\\boldsymbol{\\epsilon}_{t}$是一个高斯噪声向量。 为了简化，假设$\\boldsymbol{\\epsilon}{t} \\sim \\mathcal{N}\\left(0, \\sigma^{2} I{k}\\right)$ 于是，时间正则化项$\\mathcal{T}_{M}(X \\mid \\Theta)$可以写成： $$ \\mathcal{T}{\\mathrm{AR}}(X \\mid \\mathcal{L}, \\mathcal{W}, \\eta):=\\frac{1}{2} \\sum{t=m}^{T}\\left|\\boldsymbol{x}{t}-\\sum{l \\in \\mathcal{L}} W^{(l)} \\boldsymbol{x}{t-l}\\right|^{2}+\\frac{\\eta}{2} \\sum{t}\\left|\\boldsymbol{x}_{t}\\right|^{2} (9)$$ 其中：$m := 1 + L, L := max(L)$, and $\\eta \u003e 0$ 由于每个$W^{(l)} \\in R^{k*k}$所以我们有$|\\mathcal{L}| k^{2}$个参数要学习，这可能导致过拟合 为了避免过拟合，同时为了生成更可解释的结果，我们人为定义$W^{(l)} \\in R^{k*k}$为对角矩阵，这可以使得参数量减少至$|\\mathcal{L}| k$ 出于简化的考虑，我们使用W来表示这个k×L的矩阵，其中第l列表示$W^{(l)} \\in R^{k*k}$ 的对角线元素 简化后： $$ \\mathcal{T}{\\mathrm{AR}}(\\overline{\\boldsymbol{x}} \\mid \\mathcal{L}, \\overline{\\boldsymbol{w}}, \\eta)=\\frac{1}{2} \\sum{t=m}^{T}\\left(x_{t}-\\sum_{l \\in \\mathcal{L}} w_{l} x_{t-l}\\right)^{2}+\\frac{\\eta}{2}|\\overline{\\boldsymbol{x}}|^{2} (10)$$ $x_t$表示时刻t的向量。 将式10代入式7，得到式12： $$ \\min {F, X, \\mathcal{W}} \\sum{(i, t) \\in \\Omega}\\left(Y_{i t}-\\boldsymbol{f}_{i}^{\\top} \\boldsymbol{x}_{t}\\right)^{2}+\\lambda_{f} \\mathcal{R}_{f}(F)+\\sum_{r=1}^{k} \\lambda_{x} \\mathcal{T}_{\\mathrm{AR}}\\left(\\overline{\\boldsymbol{x}}_{r} \\mid \\mathcal{L}, \\overline{\\boldsymbol{w}}_{r}, \\eta\\right)+\\lambda_{w} \\mathcal{R}_{w}(\\mathcal{W}) (12)$$ 我们将式（12）命名为TRMF-AR. ","date":"2022-05-13 09:33:30","objectID":"/nips16_trmf/:5:0","tags":["papers"],"title":"NIPS16_TRMF","uri":"/nips16_trmf/"},{"categories":["Graduation project"],"content":"不同时间序列之间的关联性 尽管$W^{(l)} \\in R^{k*k}$是对角阵，但是TRMF还是可以建模不同时间序列（X矩阵不同行之间）的关联性。这个关联性在特征矩阵F中体现。 ","date":"2022-05-13 09:33:30","objectID":"/nips16_trmf/:5:1","tags":["papers"],"title":"NIPS16_TRMF","uri":"/nips16_trmf/"},{"categories":["Graduation project"],"content":"滞后集L的选择 TRMF中L的选择更加灵活。因此，TRMF可以提供重要的优势: 首先，因为不需要指定权重参数W，可以选择更大的L来考虑长期依赖性，这也可以产生更准确和稳健的预测。 其次，L中的时延不需要是连续的，这样就可以很容易地嵌入关于周期性或季节性的领域知识。例如，对于具有一年季节性的每周数据，可以考虑L ={1, 2, 3, 51, 52, 53}。 ","date":"2022-05-13 09:33:30","objectID":"/nips16_trmf/:5:2","tags":["papers"],"title":"NIPS16_TRMF","uri":"/nips16_trmf/"},{"categories":["Graduation project"],"content":"参数优化 式10和式12 ","date":"2022-05-13 09:33:30","objectID":"/nips16_trmf/:5:3","tags":["papers"],"title":"NIPS16_TRMF","uri":"/nips16_trmf/"},{"categories":["Graduation project"],"content":"5. 实验结果 ","date":"2022-05-13 09:33:30","objectID":"/nips16_trmf/:6:0","tags":["papers"],"title":"NIPS16_TRMF","uri":"/nips16_trmf/"},{"categories":["Graduation project"],"content":"数据集 对于synthetic数据集，我们先随机生成一个$F \\in R^{16*4}$，，生成{$x_t$}，它满足AR过程，且滞后集L={1,8}。然后Y通过$\\boldsymbol{y}{t}=F \\boldsymbol{x}{t}+\\boldsymbol{\\epsilon}{t}$ 且 $\\boldsymbol{\\epsilon}{t} \\sim \\mathcal{N}(\\mathbf{0}, 0.1 I)$生成 电力和交通数据集从UCI存储库获得，而Walmart -1和Walmart -2是来自Walmart电子商务的两个专有数据集，其中包含每周的销售信息。由于缺货等原因，missing rate分别为55.3%和49.3%。为了评价预测性能，我们考虑了归一化偏差(ND)和归一化均方根(NRMSE)。 ","date":"2022-05-13 09:33:30","objectID":"/nips16_trmf/:6:1","tags":["papers"],"title":"NIPS16_TRMF","uri":"/nips16_trmf/"},{"categories":["Graduation project"],"content":"实验结果 表3：缺失值插补结果：每种方法的ND/NRMSE。请注意，TRMF 在几乎所有情况下都优于所有竞争方法 ","date":"2022-05-13 09:33:30","objectID":"/nips16_trmf/:6:2","tags":["papers"],"title":"NIPS16_TRMF","uri":"/nips16_trmf/"},{"categories":["School courses"],"content":" 哈工大深圳苏敬勇本科生课程人工智能 参考教材：王万森《人工智能原理及其应用》，电子工业出版社， 2018 人工智能 30%+30%+40% ","date":"2022-02-24 14:06:32","objectID":"/ai_base_01/:0:0","tags":["AI"],"title":"AI_base_01","uri":"/ai_base_01/"},{"categories":["School courses"],"content":"第1章 人工智能概述 ","date":"2022-02-24 14:06:32","objectID":"/ai_base_01/:1:0","tags":["AI"],"title":"AI_base_01","uri":"/ai_base_01/"},{"categories":["School courses"],"content":"定义 自然智能 指人类和一些动物所具有的智力和行为能力 人类的自然智能（简称智能） 指人类在认识客观世界中，由思维过程和脑力活动所表现出的综合能力 定义智能的困难 从结构上，人脑有10^11-12 量级的神经元，是广泛分布、并行的、巨复杂系统 从功能上，人脑具有记忆、思维、观察、分析等能力 有待于人脑奥秘的揭示，进一步认识 智能的不同观点： 思维理论：智能来源于思维活动，智能的核心是思维，人的一切知识都是思维的产物。可望通过对思维规律和思维方法的研究，来揭示智能的本质。 知识阈值理论：智能取决于知识的数量及其可运用程度。一个系统所具有的可运用知识越多，其智能就会越高。 进化理论：是美国MIT的Brooks在对人造机器虫研究的基础上提出来的。智能取决于感知和行为，取决于对外界复杂环境的适应，智能不需要知识、不需要表示、不需要推理，智能可由逐步进化来实现。 人脑智能的层次结构 高层智能：以大脑皮层（抑制中枢）为主，主要完成记忆、思维等活动。 思维理论、知识阈值理论 中层智能：以丘脑（或称间脑，感觉中枢）为主，主要完成感知活动。 进化理论 低层智能：以小脑、脊髓为主，主要完成动作反应活动。 进化理论 智能包含的能力：感知能力、记忆和思维能力、学习和自适应能力、行为能力 人工智能的定义： 人工方法实现的智能 目前的“人工智能”一词是指用计算机模拟实现的智能，同时，人工智能又是一个学科名称。 人造的智能机器或系统 模仿、延伸以及拓展人的智能 典型的4种定义方法：（类人、理性（即以人为中心还是以理性为中心））、（思维、行为） 类人行为方法==图灵测试方法 理性行为方法与理性思维方法的关系： 首先，理性行为和理性思维强调的重点不同。理性思维方法强调的是正确思维，而理性行为方法强调的则是理性行动。 其次，理性行为可以依据理性思维进行。例如，对一些能够通过理性思维做出正确结论的事情，实现理性行为的途径往往是先通过逻辑推理得出该行为能达到的目标和结论，然后再付诸实施。 再其次，理性行为不一定要依据理性思维进行。例如，对有些事情，即使理性思维无法证明哪些行为是正确的，而其它行为是错误的，理性行为也必须有所行动。 人工智能的一般解释： **从能力的角度：人工智能是指用人工的方法在机器（计算机）上实现的智能。**是智能机器所执行的通常与人类智能有关的功能，如判断、推理、证明、识别、感知、理解、设计、思考、规划、学习和问题求解等思维活动。 **从学科的角度：人工智能是一门研究如何构造智能机器或智能系统，去模拟、延伸和扩展人类智能的学科。**是计算机科学中涉及研究、设计和应用智能机器的一个分支。 AI的研究意义： 研究人工智能是当前信息化社会的迫切要求。 智能化也是自动化发展的必然趋势。 探索人类自身智能的奥秘，发现自然智能的渊源。 目标： 远期目标：用自动机重现人类的思维过程和智能行为 近期目标：建造智能计算机代替人类的部分智力劳动 AI是一门新兴的学科，是自然科学与社会科学的交叉学科 ","date":"2022-02-24 14:06:32","objectID":"/ai_base_01/:1:1","tags":["AI"],"title":"AI_base_01","uri":"/ai_base_01/"},{"categories":["School courses"],"content":"发展简史 1956前 孕育期 1970前 形成期 1990前 知识应用期 2000前 学派融合期 兴起期 1956~2010：第一代人工智能：知识驱动（符号+知识） 2010-2020：第二代人工智能：数据驱动（大数据+深度学习） 2020-~：第三代人工智能：数据和知识驱动结合 AI四大要素：知识、数据、算法、算力 ","date":"2022-02-24 14:06:32","objectID":"/ai_base_01/:1:2","tags":["AI"],"title":"AI_base_01","uri":"/ai_base_01/"},{"categories":["School courses"],"content":"研究内容 如何获取知识? 如何将获取的知识以计算机内部代码形式加以合理表示? 如何运用知识进行推理，解决实际问题? ","date":"2022-02-24 14:06:32","objectID":"/ai_base_01/:1:3","tags":["AI"],"title":"AI_base_01","uri":"/ai_base_01/"},{"categories":["School courses"],"content":"研究方法与途径 运用计算机科学的方法（逻辑演绎） 符号主义 运用仿生学的方法（网络连接机制） 联结主义 运用进化论的思想（控制论和机器学习算法） 行为主义 ","date":"2022-02-24 14:06:32","objectID":"/ai_base_01/:1:4","tags":["AI"],"title":"AI_base_01","uri":"/ai_base_01/"},{"categories":["School courses"],"content":"研究领域 机器思维 推理 搜索 机器感知 计算机视觉 模式识别 自然语言处理 机器行为 智能控制/制造 机器学习 符号学习 神经学习 计算智能 神经计算 进化计算 模糊计算 分布智能 智能系统 ","date":"2022-02-24 14:06:32","objectID":"/ai_base_01/:1:5","tags":["AI"],"title":"AI_base_01","uri":"/ai_base_01/"},{"categories":["School courses"],"content":"应用 应用：智能机器人、智能网络、智能游戏…… ","date":"2022-02-24 14:06:32","objectID":"/ai_base_01/:1:6","tags":["AI"],"title":"AI_base_01","uri":"/ai_base_01/"},{"categories":["School courses"],"content":"对人类的影响 对经济、社会、文化都有不少积极影响，但也不能忽视其带来的威胁： 心理上的威胁 技术失控的危险 引发发法律问题 …… ","date":"2022-02-24 14:06:32","objectID":"/ai_base_01/:1:7","tags":["AI"],"title":"AI_base_01","uri":"/ai_base_01/"},{"categories":["School courses"],"content":"第2章 知识表示 ","date":"2022-02-24 14:06:32","objectID":"/ai_base_01/:2:0","tags":["AI"],"title":"AI_base_01","uri":"/ai_base_01/"},{"categories":["School courses"],"content":"知识与知识表示基本概念 知识与知识表示： 知识是人类智能的基础（符号主义学派）。 智能活动过程主要是一个获取知识并运用知识的过程。 人工智能问题的求解也是以知识为基础的，知识的获取、知识的表示和运用知识进行推理是人工智能学科研究的三个主要问题 知识点含义与结构： 费根鲍姆 知识是经过裁剪、塑造、解释和转换的信息。 Bernstein 知识是由特定领域的描述、关系和过程组成的。 Hayes-roth 知识=事实+信念+启发式 知识的层次结构：噪声-\u003e数据-\u003e信息-\u003e知识-\u003e元知识 知识、信息、数据： 数据 是记录信息的符号，是信息的载体和表示。 信息 是对数据的解释，是数据在具体的场合下具体的含义 一般把有关信息关联在一起所形成的信息结构称为知识。知识、信息、数据是3个层次的概念 知识的特性： 相对正确性 不确定性 可表示性 可利用性 知识表示： 面向计算机的知识描述或表达的形式和方法。 知识表示的过程就是把知识编码成某种数据结构的过程 知识表示的要求： 表示能力 可利用性 可组织性 可维护性 可实现性 自然性 可理解性 ","date":"2022-02-24 14:06:32","objectID":"/ai_base_01/:2:1","tags":["AI"],"title":"AI_base_01","uri":"/ai_base_01/"},{"categories":["School courses"],"content":"一阶谓词逻辑表示法 一阶谓词逻辑表示法是一种重要的知识表示方法，它以数理逻辑为基础，是到目前为止 能够表达人类思维活动规律的一种最精确的形式语言。 个体域： 个体变元的变化范围称为个体域/论述域 包揽一切事物的集合称为全总个体域 谓词逻辑中的n元谓词：$P(x_1,x_2…,x_n)$ P：谓词符号（大写字母） $x_n$：参量/项/个体 为了表达个体之间的对应关系，引入n元个体函数，简称函数：$f(x_1,x_2…,x_n)$ 函数符号（小写字母） 个体变元 量词： 全称量词 存在量词 谓词联结符号优先级：非\u003e与\u003e或\u003e蕴含（IF……THEN）\u003e等价 辖域： 紧接于量词之后被量词作用（即说明）的谓词公式称为该量词的辖域。 变元： 指导变元：量词后面的变元称为量词的指导变元； 约束变元：在一个量词的辖域中的与该量词的指导变元相同的变元称为约束变元； 自由变元：其它的变元称为自由变元； 改名规则： 一个变元在一个谓词公式中既可约束出现，又可自由出现，为了避免混淆，通常通过改名规则，使得一个谓词公式中一个变元仅以一种形式出现。 换名规则 在谓词公式中，将某量词辖域中出现的某个约束变元以及对应的指导变元更改为本辖域中没有出现过的个体变元符号，公式其它部分不变，谓词公式的等价性不变。 代替规则 在谓词公式中，将某量词辖域中出现的某个自由变元的所有出现用本辖域中未曾出现过的某个个体变元符号代替，谓词公式的等价性不变 谓词公式表示知识的步骤： 定义谓词及个体，确定每个谓词及个体的确切含义； 根据所要表达的事物或概念，为每个谓词中的变元赋以特定的值； 根据所要表达的知识的语义，用适当的联接符号将各个谓词联接起来，形成谓词公式 谓词逻辑表示法的特点： 优点 ⑴ 严密性。可以保证其演绎推理结果的正确性，可以较精确的表达知识。 ⑵ 自然性。谓词逻辑是一种接近于自然语言的形式语言。 ⑶ 通用性。拥有通用的逻辑演算方法和推理的规则。 ⑷ 易于实现。用它表示的知识易于模块化，便于知识的增删及修改，便于在计算机上实现 局限性 (1)知识表示能力差。不便于表达和加入非确定性、启发性知识等。 (2)组合爆炸。在其推理过程中，随着事实数目的增大及盲目的使用推例规则，有可能形成组合爆炸。 (3)效率低。由于推理是根据形式逻辑进行的，把推理演算与知识含义截然分开，抛弃了表达内容中所含有的语义信息，往往使推理过程太冗长，降低了系统的效率 ","date":"2022-02-24 14:06:32","objectID":"/ai_base_01/:2:2","tags":["AI"],"title":"AI_base_01","uri":"/ai_base_01/"},{"categories":["School courses"],"content":"产生式规则表示法 产生式表示法： 1943年 Post 首先在一种计算形式体系中提出。 形式上很简单，但在一定意义上模仿了人类思考的过程。 60年代开始，成为专家系统基本的知识表示方法 适合表示事实性知识和规则性知识 容易描述事实、规则以及它们的不确定性度 事实的概念 事实是断言一个语言变量的值或断言多个语言变量之间关系的陈述句。 语言变量的值: 例如，“雪是白的” 语言变量之间的关系: 例如，“王峰热爱祖国“ 事实的表示 确定性知识: (对象，属性，值) ， 例如， (snow, color, white) 或(雪，颜色，白)。其中，对象就是语言变量。(关系，对象1，对象2) ， 例如， (love, Wang Feng， country) 或 (热爱，王峰，祖国) 非确定性知识: (对象，属性，值，可信度因子)其中，“可信度因子\"是指该事实为真的相信程度。可用[0，1]之间的一个实数来表示 规则的表示： 规则的产生式表示形式常称为产生式规则，简称产生式或规则。 产生式的基本形式： P-\u003eQ或者IF P THEN Q。其中，P是产生式的前提，也称为前件，它给出了该产生式可否使用的先决条件。Q是一组结论或操作，也称为后件，它指出当P满足时，应该推出的结论或应该执行的动作 产生式系统的基本结构： 综合数据库 存放推理过程的各种当前信息。如：问题的初始状态、输入的事实、中间结论及最终结论 作为推理过程选择可用规则的依据。推理过程中某条规则是否可用，是通过该规则的前提与DB中的已知事实的匹配来确定的。可匹配的规则称为可用规则。利用可用规则进行推理，将会得到一个结论。该结论若不是目标，将作为新的事实放入DB，成为以后推理的已知事实 规则库RB(Rule Base)也称知识库KB(Knowledge Base) (1) 作用：用于存放推理所需要的所有规则，是整个产生式系统的知识集。是产生式系统能够进行推理的根本。 (2) 要求：知识的完整性、一致性、准确性、灵活性和可组织性 控制系统(Control system) 控制系统的主要作用 亦称推理机，用于控制整个产生式系统的运行，决定问题求解过程的推理线路。 控制系统的主要任务 选择匹配：按一定策略从规则库中选择规则与综合数据库中的已知事实进行匹配。匹配是指把所选规则的前提与综合数据库中的已知事实进行比较，若综合数据库中的事实与所选规则前提一致，则称匹配成功，该规则为可用；否则，称匹配失败，该规则不可用。 冲突消解：对匹配成功的规则，按照某种策略从中选出一条规则执行。 执行操作：对所执行的规则，若其后件为一个或多个结论，则把这些结论加入综合 数据库；若其后件为一个或多个操作时，执行这些操作。 终止推理：检查综合数据库中是否包含有目标，若有，则停止推理。 路径解释：在问题求解过程中，记住应用过的规则序列，以便最终能够给出问题的解的路径 规则库\u003c-\u003e控制系统\u003c-\u003e综合数据库 产生式系统的运行过程： 外部输入的初始事实放入综合数据库 从规则库中取一个条规则，将其前提同当前动态数据库中的事实/数据进行模式匹配 判断是否成功 不成功则回到2 成功则执行4 把该规则的结论放入当前动态数据库，或执行规则所规定的动作 产生式系统应用举例： 例1:设有以下两条规则 r 1: IF 动物有羽毛THEN 动物是鸟 r 2: IF 动物是鸟AND 动物善飞THEN 动物是信天翁 其中， r 1和r 2是上述两条规则在动物识别系统中的规则编号。 假设已知有以下事实: 动物有羽毛，动物善飞 求满足以上事实的动物是何种动物。 解: 由于已知事实\"动物有羽毛”，即r 1的前提条件满足，因此r 1可用，承认的r 1结论， 即推出新的事实\"动物是鸟”。此时， r 2的两个前提条件均满足，即 r 2的前提条件满 足，因此r 2可用，承认的r 2结论，即推出新的事实“动物是信天翁”。 求解： (1) 综合数据库： (M, B, Box, On, H) M: 猴子的位置 B： 香蕉的位置 Box: 箱子的位置 On=0: 猴子在地板上 On=1: 猴子在箱子上 H=0: 猴子没有抓到香蕉 H=1: 猴子抓到了香蕉 (2) 初始状态： (a, c, b, 0, 0) (3) 结束状态： （c, c, c, 1, 1）。 (4) 规则集： r1: IF (x, y, z, 0, 0) THEN (w, y, z, 0, 0)（猴子移动） r2: IF (x, y, x, 0, 0) THEN (z, y, z, 0, 0)（猴子推箱子） r3: IF (x, y, x, 0, 0) THEN (x, y, x, 1, 0)（猴子爬箱子） r4: IF (x, y, x, 1, 0) THEN (x, y, x, 0, 0)（猴子下箱子） r5: IF (x, x, x, 1, 0) THEN (x, x, x, 1, 1)（猴子抓香蕉） 其中， x, y, z, w 为变量。 解答： 根据具体问题可将规则具体为： r1: IF (a, c, b, 0, 0) THEN (b, c, b, 0, 0) r2: IF (b, c, b, 0, 0) THEN (c, c, c, 0, 0) r3: IF (b, c, b, 0, 0) THEN (b, c, b, 1, 0) r3: IF (c ,c, c, 0, 0) THEN (c, c, c, 1, 0) r4：IF (b, c, b, 1, 0) THEN (b, c, b, 0, 0) r5: IF (c, c, c, 1, 0) THEN (c, c, c, 1, 1) 在已知事实下，r1àr2àr3àr5,可得到香蕉 例2：传教士与野人问题。N个传教士，N个野人，一条船，可同时乘坐k个人，要求在任何时刻，在河的两岸，传教士和野人同时存在时，传教士的人数不能少于野人的人数。问：如何过河？(以N=3，k=2为例求解。) (1) 综合数据库： (m, c, b) 其中，0≤m≤3，0≤c≤3，b∈{ 0, 1 } (2) 初始状态： (3, 3, 1) (3) 目标状态： (0, 0, 0) (4) 规则集 r1: IF (m, c, 1) THEN (m-1, c, 0) r2: IF (m, c, 1) THEN (m, c-1, 0) r3: IF (m, c, 1) THEN (m-1, c-1, 0) r4: IF (m, c, 1) THEN (m-2, c, 0) r5: IF (m, c, 1) THEN (m, c-2, 0) r6: IF (m, c, 0) THEN (m+1, c, 1) r7: IF (m, c, 0) THEN (m, c+1, 1) r8: IF (m, c, 0) THEN (m+1, c+1, 1) r9: IF (m, c, 0) THEN (m+2, c, 1) r10: IF (m, c, 0) THEN (m, c+2, 1) 解答： 根据具体问题可将规则具体为： r5: IF (3, 3, 1) THEN (3, 1, 0) （船运2个c到右岸） r7: IF (3, 1, 0) THEN (3, 2, 1) （船运1个c到左岸） r5: IF (3 ,2, 1) THEN (3, 0, 0) （船运2个c到右岸） r7: IF (3, 0, 0) THEN (3, 1, 1) （船运1个c到左岸） r4: IF (3, 1, 1) THEN (1, 1, 0) （船运2个m到右岸） r8: IF (1, 1, 0) THEN (2, 2, 1) （船运1个m和1个c到左岸） r4: IF (2, 2, 1) THEN (0, 2, 0) （船运2个m到右岸） r7: IF (0, 2, 0) THEN (0, 3, 1) （船运1个c到左岸） r5: IF (0, 3, 1) THEN (0, 1, 0) （船运2个c到右岸） r7: IF (0, 1, 0) THEN (0, 2, 1) （船运1个c到左岸） r5: IF (0, 2, 1) THEN (0, 0, 0) （船运2个c到右岸） 在已知事实下，r5àr7àr5àr7àr4àr8àr4àr7àr5àr7àr5 ,可顺利过河 产生式系统的特点： 主要优点 自然性: 采用\"如果……，则……“的形式，人类的判断性知识基本一致。 模块性: 规则是规则库中最基本的知识单元，各规则之间只能通过综合数据库发生联系，而不能相互调用，从而增加了规则的模块性。 有效性: 产生式知识表示法既可以表示确定性知识，又可以表示不确定性知识。 主要缺点 效率较低: 各规则之间的联系必须以综合数据库为媒介。并且，其求解过程是一种反复进行的\"匹配一冲突消解一执行\"过程。这样的执行方式将导致执行的低效率。 不便于表示结构性知识: 由于产生式表示中的知识具有一致格式，且规则之间不能相互调用，因此那种具有结构关系或层次关系的知识则很难以自然的方式来表示 ","date":"2022-02-24 14:06:32","objectID":"/ai_base_01/:2:3","tags":["AI"],"title":"AI_base_01","uri":"/ai_base_01/"},{"categories":["School courses"],"content":"语义网络表示法 逻辑和产生式常用于表示有关领域中各个不同状态间的关系。 语义网络和产生式、一阶谓词逻辑有相对应的表示能力。 语义网络： 通过概念及语义关系来表示知识的一种网络图，它是一个带标注的有向图。 图中的各个节点表示各种概念、事物、对象、行为、状态等； 图中的有向弧表示节点间的联系或关系 一般由一些最基本的语义单元组成。这些最基本的语义单元被称为语义基元。可用如下三元组来表示：(节点1，弧，节点2)也可用有向图表示（有向弧） 把多个基本网元用相应的语义联系关联在一起时，就可得到一个语义网络。 语义网络中的节点还可以是一个语义子网络，所以，语义网络实质上是一种多层次的嵌套结构 基本语义关系： 实例关系ISA 体现的是“具体与抽象”的概念，含义为“是一个”，表示一个事物是另一个事物的一个实例。 分类关系AKO 亦称泛化关系，体现的是\"子类与超类\"的概念，含义为\"是一种”，表示一个事物是另一个事物的一种类型 成员关系: A-Member-of 体现的是\"个体与集体\"的关系，含义为\"是一员”，表示一个事物是另一个事物的一个成员。 属性具有继承性 聚类关系： 亦称包含关系。指具有组织或结构特征的\"部分与整体\"之间的关系。常用的包含关系是：Part-of: 含义为\"是一部分”，表示一个事物是另一个事物的一部分。 聚类关系与实例、分类、成员关系的主要区别聚类关系一般不具备属性的继承性。 属性关系 指事物和其属性之间的关系。常用的有:Have: 含义为\"有” ， 表示一个结点具有另一个结点所描述的属性Can: 含义为\"能”、“会”，表示一个结点能做另一个结点的事情 时间关系 指不同事件在其发生时间方面的先后次序关系。常用的时间关系有:Before: 含义为\"在前\"After: 含义为\"在后” 位置关系 指不同事物在位置方面的关系.常用的有: Located-on: 含义为\"在…上面” Located-under : 含义为\"在. . .下面” Located-at: 含义为\"在…” Located-inside : 含义为\"在. . .内” Located-outside : 含义为\"在…外” 相近关系 指不同事物在形状、内容等方面相似或接近。 常用的相近关系有: Similar-to: 含义为\"相似” Near-to: 含义为\"接近” 事物和概念的表示： 表示一元关系 一元关系 指可以用一元谓词P(x)表示的关系。谓词P说明实体的性质、属性等。描述的是一些最简单、最直观的事物或概念，常用:“是”、“有”、“会”、“能\"等语义关系来说明。如，“雪是白的”。 一元关系的描述 应该说，语义网络表示的是二元关系。如何用它来描述一元关系?结点1表示实体，结点2表示实体的性质或属性等， 弧表示语义关系 表示二元关系 二元关系 指可用二元谓词P(x，y)表示的关系。其中， x，y为实体， P为实体之间的关系。 二元关系的表示 单个二元关系可直接用一个基本网元来表示。复杂关系，可通过一些相对独立的二元或一元关系的组合来实现。 表示多元关系 多元关系 可用多元谓词P(x1 , x2, ……)表示的关系。其中， x1 , x2, ……为实体，谓词P说明这些实体之间的关系。 多元关系的表示 用语义网络表示多元关系时，可把它转化为一个或多个二元关系的组合，把这种多元关系表示出来。 情况和动作的表示： 情况的表示： 西蒙提出了增加情况和动作结点的描述方法。 例: 用语义网络表示:“小燕子这只燕子从春天到秋天占有一个巢” 事件和动作的表示 用这种方法表示事件或动作时，需要设立一个事件节点或动作结点。其中，事件节点由一些向外引出的弧来指出事件行为及发出者与接受者。动作结点由一些向外引出的孤来指出动作的主体与客体。 基于语义网络的推理： 语义网络的推理过程主要有两种，一种是继承，另一种是匹配。 继承的概念 是指把对事物的描述从抽象结点传递到实例结点。通过继承可以得到所需结点的一些属性值，它通常是沿着ISA、AKO等继承弧进行的。 继承的一般过程 (1) 建立一个结点表，用来存放待求解结点和所有以ISA 、AKO等继承弧与此结点相连的那些结点。初始情况下，表中只有待求解结点。 (2) 检查表中的第一个结点是否有继承弧。如果有，就把该弧所指的所有结点放入结点表的末尾，记录这些结点的所有属性，并从结点表中删除第一个结点。如果没有继承孤，仅从结点表中删除第一个结点。 (3) 重复(2) ，直到结点表为空。此时，记录下来的所有属性都是待求解结点继承来的属性。 匹配的概念 是指在知识库的语义网络中寻找与待求解问题相符的语义网络模式。 匹配的过程 (1) 根据待求解问题的要求构造一个网络片断，该网络片断中有些结点或孤的标识是空的，称为询问处，它反映的是待求解的问题。 (2) 根据该语义片断到知识库中去寻找所需要的信息。 (3) 当待求解问题的网络片断与知识库中的某语义网络片断相匹配时，则与询问处相匹配的事实就是问题的解 匹配推理示例： 设在语义网络系统的知识库中存在以下事实的语义网络：哈尔滨工业大学是一所学校，位于哈尔滨市，成立于1920年。假若要求解的问题是：哈尔滨工业大学位于哪个城市？如何利用语义网络进行推理求解？ 语义网络表示法的特点： 主要优点: 结构性: 采用把事物的属性以及事物间的各种语义联系显式地表示出来，是一种结构化的知识表示方法。 联想性: 本来是作为人类联想记忆模型提出来的，它着重强调事物间的语义联系，体现了人类的联想思维过程。 自索引性: 把各接点之间的联系以明确、简洁的方式表示出来，通过与某一结点连结的弧可以很容易的找出与该结点有关的信息，而不必查找整个知识库。这种自索引能力有效的避免搜索时所遇到的组合爆炸问题。 主要缺点 非严格性: 没有象谓词那样严格的形式表示体系，一个给定语义网络的含义完全依赖于处理程序对它所进行的解释，通过语义网络所实现的推理不能保证其正确性。 复杂性: 语义网络表示知识的手段是多种多样的，这虽然对其表示带来了灵活性，但同时也由于表示形式的不一致，使得它的处理增加了复杂性 ","date":"2022-02-24 14:06:32","objectID":"/ai_base_01/:2:4","tags":["AI"],"title":"AI_base_01","uri":"/ai_base_01/"},{"categories":["School courses"],"content":"框架表示法 框架表示法概述： 1975年，Minsky提出了框架理论。他根据人们在理解情景、故事时提出的心理学模型，认为人的知识以框架结构存在人脑中。 认为人们对现实世界中各种事物的认识都是以一种类似于框架的结构存储在记忆中的，当遇到一个新事物时，就从记忆中找出一个合适的框架，并根据新的情况对其细节加以修改、补充，从而形成对这个新事物的认识。例如，对饭店、教室等的认识。 框架: 是人们认识事物的一种通用的数据结构形式。即当新情况发生时，人们只要把新的数据加入到该通用数据结构中，便可形成一个具体的实体(类)，这样的通用数据结构就称为框架。 实例框架: 对于一个框架，当人们才把观察或认识到的具体细节填入后，就得到了该框架的一个具体实例，框架的这种具体实例被称为实例框架。 框架系统: 在框架理论中，框架是知识的基本单位，把一组有关的框架连结起来使可形成一个框架系统。 框架系统推理: 由框架之间的协调来完成。 框架组成： 一个“框架”由若干个“槽”组成，每个“槽”又划分为若干个“侧面”。一个“槽”描述对象的一个方面属性；一个“侧面”描述相应属性的一个方面。由框架名、槽名、侧面、值组成 例：一个直接描述硕士生有关情况的框架 Frame \u003cMASTER\u003e Name: Unit (Last-name, First-name) Sex: Area (male, female) Default: male Age: Unit (Years) Major: Unit (Major) Field: Unit (Field) Advisor: Unit (Last-name, First-name) Project: Area (National, Provincial, Other) Default: National Paper: Area (SCI, EI, Core, General) Default: Core Address: \u003c S-Address\u003e Telephone: Home Unit (Number) Mobile Unit (Number) 对那些结构比较复杂的知识，往往需要用多个相互联系的框架来表示。例如，对前面硕士生框架“MASTER\"可分为:“Student\"框架，描述所有学生的共性，上层框架。“Master\"框架，描述硕士生的个性，子框架，继承\"Student\"框架的属性 学生框架 Frame \u003cStudent\u003e Name: Unit (Last-name, First-name) Sex: Area (male, female) Default: male //缺省 Age: Unit (Years) If-Needed: Ask-Age //询问赋值 Address: \u003c S-Address\u003e Telephone: Home Unit (Number) Mobile Unit (Number) If-Needed: Ask-Telephone //询问赋值 硕士生框架 Frame \u003cMaster\u003e AKO: \u003cStudent\u003e //预定义槽名 Major: Unit (Major) //专业 If-Needed: Ask - Major //询问赋值 If-Added: Check-Major //后继处理 Field: Unit (Field) //方向 If-Needed : Ask - Field //询问赋值 Advisor: Unit (Last-name, First-name) //导师 If-Needed : Ask -Visor //询问赋值 Project: Area (National, Provincial, Other) //项目 Default: National //缺省 Paper: Area (SCI, EI, Core, General) //论文 Default: Core //缺省 这里，用到了一个系统预定义槽名AKO ，其含义为\"是一种”。 当AKO作为下层框架的糟名时，其槽值为上层框架的框架名，表示该下层框架所描述的事物比其上层框架更具体。并且，由AKO所联系的框架之间具有属性的继承关系 实例框架： 例如，有杨叶和柳青2个硕士生， 杨叶，女，计算机专业，参加了导师林海的网络智能研究方向的省部级项目； 柳青，22岁，计算机专业，导师是林海，论文被EI收录。 硕士生-1框架: Frame \u003cMaster-1\u003e ISA: \u003cMaster\u003e //是一个 Name: Yang, Ye Sex: female Major: Computer Field: Web-Intelligence //方向Web智能 Advisor: Lin Hai //导师林海 Project: Provincial //项目省部级 硕士生-2框架: Frame \u003cMaster-2\u003e ISA: \u003cMaster\u003e Name: Liu, Qing Age: 22 Major: Computer Advisor: Lin Hai Paper: EI //论文EI收录 其中用到了系统预定以槽名ISA，即Master-1和Master-2是2个具体的Master 框架系统： 基本结构 框架系统由框架之间的横向或纵向联系构成。 纵向联系 是指那种具有继承关系的上下层框架之间的联系。如:学生可按照接受教育的层次分为本、硕和博。每类学生又可按照所学专业的不同划分。纵向联系通过预定义槽名AKO和ISA等来实现。 横向联系 是指那种以另外一个框架名作为一个槽的槽值或侧面值所建立起来的框架之间的联系。如Student框架与S-Address框架之间就是一种横向联系。 特性继承 特性继承过程 通过ISA 、AKO链来实现。 当需要查询某一事物的某个属性，且描述该事物的框架未提供其属性值时，系统就沿ISA和AKO链追溯到具有相同槽的类或超类框架。 如果该槽提供有Default侧面值，就继承该默认值作为查询结果返回。 如果该槽提供有If-Needed侧面供继承，则执行If-Needed操作，去产生一个值作为查询结果。 如果对某个事物的某一属性进行了赋值或修改操作，则系统会自动沿ISA和AKO链追溯到具有相应的类或超类框架，去执行If-Added操作，作相应的后继处理。 If-Needed与If-Added过程的区别 它们的主要区别在于激活时机和操作目的不同。 If-Needed操作是在系统试图查询某个事物框架中未记载的属性值时激活，并根据查询需求，被动地即时产生所需要的属性值; If-Added操作是在系统对某个框架的属性作赋值或修改工作后激活，目的在于通过这些后继处理，主动做好配套操作，以消除可能存在的不一致。 特性继承的例子 如前面的学生框架 若要查询Master-l 的Sex , 则可直接回答; 但要查询Master-2的Sex , 则需要沿ISA链和AKO链到Student框架取其默认佳male. 若要查询Master-2的Field，需要沿ISA链到Master框架，执行Field槽If-Needed侧面的Ask-Field操作, 即时产生一个值,假设产生的值是Data-Mining, 则表示Master-2的研究方向为数据挖掘。 如果要修改Master-2 的Major，需要沿ISA链到Master框架, 执行Major槽If-Added侧面的Check-Major操作，对Field, Advisor进行修改, 以保持知识的一致性 匹配和填槽 框架的匹配实际上是通过对相应槽的槽名和槽值逐个进行比较，并利用继承关系来实现的。 例如，假设前面讨论的学生框架系统已建立在知识库中，若要求从知识库中找出一个满足如下条件的硕士生:male, Age\u003c25 , Major为Computer ， Project为National 把这些条件用框架表示出来，就可得到如下的初始问题框架 Frame \u003cMaster-x\u003e Name: Sex: male Age: Years \u003c25 Major: Computer Project: National 用此框架和知识库中的框架匹配，显然“Master -2”框架可以匹配。因为Age、Major槽都符合要求, Sex 槽和Project槽虽然没有给出，但由继承性可知它们分别取默认值male和National, 完全符合初始问题框架Master-x的要求，所以要找的学生有可能是Liu Qing。 例子：请用框架表示这一知识：范伟，男，30岁, 1996年10月到2012年8月间在计算机学院任讲师。 Frame：〈Teacher-1〉 Name: Fan，Wei Sex: Male Age: 30 Job： Lecturer Work-time: Start: 1996-10 End: 2012-08 Department： Computer Science 框架表示法的特征： 主要优点: 结构性:最突出特点是善于表示结构性知识，它能够把知识的内部结构关系以及知识问的特殊联系表示出来。 深层性:框架表示法不仅可以从多个方面、多重属性表示知识，而且还可以通过ISA 、AKO等槽以嵌套结构分层地对知识进行表示，因此能用来表达事物间复杂的深层联系。 继承性:在框架系统中，下层框架可以继承上层框架的槽值，也可以进行补充和修改，这样既减少知识冗余，又较好地保证了知识的一致性。 自然性:框架能把与某个实体或实体集相关特性都集中在一起，从而高度模拟了人脑对实体多方面、多层次的存储结构，直观，自然，易于理解。 主要缺点 缺乏框架的形式理论:","date":"2022-02-24 14:06:32","objectID":"/ai_base_01/:2:5","tags":["AI"],"title":"AI_base_01","uri":"/ai_base_01/"},{"categories":["School courses"],"content":"第3章 确定性推理 人工智能学科： 知识获取 知识表示 知识推理 确定性推理 不确定性推理 ","date":"2022-02-24 14:06:32","objectID":"/ai_base_01/:3:0","tags":["AI"],"title":"AI_base_01","uri":"/ai_base_01/"},{"categories":["School courses"],"content":"概述 推理就是按照某种策略从已有事实和知识推出结论的过程。 推理分类： 按推理的逻辑基础分类： 演绎推理 从已知的一般性知识出发，推理出适合于某种个别情况的结论过程。即从一般到个别的推理。常用形式：三段论法(大前提、小前提、结论) 大前提：是已知的一般性知识或推理过程得到的判断； 小前提：是关于某种具体情况或某个具体实例的判断； 结论：是由大前提推出的，并且适合于小前提的判断。 归纳推理 从大量特殊事例出发，归纳出一般性结论的推理过程。即从个别到一般的推理过程。 完全归纳推理 不完全归纳推理 枚举归纳推理 类比归纳推理 按所用知识的确定性分类 确定性推理 不确定性推理 推理时所用的知识和证据不都是确定的，推出的结论也不确定的 按推理中所用知识是否具有启发性分类 启发式推理 推理过程中应用与问题有关的启发性知识，即解决问题的的策略、技巧及经验，以加快推理过程，提高搜索效率。 非启发式推理 在推理过程中，不运用启发性知识，只按照一般的控制逻辑进行推理。这种方法缺乏对求解问题的针对性，所以推理效率较低，容易出现“组合爆炸”问题 推理过程不仅依赖于所用的推理方法，同时也依赖于推理的控制策略。 推理的控制策略是指如何使用领域知识使推理过程尽快达到目标的策略 控制策略的分类： 推理策略 推理方向控制策略 用于确定推理的控制方向，可分为正向推理、逆向推理、混合推理及双向推理。 求解策略 是指仅求一个解，还是求所有解或最优解等。 限制策略 是指对推理的深度、宽度、时间、空间等进行的限制。 冲突消解策略 是指当推理过程有多条知识可用时，如何从这多条可用知识中选出一条最佳知识用于推理的策略。 搜索策略 主要解决推理线路、推理效果、推理效率等问题。本章主要讨论推理策略，至于搜索策略见第四章。 ","date":"2022-02-24 14:06:32","objectID":"/ai_base_01/:3:1","tags":["AI"],"title":"AI_base_01","uri":"/ai_base_01/"},{"categories":["School courses"],"content":"产生式系统 基本结构 综合数据库： 存放推理过程的各种当前信息 作为推理过程选择可用规则的依据 存放推理所需所有规则的规则库RB(Rule Base)也称知识库KB(Knowledge Base) 控制系统： 控制系统的主要作用 亦称推理机，用于控制整个产生式系统的运行，决定问题求解过程的推理线路。 控制系统的主要任务 选择匹配：按一定策略从规则库种选择规则与综合数据库中的已知事实进行匹配。匹配是指把所选规则的前提与综合数据库中的已知事实进行比较，若事实库中存的事实与所选规则前提一致，则称匹配成功，该规则为可用；否则，称匹配失败，该规则不可用。 冲突消解：对匹配成功的规则，按照某种策略从中选出一条规则执行。 执行操作：对所执行的规则，若其后件为一个或多个结论，则把这些结论加入综合数据库；若其后件为一个或多个操作时，执行这些操作。 终止推理：检查综合数据库中是否包含有目标，若有，则停止推理。 路径解释：在问题求解过程中，记住应用过的规则序列，以便最终能够给出问题的解的路径 推理过程 正向推理： 从已知事实出发、正向使用规则，亦称为数据驱动推理或前向链推理 逆向推理： 从某个假设目标出发，逆向使用规则，亦称为目标驱动推理或逆向链推理 产生式系统的示例：略 推理过程的相关说明： 正向推理的特性 正向推理的主要优点是比较直观，主要缺点是推理无明确的目标，求解问题时可能会执行许多与解无关的操作，导致推理效率较低。 逆向推理的特性 逆向推理的主要优点是不必寻找和使用那些与假设目标无关的信息和规则，推理过程的目标明确，主要缺点是当用户对解的情况认识不清时，由系统自主选择假设目标的盲目性比较大，若选择不好，会影响系统效率。 双向推理方法 为互相取长补短，可以把正向和逆向结合起来使用，采用双向推理的方式。双向推理有多种不同的实现方法，可以采用先正向后逆向，也可以采用先逆向后正向，还可以采用随机选择正向和逆向的推理方法。 推理过程的不唯一性 从前面的推理算法可以看出，无论是正向推理还是逆向推理，当可用规则集中有多条规则可用时，不同的冲突消解策略将导致不同的规则使用顺序， 因此其推理过程是不唯一的。 ","date":"2022-02-24 14:06:32","objectID":"/ai_base_01/:3:2","tags":["AI"],"title":"AI_base_01","uri":"/ai_base_01/"},{"categories":["School courses"],"content":"自然演绎推理 一阶谓词逻辑基础： 谓词公式的永真性：如果谓词公式P对非空个体域D上的任一解释都取得真值T，则称P在D上是永真的；如果P在任何非空个体域上都是永真的，则称P是永真。 谓词公式的可满足性：对于谓词公式P，如果至少存在D上的一个解释，使公式P在此解释下的真值为T，则称公式P在D上是可满足的。 谓词公式的永假性：如果谓词公式P对非空个体域D上的任一解释都取真值F，则称P在D上是永假的；如果P在任何非空个体域上均是永假的，则称P永假。 谓词公式的等价性：设P与Q是D上的两个谓词公式，若对D上的任意解释，P与Q都有相同的真值，则称P与Q在D上是等价的。如果D是任意非空个体域，则称P与Q是等价的，记作P ⇔ Q。 永真蕴含式：对谓词公式P和Q，如果P→Q永真，则称P 永真蕴含Q，且称Q为P 的逻辑结论，P为Q的前提，记作P ⇒Q。 常用的等价式： 常用的永真蕴含式： 置换和合一： 在不同谓词公式中，往往会出现谓词名相同但其个体不同的情况，此时推理过程是不能直接进行匹配的，需要先进行置换 要使用假言推理，首先需要找到项a对变元x的置换，使W(a)与W (x)一致。这种寻找项对变元的置换，使谓词一致的过程叫做合一的过程。合一可理解为是寻找相对应变量的置换，使两个或多个谓词公式一致。 例如，{a/x, c/y, f(b)/z} 是一个置换。但{g(z)/x, f(x)/z}不是一个置换。原因是它在x与z之间出现了循环置换现象。即当用g(z)置换x, 用f(x)置换z时，既没有消去x，也没有消去z。若改为{g(a)/x, f(x)/z}即可，原因是用g(a)置换x ，用f(x)置换z ，若再用一次置换，用g(a)置换x, 最终原x和z被g(a)和f(g(a))置换,则经过有限次置换消去了x和z 。通常，置换是用希腊字母θ、σ、α、λ等来表示的 设θ={t1 /x1, t2 /x2 ,…, tn /xn }是一个置换，F是一个谓词公式，把公式F中出现的所有xi 换成ti (i=1, 2, …, n)，得到一个新的公式G，称G为F在置换θ 下的例示，记作$G=F_θ$ 合一： 最一般合一： 设σ是谓词公式集F 的一个合一置换，如果对F的任意一个合一置换θ都存在一个置换λ，使得 θ= σ· λ，则称σ是一个最一般(或最简单)合一(most general unifier，简记为mgu)置换 一个公式集的最一般合一是唯一的 最一般合一置换的求取算法：略 ","date":"2022-02-24 14:06:32","objectID":"/ai_base_01/:3:3","tags":["AI"],"title":"AI_base_01","uri":"/ai_base_01/"},{"categories":["School courses"],"content":"归结演绎推理 谓词公式的范式 子句集及其应用 鲁滨逊归结原理 归结演绎推理的方法 归结演绎推理的归结策略 用归结反演求取问题的答案 ","date":"2022-02-24 14:06:32","objectID":"/ai_base_01/:3:4","tags":["AI"],"title":"AI_base_01","uri":"/ai_base_01/"},{"categories":["School courses"],"content":"第4章 搜索策略 搜索策略： 搜索基本概念 搜索的分类 按是否使用启发式信息： 盲目搜索：按预定的控制策略进行搜索，在搜索过程中获得的中间信息并不改变控制策略。 启发式搜索：在搜索中加入了与问题有关的启发性信息，用于指导搜索朝着最有希望的方向前进，加速问题的求解过程并找到最优解。 按问题的表示方式： 状态空间搜索：用状态空间法来求解问题所进行的搜索 与或树搜索：用问题归约法来求解问题时所进行的搜索 状态空间搜索 盲目搜索 深度优先搜索 广度优先搜索 代价一致搜索 启发式搜索 A算法 A*算法 与或图搜索 博弈树搜索 极大极小分析法 a - b 剪枝技术 ","date":"2022-02-24 14:06:32","objectID":"/ai_base_01/:4:0","tags":["AI"],"title":"AI_base_01","uri":"/ai_base_01/"},{"categories":["School courses"],"content":"第5章 不确定性推理 ","date":"2022-02-24 14:06:32","objectID":"/ai_base_01/:5:0","tags":["AI"],"title":"AI_base_01","uri":"/ai_base_01/"},{"categories":["School courses"],"content":"概述 不确定性推理的含义 不确定性推理的基本问题： 不确定性的表示 不确定性的匹配 组合证据不确定性的计算 不确定性的更新 不确定性结论的合成 不确定性推理类型： 模型方法 数值方法 概率统计方法 绝对概率方法 贝叶斯方法 证据理论方法 HMM方法 可信度方法 模糊推理方法 粗糙集方法 非数值方法 发送率计算 控制方法 相关性制导回溯、机缘控制、启发式搜索等 ","date":"2022-02-24 14:06:32","objectID":"/ai_base_01/:5:1","tags":["AI"],"title":"AI_base_01","uri":"/ai_base_01/"},{"categories":["School courses"],"content":"可信度推理 知识不确定性的表示 证据不确定性的表示 组合证据不确定性的算法 不确定性的更新 不确定性结论的合成 ","date":"2022-02-24 14:06:32","objectID":"/ai_base_01/:5:2","tags":["AI"],"title":"AI_base_01","uri":"/ai_base_01/"},{"categories":["School courses"],"content":"主观Bayes推理 Bayes公式 知识不确定性的表示 证据不确定性的表示 组合证据不确定性的算法 不确定性的更新 不确定性结论的合成 ","date":"2022-02-24 14:06:32","objectID":"/ai_base_01/:5:3","tags":["AI"],"title":"AI_base_01","uri":"/ai_base_01/"},{"categories":["School courses"],"content":"证据理论推理 证据理论 证据理论的形式化描述 证据理论的推理模型 证据理论推理实例 ","date":"2022-02-24 14:06:32","objectID":"/ai_base_01/:5:4","tags":["AI"],"title":"AI_base_01","uri":"/ai_base_01/"},{"categories":["School courses"],"content":"模糊推理 模糊集及其运算 模糊关系及其运算 模糊知识表示 模糊概念的匹配 模糊推理的方法 ","date":"2022-02-24 14:06:32","objectID":"/ai_base_01/:5:5","tags":["AI"],"title":"AI_base_01","uri":"/ai_base_01/"},{"categories":["School courses"],"content":"Bayes网络 贝叶斯网络定义 贝叶斯网络的全联合概率分布表示 贝叶斯网络的条件独立关系 贝叶斯网络的构造 贝叶斯网络的精确推理 变量消元 贝叶斯网络的近似推理 马尔科夫链蒙特卡洛（MCMC）方法 ","date":"2022-02-24 14:06:32","objectID":"/ai_base_01/:5:6","tags":["AI"],"title":"AI_base_01","uri":"/ai_base_01/"},{"categories":["School courses"],"content":"机器学习 ","date":"2022-02-24 14:06:32","objectID":"/ai_base_01/:6:0","tags":["AI"],"title":"AI_base_01","uri":"/ai_base_01/"},{"categories":["School courses"],"content":"概述 ","date":"2022-02-24 14:06:32","objectID":"/ai_base_01/:6:1","tags":["AI"],"title":"AI_base_01","uri":"/ai_base_01/"},{"categories":["School courses"],"content":"线性回归 ","date":"2022-02-24 14:06:32","objectID":"/ai_base_01/:6:2","tags":["AI"],"title":"AI_base_01","uri":"/ai_base_01/"},{"categories":["School courses"],"content":"决策树学习 ","date":"2022-02-24 14:06:32","objectID":"/ai_base_01/:6:3","tags":["AI"],"title":"AI_base_01","uri":"/ai_base_01/"},{"categories":["School courses"],"content":"支持向量机 ","date":"2022-02-24 14:06:32","objectID":"/ai_base_01/:6:4","tags":["AI"],"title":"AI_base_01","uri":"/ai_base_01/"},{"categories":["School courses"],"content":"集成学习 ","date":"2022-02-24 14:06:32","objectID":"/ai_base_01/:6:5","tags":["AI"],"title":"AI_base_01","uri":"/ai_base_01/"},{"categories":["School courses"],"content":"深度学习 ","date":"2022-02-24 14:06:32","objectID":"/ai_base_01/:7:0","tags":["AI"],"title":"AI_base_01","uri":"/ai_base_01/"},{"categories":["School courses"],"content":"概述 ","date":"2022-02-24 14:06:32","objectID":"/ai_base_01/:7:1","tags":["AI"],"title":"AI_base_01","uri":"/ai_base_01/"},{"categories":["School courses"],"content":"前馈神经网络 ","date":"2022-02-24 14:06:32","objectID":"/ai_base_01/:7:2","tags":["AI"],"title":"AI_base_01","uri":"/ai_base_01/"},{"categories":["School courses"],"content":"几种常见的神经网络 ","date":"2022-02-24 14:06:32","objectID":"/ai_base_01/:7:3","tags":["AI"],"title":"AI_base_01","uri":"/ai_base_01/"},{"categories":["Coding"],"content":"查找算法 散列查找：也称哈希查找，有拉链法查找，也有线性探测法查找，拉链法使用数组链表结构，线性探测法使用数组。 树查找：有搜索二叉树，平衡查找树如：红黑树，B树，AVL树，B+等，使用链表树结构 ","date":"2022-02-20 19:52:33","objectID":"/algorithm_find/:0:0","tags":["data structure"],"title":"Algorithm_find","uri":"/algorithm_find/"},{"categories":["Coding"],"content":"哈希表：散列查找 线性查找：在链表上线性查找键更新值。 散列查找： 空间换时间的查找算法 依赖数据结构HashTable（Hash: 指压缩映射，它将一个比较大的域空间映射到一个比较小的域空间） 关于线性探测法与拉链法在go语法里map实现原理时有讲解。（go_base_01） 哈希算法非常多，随机分布性不同，当然，让得到的哈希值越均匀随机分布越好，拉链法形成的链表不会很长。 最好时间复杂度能达到： O(1) ，最坏情况下退化到查找链表： O(n) 。均匀性很好的哈希算法以及合适空间大小的数组，在很大概率避免了最坏情况。 ","date":"2022-02-20 19:52:33","objectID":"/algorithm_find/:1:0","tags":["data structure"],"title":"Algorithm_find","uri":"/algorithm_find/"},{"categories":["Coding"],"content":"二叉查找树 又称为二叉搜索树，二叉排序树。 二叉查找树不保证是一个平衡的二叉树，最坏情况下二叉查找树会退化成一个链表。 通用形式的二叉查找树实现甚少使用，大部分程序都使用了AVL树或红黑树。 二叉查找树中序遍历即可实现排序。 查找，添加，删除元素的时间复杂度取决于树的高度。查找，添加和删除的时间复杂度范围为 log(n)~n 。 AVL树和红黑树都是相对平衡的二叉查找树，因为特殊的旋转平衡操作，树的高度被大大压低。它们查找效率较高，添加，删除，查找操作的平均时间复杂度都为 log(n) 。 ","date":"2022-02-20 19:52:33","objectID":"/algorithm_find/:2:0","tags":["data structure"],"title":"Algorithm_find","uri":"/algorithm_find/"},{"categories":["Coding"],"content":"AVL树（平衡二叉搜索树） Adelson-Velsky and Landis。 添加和删除元素时的调整操作比较关键且重要。 // AVL树 type AVLTree struct { Root *AVLTreeNode // 树根节点 } // AVL节点 type AVLTreeNode struct { Value int64 // 值 Times int64 // 值出现的次数 Height int64 // 该节点作为树根节点，树的高度，方便计算平衡因子 Left *AVLTreeNode // 左子树 Right *AVLTreeNode // 右字树 } // 初始化一个AVL树 func NewAVLTree() *AVLTree { return new(AVLTree) } AVL树添加元素 插入节点后，需要满足所有节点的平衡因子在 [-1，0，1] 范围内，如果不在，需要进行旋转调整。旋转有四种情况： 在右子树上插上右儿子导致失衡，左旋，转一次。 在左子树上插上左儿子导致失衡，右旋，转一次。 在左子树上插上右儿子导致失衡，先左后右旋，转两次。 在右子树上插上左儿子导致失衡，先右后左旋，转两次。 右图来自维基百科： // 单右旋操作，看图说话 func RightRotation(Root *AVLTreeNode) *AVLTreeNode { // 只有Pivot和B，Root位置变了 Pivot := Root.Left B := Pivot.Right Pivot.Right = Root Root.Left = B // 只有Root和Pivot变化了高度 Root.UpdateHeight() Pivot.UpdateHeight() return Pivot } // 单左旋操作，看图说话 func LeftRotation(Root *AVLTreeNode) *AVLTreeNode { // 只有Pivot和B，Root位置变了 Pivot := Root.Right B := Pivot.Left Pivot.Left = Root Root.Right = B // 只有Root和Pivot变化了高度 Root.UpdateHeight() Pivot.UpdateHeight() return Pivot } 复用上面代码 // 先左后右旋操作，看图说话 func LeftRightRotation(node *AVLTreeNode) *AVLTreeNode { node.Left = LeftRotation(node.Left) return RightRotation(node) } // 先右后左旋操作，看图说话 func RightLeftRotation(node *AVLTreeNode) *AVLTreeNode { node.Right = RightRotation(node.Right) return LeftRotation(node) } 完成旋转操作，可以添加元素了~ // 添加元素 func (tree *AVLTree) Add(value int64) { // 往树根添加元素，会返回新的树根 tree.Root = tree.Root.Add(value) } func (node *AVLTreeNode) Add(value int64) *AVLTreeNode { // 添加值到根节点node，如果node为空，那么让值成为新的根节点，树的高度为1 if node == nil { return \u0026AVLTreeNode{Value: value, Height: 1} } // 如果值重复，什么都不用做，直接更新次数 if node.Value == value { node.Times = node.Times + 1 return node } // 辅助变量 var newTreeNode *AVLTreeNode if value \u003e node.Value { // 插入的值大于节点值，要从右子树继续插入 node.Right = node.Right.Add(value) // 平衡因子，插入右子树后，要确保树根左子树的高度不能比右子树低一层。 factor := node.BalanceFactor() // 右子树的高度变高了，导致左子树-右子树的高度从-1变成了-2。 if factor == -2 { if value \u003e node.Right.Value { // 表示在右子树上插上右儿子导致失衡，需要单左旋： newTreeNode = LeftRotation(node) } else { //表示在右子树上插上左儿子导致失衡，先右后左旋： newTreeNode = RightLeftRotation(node) } } } else { // 插入的值小于节点值，要从左子树继续插入 node.Left = node.Left.Add(value) // 平衡因子，插入左子树后，要确保树根左子树的高度不能比右子树高一层。 factor := node.BalanceFactor() // 左子树的高度变高了，导致左子树-右子树的高度从1变成了2。 if factor == 2 { if value \u003c node.Left.Value { // 表示在左子树上插上左儿子导致失衡，需要单右旋： newTreeNode = RightRotation(node) } else { //表示在左子树上插上右儿子导致失衡，先左后右旋： newTreeNode = LeftRightRotation(node) } } } if newTreeNode == nil { // 表示什么旋转都没有，根节点没变，直接刷新树高度 node.UpdateHeight() return node } else { // 旋转了，树根节点变了，需要刷新新的树根高度 newTreeNode.UpdateHeight() return newTreeNode } } 由于树的高度最高为 1.44log(n)，查找元素插入位置，最坏次数为 1.44log(n) 次。逐层更新子树高度并判断平衡是否被破坏，最坏需要 1.44log(n) 次，因此可以得知添加元素最坏时间复杂度为：2.88log(n) 当插入节点后，某子树不平衡时最多旋转 2次，也就是双旋该子树即可恢复平衡，该调整为局部特征，调整完后其父层不再需要旋转。也就是说，插入操作最坏旋转两次即可 AVL树查找元素与普通二叉查找树一致。 删除元素有四种情况： 删除的节点是叶子节点，没有儿子，直接删除后看离它最近的父亲节点是否失衡，做调整操作。 删除的节点下有两个子树，选择高度更高的子树下的节点来替换被删除的节点，如果左子树更高，选择左子树中最大的节点，也就是左子树最右边的叶子节点，如果右子树更高，选择右子树中最小的节点，也就是右子树最左边的叶子节点。最后，删除这个叶子节点，也就是变成情况1。 删除的节点只有左子树，可以知道左子树其实就只有一个节点，被删除节点本身（假设左子树多于2个节点，那么高度差就等于2了，不符合AVL树定义），将左节点替换被删除的节点，最后删除这个左节点，变成情况1。 删除的节点只有右子树，可以知道右子树其实就只有一个节点，被删除节点本身（假设右子树多于2个节点，那么高度差就等于2了，不符合AVL树定义），将右节点替换被删除的节点，最后删除这个右节点，变成情况1。 后面三种情况最后都变成情况1，就是将删除的节点变成叶子节点，然后可以直接删除该叶子节点，然后看其最近的父亲节点是否失衡，失衡时对树进行平衡。 实现代码： func (node *AVLTreeNode) Delete(value int64) *AVLTreeNode { if node == nil { // 如果是空树，直接返回 return nil } if value \u003c node.Value { // 从左子树开始删除 node.Left = node.Left.Delete(value) // 删除后要更新该子树高度 node.Left.UpdateHeight() } else if value \u003e node.Value { // 从右子树开始删除 node.Right = node.Right.Delete(value) // 删除后要更新该子树高度 node.Right.UpdateHeight() } else { // 找到该值对应的节点 // 该节点没有左右子树 // 第一种情况，删除的节点没有儿子，直接删除即可。 if node.Left == nil \u0026\u0026 node.Right == nil { return nil // 直接返回nil，表示直接该值删除 } // 该节点有两棵子树，选择更高的哪个来替换 // 第二种情况，删除的节点下有两个子树，选择高度更高的子树下的节点来替换被删除的节点，如果左子树更高，选择左子树中最大的节点，也就是左子树最右边的叶子节点，如果右子树更高，选择右子树中最小的节点，也就是右子树最左边的叶子节点。最后，删除这个叶子节点。 if node.Left != nil \u0026\u0026 node.Right != nil { // 左子树更高，拿左子树中最大值的节点替换 if node.Left.Height \u003e node.Right.Height { maxNode := node.","date":"2022-02-20 19:52:33","objectID":"/algorithm_find/:3:0","tags":["data structure"],"title":"Algorithm_find","uri":"/algorithm_find/"},{"categories":["Coding"],"content":"2-3树和左倾红黑树 左倾红黑树比普通红黑树实现更简单。 红黑树是一种近似平衡的二叉查找树，从 2-3 树或 2-3-4 树衍生而来。通过对二叉树节点进行染色，染色为红或黑节点，来模仿 2-3 树或 2-3-4 树的3节点和4节点，从而让树的高度减小。2-3-4 树对照实现的红黑树是普通的红黑树，而 2-3 树对照实现的红黑树是一种变种，称为左倾红黑树。 2-3树：它不是一棵二叉树，是一棵三叉树。具有以下特征： 内部节点要么有1个数据元素和2个孩子，要么有2个数据元素和3个孩子，叶子节点没有孩子，但有1或2个数据元素。 所有叶子节点到根节点的长度一致。这个特征保证了完全平衡，非常完美的平衡。 每个节点的数据元素保持从小到大排序，两个数据元素之间的子树的所有值大小介于两个数据元素之间。 2-3树插入元素： 先二分查找到要插入的位置 插入元素到一个2节点，直接插入即可，这样节点变成3节点。 插入元素到一个3节点，该3节点的父亲是一个2节点，先将节点变成临时的4节点，然后向上分裂调整一次。 插入元素到一个3节点，该3节点的父亲是一个3节点，先将节点变成临时的4节点，然后向上分裂调整，此时父亲节点变为临时4节点，继续向上分裂调整。 核心在于插入3节点后，该节点变为临时4节点，然后进行分裂恢复树的特征。最坏情况为插入节点后，每一次分裂后都导致上一层变为临时4节点，直到树根节点，这样需要不断向上分裂。 临时4节点的分裂，细分有六种情况： 2-3树删除元素： 情况1：删除中间节点 删除的是非叶子节点，该节点一定是有两棵或者三棵子树的，那么从子树中找到其最小后继节点，该节点是叶子节点，用该节点替换被删除的非叶子节点，然后再删除这个叶子节点，进入情况2。 如何找到最小后继节点，当有两棵子树时，那么从右子树一直往左下方找，如果有三棵子树，被删除节点在左边，那么从中子树一直往左下方找，否则从右子树一直往左下方找。 情况2：删除叶子节点 删除的是叶子节点，这时如果叶子节点是3节点，那么直接变为2节点即可，不影响平衡。但是，如果叶子节点是2节点，那么删除后，其父节点将会缺失一个儿子，破坏了满孩子的 2-3 树特征，需要进行调整后才能删除。 针对情况2，删除一个2节点的叶子节点，会导致父节点缺失一个儿子，破坏了 2-3 树的特征，我们可以进行调整变换，主要有两种调整： 重新分布：尝试从兄弟节点那里借值，然后重新调整节点。 合并：如果兄弟借不到值，合并节点（与父亲的元素），再向上递归处理。 左倾红黑树： 可以由2-3树实现 根节点的链接是黑色的。 红链接均为左链接。 没有任何一个结点同时和两条红链接相连 任意一个节点到达叶子节点的所有路径，经过的黑链接数量相同，也就是该树是完美黑色平衡的。比如，某一个节点，它可以到达5个叶子节点，那么这5条路径上的黑链接数量一样。 // 定义颜色 const ( RED = true BLACK = false ) // 左倾红黑树 type LLRBTree struct { Root *LLRBTNode // 树根节点 } // 左倾红黑树节点 type LLRBTNode struct { Value int64 // 值 Times int64 // 值出现的次数 Left *LLRBTNode // 左子树 Right *LLRBTNode // 右子树 Color bool // 父亲指向该节点的链接颜色 } // 新建一棵空树 func NewLLRBTree() *LLRBTree { return \u0026LLRBTree{} } // 节点的颜色 func IsRed(node *LLRBTNode) bool { if node == nil { return false } return node.Color == RED } 在元素添加和实现的过程中，需要做调整操作，有两种旋转操作，对某节点的右链接进行左旋转，或者左链接进行右旋转。 // 左旋转 func RotateLeft(h *LLRBTNode) *LLRBTNode { if h == nil { return nil } x := h.Right h.Right = x.Left x.Left = h x.Color = h.Color h.Color = RED return x } // 右旋转 func RotateRight(h *LLRBTNode) *LLRBTNode { if h == nil { return nil } x := h.Left h.Left = x.Right x.Right = h x.Color = h.Color h.Color = RED return x } // 颜色转换 func ColorChange(h *LLRBTNode) { if h == nil { return } h.Color = !h.Color h.Left.Color = !h.Left.Color h.Right.Color = !h.Right.Color } 添加元素实现： 每次添加元素节点时，都将该节点 Color 字段，也就是父亲指向它的链接设置为 RED 红色。接着判断其父亲是否有两个红链接（如连续的两个左红链接或者左右红色链接），或者有右红色链接，进行颜色变换或旋转操作。 几种情况： 插入元素到2节点，直接让节点变为3节点，不过当右插入时需要左旋使得红色链接在左边 插入元素到3节点，需要做旋转和颜色转换操作 // 左倾红黑树添加元素 func (tree *LLRBTree) Add(value int64) { // 跟节点开始添加元素，因为可能调整，所以需要将返回的节点赋值回根节点 tree.Root = tree.Root.Add(value) // 根节点的链接永远都是黑色的 tree.Root.Color = BLACK } // 往节点添加元素 func (node *LLRBTNode) Add(value int64) *LLRBTNode { // 插入的节点为空，将其链接颜色设置为红色，并返回 if node == nil { return \u0026LLRBTNode{ Value: value, Color: RED, } } // 插入的元素重复 if value == node.Value { node.Times = node.Times + 1 } else if value \u003e node.Value { // 插入的元素比节点值大，往右子树插入 node.Right = node.Right.Add(value) } else { // 插入的元素比节点值小，往左子树插入 node.Left = node.Left.Add(value) } // 辅助变量 nowNode := node // 右链接为红色，那么进行左旋，确保树是左倾的 // 这里做完操作后就可以结束了，因为插入操作，新插入的右红链接左旋后，nowNode节点不会出现连续两个红左链接，因为它只有一个左红链接 if IsRed(nowNode.Right) \u0026\u0026 !IsRed(nowNode.Left) { nowNode = RotateLeft(nowNode) } else { // 连续两个左链接为红色，那么进行右旋 if IsRed(nowNode.Left) \u0026\u0026 IsRed(nowNode.Left.Left) { nowNode = RotateRight(nowNode) } // 旋转后，可能左右链接都为红色，需要变色 if IsRed(nowNode.Left) \u0026\u0026 IsRed(nowNode.Right) { ColorChange(nowNode) } } return nowNode } 算法分析： 左倾红黑树的最坏树高度为 2log(n)，其中 n 为树的节点数量。为什么呢，我们先把左倾红黑树当作 2-3 树，也就是说最坏情况下沿着 2-3 树左边的节点都是3节点，其他节点都是2节点，这时树高近似 log(n)，再从 2-3 树转成左倾红黑树，当3节点不画平时，可以知道树高变成原来 2-3 树树高的两倍。虽然如此，构造一棵最坏的左倾红黑树很难。 AVL 树的最坏树高度为 1.44log(n)。由于左倾红黑树是近似平衡的二叉树，没有 AVL 树的严格平衡，树的高度会更高一点，因此查找操作效率比 AVL 树低，但时间复杂度只在于常数项的差别，去掉常数项，时间复杂度仍然是 log(n)。 我们的代码实现中，左倾红黑树的插入，需要逐层判断是否需要旋转和变色，复杂度为 log(n)，当旋转变色后导致上层存在连续的红左链接或者红色左右链接，那么需要继续旋转和变色，可能有多次这种调整操作，如图在箭头处添加新节点，出现了右红链接，要一直向上变色到根节点（实际上穿投到根节点的情况极少发生）：我们可以优化代码，使得在某一层旋转变色后，如果其父层没有连续的左红链接或者不需要变色，那么可以直接退出，不需要逐层判断是否需要旋转和变色。 对于 AVL 树来说，插入最多旋转两次，但其需要逐层更新树高度，复杂度也是为 log(n)。 按照插入效率来说，很多教程都说左倾红黑树会比 AVL 树好一点，因为其不要求严格的平衡，会插入得更快点，但根据我们实际上的递归代码，两者都需要逐层向上判断是否需要调整，只不过 AVL 树多了更新树高度的操作，此操作影响了一点点效率，但我觉得两种树的插入效率都差不多。 在此，我们不再纠结两种平衡树哪种更好","date":"2022-02-20 19:52:33","objectID":"/algorithm_find/:4:0","tags":["data structure"],"title":"Algorithm_find","uri":"/algorithm_find/"},{"categories":["Coding"],"content":"2-3-4树和普通红黑树 ","date":"2022-02-20 19:52:33","objectID":"/algorithm_find/:5:0","tags":["data structure"],"title":"Algorithm_find","uri":"/algorithm_find/"},{"categories":["Coding"],"content":"参考 https://www.cs.princeton.edu/~rs/talks/LLRB/LLRB.pdf ","date":"2022-02-20 19:52:33","objectID":"/algorithm_find/:6:0","tags":["data structure"],"title":"Algorithm_find","uri":"/algorithm_find/"},{"categories":["Coding"],"content":"排序算法 稳定性概念 定义：能保证两个相等的数，经过排序之后，其在序列的前后位置顺序不变。（A1=A2，排序前A1在A2前面，排序后A1还在A2前面） 意义：稳定性本质是维持具有相同属性的数据的插入顺序，如果后面需要使用该插入顺序排序，则稳定性排序可以避免这次排序。 冒泡排序，直接选择排序，直接插入排序被认为是初级的排序算法。中等规模用希尔排序，大规模排序使用快排、归并、堆排序这些高级排序算法。快排综合性能最好，甚至成为了很多编程库内置的排序算法。 ","date":"2022-02-20 19:52:01","objectID":"/algorithm_sort/:0:0","tags":["data structure"],"title":"Algorithm_sort","uri":"/algorithm_sort/"},{"categories":["Coding"],"content":"冒泡 自己实现时忘记考虑某一轮两两比较时已经排好序的情况，属实生疏了。时间复杂度一般是$O(n^2)$。冒泡排序是效率较低的排序算法，可以说是最慢的排序算法了，我们只需知道它是什么，在实际编程中一定不能使用如此之慢的排序算法! ","date":"2022-02-20 19:52:01","objectID":"/algorithm_sort/:1:0","tags":["data structure"],"title":"Algorithm_sort","uri":"/algorithm_sort/"},{"categories":["Coding"],"content":"选择 效率同样低下的排序算法。可以在每次循环选择时既选择最小的数，也选择最大的数，以减少循环次数达到优化的目的。工程上同样避免使用。 ","date":"2022-02-20 19:52:01","objectID":"/algorithm_sort/:2:0","tags":["data structure"],"title":"Algorithm_sort","uri":"/algorithm_sort/"},{"categories":["Coding"],"content":"插入 时间复杂度：$O(n)-O(n^2)$ 数组规模 n 较小的大多数情况下，我们可以使用插入排序，它比冒泡排序，选择排序都快，甚至比任何的排序算法都快。 数列中的有序性越高，插入排序的性能越高，因为待排序数组有序性越高，插入排序比较的次数越少。 数据规模较大时，效率也低。 ","date":"2022-02-20 19:52:01","objectID":"/algorithm_sort/:3:0","tags":["data structure"],"title":"Algorithm_sort","uri":"/algorithm_sort/"},{"categories":["Coding"],"content":"希尔 一个美国人1959年发明的，希尔排序是直接插入排序的改进版本。因为直接插入排序对那些几乎已经排好序的数列来说，排序效率极高，达到了 O(n) 的线性复杂度，但是每次只能将数据移动一位。希尔排序创造性的可以将数据移动 n 位，然后将 n 一直缩小，缩到与直接插入排序一样为 1 先取一个小于 N 的整数 d1 ，将位置是 d1 整数倍的数们分成一组，对这些数进行直接 插入排序。接着取一个小于 d1 的整数 d2 ，将位置是 d2 整数倍的数们分成一组，对这些数进行直接插入排序。接着取一个小于 d2 的整数 d3 ，将位置是 d3 整数倍的数们分成一组，对这些数进行直接插入排序。…直到取到的整数 d=1 ，接着使用直接插入排序。 这是一种分组插入方法，最后一次迭代就相当于是直接插入排序，其他迭代相当于每次移动 n 个距离的直接插入排序，这些整数是两个数之间的距离，我们称它们为增量。 我们取数列长度的一半为增量，以后每次减半，直到增量为1。 希尔排序通过分组使用直接插入排序，因为步长比 1大，在一开始可以很快将无序的数列变得不那么无序，比较和交换的次数也减少，直到最后使用步长为 1 的直接插入排序，数列已经是相对有序了，所以时间复杂度会稍好一点。 在最好情况下，也就是数列是有序时，希尔排序需要进行 logn 次增量的直接插入排序，因为每次直接插入排序最佳时间复杂度都为： O(n) ，因此希尔排序的最佳时间复杂度为： O(nlogn) 。 在最坏情况下，每一次迭代都是最坏的，假设增量序列为： d8 d7 d6 … d3 d2 1 ，那么每一轮直接插入排序的元素数量为： n/d8 n/d7 n/d6 …. n/d3 n/d2 n ，那么时间复杂度按照直接插入的最坏复杂度来计算为：$O( (n/d8)^2 + (n/d7)^2 + (n/d6)^2 + … + (n/d2)^2 + n^2) = O( \u003c 2 ) * O(n^2)$ 不同的分组增量序列，有不同的时间复杂度。Hibbard 增量序列： 1，3，7，···，2n−1 是被证明可广泛应用的分组序列，时间复杂度为： Θ(n^1.5) 。 希尔排序的时间复杂度大约在这个范围： O(n^1.3)~O(n^2) ，具体还无法用数学来严格证明它。 ","date":"2022-02-20 19:52:01","objectID":"/algorithm_sort/:4:0","tags":["data structure"],"title":"Algorithm_sort","uri":"/algorithm_sort/"},{"categories":["Coding"],"content":"归并 分治法 将两个有序数组进行合并，最多进行 N 次比较就可以生成一个新的有序数组， N 是两个数组长度之和。 归并操作最坏的时间复杂度为： O(n) ，其中 n 是较长数组的长度（因为$N\u003c2n$）。归并操作最好的时间复杂度为： O(n) ，其中 n 是较短数组的长度。正是利用这个特点，归并排序先排序较小的数组，再将有序的小数组合并形成更大有序的数组。 归并排序有两种递归做法，一种是自顶向下，一种是自底向上。 自顶向下：不断二分大数组直到无法切分，排序，不断两两合并，得到排序后数组。 每次都是一分为二，特别均匀，所以最差和最坏时间复杂度都一样。归并操作的时间复杂度为： O(n) ，因此总的时间复杂度为： T(n)=2T(n/2)+O(n) ，根据主定理公式可以知道时间复杂度为： O(nlogn) 因为不断地递归，程序栈层数会有 logn 层，所以递归栈的空间复杂度为： O(logn) ，对于排序十亿个整数，也只要： log(100 0000 0000)=29.897 ，占用的堆栈层数最多 30 层 自底向上：小数组排序合并成大数组。 时间复杂度同上 因不需要递归，没有程序栈占用，空间复杂度为O(1) 归并排序归并操作占用了额外的辅助数组，且归并操作是从一个元素的数组开始。 改进： 对于小规模数组，使用直接插入排序。 原地排序，节约掉辅助数组空间的占用。 建议使用自底向上非递归排序，不会有程序栈空间损耗 手摇算法（翻转算法）： 主要用来对数组两部分进行位置互换 eg:将字符串 abcde1234567 的前 5 个字符与后面的字符交换位置，那么手摇后变成： 1234567abcde 。 如何翻转： 将前部分逆序 将后部分逆序 对整体逆序 归并原地排序利用了手摇算法的特征，不需要额外的辅助数组。 我们自底开始，将元素按照数量为 blockSize 进行小数组排序，使用直接插入排序，然后我们对这些有序的数组向上进行原地归并操作。 归并排序是唯一一个有稳定性保证的高级排序算法，某些时候，为了寻求大规模数据下排序前后，相同元素位置不变，可以使用归并排序。 ","date":"2022-02-20 19:52:01","objectID":"/algorithm_sort/:5:0","tags":["data structure"],"title":"Algorithm_sort","uri":"/algorithm_sort/"},{"categories":["Coding"],"content":"优先队列及堆 堆排序属于选择类排序算法。 优先队列是一种能完成以下任务的队列：插入一个数值，取出最小或最大的数值（获取数值，并且删除）。 优先队列可以用二叉树来实现，我们称这种结构为二叉堆。 最小堆和最大堆是二叉堆的一种，是一棵完全二叉树（一种平衡树）。 最小堆的性质： 父节点的值都小于左右儿子节点。 这是一个递归的性质。 最大堆的性质： 父节点的值都大于左右儿子节点。 这是一个递归的性质。 最大堆和最小堆实现方式一样，只不过根节点一个是最大的，一个是最小的 最大堆特征： 最大堆实现细节(两个操作)： push：向堆中插入数据时，首先在堆的末尾插入数据，如果该数据比父亲节点还大，那么交换，然后不断向上提升，直到没有大小颠倒为止。 pop：从堆中删除最大值时，首先把最后一个值复制到根节点上，并且删除最后一个数值，然后和儿子节点比较，如果值小于儿子，与儿子节点交换，然后不断向下交换， 直到没有大小颠倒为止。在向下交换过程中，如果有两个子儿子都大于自己，就选择较大的。 最大堆有两个核心操作，一个是上浮，一个是下沉，分别对应 push 和 pop 。 上浮操作 操作一次 push 的最好时间复杂度为： O(1) ，因为第一次上浮时如果不大于父亲，那么就结束了。最坏的时间复杂度为： O(logn) ，相当于每次都大于父亲，会一直往上浮到根节点，翻转次数等于树的高度，而树的高度等于元素个数的对数： log(n) 。 构建一个最大堆，从空堆开始，每次添加元素到尾部后，需要向上翻转，最坏翻转次数是：近似 = log(1)+log(2)+log(3)+…+log(n) = log(n!) log(n!) 和 nlog(n) 是同阶的，故最坏时间复杂度便得到了。元素不全相同的情况下最好时间复杂度也是这个。 下沉操作 操作一次 pop 最好的时间复杂度也是： O(1) ，因为第一次比较时根节点就是最大的。最坏时间复杂度仍然是树的高度： O(logn) 。 从一个最大堆，逐一移除堆顶元素，然后将堆尾元素置于堆顶后，向下翻转恢复堆特征，最坏翻转次数是:近似 = log(1)+log(2)+log(3)+…+log(n) = log(n!)，同上浮。元素不全相同的情况下最好时间复杂度也是O(nlog(n)) 如果所有的元素都一样的情况下，建堆和移除堆的每一步都不需要翻转，最好时间复杂度 为： O(n) ，复杂度主要在于遍历元素。 根据最大堆，可以实现堆排序。 普通堆排序：先构建一个最小堆，然后依次把根节点元素 pop 出即可： 因为一开始会认为堆是空的，每次添加元素都需要添加到尾部，然后向上翻转，需要用 Heap.Size来记录堆的大小增长，这种堆构建，可以认为是非原地的构建，影响了效率 改进的原地自底向上的堆排序，不会从空堆开始，而是把待排序的数列当成一个混乱的最大堆，从底层逐层开始，对元素进行下沉操作，一直恢复最大堆的特征，直到根节点。 将构建堆的时间复杂度从 O(nlogn) 降为 O(n) ，总的堆排序时间复杂度从 O(2nlogn) 改进到 O(n+nlogn) 。 自底向上堆排序： 构建最大堆步骤： 先对最底部的所有非叶子节点进行下沉，即这些非叶子节点与它们的儿子节点比较，较大的儿子和父亲交换位置。 接着从次二层开始的非叶子节点重复这个操作，直到到达根节点最大堆就构建好了 ","date":"2022-02-20 19:52:01","objectID":"/algorithm_sort/:6:0","tags":["data structure"],"title":"Algorithm_sort","uri":"/algorithm_sort/"},{"categories":["Coding"],"content":"快速 亦使用了分治法。 对冒泡排序的改进。 快速排序通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列。 步骤： 先从数列中取出一个数作为基准数。一般取第一个数。 分区过程，将比这个数大的数全放到它的右边，小于或等于它的数全放到它的左边。 再对左右区间重复第二步，直到各区间只有一个数。 在最好情况下，每一轮都能平均切分，这样遍历元素只要 n/2 次就可以把数列分成两部分，每一轮的时间复杂度都是： O(n) 。因为问题规模每次被折半，折半的数列继续递归进行切分，也就是总的时间复杂度计算公式为： T(n) = 2*T(n/2) + O(n) 。按照主定理公式计算，我们可以知道时间复杂度为： O(nlogn) 最差的情况下，每次都不能平均地切分，每次切分都因为基准数是最大的或者最小的，不能分成两个数列，这样时间复杂度变为了 T(n) = T(n-1) + O(n) ，按照主定理计算可以知道时间复杂度为： O(n^2) 数据规模越大越难以出现最差的情况，在综合情况下，快速排序的平均时间复杂度为： O(nlogn) 。对比之前介绍的排序算法，快速排序比那些动不动就是平方级别的初级排序算法更佳。 为了避免切分不均匀情况的发生，有几种方法改进： 每次进行快速排序切分时，先将数列随机打乱，再进行切分，这样随机加了个震荡，减少不均匀的情况。当然，也可以随机选择一个基准数，而不是选第一个数。 每次取数列头部，中部，尾部三个数，取三个数的中位数为基准数进行切分。 快速排序使用原地排序，存储空间复杂度为： O(1) 。而因为递归栈的影响，递归的程序栈开辟的层数范围在 $logn-n$ ，所以递归栈的空间复杂度为： $O(logn)-log(n)$ ，最坏为： log(n) ，当元素较多时，程序栈可能溢出。通过改进算法，使用伪尾递归进行优化，递归栈的空间复杂度可以减小到 O(logn) 改进： 在小规模数组的情况下，直接插入排序的效率最好，当快速排序递归部分进入小数组范围，可以 切换成直接插入排序。 排序数列可能存在大量重复值，使用三向切分快速排序，将数组分成三部分，大于基准数，等于 基准数，小于基准数，这个时候需要维护三个下标。 使用伪尾递归减少程序栈空间占用，使得栈空间复杂度从 O(logn)~log(n) 变 为： O(logn) 。 伪尾递归优化： // 伪尾递归快速排序 func QuickSort3(array []int, begin, end int) { for begin \u003c end { // 进行切分 loc := partition(array, begin, end) // 那边元素少先排哪边 if loc-begin \u003c end-loc { // 先排左边 QuickSort3(array, begin, loc-1) begin = loc + 1 } else { // 先排右边 QuickSort3(array, loc+1, end) end = loc - 1 } } } 解析：很多人以为这样子是尾递归。其实这样的快排写法是伪装的尾递归，不是真正的尾递归，因为有for 循环，不是直接 return QuickSort ，递归还是不断地压栈，栈的层次仍然不断地增长。但是，因为先让规模小的部分排序，栈的深度大大减少，程序栈最深不会超过 logn 层，这样堆栈最坏空间复杂度从 O(n) 降为 O(logn) 。这种优化也是一种很好的优化，因为栈的层数减少了，对于排序十亿个整数，也只要： log(100 00000000)=29.897 ，占用的堆栈层数最多 30 层，比不进行优化，可能出现的 O(n) 常数层好很多。 非递归写法仅仅是将之前的递归栈转化为自己维持的手工栈。 ","date":"2022-02-20 19:52:01","objectID":"/algorithm_sort/:7:0","tags":["data structure"],"title":"Algorithm_sort","uri":"/algorithm_sort/"},{"categories":["Coding"],"content":"内置库使用快排的原因 首先堆排序，归并排序最好最坏时间复杂度都是： O(nlogn) ，而快速排序最坏的时间复杂度是： O(n^2) ，但是很多编程语言内置的排序算法使用的仍然是快速排序，这是为什么？ 这个问题有偏颇，选择排序算法要看具体的场景， Linux 内核用的排序算法就是堆排序，而Java 对于数量比较多的复杂对象排序，内置排序使用的是归并排序，只是一般情况下，快速排序更快。 归并排序有两个稳定，第一个稳定是排序前后相同的元素位置不变，第二个稳定是，每次都是很平均地进行排序，读取数据也是顺序读取，能够利用存储器缓存的特征，比如从磁盘读取数据进行排序。因为排序过程需要占用额外的辅助数组空间，所以这部分有代价损耗，但是原地手摇的归并排序克服了这个缺陷。 复杂度中，大 O 有一个常数项被省略了，堆排序每次取最大的值之后，都需要进行节点翻转，重新恢复堆的特征，做了大量无用功，常数项比快速排序大，大部分情况下比快速排序慢很多。但是堆排序时间较稳定，不会出现快排最坏 O(n^2) 的情况，且省空间，不需要额外的存储空间和栈空间。 当待排序数量大于16000个元素时，使用自底向上的堆排序比快速排序还快，可见此：https://core.ac.uk/download/pdf/82350265.pdf。 快速排序最坏情况下复杂度高，主要在于切分不像归并排序一样平均，而是很依赖基准数的现在，我们通过改进，比如随机数，三切分等，这种最坏情况的概率极大的降低。大多数情况下，它并不会那么地坏，大多数快才是真的块。 归并排序和快速排序都是分治法，排序的数据都是相邻的，而堆排序比较的数可能跨越很大的范围，导致局部性命中率降低，不能利用现代存储器缓存的特征，加载数据过程会损失性能。 对稳定性有要求的，要求排序前后相同元素位置不变，可以使用归并排序， Java 中的复杂对象类型，要求排序前后位置不能发生变化，所以小规模数据下使用了直接插入排序，大规模数据下使用了归并排序。 对栈，存储空间有要求的可以使用堆排序，比如 Linux 内核栈小，快速排序占用程序栈太大了，使用快速排序可能栈溢出，所以使用了堆排序。 在 Golang 中，标准库 sort 中对切片进行稳定排序：会先按照 20 个元素的范围，对整个切片分段进行插入排序，因为小数组插入排序效率高，然后再对这些已排好序的小数组进行归并排序。其中归并排序还使用了原地排序，节约了辅助空间。 快速排序限制程序栈的层数为： 2*ceil(log(n+1)) ，当递归超过该层时表示程序栈过深，那么转为堆排序。 ","date":"2022-02-20 19:52:01","objectID":"/algorithm_sort/:8:0","tags":["data structure"],"title":"Algorithm_sort","uri":"/algorithm_sort/"},{"categories":["Coding"],"content":"facade API 为facade 模块的外观接口，大部分代码使用此接口简化对facade类的访问。 facade模块同时暴露了a和b 两个Module 的NewXXX和interface，其它代码如果需要使用细节功能时可以直接调用。 package facade import \"fmt\" func NewAPI() API { return \u0026apiImpl{ a: NewAModuleAPI(), b: NewBModuleAPI(), } } //API is facade interface of facade package type API interface { Test() string } //facade implement type apiImpl struct { a AModuleAPI b BModuleAPI } func (a *apiImpl) Test() string { aRet := a.a.TestA() bRet := a.b.TestB() return fmt.Sprintf(\"%s\\n%s\", aRet, bRet) } //NewAModuleAPI return new AModuleAPI func NewAModuleAPI() AModuleAPI { return \u0026aModuleImpl{} } //AModuleAPI ... type AModuleAPI interface { TestA() string } type aModuleImpl struct{} func (*aModuleImpl) TestA() string { return \"A module running\" } //NewBModuleAPI return new BModuleAPI func NewBModuleAPI() BModuleAPI { return \u0026bModuleImpl{} } //BModuleAPI ... type BModuleAPI interface { TestB() string } type bModuleImpl struct{} func (*bModuleImpl) TestB() string { return \"B module running\" } package facade import \"testing\" var expect = \"A module running\\nB module running\" // TestFacadeAPI ... func TestFacadeAPI(t *testing.T) { api := NewAPI() ret := api.Test() if ret != expect { t.Fatalf(\"expect %s, return %s\", expect, ret) } } ","date":"2022-01-22 09:21:00","objectID":"/structural_type/:1:0","tags":["design mode"],"title":"Structural_type","uri":"/structural_type/"},{"categories":["Coding"],"content":"adapter 适配器模式用于转换一种接口适配另一种接口。 实际使用中Adaptee一般为接口，并且使用工厂函数生成实例。 在Adapter中匿名组合Adaptee接口，所以Adapter类也拥有SpecificRequest实例方法，又因为Go语言中非入侵式接口特征，其实Adapter也适配Adaptee接口。 package adapter //Target 是适配的目标接口 type Target interface { Request() string } //Adaptee 是被适配的目标接口 type Adaptee interface { SpecificRequest() string } //NewAdaptee 是被适配接口的工厂函数 func NewAdaptee() Adaptee { return \u0026adapteeImpl{} } //AdapteeImpl 是被适配的目标类 type adapteeImpl struct{} //SpecificRequest 是目标类的一个方法 func (*adapteeImpl) SpecificRequest() string { return \"adaptee method\" } //NewAdapter 是Adapter的工厂函数 func NewAdapter(adaptee Adaptee) Target { return \u0026adapter{ Adaptee: adaptee, } } //Adapter 是转换Adaptee为Target接口的适配器 type adapter struct { Adaptee } //Request 实现Target接口 func (a *adapter) Request() string { return a.SpecificRequest() } package adapter import \"testing\" var expect = \"adaptee method\" func TestAdapter(t *testing.T) { adaptee := NewAdaptee() target := NewAdapter(adaptee) res := target.Request() if res != expect { t.Fatalf(\"expect: %s, actual: %s\", expect, res) } } ","date":"2022-01-22 09:21:00","objectID":"/structural_type/:2:0","tags":["design mode"],"title":"Structural_type","uri":"/structural_type/"},{"categories":["Coding"],"content":"proxy 代理模式用于延迟处理操作或者在进行实际操作前后进行其它处理。 代理模式的常见用法有 虚代理 COW代理 远程代理 保护代理 Cache 代理 防火墙代理 同步代理 智能指引 等。。。 package proxy type Subject interface { Do() string } type RealSubject struct{} func (RealSubject) Do() string { return \"real\" } type Proxy struct { real RealSubject } func (p Proxy) Do() string { var res string // 在调用真实对象之前的工作，检查缓存，判断权限，实例化真实对象等。。 res += \"pre:\" // 调用真实对象 res += p.real.Do() // 调用之后的操作，如缓存结果，对结果进行处理等。。 res += \":after\" return res } package proxy import \"testing\" func TestProxy(t *testing.T) { var sub Subject sub = \u0026Proxy{} res := sub.Do() if res != \"pre:real:after\" { t.Fail() } } ","date":"2022-01-22 09:21:00","objectID":"/structural_type/:3:0","tags":["design mode"],"title":"Structural_type","uri":"/structural_type/"},{"categories":["Coding"],"content":"composite 组合模式统一对象和对象集，使得使用相同接口使用对象和对象集。 组合模式常用于树状结构，用于统一叶子节点和树节点的访问，并且可以用于应用某一操作到所有子节点。 package composite import \"fmt\" type Component interface { Parent() Component SetParent(Component) Name() string SetName(string) AddChild(Component) Print(string) } const ( LeafNode = iota CompositeNode ) func NewComponent(kind int, name string) Component { var c Component switch kind { case LeafNode: c = NewLeaf() case CompositeNode: c = NewComposite() } c.SetName(name) return c } type component struct { parent Component name string } func (c *component) Parent() Component { return c.parent } func (c *component) SetParent(parent Component) { c.parent = parent } func (c *component) Name() string { return c.name } func (c *component) SetName(name string) { c.name = name } func (c *component) AddChild(Component) {} func (c *component) Print(string) {} type Leaf struct { component } func NewLeaf() *Leaf { return \u0026Leaf{} } func (c *Leaf) Print(pre string) { fmt.Printf(\"%s-%s\\n\", pre, c.Name()) } type Composite struct { component childs []Component } func NewComposite() *Composite { return \u0026Composite{ childs: make([]Component, 0), } } func (c *Composite) AddChild(child Component) { child.SetParent(c) c.childs = append(c.childs, child) } func (c *Composite) Print(pre string) { fmt.Printf(\"%s+%s\\n\", pre, c.Name()) pre += \" \" for _, comp := range c.childs { comp.Print(pre) } } package composite func ExampleComposite() { root := NewComponent(CompositeNode, \"root\") c1 := NewComponent(CompositeNode, \"c1\") c2 := NewComponent(CompositeNode, \"c2\") c3 := NewComponent(CompositeNode, \"c3\") l1 := NewComponent(LeafNode, \"l1\") l2 := NewComponent(LeafNode, \"l2\") l3 := NewComponent(LeafNode, \"l3\") root.AddChild(c1) root.AddChild(c2) c1.AddChild(c3) c1.AddChild(l1) c2.AddChild(l2) c2.AddChild(l3) root.Print(\"\") // Output: // +root // +c1 // +c3 // -l1 // +c2 // -l2 // -l3 } ","date":"2022-01-22 09:21:00","objectID":"/structural_type/:4:0","tags":["design mode"],"title":"Structural_type","uri":"/structural_type/"},{"categories":["Coding"],"content":"flyweight 享元模式从对象中剥离出不发生改变且多个实例需要的重复数据，独立出一个享元，使多个对象共享，从而节省内存以及减少对象数量。 package flyweight import \"fmt\" type ImageFlyweightFactory struct { maps map[string]*ImageFlyweight } var imageFactory *ImageFlyweightFactory func GetImageFlyweightFactory() *ImageFlyweightFactory { if imageFactory == nil { imageFactory = \u0026ImageFlyweightFactory{ maps: make(map[string]*ImageFlyweight), } } return imageFactory } func (f *ImageFlyweightFactory) Get(filename string) *ImageFlyweight { image := f.maps[filename] if image == nil { image = NewImageFlyweight(filename) f.maps[filename] = image } return image } type ImageFlyweight struct { data string } func NewImageFlyweight(filename string) *ImageFlyweight { // Load image file data := fmt.Sprintf(\"image data %s\", filename) return \u0026ImageFlyweight{ data: data, } } func (i *ImageFlyweight) Data() string { return i.data } type ImageViewer struct { *ImageFlyweight } func NewImageViewer(filename string) *ImageViewer { image := GetImageFlyweightFactory().Get(filename) return \u0026ImageViewer{ ImageFlyweight: image, } } func (i *ImageViewer) Display() { fmt.Printf(\"Display: %s\\n\", i.Data()) } package flyweight import \"testing\" func ExampleFlyweight() { viewer := NewImageViewer(\"image1.png\") viewer.Display() // Output: // Display: image data image1.png } func TestFlyweight(t *testing.T) { viewer1 := NewImageViewer(\"image1.png\") viewer2 := NewImageViewer(\"image1.png\") if viewer1.ImageFlyweight != viewer2.ImageFlyweight { t.Fail() } } ","date":"2022-01-22 09:21:00","objectID":"/structural_type/:5:0","tags":["design mode"],"title":"Structural_type","uri":"/structural_type/"},{"categories":["Coding"],"content":"decorator 装饰模式使用对象组合的方式动态改变或增加对象行为。 Go语言借助于匿名组合和非入侵式接口可以很方便实现装饰模式。 使用匿名组合，在装饰器中不必显式定义转调原对象方法。 package decorator type Component interface { Calc() int } type ConcreteComponent struct{} func (*ConcreteComponent) Calc() int { return 0 } type MulDecorator struct { Component num int } func WarpMulDecorator(c Component, num int) Component { return \u0026MulDecorator{ Component: c, num: num, } } func (d *MulDecorator) Calc() int { return d.Component.Calc() * d.num } type AddDecorator struct { Component num int } func WarpAddDecorator(c Component, num int) Component { return \u0026AddDecorator{ Component: c, num: num, } } func (d *AddDecorator) Calc() int { return d.Component.Calc() + d.num } package decorator import \"fmt\" func ExampleDecorator() { var c Component = \u0026ConcreteComponent{} c = WarpAddDecorator(c, 10) c = WarpMulDecorator(c, 8) res := c.Calc() fmt.Printf(\"res %d\\n\", res) // Output: // res 80 } ","date":"2022-01-22 09:21:00","objectID":"/structural_type/:6:0","tags":["design mode"],"title":"Structural_type","uri":"/structural_type/"},{"categories":["Coding"],"content":"bridge 桥接模式分离抽象部分和实现部分。使得两部分独立扩展。 桥接模式类似于策略模式，区别在于策略模式封装一系列算法使得算法可以互相替换。 策略模式使抽象部分和实现部分分离，可以独立变化。 package bridge import \"fmt\" type AbstractMessage interface { SendMessage(text, to string) } type MessageImplementer interface { Send(text, to string) } type MessageSMS struct{} func ViaSMS() MessageImplementer { return \u0026MessageSMS{} } func (*MessageSMS) Send(text, to string) { fmt.Printf(\"send %s to %s via SMS\", text, to) } type MessageEmail struct{} func ViaEmail() MessageImplementer { return \u0026MessageEmail{} } func (*MessageEmail) Send(text, to string) { fmt.Printf(\"send %s to %s via Email\", text, to) } type CommonMessage struct { method MessageImplementer } func NewCommonMessage(method MessageImplementer) *CommonMessage { return \u0026CommonMessage{ method: method, } } func (m *CommonMessage) SendMessage(text, to string) { m.method.Send(text, to) } type UrgencyMessage struct { method MessageImplementer } func NewUrgencyMessage(method MessageImplementer) *UrgencyMessage { return \u0026UrgencyMessage{ method: method, } } func (m *UrgencyMessage) SendMessage(text, to string) { m.method.Send(fmt.Sprintf(\"[Urgency] %s\", text), to) } package bridge func ExampleCommonSMS() { m := NewCommonMessage(ViaSMS()) m.SendMessage(\"have a drink?\", \"bob\") // Output: // send have a drink? to bob via SMS } func ExampleCommonEmail() { m := NewCommonMessage(ViaEmail()) m.SendMessage(\"have a drink?\", \"bob\") // Output: // send have a drink? to bob via Email } func ExampleUrgencySMS() { m := NewUrgencyMessage(ViaSMS()) m.SendMessage(\"have a drink?\", \"bob\") // Output: // send [Urgency] have a drink? to bob via SMS } func ExampleUrgencyEmail() { m := NewUrgencyMessage(ViaEmail()) m.SendMessage(\"have a drink?\", \"bob\") // Output: // send [Urgency] have a drink? to bob via Email } 参考 ","date":"2022-01-22 09:21:00","objectID":"/structural_type/:7:0","tags":["design mode"],"title":"Structural_type","uri":"/structural_type/"},{"categories":["Coding"],"content":"mediator 中介者模式封装对象之间互交，使依赖变的简单，并且使复杂互交简单化，封装在中介者中。 例子中的中介者使用单例模式生成中介者。 中介者的change使用switch判断类型。 package mediator import ( \"fmt\" \"strings\" ) type CDDriver struct { Data string } func (c *CDDriver) ReadData() { c.Data = \"music,image\" fmt.Printf(\"CDDriver: reading data %s\\n\", c.Data) GetMediatorInstance().changed(c) } type CPU struct { Video string Sound string } func (c *CPU) Process(data string) { sp := strings.Split(data, \",\") c.Sound = sp[0] c.Video = sp[1] fmt.Printf(\"CPU: split data with Sound %s, Video %s\\n\", c.Sound, c.Video) GetMediatorInstance().changed(c) } type VideoCard struct { Data string } func (v *VideoCard) Display(data string) { v.Data = data fmt.Printf(\"VideoCard: display %s\\n\", v.Data) GetMediatorInstance().changed(v) } type SoundCard struct { Data string } func (s *SoundCard) Play(data string) { s.Data = data fmt.Printf(\"SoundCard: play %s\\n\", s.Data) GetMediatorInstance().changed(s) } type Mediator struct { CD *CDDriver CPU *CPU Video *VideoCard Sound *SoundCard } var mediator *Mediator func GetMediatorInstance() *Mediator { if mediator == nil { mediator = \u0026Mediator{} } return mediator } func (m *Mediator) changed(i interface{}) { switch inst := i.(type) { case *CDDriver: m.CPU.Process(inst.Data) case *CPU: m.Sound.Play(inst.Sound) m.Video.Display(inst.Video) } } package mediator import \"testing\" func TestMediator(t *testing.T) { mediator := GetMediatorInstance() mediator.CD = \u0026CDDriver{} mediator.CPU = \u0026CPU{} mediator.Video = \u0026VideoCard{} mediator.Sound = \u0026SoundCard{} //Tiggle mediator.CD.ReadData() if mediator.CD.Data != \"music,image\" { t.Fatalf(\"CD unexpect data %s\", mediator.CD.Data) } if mediator.CPU.Sound != \"music\" { t.Fatalf(\"CPU unexpect sound data %s\", mediator.CPU.Sound) } if mediator.CPU.Video != \"image\" { t.Fatalf(\"CPU unexpect video data %s\", mediator.CPU.Video) } if mediator.Video.Data != \"image\" { t.Fatalf(\"VidoeCard unexpect data %s\", mediator.Video.Data) } if mediator.Sound.Data != \"music\" { t.Fatalf(\"SoundCard unexpect data %s\", mediator.Sound.Data) } } ","date":"2022-01-22 09:20:41","objectID":"/behavioral_type/:1:0","tags":["design mode"],"title":"Behavioral_type","uri":"/behavioral_type/"},{"categories":["Coding"],"content":"observer 观察者模式用于触发联动。 一个对象的改变会触发其它观察者的相关动作，而此对象无需关心连动对象的具体实现。 package observer import \"fmt\" type Subject struct { observers []Observer context string } func NewSubject() *Subject { return \u0026Subject{ observers: make([]Observer, 0), } } func (s *Subject) Attach(o Observer) { s.observers = append(s.observers, o) } func (s *Subject) notify() { for _, o := range s.observers { o.Update(s) } } func (s *Subject) UpdateContext(context string) { s.context = context s.notify() } type Observer interface { Update(*Subject) } type Reader struct { name string } func NewReader(name string) *Reader { return \u0026Reader{ name: name, } } func (r *Reader) Update(s *Subject) { fmt.Printf(\"%s receive %s\\n\", r.name, s.context) } package observer func ExampleObserver() { subject := NewSubject() reader1 := NewReader(\"reader1\") reader2 := NewReader(\"reader2\") reader3 := NewReader(\"reader3\") subject.Attach(reader1) subject.Attach(reader2) subject.Attach(reader3) subject.UpdateContext(\"observer mode\") // Output: // reader1 receive observer mode // reader2 receive observer mode // reader3 receive observer mode } ","date":"2022-01-22 09:20:41","objectID":"/behavioral_type/:2:0","tags":["design mode"],"title":"Behavioral_type","uri":"/behavioral_type/"},{"categories":["Coding"],"content":"command 命令模式本质是把某个对象的方法调用封装到对象中，方便传递、存储、调用。 示例中把主板单中的启动(start)方法和重启(reboot)方法封装为命令对象，再传递到主机(box)对象中。于两个按钮进行绑定： 第一个机箱(box1)设置按钮1(button1) 为开机按钮2(button2)为重启。 第二个机箱(box1)设置按钮2(button2) 为开机按钮1(button1)为重启。 从而得到配置灵活性。 除了配置灵活外，使用命令模式还可以用作： 批处理 任务队列 undo, redo 等把具体命令封装到对象中使用的场合 package command import \"fmt\" type Command interface { Execute() } type StartCommand struct { mb *MotherBoard } func NewStartCommand(mb *MotherBoard) *StartCommand { return \u0026StartCommand{ mb: mb, } } func (c *StartCommand) Execute() { c.mb.Start() } type RebootCommand struct { mb *MotherBoard } func NewRebootCommand(mb *MotherBoard) *RebootCommand { return \u0026RebootCommand{ mb: mb, } } func (c *RebootCommand) Execute() { c.mb.Reboot() } type MotherBoard struct{} func (*MotherBoard) Start() { fmt.Print(\"system starting\\n\") } func (*MotherBoard) Reboot() { fmt.Print(\"system rebooting\\n\") } type Box struct { button1 Command button2 Command } func NewBox(button1, button2 Command) *Box { return \u0026Box{ button1: button1, button2: button2, } } func (b *Box) PressButton1() { b.button1.Execute() } func (b *Box) PressButton2() { b.button2.Execute() } package command func ExampleCommand() { mb := \u0026MotherBoard{} startCommand := NewStartCommand(mb) rebootCommand := NewRebootCommand(mb) box1 := NewBox(startCommand, rebootCommand) box1.PressButton1() box1.PressButton2() box2 := NewBox(rebootCommand, startCommand) box2.PressButton1() box2.PressButton2() // Output: // system starting // system rebooting // system rebooting // system starting } ","date":"2022-01-22 09:20:41","objectID":"/behavioral_type/:3:0","tags":["design mode"],"title":"Behavioral_type","uri":"/behavioral_type/"},{"categories":["Coding"],"content":"iterator 迭代器模式用于使用相同方式送代不同类型集合或者隐藏集合类型的具体实现。 可以使用迭代器模式使遍历同时应用送代策略，如请求新对象、过滤、处理对象等。 package iterator import \"fmt\" type Aggregate interface { Iterator() Iterator } type Iterator interface { First() IsDone() bool Next() interface{} } type Numbers struct { start, end int } func NewNumbers(start, end int) *Numbers { return \u0026Numbers{ start: start, end: end, } } func (n *Numbers) Iterator() Iterator { return \u0026NumbersIterator{ numbers: n, next: n.start, } } type NumbersIterator struct { numbers *Numbers next int } func (i *NumbersIterator) First() { i.next = i.numbers.start } func (i *NumbersIterator) IsDone() bool { return i.next \u003e i.numbers.end } func (i *NumbersIterator) Next() interface{} { if !i.IsDone() { next := i.next i.next++ return next } return nil } func IteratorPrint(i Iterator) { for i.First(); !i.IsDone(); { c := i.Next() fmt.Printf(\"%#v\\n\", c) } } package iterator func ExampleIterator() { var aggregate Aggregate aggregate = NewNumbers(1, 10) IteratorPrint(aggregate.Iterator()) // Output: // 1 // 2 // 3 // 4 // 5 // 6 // 7 // 8 // 9 // 10 } ","date":"2022-01-22 09:20:41","objectID":"/behavioral_type/:4:0","tags":["design mode"],"title":"Behavioral_type","uri":"/behavioral_type/"},{"categories":["Coding"],"content":"template method 模版方法模式使用继承机制，把通用步骤和通用方法放到父类中，把具体实现延迟到子类中实现。使得实现符合开闭原则。 如实例代码中通用步骤在父类中实现（准备、下载、保存、收尾）下载和保存的具体实现留到子类中，并且提供 保存方法的默认实现。 因为Golang不提供继承机制，需要使用匿名组合模拟实现继承。 此处需要注意：因为父类需要调用子类方法，所以子类需要匿名组合父类的同时，父类需要持有子类的引用。 package templatemethod import \"fmt\" type Downloader interface { Download(uri string) } type template struct { implement uri string } type implement interface { download() save() } func newTemplate(impl implement) *template { return \u0026template{ implement: impl, } } func (t *template) Download(uri string) { t.uri = uri fmt.Print(\"prepare downloading\\n\") t.implement.download() t.implement.save() fmt.Print(\"finish downloading\\n\") } func (t *template) save() { fmt.Print(\"default save\\n\") } type HTTPDownloader struct { *template } func NewHTTPDownloader() Downloader { downloader := \u0026HTTPDownloader{} template := newTemplate(downloader) downloader.template = template return downloader } func (d *HTTPDownloader) download() { fmt.Printf(\"download %s via http\\n\", d.uri) } func (*HTTPDownloader) save() { fmt.Printf(\"http save\\n\") } type FTPDownloader struct { *template } func NewFTPDownloader() Downloader { downloader := \u0026FTPDownloader{} template := newTemplate(downloader) downloader.template = template return downloader } func (d *FTPDownloader) download() { fmt.Printf(\"download %s via ftp\\n\", d.uri) } package templatemethod func ExampleHTTPDownloader() { var downloader Downloader = NewHTTPDownloader() downloader.Download(\"http://example.com/abc.zip\") // Output: // prepare downloading // download http://example.com/abc.zip via http // http save // finish downloading } func ExampleFTPDownloader() { var downloader Downloader = NewFTPDownloader() downloader.Download(\"ftp://example.com/abc.zip\") // Output: // prepare downloading // download ftp://example.com/abc.zip via ftp // default save // finish downloading } ","date":"2022-01-22 09:20:41","objectID":"/behavioral_type/:5:0","tags":["design mode"],"title":"Behavioral_type","uri":"/behavioral_type/"},{"categories":["Coding"],"content":"strategy 定义一系列算法，让这些算法在运行时可以互换，使得分离算法，符合开闭原则。 package strategy import \"fmt\" type Payment struct { context *PaymentContext strategy PaymentStrategy } type PaymentContext struct { Name, CardID string Money int } func NewPayment(name, cardid string, money int, strategy PaymentStrategy) *Payment { return \u0026Payment{ context: \u0026PaymentContext{ Name: name, CardID: cardid, Money: money, }, strategy: strategy, } } func (p *Payment) Pay() { p.strategy.Pay(p.context) } type PaymentStrategy interface { Pay(*PaymentContext) } type Cash struct{} func (*Cash) Pay(ctx *PaymentContext) { fmt.Printf(\"Pay $%d to %s by cash\", ctx.Money, ctx.Name) } type Bank struct{} func (*Bank) Pay(ctx *PaymentContext) { fmt.Printf(\"Pay $%d to %s by bank account %s\", ctx.Money, ctx.Name, ctx.CardID) } package strategy func ExamplePayByCash() { payment := NewPayment(\"Ada\", \"\", 123, \u0026Cash{}) payment.Pay() // Output: // Pay $123 to Ada by cash } func ExamplePayByBank() { payment := NewPayment(\"Bob\", \"0002\", 888, \u0026Bank{}) payment.Pay() // Output: // Pay $888 to Bob by bank account 0002 } ","date":"2022-01-22 09:20:41","objectID":"/behavioral_type/:6:0","tags":["design mode"],"title":"Behavioral_type","uri":"/behavioral_type/"},{"categories":["Coding"],"content":"state 状态模式用于分离状态和行为。 package state import \"fmt\" type Week interface { Today() Next(*DayContext) } type DayContext struct { today Week } func NewDayContext() *DayContext { return \u0026DayContext{ today: \u0026Sunday{}, } } func (d *DayContext) Today() { d.today.Today() } func (d *DayContext) Next() { d.today.Next(d) } type Sunday struct{} func (*Sunday) Today() { fmt.Printf(\"Sunday\\n\") } func (*Sunday) Next(ctx *DayContext) { ctx.today = \u0026Monday{} } type Monday struct{} func (*Monday) Today() { fmt.Printf(\"Monday\\n\") } func (*Monday) Next(ctx *DayContext) { ctx.today = \u0026Tuesday{} } type Tuesday struct{} func (*Tuesday) Today() { fmt.Printf(\"Tuesday\\n\") } func (*Tuesday) Next(ctx *DayContext) { ctx.today = \u0026Wednesday{} } type Wednesday struct{} func (*Wednesday) Today() { fmt.Printf(\"Wednesday\\n\") } func (*Wednesday) Next(ctx *DayContext) { ctx.today = \u0026Thursday{} } type Thursday struct{} func (*Thursday) Today() { fmt.Printf(\"Thursday\\n\") } func (*Thursday) Next(ctx *DayContext) { ctx.today = \u0026Friday{} } type Friday struct{} func (*Friday) Today() { fmt.Printf(\"Friday\\n\") } func (*Friday) Next(ctx *DayContext) { ctx.today = \u0026Saturday{} } type Saturday struct{} func (*Saturday) Today() { fmt.Printf(\"Saturday\\n\") } func (*Saturday) Next(ctx *DayContext) { ctx.today = \u0026Sunday{} } package state func ExampleWeek() { ctx := NewDayContext() todayAndNext := func() { ctx.Today() ctx.Next() } for i := 0; i \u003c 8; i++ { todayAndNext() } // Output: // Sunday // Monday // Tuesday // Wednesday // Thursday // Friday // Saturday // Sunday } ","date":"2022-01-22 09:20:41","objectID":"/behavioral_type/:7:0","tags":["design mode"],"title":"Behavioral_type","uri":"/behavioral_type/"},{"categories":["Coding"],"content":"memento 备忘录模式用于保存程序内部状态到外部，又不希望暴露内部状态的情形。 程序内部状态使用窄接口传递给外部进行存储，从而不暴露程序实现细节。 备忘录模式同时可以离线保存内部状态，如保存到数据库，文件等。 package memento import \"fmt\" type Memento interface{} type Game struct { hp, mp int } type gameMemento struct { hp, mp int } func (g *Game) Play(mpDelta, hpDelta int) { g.mp += mpDelta g.hp += hpDelta } func (g *Game) Save() Memento { return \u0026gameMemento{ hp: g.hp, mp: g.mp, } } func (g *Game) Load(m Memento) { gm := m.(*gameMemento) g.mp = gm.mp g.hp = gm.hp } func (g *Game) Status() { fmt.Printf(\"Current HP:%d, MP:%d\\n\", g.hp, g.mp) } package memento func ExampleGame() { game := \u0026Game{ hp: 10, mp: 10, } game.Status() progress := game.Save() game.Play(-2, -3) game.Status() game.Load(progress) game.Status() // Output: // Current HP:10, MP:10 // Current HP:7, MP:8 // Current HP:10, MP:10 } ","date":"2022-01-22 09:20:41","objectID":"/behavioral_type/:8:0","tags":["design mode"],"title":"Behavioral_type","uri":"/behavioral_type/"},{"categories":["Coding"],"content":"iterpreter 解释器模式定义一套语言文法，并设计该语言解释器，使用户能使用特定文法控制解释器行为。 解释器模式的意义在于，它分离多种复杂功能的实现，每个功能只需关注自身的解释。 对于调用者不用关心内部的解释器的工作，只需要用简单的方式组合命令就可以。 package interpreter import ( \"strconv\" \"strings\" ) type Node interface { Interpret() int } type ValNode struct { val int } func (n *ValNode) Interpret() int { return n.val } type AddNode struct { left, right Node } func (n *AddNode) Interpret() int { return n.left.Interpret() + n.right.Interpret() } type MinNode struct { left, right Node } func (n *MinNode) Interpret() int { return n.left.Interpret() - n.right.Interpret() } type Parser struct { exp []string index int prev Node } func (p *Parser) Parse(exp string) { p.exp = strings.Split(exp, \" \") for { if p.index \u003e= len(p.exp) { return } switch p.exp[p.index] { case \"+\": p.prev = p.newAddNode() case \"-\": p.prev = p.newMinNode() default: p.prev = p.newValNode() } } } func (p *Parser) newAddNode() Node { p.index++ return \u0026AddNode{ left: p.prev, right: p.newValNode(), } } func (p *Parser) newMinNode() Node { p.index++ return \u0026MinNode{ left: p.prev, right: p.newValNode(), } } func (p *Parser) newValNode() Node { v, _ := strconv.Atoi(p.exp[p.index]) p.index++ return \u0026ValNode{ val: v, } } func (p *Parser) Result() Node { return p.prev } package interpreter import \"testing\" func TestInterpreter(t *testing.T) { p := \u0026Parser{} p.Parse(\"1 + 2 + 3 - 4 + 5 - 6\") res := p.Result().Interpret() expect := 1 if res != expect { t.Fatalf(\"expect %d got %d\", expect, res) } } ","date":"2022-01-22 09:20:41","objectID":"/behavioral_type/:9:0","tags":["design mode"],"title":"Behavioral_type","uri":"/behavioral_type/"},{"categories":["Coding"],"content":"chain of responsibility 职责链模式用于分离不同职责，并且动态组合相关职责。 Golang实现职责链模式时候，因为没有继承的支持，使用链对象包涵职责的方式，即： 链对象包含当前职责对象以及下一个职责链。 职责对象提供接口表示是否能处理对应请求。 职责对象提供处理函数处理相关职责。 同时可在职责链类中实现职责接口相关函数，使职责链对象可以当做一般职责对象是用。 package chain import \"fmt\" type Manager interface { HaveRight(money int) bool HandleFeeRequest(name string, money int) bool } type RequestChain struct { Manager successor *RequestChain } func (r *RequestChain) SetSuccessor(m *RequestChain) { r.successor = m } func (r *RequestChain) HandleFeeRequest(name string, money int) bool { if r.Manager.HaveRight(money) { return r.Manager.HandleFeeRequest(name, money) } if r.successor != nil { return r.successor.HandleFeeRequest(name, money) } return false } func (r *RequestChain) HaveRight(money int) bool { return true } type ProjectManager struct{} func NewProjectManagerChain() *RequestChain { return \u0026RequestChain{ Manager: \u0026ProjectManager{}, } } func (*ProjectManager) HaveRight(money int) bool { return money \u003c 500 } func (*ProjectManager) HandleFeeRequest(name string, money int) bool { if name == \"bob\" { fmt.Printf(\"Project manager permit %s %d fee request\\n\", name, money) return true } fmt.Printf(\"Project manager don't permit %s %d fee request\\n\", name, money) return false } type DepManager struct{} func NewDepManagerChain() *RequestChain { return \u0026RequestChain{ Manager: \u0026DepManager{}, } } func (*DepManager) HaveRight(money int) bool { return money \u003c 5000 } func (*DepManager) HandleFeeRequest(name string, money int) bool { if name == \"tom\" { fmt.Printf(\"Dep manager permit %s %d fee request\\n\", name, money) return true } fmt.Printf(\"Dep manager don't permit %s %d fee request\\n\", name, money) return false } type GeneralManager struct{} func NewGeneralManagerChain() *RequestChain { return \u0026RequestChain{ Manager: \u0026GeneralManager{}, } } func (*GeneralManager) HaveRight(money int) bool { return true } func (*GeneralManager) HandleFeeRequest(name string, money int) bool { if name == \"ada\" { fmt.Printf(\"General manager permit %s %d fee request\\n\", name, money) return true } fmt.Printf(\"General manager don't permit %s %d fee request\\n\", name, money) return false } package chain func ExampleChain() { c1 := NewProjectManagerChain() c2 := NewDepManagerChain() c3 := NewGeneralManagerChain() c1.SetSuccessor(c2) c2.SetSuccessor(c3) var c Manager = c1 c.HandleFeeRequest(\"bob\", 400) c.HandleFeeRequest(\"tom\", 1400) c.HandleFeeRequest(\"ada\", 10000) c.HandleFeeRequest(\"floar\", 400) // Output: // Project manager permit bob 400 fee request // Dep manager permit tom 1400 fee request // General manager permit ada 10000 fee request // Project manager don't permit floar 400 fee request } ","date":"2022-01-22 09:20:41","objectID":"/behavioral_type/:10:0","tags":["design mode"],"title":"Behavioral_type","uri":"/behavioral_type/"},{"categories":["Coding"],"content":"visitor 访问者模式可以给一系列对象透明的添加功能，并且把相关代码封装到一个类中。 对象只要预留访问者接口Accept则后期为对象添加功能的时候就不需要改动对象。 package visitor import \"fmt\" type Customer interface { Accept(Visitor) } type Visitor interface { Visit(Customer) } type EnterpriseCustomer struct { name string } type CustomerCol struct { customers []Customer } func (c *CustomerCol) Add(customer Customer) { c.customers = append(c.customers, customer) } func (c *CustomerCol) Accept(visitor Visitor) { for _, customer := range c.customers { customer.Accept(visitor) } } func NewEnterpriseCustomer(name string) *EnterpriseCustomer { return \u0026EnterpriseCustomer{ name: name, } } func (c *EnterpriseCustomer) Accept(visitor Visitor) { visitor.Visit(c) } type IndividualCustomer struct { name string } func NewIndividualCustomer(name string) *IndividualCustomer { return \u0026IndividualCustomer{ name: name, } } func (c *IndividualCustomer) Accept(visitor Visitor) { visitor.Visit(c) } type ServiceRequestVisitor struct{} func (*ServiceRequestVisitor) Visit(customer Customer) { switch c := customer.(type) { case *EnterpriseCustomer: fmt.Printf(\"serving enterprise customer %s\\n\", c.name) case *IndividualCustomer: fmt.Printf(\"serving individual customer %s\\n\", c.name) } } // only for enterprise type AnalysisVisitor struct{} func (*AnalysisVisitor) Visit(customer Customer) { switch c := customer.(type) { case *EnterpriseCustomer: fmt.Printf(\"analysis enterprise customer %s\\n\", c.name) } } package visitor func ExampleRequestVisitor() { c := \u0026CustomerCol{} c.Add(NewEnterpriseCustomer(\"A company\")) c.Add(NewEnterpriseCustomer(\"B company\")) c.Add(NewIndividualCustomer(\"bob\")) c.Accept(\u0026ServiceRequestVisitor{}) // Output: // serving enterprise customer A company // serving enterprise customer B company // serving individual customer bob } func ExampleAnalysis() { c := \u0026CustomerCol{} c.Add(NewEnterpriseCustomer(\"A company\")) c.Add(NewIndividualCustomer(\"bob\")) c.Add(NewEnterpriseCustomer(\"B company\")) c.Accept(\u0026AnalysisVisitor{}) // Output: // analysis enterprise customer A company // analysis enterprise customer B company } 参考 ","date":"2022-01-22 09:20:41","objectID":"/behavioral_type/:11:0","tags":["design mode"],"title":"Behavioral_type","uri":"/behavioral_type/"},{"categories":["Coding"],"content":"simple factory go 语言没有构造函数一说，所以一般会定义NewXXX函数来初始化相关类。 NewXXX 函数根据参数返回不同接口时就是简单工厂模式。 在这个simplefactory包中只有API 接口和NewAPI函数为包外可见，封装了实现细节。 package simplefactory import \"fmt\" //API is interface type API interface { Say(name string) string } //NewAPI return Api instance by type func NewAPI(t int) API { if t == 1 { return \u0026hiAPI{} } else if t == 2 { return \u0026helloAPI{} } return nil } //hiAPI is one of API implement type hiAPI struct{} //Say hi to name func (*hiAPI) Say(name string) string { return fmt.Sprintf(\"Hi, %s\", name) } //HelloAPI is another API implement type helloAPI struct{} //Say hello to name func (*helloAPI) Say(name string) string { return fmt.Sprintf(\"Hello, %s\", name) } package simplefactory import \"testing\" //TestType1 test get hiapi with factory func TestType1(t *testing.T) { api := NewAPI(1) s := api.Say(\"Tom\") if s != \"Hi, Tom\" { t.Fatal(\"Type1 test fail\") } } func TestType2(t *testing.T) { api := NewAPI(2) s := api.Say(\"Tom\") if s != \"Hello, Tom\" { t.Fatal(\"Type2 test fail\") } } ","date":"2022-01-22 09:19:30","objectID":"/create_type/:1:0","tags":["design mode"],"title":"Create_type","uri":"/create_type/"},{"categories":["Coding"],"content":"factory method 工厂方法模式使用子类的方式延迟生成对象到子类中实现。 Go中不存在继承 所以使用匿名组合来实现 package factorymethod //Operator 是被封装的实际类接口 type Operator interface { SetA(int) SetB(int) Result() int } //OperatorFactory 是工厂接口 type OperatorFactory interface { Create() Operator } //OperatorBase 是Operator 接口实现的基类，封装公用方法 type OperatorBase struct { a, b int } //SetA 设置 A func (o *OperatorBase) SetA(a int) { o.a = a } //SetB 设置 B func (o *OperatorBase) SetB(b int) { o.b = b } //PlusOperatorFactory 是 PlusOperator 的工厂类 type PlusOperatorFactory struct{} func (PlusOperatorFactory) Create() Operator { return \u0026PlusOperator{ OperatorBase: \u0026OperatorBase{}, } } //PlusOperator Operator 的实际加法实现 type PlusOperator struct { *OperatorBase } //Result 获取结果 func (o PlusOperator) Result() int { return o.a + o.b } //MinusOperatorFactory 是 MinusOperator 的工厂类 type MinusOperatorFactory struct{} func (MinusOperatorFactory) Create() Operator { return \u0026MinusOperator{ OperatorBase: \u0026OperatorBase{}, } } //MinusOperator Operator 的实际减法实现 type MinusOperator struct { *OperatorBase } //Result 获取结果 func (o MinusOperator) Result() int { return o.a - o.b } package factorymethod import \"testing\" func compute(factory OperatorFactory, a, b int) int { op := factory.Create() op.SetA(a) op.SetB(b) return op.Result() } func TestOperator(t *testing.T) { var ( factory OperatorFactory ) factory = PlusOperatorFactory{} if compute(factory, 1, 2) != 3 { t.Fatal(\"error with factory method pattern\") } factory = MinusOperatorFactory{} if compute(factory, 4, 2) != 2 { t.Fatal(\"error with factory method pattern\") } } ","date":"2022-01-22 09:19:30","objectID":"/create_type/:2:0","tags":["design mode"],"title":"Create_type","uri":"/create_type/"},{"categories":["Coding"],"content":"abstract factory 抽象工厂模式用于生成产品族的工厂，所生成的对象是有关联的。 如果抽象工厂退化成生成的对象无关联则成为工厂函数模式。 比如本例子中使用RDB和XML存储订单信息，抽象工厂分别能生成相关的主订单信息和订单详情信息。 如果业务逻辑中需要替换使用的时候只需要改动工厂函数相关的类就能替换使用不同的存储方式了。 package abstractfactory import \"fmt\" //OrderMainDAO 为订单主记录 type OrderMainDAO interface { SaveOrderMain() } //OrderDetailDAO 为订单详情纪录 type OrderDetailDAO interface { SaveOrderDetail() } //DAOFactory DAO 抽象模式工厂接口 type DAOFactory interface { CreateOrderMainDAO() OrderMainDAO CreateOrderDetailDAO() OrderDetailDAO } //RDBMainDAP 为关系型数据库的OrderMainDAO实现 type RDBMainDAO struct{} //SaveOrderMain ... func (*RDBMainDAO) SaveOrderMain() { fmt.Print(\"rdb main save\\n\") } //RDBDetailDAO 为关系型数据库的OrderDetailDAO实现 type RDBDetailDAO struct{} // SaveOrderDetail ... func (*RDBDetailDAO) SaveOrderDetail() { fmt.Print(\"rdb detail save\\n\") } //RDBDAOFactory 是RDB 抽象工厂实现 type RDBDAOFactory struct{} func (*RDBDAOFactory) CreateOrderMainDAO() OrderMainDAO { return \u0026RDBMainDAO{} } func (*RDBDAOFactory) CreateOrderDetailDAO() OrderDetailDAO { return \u0026RDBDetailDAO{} } //XMLMainDAO XML存储 type XMLMainDAO struct{} //SaveOrderMain ... func (*XMLMainDAO) SaveOrderMain() { fmt.Print(\"xml main save\\n\") } //XMLDetailDAO XML存储 type XMLDetailDAO struct{} // SaveOrderDetail ... func (*XMLDetailDAO) SaveOrderDetail() { fmt.Print(\"xml detail save\") } //XMLDAOFactory 是RDB 抽象工厂实现 type XMLDAOFactory struct{} func (*XMLDAOFactory) CreateOrderMainDAO() OrderMainDAO { return \u0026XMLMainDAO{} } func (*XMLDAOFactory) CreateOrderDetailDAO() OrderDetailDAO { return \u0026XMLDetailDAO{} } package abstractfactory func getMainAndDetail(factory DAOFactory) { factory.CreateOrderMainDAO().SaveOrderMain() factory.CreateOrderDetailDAO().SaveOrderDetail() } func ExampleRdbFactory() { var factory DAOFactory factory = \u0026RDBDAOFactory{} getMainAndDetail(factory) // Output: // rdb main save // rdb detail save } func ExampleXmlFactory() { var factory DAOFactory factory = \u0026XMLDAOFactory{} getMainAndDetail(factory) // Output: // xml main save // xml detail save } ","date":"2022-01-22 09:19:30","objectID":"/create_type/:3:0","tags":["design mode"],"title":"Create_type","uri":"/create_type/"},{"categories":["Coding"],"content":"builder package builder //Builder 是生成器接口 type Builder interface { Part1() Part2() Part3() } type Director struct { builder Builder } // NewDirector ... func NewDirector(builder Builder) *Director { return \u0026Director{ builder: builder, } } //Construct Product func (d *Director) Construct() { d.builder.Part1() d.builder.Part2() d.builder.Part3() } type Builder1 struct { result string } func (b *Builder1) Part1() { b.result += \"1\" } func (b *Builder1) Part2() { b.result += \"2\" } func (b *Builder1) Part3() { b.result += \"3\" } func (b *Builder1) GetResult() string { return b.result } type Builder2 struct { result int } func (b *Builder2) Part1() { b.result += 1 } func (b *Builder2) Part2() { b.result += 2 } func (b *Builder2) Part3() { b.result += 3 } func (b *Builder2) GetResult() int { return b.result } package builder import \"testing\" func TestBuilder1(t *testing.T) { builder := \u0026Builder1{} director := NewDirector(builder) director.Construct() res := builder.GetResult() if res != \"123\" { t.Fatalf(\"Builder1 fail expect 123 acture %s\", res) } } func TestBuilder2(t *testing.T) { builder := \u0026Builder2{} director := NewDirector(builder) director.Construct() res := builder.GetResult() if res != 6 { t.Fatalf(\"Builder2 fail expect 6 acture %d\", res) } } ","date":"2022-01-22 09:19:30","objectID":"/create_type/:4:0","tags":["design mode"],"title":"Create_type","uri":"/create_type/"},{"categories":["Coding"],"content":"prototype 原型模式使对象能复制自身，并且暴露到接口中，使客户端面向接口编程时，不知道接口实际对象的情况下生成新的对象。 原型模式配合原型管理器使用，使得客户端在不知道具体类的情况下，通过接口管理器得到新的实例，并且包含部分预设定配置。 package prototype //Cloneable 是原型对象需要实现的接口 type Cloneable interface { Clone() Cloneable } type PrototypeManager struct { prototypes map[string]Cloneable } func NewPrototypeManager() *PrototypeManager { return \u0026PrototypeManager{ prototypes: make(map[string]Cloneable), } } func (p *PrototypeManager) Get(name string) Cloneable { return p.prototypes[name].Clone() } func (p *PrototypeManager) Set(name string, prototype Cloneable) { p.prototypes[name] = prototype } package prototype import \"testing\" var manager *PrototypeManager type Type1 struct { name string } func (t *Type1) Clone() Cloneable { tc := *t return \u0026tc } type Type2 struct { name string } func (t *Type2) Clone() Cloneable { tc := *t return \u0026tc } func TestClone(t *testing.T) { t1 := manager.Get(\"t1\") t2 := t1.Clone() if t1 == t2 { t.Fatal(\"error! get clone not working\") } } func TestCloneFromManager(t *testing.T) { c := manager.Get(\"t1\").Clone() t1 := c.(*Type1) if t1.name != \"type1\" { t.Fatal(\"error\") } } func init() { manager = NewPrototypeManager() t1 := \u0026Type1{ name: \"type1\", } manager.Set(\"t1\", t1) } ","date":"2022-01-22 09:19:30","objectID":"/create_type/:5:0","tags":["design mode"],"title":"Create_type","uri":"/create_type/"},{"categories":["Coding"],"content":"singleton 使用懒惰模式的单例模式，使用双重检查加锁保证线程安全 package singleton import \"sync\" // Singleton 是单例模式接口，导出的 // 通过该接口可以避免 GetInstance 返回一个包私有类型的指针 type Singleton interface { foo() } // singleton 是单例模式类，包私有的 type singleton struct{} func (s singleton) foo() {} var ( instance *singleton once sync.Once ) //GetInstance 用于获取单例模式对象 func GetInstance() Singleton { once.Do(func() { instance = \u0026singleton{} }) return instance } package singleton import ( \"sync\" \"testing\" ) const parCount = 100 func TestSingleton(t *testing.T) { ins1 := GetInstance() ins2 := GetInstance() if ins1 != ins2 { t.Fatal(\"instance is not equal\") } } func TestParallelSingleton(t *testing.T) { start := make(chan struct{}) wg := sync.WaitGroup{} wg.Add(parCount) instances := [parCount]Singleton{} for i := 0; i \u003c parCount; i++ { go func(index int) { //协程阻塞，等待channel被关闭才能继续运行 \u003c-start instances[index] = GetInstance() wg.Done() }(i) } //关闭channel，所有协程同时开始运行，实现并行(parallel) close(start) wg.Wait() for i := 1; i \u003c parCount; i++ { if instances[i] != instances[i-1] { t.Fatal(\"instance is not equal\") } } } 参考 ","date":"2022-01-22 09:19:30","objectID":"/create_type/:6:0","tags":["design mode"],"title":"Create_type","uri":"/create_type/"},{"categories":["Catalogue","Coding"],"content":" 学习代码随想录笔记 ","date":"2022-01-19 10:06:22","objectID":"/algo_catalogue/:0:0","tags":["catalogue","data structure"],"title":"Algo_catalogue","uri":"/algo_catalogue/"},{"categories":["Catalogue","Coding"],"content":"algorithm_array algorithm_backTracking algorithm_binaryTree algorithm_doublePointer algorithm_dp algorithm_find algorithm_greedy algorithm_hashTable algorithm_linkedList algorithm_sort algorithm_stackAndQueue algorithm_string ","date":"2022-01-19 10:06:22","objectID":"/algo_catalogue/:1:0","tags":["catalogue","data structure"],"title":"Algo_catalogue","uri":"/algo_catalogue/"},{"categories":["Go"],"content":"常用标准库 ","date":"2022-01-12 22:17:07","objectID":"/go_base_09/:0:0","tags":["go grammar"],"title":"Go_base_09","uri":"/go_base_09/"},{"categories":["Go"],"content":"前言 ","date":"2022-01-12 22:17:07","objectID":"/go_base_09/:1:0","tags":["go grammar"],"title":"Go_base_09","uri":"/go_base_09/"},{"categories":["Go"],"content":"包复用 package: 基本复⽤模块单元：以⾸字⺟⼤写来表明可被包外代码访问 代码的 package 可以和所在的⽬录不⼀致 同⼀⽬录⾥的 Go 代码的 package 要保持⼀致 ","date":"2022-01-12 22:17:07","objectID":"/go_base_09/:1:1","tags":["go grammar"],"title":"Go_base_09","uri":"/go_base_09/"},{"categories":["Go"],"content":"依赖管理 Go 未解决的依赖问题： 同⼀环境下，不同项⽬使⽤同⼀包的不同版本 ⽆法管理对包的特定版本的依赖 vendor 路径 随着 Go 1.5 release 版本的发布，vendor ⽬录被添加到除了 GOPATH 和GOROOT 之外的依赖⽬录查找的解决⽅案。在 Go 1.6 之前，你需要⼿动的设置环境变量查找依赖包路径的解决⽅案如下： 当前包下的 vendor ⽬录 向上级⽬录查找，直到找到 src 下的 vendor ⽬录 在 GOPATH 下⾯查找依赖包 在 GOROOT ⽬录下查找 常用依赖管理工具： godep glide dep ","date":"2022-01-12 22:17:07","objectID":"/go_base_09/:1:2","tags":["go grammar"],"title":"Go_base_09","uri":"/go_base_09/"},{"categories":["Go"],"content":"fmt ","date":"2022-01-12 22:17:07","objectID":"/go_base_09/:2:0","tags":["go grammar"],"title":"Go_base_09","uri":"/go_base_09/"},{"categories":["Go"],"content":"Time ","date":"2022-01-12 22:17:07","objectID":"/go_base_09/:3:0","tags":["go grammar"],"title":"Go_base_09","uri":"/go_base_09/"},{"categories":["Go"],"content":"Flag ","date":"2022-01-12 22:17:07","objectID":"/go_base_09/:4:0","tags":["go grammar"],"title":"Go_base_09","uri":"/go_base_09/"},{"categories":["Go"],"content":"Log ","date":"2022-01-12 22:17:07","objectID":"/go_base_09/:5:0","tags":["go grammar"],"title":"Go_base_09","uri":"/go_base_09/"},{"categories":["Go"],"content":"IO操作 ","date":"2022-01-12 22:17:07","objectID":"/go_base_09/:6:0","tags":["go grammar"],"title":"Go_base_09","uri":"/go_base_09/"},{"categories":["Go"],"content":"Strconv ","date":"2022-01-12 22:17:07","objectID":"/go_base_09/:7:0","tags":["go grammar"],"title":"Go_base_09","uri":"/go_base_09/"},{"categories":["Go"],"content":"Template ","date":"2022-01-12 22:17:07","objectID":"/go_base_09/:8:0","tags":["go grammar"],"title":"Go_base_09","uri":"/go_base_09/"},{"categories":["Go"],"content":"Http ","date":"2022-01-12 22:17:07","objectID":"/go_base_09/:9:0","tags":["go grammar"],"title":"Go_base_09","uri":"/go_base_09/"},{"categories":["Go"],"content":"Context ","date":"2022-01-12 22:17:07","objectID":"/go_base_09/:10:0","tags":["go grammar"],"title":"Go_base_09","uri":"/go_base_09/"},{"categories":["Go"],"content":"数据格式 ","date":"2022-01-12 22:17:07","objectID":"/go_base_09/:11:0","tags":["go grammar"],"title":"Go_base_09","uri":"/go_base_09/"},{"categories":["Go"],"content":"反射和unsafe ","date":"2022-01-12 22:17:07","objectID":"/go_base_09/:12:0","tags":["go grammar"],"title":"Go_base_09","uri":"/go_base_09/"},{"categories":["Go"],"content":"反射编程 反射是指在程序运行期对程序本身进行访问和修改的能力 变量的内在机制 变量包含类型信息和值信息 var arr [10]int arr[0] = 10 类型信息：是静态的元信息，是预先定义好的 值信息：是程序运行过程中动态改变的 反射的使用 reflect包封装了反射相关的方法 获取类型信息：reflect.TypeOf，是静态的 获取值信息：reflect.ValueOf，是动态的 空接口与反射 反射可以在运行时动态获取程序的各种详细信息 反射获取interface类型信息 package main import ( \"fmt\" \"reflect\" ) //反射获取interface类型信息 func reflect_type(a interface{}) { t := reflect.TypeOf(a) fmt.Println(\"类型是：\", t) // kind()可以获取具体类型 k := t.Kind() fmt.Println(k) switch k { case reflect.Float64: fmt.Printf(\"a is float64\\n\") case reflect.String: fmt.Println(\"string\") } } func main() { var x float64 = 3.4 reflect_type(x) } 反射获取interface值信息 package main import ( \"fmt\" \"reflect\" ) //反射获取interface值信息 func reflect_value(a interface{}) { v := reflect.ValueOf(a) fmt.Println(v) k := v.Kind() fmt.Println(k) switch k { case reflect.Float64: fmt.Println(\"a是：\", v.Float()) } } func main() { var x float64 = 3.4 reflect_value(x) } 反射修改值信息 package main import ( \"fmt\" \"reflect\" ) //反射修改值 func reflect_set_value(a interface{}) { v := reflect.ValueOf(a) k := v.Kind() switch k { case reflect.Float64: // 反射修改值 v.SetFloat(6.9) fmt.Println(\"a is \", v.Float()) case reflect.Ptr: // Elem()获取地址指向的值 v.Elem().SetFloat(7.9) fmt.Println(\"case:\", v.Elem().Float()) // 地址 fmt.Println(v.Pointer()) } } func main() { var x float64 = 3.4 // 反射认为下面是指针类型，不是float类型 reflect_set_value(\u0026x) fmt.Println(\"main:\", x) } 结构体与反射 查看类型字段和方法 package main import ( \"fmt\" \"reflect\" ) // 定义结构体 type User struct { Id int Name string Age int } // 绑方法 func (u User) Hello() { fmt.Println(\"Hello\") } // 传入interface{} func Poni(o interface{}) { t := reflect.TypeOf(o) fmt.Println(\"类型：\", t) fmt.Println(\"字符串类型：\", t.Name()) // 获取值 v := reflect.ValueOf(o) fmt.Println(v) // 可以获取所有属性 // 获取结构体字段个数：t.NumField() for i := 0; i \u003c t.NumField(); i++ { // 取每个字段 f := t.Field(i) fmt.Printf(\"%s : %v\", f.Name, f.Type) // 获取字段的值信息 // Interface()：获取字段对应的值 val := v.Field(i).Interface() fmt.Println(\"val :\", val) } fmt.Println(\"=================方法====================\") for i := 0; i \u003c t.NumMethod(); i++ { m := t.Method(i) fmt.Println(m.Name) fmt.Println(m.Type) } } func main() { u := User{1, \"zs\", 20} Poni(u) } 查看匿名字段 package main import ( \"fmt\" \"reflect\" ) // 定义结构体 type User struct { Id int Name string Age int } // 匿名字段 type Boy struct { User Addr string } func main() { m := Boy{User{1, \"zs\", 20}, \"bj\"} t := reflect.TypeOf(m) fmt.Println(t) // Anonymous：匿名 fmt.Printf(\"%#v\\n\", t.Field(0)) // 值信息 fmt.Printf(\"%#v\\n\", reflect.ValueOf(m).Field(0)) } 修改结构体的值： package main import ( \"fmt\" \"reflect\" ) // 定义结构体 type User struct { Id int Name string Age int } // 修改结构体值 func SetValue(o interface{}) { v := reflect.ValueOf(o) // 获取指针指向的元素 v = v.Elem() // 取字段 f := v.FieldByName(\"Name\") if f.Kind() == reflect.String { f.SetString(\"kuteng\") } } func main() { u := User{1, \"5lmh.com\", 20} SetValue(\u0026u) fmt.Println(u) } 调用方法 package main import ( \"fmt\" \"reflect\" ) // 定义结构体 type User struct { Id int Name string Age int } func (u User) Hello(name string) { fmt.Println(\"Hello：\", name) } func main() { u := User{1, \"5lmh.com\", 20} v := reflect.ValueOf(u) // 获取方法 m := v.MethodByName(\"Hello\") // 构建一些参数 args := []reflect.Value{reflect.ValueOf(\"6666\")} // 没参数的情况下：var args2 []reflect.Value // 调用方法，需要传入方法的参数 m.Call(args) } 获取字段的tag package main import ( \"fmt\" \"reflect\" ) type Student struct { Name string `json:\"name1\" db:\"name2\"` } func main() { var s Student v := reflect.ValueOf(\u0026s) // 类型 t := v.Type() // 获取字段 f := t.Elem().Field(0) fmt.Println(f.Tag.Get(\"json\")) fmt.Println(f.Tag.Get(\"db\")) } 万能程序 DeepEqual比较切片和map func TestDeepEqual(t *testing.T) { a := map[int]string{1: \"one\", 2: \"two\", 3: \"three\"} b := map[int]string{1: \"one\", 2: \"two\", 3: \"three\"} // t.Log(a == b) t.Log(\"a==b?\", reflect.DeepEqual(a, b)) s1 := []int{1, 2, 3} s2 := []int{1, 2, 3} s3 := []int{2, 3, 1} t.Log(\"s1 == s2?\", reflect.DeepEqual(s1, s2)) t.Log(\"s1 == s3?\", reflect.DeepEqual(s1, s3)) c1 := Customer{\"1\", \"Mike\", 40} c2 := Customer{\"1\", \"Mike\", 40} fmt.Println(c1 == c2) fmt.Println(reflect.DeepEqual(c1, c2","date":"2022-01-12 22:17:07","objectID":"/go_base_09/:12:1","tags":["go grammar"],"title":"Go_base_09","uri":"/go_base_09/"},{"categories":["Go"],"content":"文件操作 ","date":"2022-01-12 22:17:07","objectID":"/go_base_09/:13:0","tags":["go grammar"],"title":"Go_base_09","uri":"/go_base_09/"},{"categories":["Go"],"content":"go module ","date":"2022-01-12 22:17:07","objectID":"/go_base_09/:14:0","tags":["go grammar"],"title":"Go_base_09","uri":"/go_base_09/"},{"categories":["Go"],"content":"String ","date":"2022-01-12 22:17:07","objectID":"/go_base_09/:15:0","tags":["go grammar"],"title":"Go_base_09","uri":"/go_base_09/"},{"categories":["Go"],"content":" 参考学习go语言中文网、C语言中文网、golang官方文档等 ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:0:0","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"前言 计算机里的数据都是以字节形式进行存储和处理，从而需要编码来表达信息。ASCII是简单字符集编码模型，定义了这个字符集里包含的字符以及其映射成的8位比特值。 关于现代编码模型： 一个字符如何映射成有限长度的比特值？ 需要表示字符的范围–字符表（character repertoire） CR映射到一个整数集，称映射为编码字符集（coded character set），也就是Unicode的概念，那些整数称为码点（code point） 将CCS里的整数映射成有限长度的比特值，这个对应关系称为字符编码方式或字符编码表（character encoding form），比如UTF-8，UTF-16。（Unicode Transformation Format，8或者16是指码元的大小，码元是一个已编码文本中具有最短的比特组合的单元，即最小单位是一个字节或者两个字节） UTF-8是完全兼容ASCII的，多字节表示一个字符时Unicode码点范围以及对应的bit组合： 一字节：U+00~U+7F————–UTF-8字节流（二进制）：0xxxxxxx 二字节：U+80~U+7FF————-UTF-8字节流（二进制）：110xxxxx 10xxxxxx 三字节：U+800~U+7FFF———–UTF-8字节流（二进制）：1110xxxx 10xxxxxx 10xxxxxx 四字节：U+10000~U+10FFFF——-UTF-8字节流（二进制）：11110xxx 10xxxxxx 10xxxxxx 10xxxxxx 汉字大多是三字节 关于Unicode和UTF-8： func TestString(t *testing.T) { var s string t.Log(s) //初始化为默认零值“” s = \"hello\" t.Log(len(s)) //s[1] = '3' //string是不可变的byte slice //s = \"\\xE4\\xB8\\xA5\" //可以存储任何二进制数据 s = \"\\xE4\\xBA\\xBB\\xFF\" t.Log(s) t.Log(len(s)) s = \"中\" t.Log(len(s)) //是byte数 c := []rune(s) t.Log(len(c)) // t.Log(\"rune size:\", unsafe.Sizeof(c[0])) t.Logf(\"中 unicode %x\", c[0]) t.Logf(\"中 UTF8 %x\", s) } Running tool: D:\\go\\bin\\go.exe test -timeout 30s -run ^TestString$ code/code/ch9/string === RUN TestString d:\\Go\\Go_WorkSpace\\go_learning-master\\code\\ch9\\string\\string_test.go:9: d:\\Go\\Go_WorkSpace\\go_learning-master\\code\\ch9\\string\\string_test.go:11: 5 d:\\Go\\Go_WorkSpace\\go_learning-master\\code\\ch9\\string\\string_test.go:15: 亻� d:\\Go\\Go_WorkSpace\\go_learning-master\\code\\ch9\\string\\string_test.go:16: 4 d:\\Go\\Go_WorkSpace\\go_learning-master\\code\\ch9\\string\\string_test.go:18: 3 d:\\Go\\Go_WorkSpace\\go_learning-master\\code\\ch9\\string\\string_test.go:21: 1 d:\\Go\\Go_WorkSpace\\go_learning-master\\code\\ch9\\string\\string_test.go:23: 中 unicode 4e2d d:\\Go\\Go_WorkSpace\\go_learning-master\\code\\ch9\\string\\string_test.go:24: 中 UTF8 e4b8ad --- PASS: TestString (0.00s) PASS ok code/code/ch9/string 0.514s ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:1:0","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"go起源 07年 三位大牛 解决三个困难：多核硬件架构、超大规模的分布式计算集群、如今使用的web开发模式导致的前所未有的开发规模和更新速度 Go 官方下载站点是 golang.org/dl，但我们可以用针对中国大陆的镜像站点 golang.google.cn/dl 来下载 ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:2:0","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"主要特征 自动立即回收。(自带GC) 更丰富的内置类型。 函数多返回值。 错误处理。 匿名函数和闭包。 类型和接口。 并发编程。 反射。 有复合，无继承（因为复合大于继承，干脆不要继承） Go的函数、变量、常量、自定义类型、包(package)的命名方式遵循以下规则： 1）首字符可以是任意的Unicode字符（一种字符集，一个字符两个字节，表示包括了每种语言）或者下划线 2）剩余字符可以是Unicode字符、下划线、数字 3）字符长度不限 25关键字： break default func interface select case defer go map struct chan else goto package switch const fallthrough if range type continue for import return var select和switch:select只能应用于channel的操作，既可以用于channel的数据接收，也可以用于channel的数据发送。如果select的多个分支都满足条件，则会随机的选取其中一个满足条件的分支。而switch用于一般的分支判断，顺序执行。 continue 如果循环体中的代码执行到一半，要中断当前迭代，忽略此迭代循环体中的后续代码（循环后置语句eg:x++不会被忽略），并回到 for 循环条件判断，尝试开启下一次迭代,使用continue关键字。 看上去好像和C没区别，其实Go的continue增加了对lable的支持，label 语句的作用，是标记跳转的目标。在中断内层 for 循环，回到外层 for 循环继续执行的场景应用比较合适 func main() { var sum int var sl = []int{1, 2, 3, 4, 5, 6} loop: for i := 0; i \u003c len(sl); i++ { if sl[i]%2 == 0 { // 忽略切片中值为偶数的元素 continue loop } sum += sl[i] } println(sum) // 9 } 注意与goto的区别： 一旦使用 goto 跳转，那么不管是内层循环还是外层循环都会被终结，代码将会从 outerloop 这个 label 处，开始重新执行我们的嵌套循环语句，这与带 label 的 continue 的跳转语义是完全不同的。 goto 是一种公认的、难于驾驭的语法元素，应用 goto 的代码可读性差、代码难于维护还易错。而 Go 语言保留了 goto，具体我不得而知 break Go 语言规范中明确规定，不带 label 的 break 语句中断执行并跳出的，是同一函数内 break 语句所在的最内层的 for、switch 或 select package main import \"time\" import \"fmt\" func main() { c1 := make(chan string) c2 := make(chan string) go func() { time.Sleep(time.Second * 1) c1 \u003c- \"one\" }() go func() { time.Sleep(time.Second * 2) c2 \u003c- \"two\" }() for i := 0; i \u003c 2; i++ { select { case msg1 := \u003c-c1: fmt.Println(\"received\", msg1) case msg2 := \u003c-c2: fmt.Println(\"received\", msg2) } } } fallthrough:可以使用fallthrough强制执行该case执行完下一条case代码，fallthrough不会判断下一条case的判断结果是否为true。 37个保留字： Constants: true false iota nil Types: int int8 int16 int32 int64 uint uint8 uint16 uint32 uint64 uintptr float32 float64 complex128 complex64 bool byte rune string error Functions: make len cap new append copy close delete complex real imag panic recover new\u0026make func new(Type) *Type func make(t Type, size …IntegerType) Type go声明：var,const,type,func ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:3:0","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"内置类型与函数 值类型： bool int(32 or 64), int8, int16, int32, int64 uint(32 or 64), uint8(byte), uint16, uint32, uint64 float32, float64 string complex64, complex128 array 引用类型（声明的同时需要分配内存空间，不然会引发panic，分配内存可以用new或者make）： slice map chan …… 内置函数（无需导入即可使用）: append -- 用来追加元素到数组、slice中,返回修改后的数组、slice close -- 主要用来关闭channel delete -- 从map中删除key对应的value panic -- 停止常规的goroutine （panic和recover：用来做错误处理） recover -- 允许程序定义goroutine的panic动作 real -- 返回complex的实部 （complex、real imag：用于创建和操作复数） imag -- 返回complex的虚部 make -- 用来分配内存，返回Type本身(只能应用于slice, map, channel) make 函数允许在运行期动态指定数组长度，绕开了数组类型必须使用编译期常量的限制。 new -- 用来分配内存，主要用来分配值类型，比如int、struct。返回指向Type的指针 cap -- capacity用于返回某个类型的最大容量（只能用于切片和 map） copy -- 用于复制和连接slice，返回复制的数目，copy(a,b) 只有 min(len(a),len(b))个元素会被成功拷贝。 len -- 用来求长度，比如string、array、slice、map、channel ，返回长度 print、println -- 底层打印函数，在部署环境中建议使用 fmt 包 内置接口error： type error interface { //只要实现了Error()函数，返回值为String的都实现了err接口（鸭子类型） Error() String } ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:4:0","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"init \u0026 main 以及Go包的初始化顺序 go语言中init函数用于包(package)的初始化，该函数是go语言的一个重要特性。有下面的特征： init函数是用于程序执行前做包的初始化的函数，比如初始化包里的变量等 每个包可以拥有多个init函数 包的每个源文件也可以拥有多个init函数 同一个包中多个init函数的执行顺序go语言没有明确的定义(说明) 不同包的init函数按照包导入的依赖关系决定该初始化函数的执行顺序 init函数不能被其他函数调用，而是在main函数执行之前，自动被调用 init()函数的用途： 重置包级变量值，对包内部以及暴露到外部的包级数据（主要是包级变量）的初始状态进行检查 实现对包级变量的复杂初始化，有些包级变量需要一个比较复杂的初始化过程，使用init()比较合适 在 init 函数中实现“注册模式”，如下 import ( \"database/sql\" _ \"github.com/lib/pq\" ) func main() { db, err := sql.Open(\"postgres\", \"user=pqgotest dbname=pqgotest sslmode=verify-full\") if err != nil { log.Fatal(err) } age := 21 rows, err := db.Query(\"SELECT name FROM users WHERE age = $1\", age) ... } //pq包的init() func init() { sql.Register(\"postgres\", \u0026Driver{}) } pq 包将自己实现的 sql 驱动注册到了 sql 包中。这样只要应用层代码在 Open 数据库的时候，传入驱动的名字（这里是“postgres”)，那么通过 sql.Open 函数，返回的数据库实例句柄对数据库进行的操作，实际上调用的都是 pq 包中相应的驱动实现。 从标准库 database/sql 包的角度来看，这种“注册模式”实质是一种工厂设计模式的实现，sql.Open 函数就是这个模式中的工厂方法，它根据外部传入的驱动名称“生产”出不同类别的数据库实例句柄。 这种“注册模式”在标准库的其他包中也有广泛应用，比如说，使用标准库 image 包获取各种格式图片的宽和高： package main import ( \"fmt\" \"image\" _ \"image/gif\" // 以空导入方式注入gif图片格式驱动 _ \"image/jpeg\" // 以空导入方式注入jpeg图片格式驱动 _ \"image/png\" // 以空导入方式注入png图片格式驱动 \"os\" ) func main() { // 支持png, jpeg, gif width, height, err := imageSize(os.Args[1]) // 获取传入的图片文件的宽与高 if err != nil { fmt.Println(\"get image size error:\", err) return } fmt.Printf(\"image size: [%d, %d]\\n\", width, height) } func imageSize(imageFile string) (int, int, error) { f, _ := os.Open(imageFile) // 打开图文文件 defer f.Close() img, _, err := image.Decode(f) // 对文件进行解码，得到图片实例 if err != nil { return 0, 0, err } b := img.Bounds() // 返回图片区域 return b.Max.X, b.Max.Y, nil } // $GOROOT/src/image/png/reader.go func init() { image.RegisterFormat(\"png\", pngHeader, Decode, DecodeConfig) } // $GOROOT/src/image/jpeg/reader.go func init() { image.RegisterFormat(\"jpeg\", \"\\xff\\xd8\", Decode, DecodeConfig) } // $GOROOT/src/image/gif/reader.go func init() { image.RegisterFormat(\"gif\", \"GIF8?a\", Decode, DecodeConfig) } Go语言程序的默认入口函数(主函数)： func main(){ …… //通过os.Args获取参数eg:os.Args[0] //不支持返回值，可以通过os.Exit()来返回状态 } 在启动了多个 Goroutine 的 Go 应用中，main.main 函数将在 Go 应用的主 Goroutine 中执行。 init函数和main函数的异同： 同 两个函数在定义时不能有任何的参数和返回值，且Go程序自动调用。 异 init可以应用于任意包中，且可以重复定义多个。 main函数只能用于main包中，且只能定义一个。 init()执行顺序： 对同一个go文件的init()调用顺序是从上到下的。 对同一个package中不同文件是按文件名字符串比较“从小到大”顺序调用各文件中的init()函数。 对于不同的package，如果不相互依赖的话，按照main包中”先import的后调用”的顺序调用其包中的init()，如果package存在依赖，则先调用最早被依赖的package中的init()，最后调用main函数。 同一个包被多次调用只会执行一次init()函数 如果init函数中使用了println()或者print()你会发现在执行过程中这两个不会按照你想象中的顺序执行。这两个函数官方只推荐在测试环境中使用，对于正式环境不要使用。 Go包初始化：从main包开始按照深度优先初始化main包的依赖包，初始化一个包时的顺序是初始化依赖包、常量、变量、init()，回到main包时同样初始化常量、变量、init()，再执行main()函数。 ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:5:0","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"go命令 PS D:\\Blog\\qizhengzou.github.io-blog\\content\\posts\u003e go Go is a tool for managing Go source code. Usage: go \u003ccommand\u003e [arguments] The commands are: bug start a bug report build compile packages and dependencies clean remove object files and cached files doc show documentation for package or symbol env print Go environment information fix update packages to use new APIs fmt gofmt (reformat) package sources generate generate Go files by processing source get add dependencies to current module and install them install compile and install packages and dependencies list list packages or modules mod module maintenance run compile and run Go program test test packages tool run specified go tool version print Go version vet report likely mistakes in packages Use \"go help \u003ccommand\u003e\" for more information about a command. Additional help topics: buildconstraint build constraints buildmode build modes c calling between Go and C cache build and test caching environment environment variables filetype file types go.mod the go.mod file gopath GOPATH environment variable gopath-get legacy GOPATH go get goproxy module proxy protocol importpath import path syntax modules modules, module versions, and more module-get module-aware go get module-auth module authentication using go.sum packages package lists and patterns private configuration for downloading non-public code testflag testing flags testfunc testing functions vcs controlling version control with GOVCS Use \"go help \u003ctopic\u003e\" for more information about that topic. ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:6:0","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"go env 用于打印Go语言的环境信息。 ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:6:1","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"go run命令 可以编译并运行命令源码文件。 ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:6:2","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"go get 可以根据要求和实际情况从互联网上下载或更新指定的代码包及其依赖包，并对它们进行编译和安装。 ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:6:3","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"go build命令 用于编译我们指定的源码文件或代码包以及它们的依赖包。 ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:6:4","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"go install 用于编译并安装指定的代码包及它们的依赖包。 ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:6:5","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"go clean命令 会删除掉执行其它命令时产生的一些文件和目录。 ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:6:6","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"go doc命令 可以打印附于Go语言程序实体上的文档。我们可以通过把程序实体的标识符作为该命令的参数来达到查看其文档的目的。 ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:6:7","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"go test命令 用于对Go语言编写的程序进行测试。 在命名文件时需要让文件必须以_test结尾。默认的情况下，go test命令不需要任何的参数，它会自动把你源码包下面所有 test 文件测试完毕，当然你也可以带上参数。 这里介绍几个常用的参数： -bench regexp 执行相应的 benchmarks，例如 -bench=.； -cover 开启测试覆盖率； -run regexp 只运行 regexp 匹配的函数，例如 -run=Array 那么就执行包含有 Array 开头的函数； -v 显示测试的详细命令。 单元测试源码文件可以由多个测试用例组成，每个测试用例函数需要以Test为前缀。**测试用例文件不会参与正常源码编译，不会被包含到可执行文件中。**测试用例文件使用go test指令来执行，没有也不需要 main() 作为函数入口。所有在以_test结尾的源码内以Test开头的函数会自动被执行。测试用例可以不传入 *testing.T 参数。单元（功能）测试以testing.T为参数，性能（压力）测试以testing.B为参数。 运行指定示例： PS D:\\Go\\Go_WorkSpace\\go_learning-master\\code\\ch2\\constant_test\u003e go test -v -run TestTest test_test.go === RUN TestTest test_test.go:6: kk --- PASS: TestTest (0.00s) PASS ok command-line-arguments 0.425s t.FailNow()———–标记错误并终止当前测试用例 t.Fail()————–仅标记错误 每个测试用例可能并发执行，使用 testing.T 提供的日志输出可以保证日志跟随这个测试上下文一起打印输出。testing.T 提供了几种日志输出方法： Log 打印日志 Logf 格式化打印日志 Error 打印错误日志 Errorf 格式化打印错误日志 Fatal 打印致命日志 Fatalf 格式化打印致命日志 单元测试使用示例： //demo.go package demo // 冒泡排序 func BubbleSort(list []int) []int { n := len(list) for i := n - 1; i \u003e 0; i-- { for j := 0; j \u003c i; j++ { if list[j] \u003e list[j+1] { list[j], list[j+1] = list[j+1], list[j] } } } return list } //demo_test.go package demo import \"testing\" func TestBubbleSort(t *testing.T) { area := BubbleSort([]list{2,1,3,4,65,13,22}) if area != {1,2,3,4,13,22,65} { t.Error(\"测试失败\") } } 执行： PS D:\\code\u003e go test -v === RUN TestGetArea --- PASS: TestGetArea (0.00s) PASS ok _/D_/code 0.435s 基准测试——获得代码内存占用和运行效率的性能数据 使用者无须准备高精度的计时器和各种分析工具，基准测试本身即可以打印出非常标准的测试报告。 package code import \"testing\" func Benchmark_Add(b *testing.B) { var n int for i := 0; i \u003c b.N; i++ { n++ } } 这段代码使用基准测试框架测试加法性能。第 7 行中的 b.N 由基准测试框架提供。测试代码需要保证函数可重入性及无状态，也就是说，测试代码不使用全局变量等带有记忆性质的数据结构。避免多次运行同一段代码时的环境不一致，不能假设 N 值范围。 //-bench=.相当于-run。在windows下使用-bench=\".\" $ go test -v -bench=. benchmark_test.go goos: linux goarch: amd64 Benchmark_Add-4 20000000 0.33 ns/op // 20000000指的是测试执行次数 PASS ok command-line-arguments 0.700s 基准测试原理：基准测试框架对一个测试用例的默认测试时间是 1 秒。开始测试时，当以 Benchmark 开头的基准测试用例函数返回时还不到 1 秒，那么 testing.B 中的 N 值将按 1、2、5、10、20、50……递增，同时以递增后的值重新调用基准测试用例函数。 通过-benchtime参数可以自定义测试时间，例如： $ go test -v -bench=. -benchtime=5s benchmark_test.go goos: linux goarch: amd64 Benchmark_Add-4 10000000000 0.33 ns/op PASS ok command-line-arguments 3.380s 基准测试可以对一段代码可能存在的内存分配进行统计，下面是一段使用字符串格式化的函数，内部会进行一些分配操作。 func Benchmark_Alloc(b *testing.B) { for i := 0; i \u003c b.N; i++ { fmt.Sprintf(\"%d\", i) } } $ go test -v -bench=Alloc -benchmem benchmark_test.go goos: linux goarch: amd64 Benchmark_Alloc-4 20000000 109 ns/op 16 B/op 2 allocs/op PASS ok command-line-arguments 2.311s 第 1 行的代码中-bench后添加了 Alloc，指定只测试 Benchmark_Alloc() 函数。 第 4 行代码的“16 B/op”表示每一次调用需要分配 16 个字节，“2 allocs/op”表示每一次调用有两次分配 开发者根据这些信息可以迅速找到可能的分配点，进行优化和调整。 控制计时器：有些测试需要一定的启动和初始化时间，如果从 Benchmark() 函数开始计时会很大程度上影响测试结果的精准性。testing.B 提供了一系列的方法可以方便地控制计时器，从而让计时器只在需要的区间进行测试。我们通过下面的代码来了解计时器的控制。 func Benchmark_Add_TimerControl(b *testing.B) { // 重置计时器 b.ResetTimer() // 停止计时器 b.StopTimer() // 开始计时器 b.StartTimer() var n int for i := 0; i \u003c b.N; i++ { n++ } } 从 Benchmark() 函数开始，Timer 就开始计数。计数器内部不仅包含耗时数据，还包括内存分配的数据。 ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:6:8","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"go list命令 作用是列出指定的代码包的信息。 ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:6:9","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"go fix 会把指定代码包的所有Go语言源码文件中的旧版本代码修正为新版本的代码。 ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:6:10","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"go vet 是一个用于检查Go语言源码中静态错误的简单工具。比如是否存在变量遮蔽。 $go install golang.org/x/tools/go/analysis/passes/shadow/cmd/shadow@latest go: downloading golang.org/x/tools v0.1.5 go: downloading golang.org/x/mod v0.4.2 $go vet -vettool=$(which shadow) -strict complex.go ./complex.go:13:12: declaration of \"err\" shadows declaration at line 11 ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:6:11","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"go tool pprof命令 交互式的访问概要文件的内容。监测进程的运行数据，用于监控程序的性能，对内存使用和CPU使用的情况统信息进行分析。官方提供了两个包**：runtime/pprof和net/http/pprof**，前者用于普通代码的性能分析，后者用于web服务器的性能分析。 runtime/pprof PS D:\\Go\\Go_WorkSpace\\go_learning-master\\code\\ch46\\tools\\file\u003e go tool pprof prof cpu.prof prof: open prof: The system cannot find the file specified. Fetched 1 source profiles out of 2 Type: cpu Time: Mar 10, 2022 at 10:41am (CST) Duration: 2.77s, Total samples = 1.70s (61.39%) Entering interactive mode (type \"help\" for commands, \"o\" for options) (pprof) top Showing nodes accounting for 1.67s, 98.24% of 1.70s total Showing top 10 nodes out of 34 flat flat% sum% cum cum% 0.49s 28.82% 28.82% 1.62s 95.29% main.fillMatrix 0.35s 20.59% 49.41% 1.13s 66.47% math/rand.(*Rand).Intn 0.33s 19.41% 68.82% 0.78s 45.88% math/rand.(*Rand).Int31n 0.14s 8.24% 77.06% 0.14s 8.24% math/rand.(*rngSource).Uint64 (inline) 0.13s 7.65% 84.71% 0.45s 26.47% math/rand.(*Rand).Int31 (inline) 0.10s 5.88% 90.59% 0.24s 14.12% math/rand.(*rngSource).Int63 0.08s 4.71% 95.29% 0.32s 18.82% math/rand.(*Rand).Int63 0.02s 1.18% 96.47% 0.02s 1.18% main.calculate 0.02s 1.18% 97.65% 0.02s 1.18% runtime.stdcall1 0.01s 0.59% 98.24% 0.01s 0.59% runtime.lock2 (pprof) list fillMatrix Total: 1.70s ROUTINE ======================== main.fillMatrix in D:\\go\\Go_WorkSpace\\go_learning-master\\code\\ch46\\tools\\file\\prof.go 490ms 1.62s (flat, cum) 95.29% of Total . . 16: . . 17:func fillMatrix(m *[row][col]int) { . . 18: s := rand.New(rand.NewSource(time.Now().UnixNano())) . . 19: . . 20: for i := 0; i \u003c row; i++ { 20ms 20ms 21: for j := 0; j \u003c col; j++ { 470ms 1.60s 22: m[i][j] = s.Intn(100000) . . 23: } . . 24: } . . 25:} . . 26: . . 27:func calculate(m *[row][col]int) { (pprof) top/tree/web top [n]，查看排名前n个数据，默认为10。（这个函数本身占用的时间，以及这个函数包括调用其他函数的时间） tree [n]，以树状图形式显示，默认显示10个。 net/http/pprof ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:6:12","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"go modules go modules 是 golang 1.11 新加的特性 go mod download download modules to local cache(下载依赖包) edit edit go.mod from tools or scripts（编辑go.mod） graph print module requirement graph (打印模块依赖图) init initialize new module in current directory（在当前目录初始化mod） tidy add missing and remove unused modules(拉取缺少的模块，移除不用的模块,常用) vendor make vendored copy of dependencies(将依赖复制到vendor下) verify verify dependencies have expected content (验证依赖是否正确 why explain why packages or modules are needed(解释为什么需要依赖) go.mod文件一旦创建后，它的内容将会被go toolchain全面掌控。go toolchain会在各类命令执行时，比如go get、go build、go mod等修改和维护go.mod文件。 ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:6:13","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"运算符 Go 语言内置的运算符有： 算术运算符 ++ 和 – 只有后置的，没有前置的，只作为语句，不作为表达式 关系运算符 逻辑运算符 位运算符 按位置零运算符 x \u0026^ y ——如果y非零，则z为0；如果y为零，则z为x（先非再与），注意按位运算 赋值运算符（一个赋值语句可以给多个变量进行赋值，多重赋值时，变量的左值和右值按从左到右的顺序赋值。多重赋值在 Go 语言的错误处理和函数返回值中会大量地使用。） = 简单的赋值运算符，将一个表达式的值赋给一个左值 += 相加后再赋值 -= 相减后再赋值 *= 相乘后再赋值 /= 相除后再赋值 %= 求余后再赋值 «= 左移后赋值 \u003e\u003e= 右移后赋值 \u0026= 按位与后赋值 l= 按位或后赋值 ^= 按位异或后赋值 ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:7:0","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"下划线 “_”是特殊标识符，用来忽略结果。 下划线在import中 import 下划线（如：import _ hello/imp）的作用：当导入一个包时，该包下的文件里所有init()函数都会被执行，然而，有些时候我们并不需要把整个包都导入进来，仅仅是是希望它执行init()函数而已。这个时候就可以使用 import _ 引用该包。即使用【import _ 包路径】只是引用该包，仅仅是为了调用init()函数，所以无法通过包名来调用包中的其他函数。 注意区别于.在import中，它是指import进来的package里的所有的方法是在当前的名字空间的，使用其方法时直接使用即可。 下划线在代码中 作为占位符 ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:8:0","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"格式占位符%… 普通占位符 占位符 说明 举例 输出 %v 相应值的默认格式。 Printf(\"%v\", people) {zhangsan}， %+v 打印结构体时，会添加字段名 Printf(\"%+v\", people) {Name:zhangsan} %#v 相应值的Go语法表示 Printf(\"#v\", people) main.Human{Name:\"zhangsan\"} %T 相应值的类型的Go语法表示 Printf(\"%T\", people) main.Human %% 字面上的百分号，并非值的占位符 Printf(\"%%\") % 布尔占位符 占位符 说明 举例 输出 %t true 或 false。 Printf(\"%t\", true) true 整数占位符 占位符 说明 举例 输出 %b 二进制表示 Printf(\"%b\", 5) 101 %c 相应Unicode码点所表示的字符 Printf(\"%c\", 0x4E2D) 中 %d 十进制表示 Printf(\"%d\", 0x12) 18 %o 八进制表示 Printf(\"%o\", 10) 12 %q 单引号围绕的字符字面值，由Go语法安全地转义 Printf(\"%q\", 0x4E2D) '中' %x 十六进制表示，字母形式为小写 a-f Printf(\"%x\", 13) d %X 十六进制表示，字母形式为大写 A-F Printf(\"%x\", 13) D %U Unicode格式：U+1234，等同于 \"U+%04X\" Printf(\"%U\", 0x4E2D) U+4E2D 浮点数和复数的组成部分（实部和虚部） 占位符 说明 举例 输出 %b 无小数部分的，指数为二的幂的科学计数法， 与 strconv.FormatFloat 的 'b' 转换格式一致。例如 -123456p-78 %e 科学计数法，例如 -1234.456e+78 Printf(\"%e\", 10.2) 1.020000e+01 %E 科学计数法，例如 -1234.456E+78 Printf(\"%e\", 10.2) 1.020000E+01 %f 有小数点而无指数，例如 123.456 Printf(\"%f\", 10.2) 10.200000 %g 根据情况选择 %e 或 %f 以产生更紧凑的（无末尾的0）输出 Printf(\"%g\", 10.20) 10.2 %G 根据情况选择 %E 或 %f 以产生更紧凑的（无末尾的0）输出 Printf(\"%G\", 10.20+2i) (10.2+2i) 字符串与字节切片 占位符 说明 举例 输出 %s 输出字符串表示（string类型或[]byte) Printf(\"%s\", []byte(\"Go语言\")) Go语言 %q 双引号围绕的字符串，由Go语法安全地转义 Printf(\"%q\", \"Go语言\") \"Go语言\" %x 十六进制，小写字母，每字节两个字符 Printf(\"%x\", \"golang\") 676f6c616e67 %X 十六进制，大写字母，每字节两个字符 Printf(\"%X\", \"golang\") 676F6C616E67 指针 占位符 说明 举例 输出 %p 十六进制表示，前缀 0x Printf(\"%p\", \u0026people) 0x4f57f0 其它标记 占位符 说明 举例 输出 + 总打印数值的正负号；对于%q（%+q）保证只输出ASCII编码的字符。 Printf(\"%+q\", \"中文\") \"\\u4e2d\\u6587\" - 在右侧而非左侧填充空格（左对齐该区域） # 备用格式：为八进制添加前导 0（%#o） Printf(\"%#U\", '中') U+4E2D 为十六进制添加前导 0x（%#x）或 0X（%#X），为 %p（%#p）去掉前导 0x； 如果可能的话，%q（%#q）会打印原始 （即反引号围绕的）字符串； 如果是可打印字符，%U（%#U）会写出该字符的 Unicode 编码形式（如字符 x 会被打印成 U+0078 'x'）。 ' ' (空格)为数值中省略的正负号留出空白（% d）； 以十六进制（% x, % X）打印字符串或切片时，在字节之间用空格隔开 0 填充前导的0而非空格；对于数字，这会将填充移到正负号之后 golang没有 ‘%u’ 点位符，若整数为无符号类型，默认就会被打印成无符号的。 宽度与精度的控制格式以Unicode码点为单位。宽度为该数值占用区域的最小宽度；精度为小数点之后的位数。 操作数的类型为int时，宽度与精度都可用字符 ‘*’ 表示。 对于 %g/%G 而言，精度为所有数字的总数，例如：123.45，%.4g 会打印123.5，（而 %6.2f 会打印123.45）。 %e 和 %f 的默认精度为6 对大多数的数值类型而言，宽度为输出的最小字符数，如果必要的话会为已格式化的形式填充空格。 而以字符串类型，精度为输出的最大字符数，如果必要的话会直接截断。 ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:9:0","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"变量和常量 变量： 为什么要有变量：程序运行过程中的数据都是保存在内存中，我们想要在代码中操作某个数据时就需要去内存上找到这个变量，但是如果我们直接在代码中通过内存地址去操作变量的话，代码的可读性会非常差而且还容易出错，所以我们就利用变量将这个数据的内存地址保存起来，以后直接通过这个变量就能找到内存上对应的数据了。 Go语言中的变量需要声明后才能使用，同一作用域内不支持重复声明。并且Go语言的变量声明后必须使用。 批量声明变量：（“声明聚类”） var ( a string b int c bool d float32 ) 建议将延迟初始化的变量声明放在一个 var 声明块，将声明且显式初始化的变量放在另一个 var 块中 变量声明咱们一般采用就近原则，以实现变量的作用域最小化 在函数内部，可以使用更简略的 := 方式声明并初始化变量。 匿名变量_ 常量: const ( pi = 3.1415 e = 2.7182 ) 如果省略了值则表示和上面一行的值相同 iota是go语言的常量计数器，只能在常量的表达式中使用。iota在const关键字出现时将被重置为0。const中每新增一行常量声明将使iota计数一次(iota可理解为const语句块中的行索引)。 使用iota能简化定义，在定义枚举时很有用。 可以使用_跳过某些值 const ( _ = iota KB = 1 \u003c\u003c (10 * iota) MB = 1 \u003c\u003c (10 * iota) GB = 1 \u003c\u003c (10 * iota) TB = 1 \u003c\u003c (10 * iota) PB = 1 \u003c\u003c (10 * iota) ) const ( a, b = iota + 1, iota + 2 //1,2 c, d //2,3 e, f //3,4 ) Go在常量上还是有一定创新的： 与C对比： C 语言中，原生不支持常量，字面值担负着常量的角色，C 语言的常用实践是使用宏（macro）定义记号来指代这些字面值，但它是一种仅在预编译阶段进行替换的字面值，继承了宏替换的复杂性和易错性，而且还有类型不安全、无法在调试时通过宏名字输出常量的值，等等问题。后续 C 标准中提供的 const 关键字修饰的标识符也不够完美，因为 const 关键字修饰的标识符本质上依旧是变量，它甚至无法用作数组变量声明中的初始长度（除非用 GNU 扩展 C）。 Go 原生提供的用 const 关键字定义的常量，整合了 C 语言中宏定义常量、const 修饰的“只读变量”，以及枚举常量这三种形式，并消除了每种形式的不足，使得 Go 常量是类型安全的，而且对编译器优化友好。 支持无类型常量； eg: const n = 13 常量 n 在声明时并没有显式地被赋予类型（但并非真的无类型，由初始值给予默认类型），在 Go 中，这样的常量就被称为无类型常量（Untyped Constant） 但下面的例子里边为啥编译器不报错？ type myInt int const n = 13 func main() { var a myInt = 5 fmt.Println(a + n) // 输出：18 } 支持常量隐式自动转型； 对于无类型常量参与的表达式求值，Go 编译器会根据上下文中的类型信息，把无类型常量自动转换为相应的类型后，再参与求值计算，这一转型动作是隐式进行的。但由于转型的对象是一个常量，所以这并不会引发类型安全问题，Go 编译器会保证这一转型的安全性。 这就很好地解释了上面的问题。 注意：如果 Go 编译器在做隐式转型时，发现无法将常量转换为目标类型，Go 编译器也会报错，比如转型后溢出了。 以及前面有提到的可用于实现枚举。 ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:10:0","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"基本类型 类型 长度(字节) 默认值 说明 bool 1 false byte 1 0 uint8，一个ASCII字符 rune 4 0 Unicode Code Point，int32，一个utf-8字符,c:=[]rune(s)//指将字符串s转化为rune的切片 int, uint 4或8 0 由操作系统位数(32/64)决定 int8, uint8 1 0 -128 ~ 127, 0 ~ 255，byte是uint8 的别名 int16, uint16 2 0 -32768 ~ 32767, 0 ~ 65535 int32, uint32 4 0 -21亿~ 21亿, 0 ~ 42亿，rune是int32 的别名 int64, uint64 8 0 float32 4 0.0 float64 8 0.0 complex64 8 complex128 16 uintptr 4或8 以存储指针的 uint32 或 uint64 整数 array 值类型 struct 值类型 string “” UTF-8 字符串 slice nil 引用类型 map nil 引用类型 channel nil 引用类型 interface nil 接口 function nil 函数 uintptr 实际上就是一个 uint 用来表示地址，go 的指针和 c 不一样不能进行偏移操作，如果非要偏移的话就需要 unsafe.Pointer 和 uintptr 配合来实现。uintptr 不是一个指针 所以 GC 时也不会处理 uintptr 的引用。如果不涉及地址偏移时没有必要使用 uintptr 。——来自知乎回答 标准库 math 定义了各数字类型取值范围。 空指针值 nil，而非C/C++ NULL。golang中有多种引用类型：pointer、interface、slice、map、channel、function。go作为一个强类型语言（类型是定义好的无法改变，不像c，你定义一个short可以当成char用，因为可以直接操作内存），不同引用类型的判空（nil）规则是不同的；比如：interface的判空规则是，需要判断类型和值是否都为nil(interface的底层是有类型和值构成的)slice的判空，需要判断slice引用底层数组的指针为空，容量和size均为0。 不允许将整型强制转换为布尔型。 字符串的内部实现使用UTF-8编码。（UTF-8是Unicode的存储实现，转化为有限长度比特组合的规则） 只有显示类型转化。 ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:11:0","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"string 值类型，空值是空字符串而不是nil。本质就是个只读的（不可变的）byte切片。 // $GOROOT/src/reflect/value.go // StringHeader是一个string的运行时表示 type StringHeader struct { Data uintptr Len int } string 类型其实是一个“描述符”，它本身并不真正存储字符串数据，而仅是由一个指向底层存储的指针和字符串的长度字段组成的 多行字符串，用反引号` s1 := `第一行 第二行 第三行 ` fmt.Println(s1) 方法 介绍 len(str) 求长度 +或fmt.Sprintf 拼接字符串 strings.Split 分割 strings.Contains 判断是否包含 strings.HasPrefix,strings.HasSuffix 前缀/后缀判断 strings.Index(),strings.LastIndex() 子串出现的位置 strings.Join(a[]string, sep string) join操作 遍历字符串： // Traversal strings func traversalString() { s := \"JeFo的博客\" for i := 0; i \u003c len(s); i++ { //Traversal by byte fmt.Printf(\"%v(%c) \", s[i], s[i]) } fmt.Println() for _, r := range s { //Traversal by rune fmt.Printf(\"%v(%c) \", r, r) } fmt.Println() } 74(J) 101(e) 70(F) 111(o) 231(ç) 154() 132( ) 229(å) 141() 154() 229(å) 174(®) 162(¢) 74(J) 101(e) 70(F) 111(o) 30340(的) 21338(博) 23458(客) 可以调用标准库 UTF-8 包中的 RuneCountInString 函数获取字符串字符个数。（len只能获得字节个数） Go 原生支持通过 +/+= 操作符进行字符串连接。以及，Go 还提供了 strings.Builder、strings.Join、fmt.Sprintf 等函数来进行字符串连接操作。 如果能知道拼接字符串的个数，那么使用bytes.Buffer和strings.Builder的Grows申请空间后，性能是最好的；如果不能确定长度，那么bytes.Buffer和strings.Builder也比“+”和fmt.Sprintf性能好很多。 bytes.Buffer与strings.Builder，strings.Builder更合适，因为bytes.Buffer 转化为字符串时重新申请了一块空间，存放生成的字符串变量，而 strings.Builder 直接将底层的 []byte 转换成了字符串类型返回了回来。 字符串比较： Go 字符串类型支持各种比较关系操作符，包括 = =、!= 、\u003e=、\u003c=、\u003e 和 \u003c。在字符串的比较上，Go 采用字典序的比较策略，分别从每个字符串的起始处，开始逐个字节地对两个字符串类型变量进行比较。 Go 支持字符串与字节切片、字符串与 rune 切片的双向转换，并且这种转换无需调用任何函数，只需使用显式类型转换就可以了 修改字符串： 要修改字符串，需要先将其转换成[]rune或[]byte，完成后再转换为string。无论哪种转换，都会重新分配内存，并复制字节数组。 为什么go要原生支持字符串类型？ c语言并没有内置字符串类型 不是原生类型，编译器不会对它进行类型校验，导致类型安全性差； 字符串操作时要时刻考虑结尾的’\\0’，防止缓冲区溢出； 以字符数组形式定义的“字符串”，它的值是可变的，在并发场景中需要考虑同步问题； 获取一个字符串的长度代价较大，通常是 O(n) 时间复杂度； C 语言没有内置对非 ASCII 字符（如中文字符）的支持。 go内置了字符串类型的好处 string 类型的数据是不可变的，提高了字符串的并发安全性和存储利用率。 没有结尾’\\0’，而且获取长度的时间复杂度是常数时间，消除了获取字符串长度的开销。 原生支持“所见即所得”的原始字符串，大大降低构造多行字符串时的心智负担。 在 C 语言中构造多行字符串，一般就是两个方法：要么使用多个字符串的自然拼接，要么需要结合续行符”\"。但因为有转义字符的存在，我们很难控制好格式。Go 语言就简单多了，通过一对反引号原生支持构造“所见即所得”的原始字符串（Raw String）。而且，Go 语言原始字符串中的任意转义字符都不会起到转义的作用 对非 ASCII 字符提供原生支持，消除了源码在不同环境下显示乱码的可能。 ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:12:0","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"数组 数组可以通过下标进行访问，下标是从0开始，最后一个元素下标是：len-1 支持 “==”、\"!=” 操作符，因为内存总是被初始化过的。 相同类型的数组之间可以使用 == 或 != 进行比较，但不可以使用 \u003c 或 \u003e，也可以相互赋值。 长度不同类型也不同。 指针数组 [n]*T，数组指针 *[n]T。 多维数组除了第一维，初始化时都不能用[…]省略长度声明。 值拷贝行为会造成性能问题，通常会建议使用 slice，或数组指针。 ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:13:0","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"列表list 初始化： 通过 container/list 包的 New() 函数初始化 list。变量名 := list.New() 通过 var 关键字声明初始化 list 。var 变量名 list.List 列表与切片和 map 不同的是，列表并没有具体元素类型的限制，因此，列表的元素可以是任意类型，这既带来了便利，也引来一些问题，例如给列表中放入了一个 interface{} 类型的值，取出值后，如果要将 interface{} 转换为其他类型将会发生宕机。 源码数据结构： type Element struct { // Next and previous pointers in the doubly-linked list of elements. // To simplify the implementation, internally a list l is implemented // as a ring, such that \u0026l.root is both the next element of the last // list element (l.Back()) and the previous element of the first list // element (l.Front()). next, prev *Element // The list to which this element belongs. list *List // The value stored with this element. Value interface{} } type List struct { root Element // sentinel list element, only \u0026root, root.prev, and root.next are used len int // current list length excluding (this) sentinel element } 其他源码列出稍冗长，root.prev可以视作尾节点，root.next相当于头节点，不过这些是透明的，被封装好的。 在列表中插入元素删除元素都有简便方法。 ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:14:0","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"切片 只能和nil进行比较。 //用make()初始化 var s3 []int = make([]int, 0, 10)//len=0,cap=10 var s4 []int = make([]int, 5)//len=5 //先初始化一个数组，再截取相应部分得到切片 arr := [5]int{1, 2, 3, 4, 5} var s6 []int //数组的切片化 s6 = arr[1:4] // 左闭右开 s7 = arr[1:3:5]//arr[low,high,max]，len=high-low cap=max-low 切片追加append（内置函数）： // The append built-in function appends elements to the end of a slice. If // it has sufficient capacity, the destination is resliced to accommodate the // new elements. If it does not, a new underlying array will be allocated. // Append returns the updated slice. It is therefore necessary to store the // result of append, often in the variable holding the slice itself: // slice = append(slice, elem1, elem2) // slice = append(slice, anotherSlice...) // As a special case, it is legal to append a string to a byte slice, like this: // slice = append([]byte(\"hello \"), \"world\"...) var a = []int{1, 2, 3} fmt.Printf(\"slice a : %v\\n\", a) var b = []int{4, 5, 6} fmt.Printf(\"slice b : %v\\n\", b) c := append(a, b...) fmt.Printf(\"slice c : %v\\n\", c) d := append(c, 7) fmt.Printf(\"slice d : %v\\n\", d) e := append(d, 8, 9, 10) fmt.Printf(\"slice e : %v\\n\", e) slice := append([]byte(\"hello \"), \"world\"...)//**注意**是字节数组和字符串。 fmt.Printf(\"slice slice : %v\\n\", slice) func TestOne(t *testing.T) { q := make([]int, 3, 10) w := append(q, 1) t.Log(len(w), len(q)) e := append(q, 2) //append是加在该切片的len后面，但不是最后一个元素后面，因为底层数组会被改变，而切片变量的结构体所记录的信息是固定的。 t.Log(q, w, e) } 超出原 slice.cap 限制，就会重新分配底层数组，即便原数组并未填满。 通常以 2 倍容量重新分配底层数组。在大批量添加数据时，建议一次性分配足够大的空间，以减少内存分配和数据复制开销。或初始化足够长的 len 属性，改用索引号进行操作。 及时释放不再使用的 slice 对象，避免持有过期数组，造成 GC 无法回收。 切片resize: package main import ( \"fmt\" ) func main() { var a = []int{1, 3, 4, 5} fmt.Printf(\"slice a : %v , len(a) : %v\\n\", a, len(a)) b := a[1:2] fmt.Printf(\"slice b : %v , len(b) : %v\\n\", b, len(b)) c := b[1:3] fmt.Printf(\"slice c : %v , len(c) : %v\\n\", c, len(c)) } slice a : [1 3 4 5] , len(a) : 4 slice b : [3] , len(b) : 1 slice c : [4 5] , len(c) : 2 string \u0026 slice : string底层就是一个byte的数组，因此，也可以进行切片操作。 二维切片： …… a := make([][]int,dy) for i = range a { a[i] = make([]int, dx) } ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:15:0","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"slice切片底层实现 切片的设计想法是由动态数组概念而来，为了开发者可以更加方便的使一个数据结构可以自动增加和减少。但是切片本身并不是动态数据或者数组指针。切片常见的操作有 reslice、append、copy。与此同时，切片还具有可索引，可迭代的优秀特性。 func main() { arrayA := []int{1, 2} testArrayPoint(\u0026arrayA) // 1.传数组指针 arrayB := arrayA[:] testArrayPoint(\u0026arrayB) // 2.传切片 fmt.Printf(\"arrayA : %p , %v\\n\", \u0026arrayA, arrayA) } func testArrayPoint(x *[]int) { fmt.Printf(\"func Array : %p , %v\\n\", x, *x) (*x)[1] += 1 } func Array : 0xc4200b0140 , [1 2] func Array : 0xc4200b0180 , [1 3] arrayA : 0xc4200b0140 , [1 4] 传指针会有一个弊端，从打印结果可以看到，第一行和第三行指针地址都是同一个，万一原数组的指针指向更改了，那么函数里面的指针指向都会跟着更改。 用切片传数组参数，既可以达到节约内存的目的，也可以达到合理处理好共享内存的问题。打印结果第二行就是切片，切片的指针和原来数组的指针是不同的。 slice数据结构源码： // runtime/slice.go type slice struct { array unsafe.Pointer // 指向一个数组的指针 len int // 切片长度 cap int // 切片容量 } 注意：Golang 语言是没有操作原始内存的指针的，所以 unsafe 包提供相关的对内存指针的操作，一般情况下非专业人员勿用 如果想从 slice 中得到一块内存地址，可以这样做： s := make([]byte, 200) ptr := unsafe.Pointer(\u0026s[0]) 自己构造一个slice: var ptr unsafe.Pointer var s1 = struct { addr uintptr len int cap int }{ptr, length, length} s := *(*[]byte)(unsafe.Pointer(\u0026s1)) 在 Go 的反射中就存在一个与之对应的数据结构 SliceHeader，我们可以用它来构造一个 slice： var o []byte sliceHeader := (*reflect.SliceHeader)((unsafe.Pointer(\u0026o))) sliceHeader.Cap = length sliceHeader.Len = length sliceHeader.Data = uintptr(ptr) 此外，unsafe的Sizeof函数： var a, b = int(5), uint(6) var p uintptr = 0x12345678 fmt.Println(\"signed integer a's length is\", unsafe.Sizeof(a)) // 8 fmt.Println(\"unsigned integer b's length is\", unsafe.Sizeof(b)) // 8 fmt.Println(\"uintptr's length is\", unsafe.Sizeof(p)) // 8 并非所有时候都适合用切片代替数组：因为切片底层数组可能会在堆上分配内存，而且小数组在栈上拷贝的消耗也未必比make 消耗大。 ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:15:1","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"创建切片 make 函数允许在运行期动态指定数组长度，绕开了数组类型必须使用编译期常量的限制。 创建切片有两种形式，make 创建切片，字面量创建切片（既可以初始化一个新的，也可以截取一个数组,截取一个数组的时候cap未声明时为数组容量）。 空切片和nil切片 nil切片：| nil (Pointer) | Len(int) | Cap(int) | var slice []int nil 切片被用在很多标准库和内置函数中，描述一个不存在的切片的时候，就需要用到 nil 切片。比如函数在发生异常的时候，返回的切片就是 nil 切片。nil 切片的指针指向 nil。 空切片： | Array (Pointer) | Len(int) | Cap(int) | silce := make( []int , 0 ) slice := []int{ } 空切片一般会用来表示一个空的集合。比如数据库查询，一条结果也没有查到，那么就可以返回一个空切片。 空切片和 nil 切片的区别在于，空切片指向的地址不是nil，指向的是一个内存地址，但是它没有分配任何内存空间，即底层元素包含0个元素。 不管是使用 nil 切片还是空切片，对其调用内置函数 append，len 和 cap 的效果都是一样的。 扩容策略 如果切片的容量小于 1024 个元素，于是扩容的时候就翻倍增加容量。 一旦元素个数超过 1024 个元素，那么增长因子就变成 1.25 ，即每次增加原来容量的四分之一。 注意：扩容扩大的容量都是针对原来的容量而言的，而不是针对原来数组的长度而言的。 扩容后的数组是新数组还是老数组？ 如果如果切片扩容后容量比原来数组的容量最大值还大，扩容切片需要另开一片内存区域，把原来的值拷贝过来，再执行append()操作。 否则，不会开辟新数组，这种情况很危险，因为这种情况下，扩容以后的数组还是指向原来的数组,多个原来的数组上的切片会受新切片所影响！ ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:15:2","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"切片拷贝 slicecopy 方法会把源切片值(即 fm Slice )中的元素复制到目标切片(即 to Slice )中，并返回被复制的元素个数，copy 的两个类型必须一致。slicecopy 方法最终的复制结果取决于较短的那个切片，当较短的切片复制完成，整个复制过程就全部完成了。 如果用 range 的方式去遍历一个切片，拿到的 Value 其实是切片里面的值拷贝。所以每次打印 Value 的地址都不变。由于 Value 是值拷贝的，并非引用传递，所以直接改 Value 是达不到更改原切片值的目的的，需要通过 \u0026slice[index] 获取真实的地址。 ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:15:3","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"指针 区别于C/C++中的指针，Go语言中的指针不能进行偏移和运算，是安全指针。 首先需要知道指针地址、指针类型和指针取值。 指针地址和指针类型： Go语言中的值类型（int、float、bool、string、array、struct）都有对应的指针类型 指针取值：* 空指针： 当一个指针被定义后没有分配到任何变量时，它的值为 nil new和make: 在Go语言中对于引用类型的变量，我们在使用的时候不仅要声明它，还要为它分配内存空间，否则我们的值就没办法存储。 new 函数签名和举例 func new(Type) *Type func main() { var a *int a = new(int) *a = 10 fmt.Println(*a) } new函数不太常用，使用new函数得到的是一个类型的指针，并且该指针对应的值为该类型的零值。 make 只用于slice、map以及chan的内存创建，而且它返回的类型就是这三个类型本身,因为这三种类型就是引用类型，所以就没有必要返回他们的指针了。 以map举例： func main() { var b map[string]int b = make(map[string]int, 10) b[\"测试\"] = 100 fmt.Println(b) } ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:16:0","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"map map[KeyType]ValueType 初始化时用make申请内存（或者直接填充元素）： make(map[KeyType]ValueType, [cap])//cap不是必须的，但最好一开始就申请一个合适的容量 // // 初始化 + 赋值一体化 m3 := map[string]string{ \"a\": \"aa\", \"b\": \"bb\", } 判断某个key是否存在： //map[key]会返回两个值，第二个是该键是否存在 value, ok := map[key] map的遍历还是正常用for range，但有一点需要注意：遍历map时元素顺序与添加键值对的顺序无关。 按照指定顺序遍历map:思路是将map的key取出另存为切片再排序，再按照切片的顺序进行遍历即可。 因为 map 类型要保证 key 的唯一性。key 的类型必须支持“==”和“!=”两种比较操作符，比如函数类型、map 类型自身，以及切片类型是不能作为 map 的 key 类型的。value类型则没有限制。 map \u0026 切片： 元素为map的切片： func main() { var mapSlice = make([]map[string]string, 3) for index, value := range mapSlice { fmt.Printf(\"index:%d value:%v\\n\", index, value) } fmt.Println(\"after init\") // 对切片中的map元素进行初始化 mapSlice[0] = make(map[string]string, 10) mapSlice[0][\"name\"] = \"王五\" mapSlice[0][\"password\"] = \"123456\" mapSlice[0][\"address\"] = \"红旗大街\" } value为切片的map: func main() { var sliceMap = make(map[string][]string, 3) fmt.Println(sliceMap) fmt.Println(\"after init\") key := \"中国\" value, ok := sliceMap[key] if !ok { value = make([]string, 0, 2) } value = append(value, \"北京\", \"上海\") sliceMap[key] = value fmt.Println(sliceMap) } 获取键值对数量： m := map[string]int { \"key1\" : 1, \"key2\" : 2, } fmt.Println(len(m)) // 2 m[\"key3\"] = 3 fmt.Println(len(m)) // 3 注意：不能对 map 类型变量调用 cap，来获取当前容量 map删除键值对：（即便传给 delete 的键在 map 中并不存在，delete 函数的执行也不会失败，更不会抛出运行时的异常。） delete(map,key) ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:17:0","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"map实现原理 map底层存储方式为（结构体）数组，在存储时key不能重复，当key重复时，value进行覆盖，我们通过key进行hash运算（可以简单理解为把key转化为一个整形数字）然后对数组的长度取余，得到key存储在数组的哪个下标位置，最后将key和value组装为一个结构体，放入数组下标处。 哈希冲突：即不同key经哈希映射后得到相同的数组下标。 解决办法：开放定址法： 发现hashkey(key)的下标已经被别key占用的时候，在这个数组中空间中重新找一个没被占用的存储这个冲突的key。寻找方式有很多。常见的有线性探测法，线性补偿探测法，随机探测法。 线性探测法： 从冲突的下标处开始往后探测，到达数组末尾时，从数组开始处探测，直到找到一个空位置存储这个key，当数组都找不到的情况下会扩容（事实上当数组容量快满的时候就会扩容了） 查找某一个key的时候，找到key对应的下标，比较key是否相等，如果相等直接取出来，否则按照顺序探测直到碰到一个空位置，说明key不存在。 拉链法： 当key的hash冲突时，我们在冲突位置的元素上形成一个链表，通过指针互连接。 当查找时，发现key冲突，顺着链表一直往下找，直到链表的尾节点，找不到则返回空 开放定址法的优缺点： 由上面可以看出拉链法比线性探测处理简单 线性探测查找是会被拉链法会更消耗时间 线性探测会更加容易导致扩容，而拉链不会 拉链存储了指针，所以空间上会比线性探测占用多一点 拉链是动态申请存储空间的，所以更适合链长不确定的 ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:17:1","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"go中map的实现原理 go里面map并不是线程安全的，在1.9版本之前用map加互斥锁来解决此问题，之后加了sync.map性能稍微高了一些，因为它有一块只读的buffer，相当于由两个buffer组成，一块只读，一块读写。sync.map更适合于读非常多，能够占到90%以上的情况。如果读写差不多或者说写更多的话，sync.map的性能就比较差了。 在读写对半的情况下，可以考虑引入concurrent_map包。（go get -u +包地址） 在go1.16中，map也是数组存储的的，每个数组下标处存储的是一个bucket,这个bucket的类型见下面代码，每个bucket中可以存储8个kv键值对，当每个bucket存储的kv对到达8个之后，会通过overflow指针指向一个新的bucket，从而形成一个链表,看bmap的结构 // A bucket for a Go map. type bmap struct { // tophash generally contains the top byte of the hash value // for each key in this bucket. If tophash[0] \u003c minTopHash, // tophash[0] is a bucket evacuation state instead.即桶疏散状态 tophash [bucketCnt]uint8 // Followed by bucketCnt keys and then bucketCnt elems. // NOTE: packing all the keys together and then all the elems together makes the // code a bit more complicated than alternating key/elem/key/elem/... but it allows // us to eliminate padding which would be needed for, e.g., map[int64]int8. // Followed by an overflow pointer. } tophash用来快速查找key值是否在该bucket中，而不同每次都通过真值进行比较。 map[int64]int8,key是int64（8个字节），value是int8（一个字节），kv的长度不同，如果按照kv格式存放，则考虑内存对齐v也会占用int64，而按照后者存储时，8个v刚好占用一个int64 当往map中存储一个kv对时，通过k获取hash值，hash值的低八位和bucket数组长度取余，定位到在数组中的那个下标，hash值的高八位存储在bucket中的tophash中，用来快速判断key是否存在，key和value的具体值则通过指针运算存储，当一个bucket满时，通过overfolw指针链接到下一个bucket。 map的存储源码： // Like mapaccess, but allocates a slot for the key if it is not present in the map.如果key不在map里为其分配一个插槽（狭槽） func mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { if h == nil { panic(plainError(\"assignment to entry in nil map\")) } if raceenabled { callerpc := getcallerpc() pc := funcPC(mapassign) racewritepc(unsafe.Pointer(h), callerpc, pc) raceReadObjectPC(t.key, key, callerpc, pc) } if msanenabled { //获取hash算法 msanread(key, t.key.size) } if h.flags\u0026hashWriting != 0 { throw(\"concurrent map writes\") } //计算哈希值 hash := t.hasher(key, uintptr(h.hash0)) // Set hashWriting after calling t.hasher, since t.hasher may panic, // in which case we have not actually done a write. h.flags ^= hashWriting //如果bucket数组一开始为空，则初始化 if h.buckets == nil { h.buckets = newobject(t.bucket) // newarray(t.bucket, 1) } again: //定位在哪一个bucket中 bucket := hash \u0026 bucketMask(h.B) if h.growing() { growWork(t, h, bucket) } //得到bucket的结构体 b := (*bmap)(add(h.buckets, bucket*uintptr(t.bucketsize))) //获取高八位的哈希值 top := tophash(hash) var inserti *uint8 var insertk unsafe.Pointer var elem unsafe.Pointer bucketloop: //死循环 for { //循环bucket中的tophash数组 for i := uintptr(0); i \u003c bucketCnt; i++ { //如果hash不相等 if b.tophash[i] != top { //判断是否为空，为空则插入 if isEmpty(b.tophash[i]) \u0026\u0026 inserti == nil { inserti = \u0026b.tophash[i] insertk = add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) elem = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize)) } //插入成功，终止外层循环 if b.tophash[i] == emptyRest { break bucketloop } continue } //高八位哈希值一样，获取已存在的kay k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) if t.indirectkey() { k = *((*unsafe.Pointer)(k)) } //判断两个key是否相等，不相等就循环下一个 if !t.key.equal(key, k) { continue } // already have a mapping for key. Update it. if t.needkeyupdate() { typedmemmove(t.key, k, key) } //获取已存在的value elem = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize)) goto done } //如果上一个bucket没能找到插入，则通过overflow获取链表上的下一个bucket ovf := b.overflow(t) if ovf == nil { break } b = ovf } // Did not find mapping for key. Allocate new cell \u0026 add entry. // If we hit the max load factor or we have too many overflow buckets, // and we're not already in the middle of growing, start growing. if !h.growing() \u0026\u0026 (overLoadFactor(h.count+1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) { hashGrow(t, h) goto again // Growing the table invalidates everything, so try again } if inserti == nil { // The current bucket and all the overflow buckets connected to it are full, allocate a new one. newb := h.newoverflow(t, b) inserti = \u0026newb.tophash[0] insertk = add(unsafe.Pointer(newb), dataOffset) elem = add(insertk, bucketCnt*uintptr(t.keysize)) } // ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:17:2","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"map与工厂模式 map的value可以是一个方法。 与 Go 的 Dock type 接⼝⽅式⼀起，可以⽅便的实现单⼀⽅法对象的⼯⼚模式 func TestMapWithFunValue(t *testing.T) { m := map[int]func(op int) int{} m[1] = func(op int) int { return op } m[2] = func(op int) int { return op * op } m[3] = func(op int) int { return op * op * op } t.Log(m[1](2), m[2](2), m[3](2)) } ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:17:3","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"set Go 的内置集合中没有 Set 实现， 可以 map[type]bool。 map可以保证添加元素的唯⼀性，方便判断唯一元素的个数 基本操作 添加元素 判断元素是否存在 删除元素 元素个数 func TestMapForSet(t *testing.T) { mySet := map[int]bool{} mySet[1] = true n := 3 if mySet[n] { t.Logf(\"%d is existing\", n) } else { t.Logf(\"%d is not existing\", n) } mySet[3] = true t.Log(len(mySet)) delete(mySet, 1) n = 1 if mySet[n] { t.Logf(\"%d is existing\", n) } else { t.Logf(\"%d is not existing\", n) } } ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:18:0","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"结构体 Go语言中通过结构体的内嵌再配合接口比面向对象具有更高的扩展性和灵活性。 ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:19:0","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"类型别名和自定义类型 自定义类型（新类型）： //将MyInt定义为int类型 type MyInt int 可以基于内置的基本类型定义，也可以通过struct定义。 类型别名（Go1.9添加的新功能，注意编译后是原来的类型）： //将MyInt作为为int类型的昵称 type MyInt = int ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:19:1","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"结构体 本质上是一种聚合型的数据类型。 通过struct可以实现面向对象。 定义的时候，同样类型的字段也可以写在一行。 只有结构体被实例化时，才会真正被分配内存。 匿名结构体：定义临时数据结构时可能会用到。 语法糖：Go语言中支持对结构体指针直接使用.来访问结构体的成员，在使用new分配内存后得到的便是结构体指针。 对于包含结构体类型字段的结构体类型来说,可以无需提供字段的名字: 以这种方式定义的结构体字段，我们叫做嵌入字段（Embedded Field）。我们也可以将这种字段称为匿名字段，或者把类型名看作是这个字段的名字 type Book struct { Title string Person ... ... } func main(){ var book Book println(book.Person.Phone) // 将类型名当作嵌入字段的名字 println(book.Phone) // 支持直接访问嵌入字段所属类型中字段 } 注意： 结构体类型 T 定义中，不能有以自身类型 T 定义的字段，但却可以拥有自身类型的指针类型、以自身类型为元素类型的切片类型，以及以自身类型作为 value 类型的 map 类型的字段，因为指针、map、切片的变量元数据的内存占用大小是固定的。 type T struct { a T // wrong t *T // ok st []T // ok m map[string]T // ok } sync.Mutex和bytes.Buffer的“零值可用”： var mu sync.Mutex mu.Lock() mu.Unlock() var b bytes.Buffer b.Write([]byte(\"Hello, Go\")) fmt.Println(b.String()) // 输出：Hello, Go 使用\u0026对结构体进行取地址操作相当于对该结构体类型进行了一次new实例化操作。 p := \u0026person{} 初始化（没有指定初始值的字段的值就是该字段类型的零值）： p := person{ a: \"1a\", b: \"2b\", } //结构体指针 q := \u0026ss{ a: \"1a\", b: \"2b\", } //简写需**注意**三点：1.必须初始化结构体的所有字段。2.初始值的填充顺序必须与字段在结构体中的声明顺序一致。3.该方式不能和键值初始化方式混用。 s := \u0026d{ \"aq\", \"sw\", } Go 语言并不推荐我们按字段顺序对一个结构体类型变量进行显式初始化，甚至 Go 官方还在提供的 go vet 工具中专门内置了一条检查规则：“composites”，用来静态检查代码中结构体变量初始化是否使用了这种方法，一旦发现，就会给出警告。 Go 推荐我们用“field:value”形式的复合字面值，对结构体类型变量进行显式初始化，这种方式可以降低结构体类型使用者和结构体类型设计者之间的耦合 var t = T{ F2: \"hello\", F1: 11, F4: 14, } 空结构体的作用： 空结构体类型变量内存占用为0 使用空结构体类型元素，作为一种“事件”信息进行 Goroutine 之间的通信 var c = make(chan Empty) // 声明一个元素类型为Empty的channel c\u003c-Empty{} // 向channel写入一个“事件” 这种以空结构体为元素类建立的 channel，是目前能实现的、内存占用最小的 Goroutine 间通信方式。 空标识符“_”作为结构体类型定义中的字段名称的作用： 自己实现一个结构体构造函数： //值拷贝开销太大，返回结构体指针 func newPerson(name, city string, age int8) *person { return \u0026person{ name: name, city: city, age: age, } } 如果一个结构体类型中包含未导出字段，并且这个字段的零值还不可用时,又或是一个结构体类型中的某些字段，需要一个复杂的初始化逻辑时：需要使用一个特定的构造函数，来创建并初始化结构体变量了。 结构体类型的内存布局： 在真实情况下，虽然 Go 编译器没有在结构体变量占用的内存空间中插入额外字段，但结构体字段实际上可能并不是紧密相连的，中间可能存在“缝隙”。这些“缝隙”同样是结构体变量占用的内存空间的一部分，它们是 Go 编译器插入的“填充物（Padding）” 这是为了内存对齐。 方法和接收者 Go语言中的方法（Method）是一种作用于特定类型变量的函数。这种特定类型变量叫做接收者（Receiver）。接收者的概念就类似于其他语言中的this或者 self。 //接收者变量：接收者中的参数变量名在命名时，官方建议使用接收者类型名的第一个小写字母，而不是self、this之类的命名。例如，Person类型的接收者变量应该命名为 p，Connector类型的接收者变量应该命名为c等。 func (接收者变量 接收者类型) 方法名(参数列表) (返回参数) { 函数体 } 指针类型的接收者： 指针类型的接收者由一个结构体的指针组成，由于指针的特性，调用方法时修改接收者指针的任意成员变量，在方法结束后，修改都是有效的。这种方式就十分接近于其他语言中面向对象中的this或者self。 例如我们为Person添加一个SetAge方法，来修改实例变量的年龄。 // SetAge 设置p的年龄 // 使用指针接收者 func (p *Person) SetAge(newAge int8) { p.age = newAge } //调用该方法 func main() { p1 := NewPerson(\"测试\", 25) fmt.Println(p1.age) // 25 p1.SetAge(30) fmt.Println(p1.age) // 30 } 值类型的接收者： // SetAge2 设置p的年龄 // 使用值接收者 func (p Person) SetAge2(newAge int8) { p.age = newAge } func main() { p1 := NewPerson(\"测试\", 25) p1.Dream() fmt.Println(p1.age) // 25 p1.SetAge2(30) // (*p1).SetAge2(30) fmt.Println(p1.age) // 25 } 什么时候应该使用指针类型接收者： 需要修改接收者中的值 接收者是拷贝代价比较大的大对象 保证一致性，如果有某个方法使用了指针接收者，那么其他的方法也应该使用指针接收者。 为任意类型添加方法： 在Go语言中，接收者的类型可以是任何类型，不仅仅是结构体，任何类型都可以拥有方法。 举个例子，我们基于内置的int类型使用type关键字可以定义新的自定义类型，然后为我们的自定义类型添加方法。 注意事项：非本地类型不能定义方法，也就是说我们不能给别的包的类型定义方法。 结构体的匿名字段： 结构体允许其成员字段在声明时没有字段名而只有类型，这种没有名字的字段就称为匿名字段。 匿名字段默认采用类型名作为字段名，结构体要求字段名称必须唯一，因此一个结构体中同种类型的匿名字段只能有一个。 嵌套结构体 一个结构体中可以嵌套包含另一个结构体或结构体指针。 嵌套结构体内部可能存在相同的字段名。这个时候为了避免歧义需要指定具体的内嵌结构体的字段。 类型的“继承”： 即通过类型嵌入，包括接口类型的类型嵌入和结构体类型的类型嵌入。 结构体类型中嵌入接口类型：结构体类型的方法集合，包含嵌入的接口类型的方法集合。 结构体类型嵌入接口类型在日常编码中有一个妙用，就是可以简化单元测试的编写：见下面例子： 由于嵌入某接口类型的结构体类型的方法集合包含了这个接口类型的方法集合，这就意味着，这个结构体类型也是它嵌入的接口类型的一个实现 package employee type Result struct { Count int } func (r Result) Int() int { return r.Count } type Rows []struct{} type Stmt interface { Close() error NumInput() int Exec(stmt string, args ...string) (Result, error) Query(args []string) (Rows, error) } // 返回男性员工总数 func MaleCount(s Stmt) (int, error) { result, err := s.Exec(\"select count(*) from employee_tab where gender=?\", \"1\") if err != nil { return 0, err } return result.Int(), nil } package employee import \"testing\" type fakeStmtForMaleCount struct { Stmt } func (fakeStmtForMaleCount) Exec(stmt string, args ...string) (Result, error) { return Result{Count: 5}, nil } func TestEmployeeMaleCount(t *testing.T) { f :=","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:19:2","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"go项目的标准布局演进 官方并没有给标准布局，但社区还是有的。随着go版本的不断更新，Go源码比例不断增大，Go 1.0时还占比32%的C语言现在也只不过占比不到1%。而项目布局一直保持了下来。 Go 1.3 src 目录下面的结构： 以 all.bash 为代表的代码构建的脚本源文件放在了 src 下面的顶层目录下。 src 下的二级目录 cmd 下面存放着 Go 相关可执行文件的相关目录 每个子目录都是一个 Go 工具链命令或子命令对应的可执行文件 src 下的二级目录 pkg 下面存放着运行时实现、标准库包实现，这些包既可以被上面 cmd 下各程序所导入，也可以被 Go 语言项目之外的 Go 程序依赖并导入。 Go 1.4 版本删除 pkg 这一中间层目录并引入 internal 目录。“src/pkg/xxx”-\u003e“src/xxx” 根据 internal 机制的定义，一个 Go 项目里的 internal 目录下的 Go 包，只可以被本项目内部的包导入。项目外部是无法导入这个 internal 目录下面的包的。 internal 目录的引入，让一个 Go 项目中 Go 包的分类与用途变得更加清晰 Go 1.6 版本增加 vendor 目录 为了解决 Go 包依赖版本管理的问题，Go 核心团队在 Go 1.5 版本中做了第一次改进。增加了 vendor 构建机制，也就是 Go 源码的编译可以不在 GOPATH 环境变量下面搜索依赖包的路径，而在 vendor 目录下查找对应的依赖包 Go 1.7 版本，Go 在 vendor 下缓存了其依赖的外部包。这些依赖包主要是 golang.org/x 下面的包 vendor 机制与目录的引入，让 Go 项目第一次具有了可重现构建（Reproducible Build）的能力。 Go 1.13 版本引入 go.mod 和 go.sum 在 Go 1.11 版本中，Go 核心团队做出了第二次改进尝试：引入了 Go Module 构建机制，也就是在项目引入 go.mod 以及在 go.mod 中明确项目所依赖的第三方包和版本，项目的构建就将摆脱 GOPATH 的束缚，实现精准的可重现构建。 Go 语言项目自身在 Go 1.13 版本引入 go.mod 和 go.sum 以支持 Go Module 构建机制 Go 可执行程序项目的典型结构布局： ├── cmd/ │ ├── app1/ │ │ └── main.go │ └── app2/ │ └── main.go ├── go.mod ├── go.sum ├── internal/ │ ├── pkga/ │ │ └── pkg_a.go │ └── pkgb/ │ └── pkg_b.go ├── pkg1/ │ └── pkg1.go ├── pkg2/ │ └── pkg2.go └── vendor/ cmd（也可以是app或者其他名字） 存放项目要编译构建的可执行文件对应的 main 包的源文件。如果你的项目中有多个可执行文件需要构建，每个可执行文件的 main 包单独放在一个子目录中，cmd 目录下的各 app 的 main 包将整个项目的依赖连接在一起 通常来说，main 包应该很简洁。我们在 main 包中会做一些命令行参数解析、资源初始化、日志设施初始化、数据库连接初始化等工作，之后就会将程序的执行权限交给更高级的执行控制对象 pkgN 一个存放项目自身要使用、同样也是可执行文件对应 main 包所要依赖的库文件，同时这些目录下的包还可以被外部项目引用。 go.mod和go.sum 包依赖管理的配置文件 vendor（可选） 前面有说，vendor 是 Go 1.5 版本引入的用于在项目本地缓存特定版本依赖包的机制 Go Module 机制也保留了 vendor 目录（通过 go mod vendor 可以生成 vendor 下的依赖包，通过 go build -mod=vendor 可以实现基于 vendor 的构建）。一般我们仅保留项目根目录下的 vendor 目录，否则会造成不必要的依赖选择的复杂性。 etc 如若喜欢借助一些第三方的构建工具辅助构建，比如：make、bazel 等。你可以将这类外部辅助构建工具涉及的诸多脚本文件（比如 Makefile）放置在项目的顶层目录下，就像 Go 1.3中的 all.bash 那样。 如果app1，app2的发布版本不总是同步的，建议将每个项目单独作为一个 module 进行单独的版本管理和演进，避免版本管理的“分歧”带来更大的复杂性。当然新版Go命令较好地解决了这一点，可以采用如下结构： ├── go.mod // mainmodule ├── module1 │ └── go.mod // module1 └── module2 └── go.mod // module2 可以通过 git tag 名字来区分不同 module 的版本。其中 vX.Y.Z 形式的 tag 名字用于代码仓库下的 mainmodule；而 module1/vX.Y.Z 形式的 tag 名字用于指示 module1 的版本。 Go 库项目的典型结构布局：Go 库项目主要作用还是对外暴露 API。 ├── go.mod ├── internal/ │ ├── pkga/ │ │ └── pkg_a.go │ └── pkgb/ │ └── pkg_b.go ├── pkg1/ │ └── pkg1.go └── pkg2/ └── pkg2.go 不需要构建可执行程序 仅限项目内部使用而不想暴露到外部的包，可以放在项目顶层的 internal 目录下面。当然 internal 也可以有多个并存在于项目结构中的任一目录层级中，关键是项目结构设计人员要明确各级 internal 包的应用层次和范围。 ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:20:0","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"go应用构建模式的演进 Go 程序的构建过程就是确定包版本、编译包以及将编译后得到的目标文件链接在一起的过程。 包依赖管理演进： GOPATH模式。 Go 编译器可以在本地 GOPATH 环境变量配置的路径下，搜寻 Go 程序依赖的第三方包。如果存在，就使用这个本地包进行编译；如果不存在，就会报编译错误 如果你没有显式设置 GOPATH 环境变量，Go 会将 GOPATH 设置为默认值，不同操作系统下默认值的路径不同 可以通过 go get 命令将本地缺失的第三方依赖包下载到本地。不仅能将包下载到 GOPATH 环境变量配置的目录下，它还会检查该包的依赖包在本地是否存在，如果不存在，go get 也会一并将它们下载到本地。但是，go get只能得到最新主线版本的依赖包，不能保证Reproduceable Build 总之，在 GOPATH 构建模式下，Go 编译器实质上并没有关注 Go 项目所依赖的第三方包的版本。从而有了Vendor机制控制依赖包版本。 Vendor机制 本质上就是在 Go 项目的某个特定目录下，将项目的所有依赖包缓存起来，这个特定目录名就是 vendor。 Go 编译器会优先感知和使用 vendor 目录下缓存的第三方包版本，而不是 GOPATH 环境变量所配置的路径下的第三方包版本。 目录示例： ├── main.go └── vendor/ ├── github.com/ │ └── sirupsen/ │ └── logrus/ └── golang.org/ └── x/ └── sys/ └── unix/ 开启 vendor 机制，你的 Go 项目必须位于 GOPATH 环境变量配置的某个路径的 src 目录下面 不足之处主要在于需要手工管理 vendor 下面的 Go 依赖包（Go 社区先后开发了诸如 gb、glide、dep 等工具，都是用来进行依赖分析管理的，自身却都存在某些问题）、庞大的vendor目录也得提交到代码仓库，以及项目路径的限制。 Go Module 如何创建？ go mod init go mod tidy go build go.sum是由 go mod 相关命令维护的一个文件，它存放了特定版本 module 内容的哈希值。这是 Go Module 的一个安全措施。当将来这里的某个 module 的特定版本被再次下载的时候，go 命令会使用 go.sum 文件中对应的哈希值，和新下载的内容的哈希值进行比对，只有哈希值比对一致才是合法的，这样可以确保你的项目所依赖的 module 内容，不会被恶意或意外篡改。 项目所依赖的包有很多版本，Go Module 是如何选出最适合的那个版本？ Go Module 的语义导入版本机制 go.mod 的 require 段中依赖的版本号，都符合 vX.Y.Z 的格式。语义版本号分成 3 部分：主版本号 (major)、次版本号 (minor) 和补丁版本号 (patch)。分别对应XYZ。 按照语义版本规范，主版本号不同的两个版本是相互不兼容的。而且，在主版本号相同的情况下，次版本号大都是向后兼容次版本号小的版本。补丁版本号也不影响兼容性 Go Module 规定：如果同一个包的新旧版本是兼容的，那么它们的包导入路径应该是相同的。 如果不兼容，Go Module 创新性地给出了一个方法：将包主版本号引入到包导入路径中，我们可以像下面这样导入 logrus v2.0.0 版本依赖包： import \"github.com/sirupsen/logrus/v2\" 关于主版本号为0时，按照语义版本规范的说法，v0.y.z 这样的版本号是用于项目初始开发阶段的版本号。在这个阶段任何事情都有可能发生，其 API 也不应该被认为是稳定的。Go Module 将这样的版本 (v0) 与主版本号 v1 做同等对待，也就是采用不带主版本号的包导入路径 总之，通过在包导入路径中引入主版本号的方式，来区别同一个包的不兼容版本。 最小版本选择原则 包依赖关系比较复杂时，一个包A的两个依赖包BC可能依赖于不同版本的某个包D，那A依赖于D的哪个版本？ Go 会在该项目依赖项的所有版本中，选出符合项目整体要求的“最小版本”。 明确具体版本下 Go Module 的实际表现行为还是比较重要的，方便应用时选择切换。 Go 各版本构建模式机制和切换： Go 1.11后一段时间GOPATH 构建模式与 Go Modules 构建模式各自独立工作，我们可以通过设置环境变量 GO111MODULE 的值在两种构建模式间切换。 Go 1.16 版本，Go Module 构建模式成为了默认模式。 目前我觉得GOPATH似乎可以抛弃了 Go Module常规操作： 为当前 module 添加一个依赖： go get 命令将我们新增的依赖包下载到了本地 module 缓存里，并在 go.mod 文件的 require 段中新增相关内容。 使用 go mod tidy 命令，在执行构建前自动分析源码中的依赖变化，识别新增依赖项并下载它们 两种方法都行，复杂的项目用go mod tidy/go get .（注意二者还是有区别的,看到后面你就知道了） 升级、降级依赖版本： 查询某个依赖包的版本 PS D:\\Blog\\qizhengzou.github.io-blog\\content\\posts\u003e go list -m -versions github.com/sirupsen/logrus github.com/sirupsen/logrus v0.1.0 v0.1.1 v0.2.0 v0.3.0 v0.4.0 v0.4.1 v0.5.0 v0.5.1 v0.6.0 v0.6.1 v0.6.2 v0.6.3 v0.6.4 v0.6.5 v0.6.6 v0.7.0 v0.7.1 v0.7.2 v0.7.3 v0.8.0 v0.8.1 v0.8.2 v0.8.3 v0.8.4 v0.8.5 v0.8.6 v0.8.7 v0.9.0 v0.10.0 v0.11.0 v0.11.1 v0.11.2 v0.11.3 v0.11.4 v0.11.5 v1.0.0 v1.0.1 v1.0.3 v1.0.4 v1.0.5 v1.0.6 v1.1.0 v1.1.1 v1.2.0 v1.3.0 v1.4.0 v1.4.1 v1.4.2 v1.5.0 v1.6.0 v1.7.0 v1.7.1 v1.8.0 v1.8.1 //go mod tidy帮我们选择了v1.8.1 我们可以在项目的 module 根目录下，执行带有版本号的 go get 命令eg: go get github.com/sirupsen/logrus@v1.7.0 或者，用 go mod edit 命令，明确告知我们要依赖 v1.7.0 版本，而不是 v1.8.1。执行go mod edit -require=github.com/sirupsen/logrus@v1.7.0再go mod tidy。 添加一个主版本号大于 1 的依赖： 在声明它的导入路径的基础上，加上版本号信息 升级依赖版本到一个不兼容版本： 需要注意一点，可能需要移除对某个包的依赖 移除一个依赖 要想彻底从项目中移除 go.mod 中的依赖项，仅从源码中删除对依赖项的导入语句还不够。 还得用 go mod tidy 命令，将这个依赖项彻底从 Go Module 构建上下文中清除掉。go mod tidy 会自动分析源码依赖，而且将不再使用的依赖从 go.mod 和 go.sum 中移除。 特殊情况：借用Vendor Vendor机制其实可以作为Go Module的一个很好的补充。 在一些不方便访问外部网络，并且对 Go 应用构建性能敏感的环境，比如在一些内部的持续集成或持续交付环境（CI/CD）中，使用 vendor 机制可以实现与 Go Module 等价的构建。 Go 提供了可以快速建立和更新 vendor 的命令： go mod vendor make vendored copy of dependencies(将依赖复制到vendor下) 在 go build 后面加上 -mod=vendor 参数，可以快速基于 vendor 构建项目。 在 Go 1.14 及以后版本中，如果 Go 项目的顶层目录下存在 vendor 目录，那么 go build 默认也会优先基于 vendor 构建，除非你给 go build 传入 -mod=mod 的参数 ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:21:0","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Go"],"content":"参考 https://cloud.tencent.com/developer/article/1526095 https://www.topgoer.cn/docs/golang/chapter02 https://time.geekbang.org/column/article/429143 ","date":"2022-01-06 20:55:59","objectID":"/go_base_01/:22:0","tags":["go grammar"],"title":"Go_base_01","uri":"/go_base_01/"},{"categories":["Catalogue","Go"],"content":" 参考学习go语言中文网、C语言中文网、golang官方文档等 go_base_01 go起源 环境相关 主要特征 内置类型与函数 init \u0026 main以及Go包的初始化顺序 go命令 go env go run命令 go get go build命令 go install go clean命令 go doc命令 go test命令 go list命令 go fix go vet go tool pprof命令 go modules 运算符 下划线 格式占位符%…… 变量和常量 基本类型 string： 数组 切片 切片底层实现 创建切片 切片拷贝 指针 map map实现原理 go中map的实现原理 map与工厂模式 set 结构体 类型别名和自定义类型 结构体 方法和接收者 go项目的标准布局演进 go应用构建模式的演进 参考 go_base_02 if switch Type Switch select 基本使用 典型用法 for range Goto Break Continue go_base_03 函数定义 参数 不定参 返回值 匿名函数 闭包、递归 闭包 go递归函数 延迟调用（defer） defer陷阱 异常处理，错误处理 单元测试 go test工具 测试函数 测试组 子测试 测试覆盖率 基准测试 x性能比较函数 重置时间 并行测试 Setup与TearDown 示例函数 func ToUpper 压力测试 Go怎么写测试用例 如何编写测试用例 如何编写压力测试 小结 BDD go_base_04 方法定义 匿名字段 方法集 表达式 自定义error 抛异常和处理异常 系统抛 返回异常 自定义error go_base_05 匿名字段 接口 接口 类型与接口的关系 空接口 空接口的应用 类型断言 go_base_06 互联网协议介绍 互联网分层模型 socket编程 http编程 WebSocket编程 go_base_07 并发介绍 Goroutine runtime包 Channel Goroutine池 定时器 select 并发安全和锁 Sync 原子操作 GMP原理和调度 爬虫小案例 ","date":"2022-01-06 09:17:19","objectID":"/go_grammar_catalogue/:0:0","tags":["catalogue","go grammar"],"title":"Go_grammar_catalogue","uri":"/go_grammar_catalogue/"},{"categories":["Go"],"content":" 参考学习go语言中文网、C语言中文网、golang官方文档等 并发编程 ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:0:0","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"并发介绍 进程和线程 进程是程序在操作系统中的一次执行过程，系统进行资源分配和调度的一个独立单位。 线程是进程的一个执行实体,是CPU调度和分派的基本单位,它是比进程更小的能独立运行的基本单位。 一个进程可以创建和撤销多个线程;同一个进程中的多个线程之间可以并发执行。 并发和并行 多线程程序在一个核的cpu上运行，就是并发。（一段时间内都有运行） 多线程程序在多个核的cpu上运行，就是并行。（同时运行） 协程和线程 协程：独立的栈空间，共享堆空间，调度由用户自己控制，本质上有点类似于用户级线程，这些用户级线程的调度也是自己实现的。 线程：一个线程上可以跑多个协程，协程是轻量级的线程。 goroutine 只是由官方实现的超级”线程池”。 每个实力4~5KB的栈内存占用和由于实现机制而大幅减少的创建和销毁开销是go高并发的根本原因。 并发不是并行： 并发主要由切换时间片来实现”同时”运行，并行则是直接利用多核实现多线程的运行，go可以设置使用核数，以发挥多核计算机的能力。 goroutine 奉行通过通信来共享内存，而不是共享内存来通信。 ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:1:0","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"Goroutine 在java/c++中我们要实现并发编程的时候，我们通常需要自己维护一个线程池，并且需要自己去包装一个又一个的任务，同时需要自己去调度线程执行任务并维护上下文切换，这一切通常会耗费程序员大量的心智。那么能不能有一种机制，程序员只需要定义很多个任务，让系统去帮助我们把这些任务分配到CPU上实现并发执行呢？ Go语言中的goroutine就是这样一种机制，goroutine的概念类似于线程，但 goroutine是由Go的运行时（runtime）调度和管理的。Go程序会智能地将 goroutine 中的任务合理地分配给每个CPU。Go语言之所以被称为现代化的编程语言，就是因为它在语言层面已经内置了调度和上下文切换的机制。 在Go语言编程中你不需要去自己写进程、线程、协程，你的技能包里只有一个技能–goroutine，当你需要让某个任务并发执行的时候，你只需要把这个任务包装成一个函数，开启一个goroutine去执行这个函数就可以了，就是这么简单粗暴。 ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:2:0","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"使用goroutine Go语言中使用goroutine非常简单，只需要在调用函数的时候在前面加上go关键字，就可以为一个函数创建一个goroutine。 一个goroutine必定对应一个函数，可以创建多个goroutine去执行相同的函数。 启动单个goroutine 启动goroutine的方式非常简单，只需要在调用的函数（普通函数和匿名函数）前面加上一个go关键字。 举个例子如下： func hello() { fmt.Println(\"Hello Goroutine!\") } func main() { hello() fmt.Println(\"main goroutine done!\") } 这个示例中hello函数和下面的语句是串行的，执行的结果是打印完Hello Goroutine!后打印main goroutine done!。 接下来我们在调用hello函数前面加上关键字go，也就是启动一个goroutine去执行hello这个函数。 func main() { go hello() // 启动另外一个goroutine去执行hello函数 fmt.Println(\"main goroutine done!\") } 这一次的执行结果只打印了main goroutine done!，并没有打印Hello Goroutine!。为什么呢？ 在程序启动时，Go程序就会为main()函数创建一个默认的goroutine。 当main()函数返回的时候该goroutine就结束了，所有在main()函数中启动的goroutine会一同结束，main函数所在的goroutine就像是权利的游戏中的夜王，其他的goroutine都是异鬼，夜王一死它转化的那些异鬼也就全部GG了。 所以我们要想办法让main函数等一等hello函数，最简单粗暴的方式就是time.Sleep了。 func main() { go hello() // 启动另外一个goroutine去执行hello函数 fmt.Println(\"main goroutine done!\") time.Sleep(time.Second) } 执行上面的代码你会发现，这一次先打印main goroutine done!，然后紧接着打印Hello Goroutine!。 首先为什么会先打印main goroutine done!是因为我们在创建新的goroutine的时候需要花费一些时间，而此时main函数所在的goroutine是继续执行的。 启动多个goroutine 在Go语言中实现并发就是这样简单，我们还可以启动多个goroutine。让我们再来一个例子： （这里使用了sync.WaitGroup来实现goroutine的同步） var wg sync.WaitGroup func hello(i int) { defer wg.Done() // goroutine结束就登记-1 fmt.Println(\"Hello Goroutine!\", i) } func main() { for i := 0; i \u003c 10; i++ { wg.Add(1) // 启动一个goroutine就登记+1 go hello(i) } wg.Wait() // 等待所有登记的goroutine都结束 } 多次执行上面的代码，会发现每次打印的数字的顺序都不一致。这是因为10个goroutine是并发执行的，而goroutine的调度是随机的。 注意 如果主协程退出了，其他任务还执行吗（运行下面的代码测试一下吧） package main import ( \"fmt\" \"time\" ) func main() { // 合起来写 go func() { i := 0 for { i++ fmt.Printf(\"new goroutine: i = %d\\n\", i) time.Sleep(time.Second) } }() i := 0 for { i++ fmt.Printf(\"main goroutine: i = %d\\n\", i) time.Sleep(time.Second) if i == 2 { break } } } ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:2:1","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"goroutine与线程 可增长的栈 OS线程（操作系统线程）一般都有固定的栈内存（通常为2MB）,一个goroutine的栈在其生命周期开始时只有很小的栈（典型情况下2KB），goroutine的栈不是固定的，他可以按需增大和缩小，goroutine的栈大小限制可以达到1GB，虽然极少会用到这么大。所以在Go语言中一次创建十万左右的goroutine也是可以的。 goroutine调度 GPM是Go语言运行时（runtime）层面的实现，是go语言自己实现的一套调度系统。区别于操作系统调度OS线程。 G很好理解，就是个goroutine的，里面除了存放本goroutine信息外 还有与所在P的绑定等信息。 P是go语言实现的协程处理器，管理着一组goroutine队列，P里面会存储当前goroutine运行的上下文环境（函数指针，堆栈地址及地址边界），P会对自己管理的goroutine队列做一些调度（比如把占用CPU时间较长的goroutine暂停，或者阻塞的协程进行跳过（有一个守护线程会记录每个processor完成的协程的数量，如果有个P完成的协程的数量一直不变，说明被阻塞了，守护线程会往这个协程的用户栈里插入一个特殊的标记，当协程运行内敛函数时会读到这个标记，会把自己中断下来，然后查找等候协程队列的队尾，然后切换成别的线程进一步运行）、运行后续的goroutine等等）当自己的队列消费完了就去全局队列里取，如果全局队列里也消费完了会去其他P的队列里抢任务。 另一个提高整个并发能力的机制：当某一个协程被系统中断了，比如一些IO操作，需要等待的时候，为了提高整体的并发，processor会把自己移到另一个可使用的系统进程当中，继续执行它所挂的队列里的其他的协程，当被中断的协程被唤醒，会把自己加入到某一个pocessor的协程等待队列里，或者加入到全局等待队列当中。需要注意的一点：当一个协程被中断的时候，其在寄存器里的运行状态也会保存到这个协程对象里，当协程再次获得运行的机会，这些又会重新写入寄存器继续运行。 go的协程机制与系统线程的这种多对多的关系以及它是如何来高效地利用系统线程来尽量多的运行并发的协程任务的。 M（machine）是Go运行时（runtime）对操作系统内核线程的虚拟， M与内核线程一般是一一映射的关系，也可以是多对一， 一个groutine最终是要放到M上执行的； P与M一般也是一一对应的。他们关系是： P管理着一组G挂载在M上运行。当一个G长久阻塞在一个M上时，runtime会新建一个M，阻塞G所在的P会把其他的G 挂载在新建的M上。当旧的G阻塞完成或者认为其已经死掉时回收旧的M。 P的个数是通过runtime.GOMAXPROCS设定（最大256），Go1.5版本之后默认为物理线程数。 在并发量大的时候会增加一些P和M，但不会太多，切换太频繁的话得不偿失。 单从线程调度讲，Go语言相比起其他语言的优势在于OS线程是由OS内核来调度的，goroutine则是由Go运行时（runtime）自己的调度器调度的，这个调度器使用一个称为m:n调度的技术（复用/调度m个goroutine到n个OS线程）。 其一大特点是goroutine的调度是在用户态下完成的， 不涉及内核态与用户态之间的频繁切换，包括内存的分配与释放，都是在用户态维护着一块大的内存池， 不直接调用系统的malloc函数（除非内存池需要改变），成本比调度OS线程低很多。 另一方面充分利用了多核的硬件资源，近似的把若干goroutine均分在物理线程上， 再加上本身goroutine的超轻量，以上种种保证了go调度方面的性能。 kernel space entity 系统线程或者说内核对象，内核对象切换的消耗很大。 多个协程对应于一个内核线程时，这些协程切换时消耗较少。 package groutine_test import ( \"fmt\" \"testing\" \"time\" ) func TestGroutine(t *testing.T) { for i := 0; i \u003c 10; i++ { go func(i int) { time.Sleep(time.Second * 1) fmt.Println(i) }(i) } time.Sleep(time.Millisecond * 50) } ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:2:2","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"runtime包 ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:3:0","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"runtime.Gosched() 让出CPU时间片，重新等待安排任务(大概意思就是本来计划的好好的周末出去烧烤，但是你妈让你去相亲,两种情况第一就是你相亲速度非常快，见面就黄不耽误你继续烧烤，第二种情况就是你相亲速度特别慢，见面就是你侬我侬的，耽误了烧烤，但是还馋就是耽误了烧烤你还得去烧烤) package main import ( \"fmt\" \"runtime\" ) func main() { go func(s string) { for i := 0; i \u003c 2; i++ { fmt.Println(s) } }(\"world\") // 主协程 for i := 0; i \u003c 2; i++ { // 切一下，再次分配任务 runtime.Gosched() fmt.Println(\"hello\") } } ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:3:1","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"runtime.Goexit() 退出当前协程(一边烧烤一边相亲，突然发现相亲对象太丑影响烧烤，果断让她滚蛋，然后也就没有然后了) package main import ( \"fmt\" \"runtime\" ) func main() { go func() { defer fmt.Println(\"A.defer\") func() { defer fmt.Println(\"B.defer\") // 结束协程 runtime.Goexit() defer fmt.Println(\"C.defer\") fmt.Println(\"B\") }() fmt.Println(\"A\") }() for { } } ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:3:2","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"runtime.GOMAXPROCS Go运行时的调度器使用GOMAXPROCS参数来确定需要使用多少个OS线程来同时执行Go代码。默认值是机器上的CPU核心数。例如在一个8核心的机器上，调度器会把Go代码同时调度到8个OS线程上（GOMAXPROCS是m:n调度中的n）。 Go语言中可以通过runtime.GOMAXPROCS()函数设置当前程序并发时占用的CPU逻辑核心数。 Go1.5版本之前，默认使用的是单核心执行。Go1.5版本之后，默认使用全部的CPU逻辑核心数。 我们可以通过将任务分配到不同的CPU逻辑核心上实现并行的效果，这里举个例子： func a() { for i := 1; i \u003c 10; i++ { fmt.Println(\"A:\", i) } } func b() { for i := 1; i \u003c 10; i++ { fmt.Println(\"B:\", i) } } func main() { runtime.GOMAXPROCS(1) go a() go b() time.Sleep(time.Second) } 两个任务只有一个逻辑核心，此时是做完一个任务再做另一个任务。 将逻辑核心数设为2，此时两个任务并行执行，代码如下。 func a() { for i := 1; i \u003c 10; i++ { fmt.Println(\"A:\", i) } } func b() { for i := 1; i \u003c 10; i++ { fmt.Println(\"B:\", i) } } func main() { runtime.GOMAXPROCS(2) go a() go b() time.Sleep(time.Second) } Go语言中的操作系统线程和goroutine的关系： 一个操作系统线程对应用户态多个goroutine。 go程序可以同时使用多个操作系统线程。 goroutine和OS线程是多对多的关系，即m:n。 ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:3:3","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"共享内存机制 使用锁来实现并发控制 package share_mem import ( \"sync\" \"testing\" \"time\" ) func TestCounter(t *testing.T) { counter := 0 for i := 0; i \u003c 5000; i++ { go func() { counter++ }() } time.Sleep(1 * time.Second) t.Logf(\"counter = %d\", counter) } //使用锁实现线程安全 func TestCounterThreadSafe(t *testing.T) { var mut sync.Mutex counter := 0 for i := 0; i \u003c 5000; i++ { go func() { defer func() { mut.Unlock() }() mut.Lock() counter++ }() } time.Sleep(1 * time.Second) t.Logf(\"counter = %d\", counter) } //是要弄WaitGroup实现 func TestCounterWaitGroup(t *testing.T) { var mut sync.Mutex var wg sync.WaitGroup counter := 0 for i := 0; i \u003c 5000; i++ { wg.Add(1) go func() { defer func() { mut.Unlock() }() mut.Lock() counter++ wg.Done() }() } wg.Wait() t.Logf(\"counter = %d\", counter) } ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:4:0","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"CSP 并发机制 communicating sequential processes通信顺序进程。 依赖于通道来完成两个通信实体之间的协调。 CSP VS Actor Model 和Actor的直接通讯不同，CSP模式则是通过Channel进⾏通讯的，更松耦合⼀些。 Go中channel是有容量限制并且独⽴于处理Groutine，⽽如Erlang，Actor模式中的mailbox容量是⽆限的，接收进程也总是被动地处理消息 可利用channel实现异步返回。 ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:5:0","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"Channel ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:6:0","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"channel 单纯地将函数并发执行是没有意义的。函数与函数间需要交换数据才能体现并发执行函数的意义。 虽然可以使用共享内存进行数据交换，但是共享内存在不同的goroutine中容易发生竞态问题。为了保证数据交换的正确性，必须使用互斥量对内存进行加锁，这种做法势必造成性能问题。 Go语言的并发模型是CSP（Communicating Sequential Processes），提倡通过通信共享内存而不是通过共享内存而实现通信。 如果说goroutine是Go程序并发的执行体，channel就是它们之间的连接。channel是可以让一个goroutine发送特定值到另一个goroutine的通信机制。 Go 语言中的通道（channel）是一种特殊的类型。通道像一个传送带或者队列，总是遵循先入先出（First In First Out）的规则，保证收发数据的顺序。每一个通道都是一个具体类型的导管，也就是声明channel的时候需要为其指定元素类型。 ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:6:1","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"channel类型 channel是一种类型，一种引用类型。声明通道类型的格式如下： var 变量 chan 元素类型 举几个例子： var ch1 chan int // 声明一个传递整型的通道 var ch2 chan bool // 声明一个传递布尔型的通道 var ch3 chan []int // 声明一个传递int切片的通道 ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:6:2","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"创建channel 通道是引用类型，通道类型的空值是nil。 var ch chan int fmt.Println(ch) // \u003cnil\u003e 声明的通道后需要使用make函数初始化之后才能使用。 创建channel的格式如下： make(chan 元素类型, [缓冲大小]) channel的缓冲大小是可选的。 举几个例子： ch4 := make(chan int) ch5 := make(chan bool) ch6 := make(chan []int) ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:6:3","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"channel操作 通道有发送（send）、接收(receive）和关闭（close）三种操作。 发送和接收都使用\u003c-符号。 现在我们先使用以下语句定义一个通道： ch := make(chan int) 发送 将一个值发送到通道中。 ch \u003c- 10 // 把10发送到ch中 接收 从一个通道中接收值。 x := \u003c- ch // 从ch中接收值并赋值给变量x \u003c-ch // 从ch中接收值，忽略结果 关闭 我们通过调用内置的close函数来关闭通道。 close(ch) 关于关闭通道需要注意的事情是，只有在通知接收方goroutine所有的数据都发送完毕的时候才需要关闭通道。通道是可以被垃圾回收机制回收的，它和关闭文件是不一样的，在结束操作之后关闭文件是必须要做的，但关闭通道不是必须的。 关闭后的通道有以下特点： 对一个关闭的通道再发送值就会导致panic。 对一个关闭的通道进行接收会一直获取值直到通道为空。 对一个关闭的并且没有值的通道执行接收操作会得到对应类型的零值。 关闭一个已经关闭的通道会导致panic。 v, ok \u003c-ch; ok 为 bool 值，true 表示正常接受，false 表示通道关闭 所有的 channel 接收者都会在 channel 关闭时，⽴刻从阻塞等待中返回且上 述 ok 值为 false。这个⼴播机制常被利⽤，进⾏向多个订阅者同时发送信号。如：退出信号 package channel_close import ( \"fmt\" \"sync\" \"testing\" ) func dataProducer(ch chan int, wg *sync.WaitGroup) { go func() { for i := 0; i \u003c 10; i++ { ch \u003c- i } close(ch) wg.Done() }() } func dataReceiver(ch chan int, wg *sync.WaitGroup) { go func() { for { if data, ok := \u003c-ch; ok { fmt.Println(data) } else { break } } wg.Done() }() } func TestCloseChannel(t *testing.T) { var wg sync.WaitGroup ch := make(chan int) wg.Add(1) dataProducer(ch, \u0026wg) wg.Add(1) dataReceiver(ch, \u0026wg) // wg.Add(1) // dataReceiver(ch, \u0026wg) wg.Wait() } ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:6:4","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"任务的返回 package concurrency import ( \"fmt\" \"testing\" \"time\" ) func isCancelled(cancelChan chan struct{}) bool { select { case \u003c-cancelChan: return true default: return false } } func cancel_1(cancelChan chan struct{}) { cancelChan \u003c- struct{}{} } func cancel_2(cancelChan chan struct{}) { close(cancelChan) } func TestCancel(t *testing.T) { cancelChan := make(chan struct{}, 0) for i := 0; i \u003c 5; i++ { go func(i int, cancelCh chan struct{}) { for { if isCancelled(cancelCh) { break } time.Sleep(time.Millisecond * 5) } fmt.Println(i, \"Cancelled\") }(i, cancelChan) } cancel_2(cancelChan) time.Sleep(time.Second * 1) } ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:6:5","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"context与任务的取消 关联任务的取消。 go1.9以后，把context正式并入到golang正式的一个包里面了。 context： 根 Context：通过 context.Background () 创建 ⼦ Context：context.WithCancel(parentContext) 创建 ctx, cancel := context.WithCancel(context.Background()) 当前 Context 被取消时，基于他的⼦ context 都会被取消 接收取消通知 \u003c-ctx.Done() package cancel import ( \"context\" \"fmt\" \"testing\" \"time\" ) func isCancelled(ctx context.Context) bool { select { case \u003c-ctx.Done(): return true default: return false } } func TestCancel(t *testing.T) { ctx, cancel := context.WithCancel(context.Background()) for i := 0; i \u003c 5; i++ { go func(i int, ctx context.Context) { for { if isCancelled(ctx) { break } time.Sleep(time.Millisecond * 5) } fmt.Println(i, \"Cancelled\") }(i, ctx) } cancel() time.Sleep(time.Second * 1) } ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:6:6","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"无缓冲的通道 无缓冲的通道又称为阻塞的通道。我们来看一下下面的代码： func main() { ch := make(chan int) ch \u003c- 10 fmt.Println(\"发送成功\") } 上面这段代码能够通过编译，但是执行的时候会出现以下错误： fatal error: all goroutines are asleep - deadlock! goroutine 1 [chan send]: main.main() .../src/github.com/pprof/studygo/day06/channel02/main.go:8 +0x54 为什么会出现deadlock错误呢？ 因为我们使用ch := make(chan int)创建的是无缓冲的通道，无缓冲的通道只有在有人接收值的时候才能发送值。就像你住的小区没有快递柜和代收点，快递员给你打电话必须要把这个物品送到你的手中，简单来说就是无缓冲的通道必须有接收才能发送。 上面的代码会阻塞在ch \u003c- 10这一行代码形成死锁，那如何解决这个问题呢？ 一种方法是启用一个goroutine去接收值，例如： func recv(c chan int) { ret := \u003c-c fmt.Println(\"接收成功\", ret) } func main() { ch := make(chan int) go recv(ch) // 启用goroutine从通道接收值 ch \u003c- 10 fmt.Println(\"发送成功\") } 无缓冲通道上的发送操作会阻塞，直到另一个goroutine在该通道上执行接收操作，这时值才能发送成功，两个goroutine将继续执行。相反，如果接收操作先执行，接收方的goroutine将阻塞，直到另一个goroutine在该通道上发送一个值。 使用无缓冲通道进行通信将导致发送和接收的goroutine同步化。因此，无缓冲通道也被称为同步通道。 有缓冲的通道 解决上面问题的方法还有一种就是使用有缓冲区的通道。 我们可以在使用make函数初始化通道的时候为其指定通道的容量，例如： func main() { ch := make(chan int, 1) // 创建一个容量为1的有缓冲区通道 ch \u003c- 10 fmt.Println(\"发送成功\") } 只要通道的容量大于零，那么该通道就是有缓冲的通道，通道的容量表示通道中能存放元素的数量。就像你小区的快递柜只有那么个多格子，格子满了就装不下了，就阻塞了，等到别人取走一个快递员就能往里面放一个。 我们可以使用内置的len函数获取通道内元素的数量，使用cap函数获取通道的容量，虽然我们很少会这么做。 ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:6:7","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"close() 可以通过内置的close()函数关闭channel（如果你的管道不往里存值或者取值的时候一定记得关闭管道） package main import \"fmt\" func main() { c := make(chan int) go func() { for i := 0; i \u003c 5; i++ { c \u003c- i } close(c) }() for { if data, ok := \u003c-c; ok { fmt.Println(data) } else { break } } fmt.Println(\"main结束\") } ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:6:8","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"如何优雅的从通道循环取值 当通过通道发送有限的数据时，我们可以通过close函数关闭通道来告知从该通道接收值的goroutine停止等待。当通道被关闭时，往该通道发送值会引发panic，从该通道里接收的值一直都是类型零值。那如何判断一个通道是否被关闭了呢？ 我们来看下面这个例子： // channel 练习 func main() { ch1 := make(chan int) ch2 := make(chan int) // 开启goroutine将0~100的数发送到ch1中 go func() { for i := 0; i \u003c 100; i++ { ch1 \u003c- i } close(ch1) }() // 开启goroutine从ch1中接收值，并将该值的平方发送到ch2中 go func() { for { i, ok := \u003c-ch1 // 通道关闭后再取值ok=false if !ok { break } ch2 \u003c- i * i } close(ch2) }() // 在主goroutine中从ch2中接收值打印 for i := range ch2 { // 通道关闭后会退出for range循环 fmt.Println(i) } } 从上面的例子中我们看到有两种方式在接收值的时候判断通道是否被关闭，我们通常使用的是for range的方式。 ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:6:9","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"单向通道 有的时候我们会将通道作为参数在多个任务函数间传递，很多时候我们在不同的任务函数中使用通道都会对其进行限制，比如限制通道在函数中只能发送或只能接收。 Go语言中提供了单向通道来处理这种情况。例如，我们把上面的例子改造如下： func counter(out chan\u003c- int) { for i := 0; i \u003c 100; i++ { out \u003c- i } close(out) } func squarer(out chan\u003c- int, in \u003c-chan int) { for i := range in { out \u003c- i * i } close(out) } func printer(in \u003c-chan int) { for i := range in { fmt.Println(i) } } func main() { ch1 := make(chan int) ch2 := make(chan int) go counter(ch1) go squarer(ch2, ch1) printer(ch2) } 其中， chan\u003c- int是一个只能发送的通道，可以发送但是不能接收； \u003c-chan int是一个只能接收的通道，可以接收但是不能发送。 在函数传参及任何赋值操作中将双向通道转换为单向通道是可以的，但反过来是不可以的。 ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:6:10","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"通道总结 channel常见的异常总结，如下图： 注意:关闭已经关闭的channel也会引发panic。 ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:6:11","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"用多路选择实现超时控制 多路选择select package select_test import ( \"fmt\" \"testing\" \"time\" ) func service() string { time.Sleep(time.Millisecond * 500) return \"Done\" } func AsyncService() chan string { retCh := make(chan string, 1) //retCh := make(chan string, 1) go func() { ret := service() fmt.Println(\"returned result.\") retCh \u003c- ret fmt.Println(\"service exited.\") }() return retCh } func TestSelect(t *testing.T) { select { case ret := \u003c-AsyncService(): t.Log(ret) case \u003c-time.After(time.Millisecond * 100): t.Error(\"time out\") } } ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:7:0","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"Goroutine池 ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:8:0","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"worker pool（goroutine池） 本质上是生产者消费者模型 可以有效控制goroutine数量，防止暴涨 需求： 计算一个数字的各个位数之和，例如数字123，结果为1+2+3=6 随机生成数字进行计算 控制台输出结果如下： package main import ( \"fmt\" \"math/rand\" ) type Job struct { // id Id int // 需要计算的随机数 RandNum int } type Result struct { // 这里必须传对象实例 job *Job // 求和 sum int } func main() { // 需要2个管道 // 1.job管道 jobChan := make(chan *Job, 128) // 2.结果管道 resultChan := make(chan *Result, 128) // 3.创建工作池 createPool(64, jobChan, resultChan) // 4.开个打印的协程 go func(resultChan chan *Result) { // 遍历结果管道打印 for result := range resultChan { fmt.Printf(\"job id:%v randnum:%v result:%d\\n\", result.job.Id, result.job.RandNum, result.sum) } }(resultChan) var id int // 循环创建job，输入到管道 for { id++ // 生成随机数 r_num := rand.Int() job := \u0026Job{ Id: id, RandNum: r_num, } jobChan \u003c- job } } // 创建工作池 // 参数1：开几个协程 func createPool(num int, jobChan chan *Job, resultChan chan *Result) { // 根据开协程个数，去跑运行 for i := 0; i \u003c num; i++ { go func(jobChan chan *Job, resultChan chan *Result) { // 执行运算 // 遍历job管道所有数据，进行相加 for job := range jobChan { // 随机数接过来 r_num := job.RandNum // 随机数每一位相加 // 定义返回值 var sum int for r_num != 0 { tmp := r_num % 10 sum += tmp r_num /= 10 } // 想要的结果是Result r := \u0026Result{ job: job, sum: sum, } //运算结果扔到管道 resultChan \u003c- r } }(jobChan, resultChan) } } ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:8:1","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"定时器 ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:9:0","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"定时器 Timer：时间到了，执行只执行1次 package main import ( \"fmt\" \"time\" ) func main() { // 1.timer基本使用 //timer1 := time.NewTimer(2 * time.Second) //t1 := time.Now() //fmt.Printf(\"t1:%v\\n\", t1) //t2 := \u003c-timer1.C //fmt.Printf(\"t2:%v\\n\", t2) // 2.验证timer只能响应1次 //timer2 := time.NewTimer(time.Second) //for { // \u003c-timer2.C // fmt.Println(\"时间到\") //} // 3.timer实现延时的功能 //(1) //time.Sleep(time.Second) //(2) //timer3 := time.NewTimer(2 * time.Second) //\u003c-timer3.C //fmt.Println(\"2秒到\") //(3) //\u003c-time.After(2*time.Second) //fmt.Println(\"2秒到\") // 4.停止定时器 //timer4 := time.NewTimer(2 * time.Second) //go func() { // \u003c-timer4.C // fmt.Println(\"定时器执行了\") //}() //b := timer4.Stop() //if b { // fmt.Println(\"timer4已经关闭\") //} // 5.重置定时器 timer5 := time.NewTimer(3 * time.Second) timer5.Reset(1 * time.Second) fmt.Println(time.Now()) fmt.Println(\u003c-timer5.C) for { } } Ticker：时间到了，多次执行 package main import ( \"fmt\" \"time\" ) func main() { // 1.获取ticker对象 ticker := time.NewTicker(1 * time.Second) i := 0 // 子协程 go func() { for { //\u003c-ticker.C i++ fmt.Println(\u003c-ticker.C) if i == 5 { //停止 ticker.Stop() } } }() for { } } ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:9:1","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"select ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:10:0","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"select多路复用 在某些场景下我们需要同时从多个通道接收数据。通道在接收数据时，如果没有数据可以接收将会发生阻塞。你也许会写出如下代码使用遍历的方式来实现： for{ // 尝试从ch1接收值 data, ok := \u003c-ch1 // 尝试从ch2接收值 data, ok := \u003c-ch2 … } 这种方式虽然可以实现从多个通道接收值的需求，但是运行性能会差很多。为了应对这种场景，Go内置了select关键字，可以同时响应多个通道的操作。 select的使用类似于switch语句，它有一系列case分支和一个默认的分支。每个case会对应一个通道的通信（接收或发送）过程。select会一直等待，直到某个case的通信操作完成时，就会执行case分支对应的语句。具体格式如下： select { case \u003c-chan1: // 如果chan1成功读到数据，则进行该case处理语句 case chan2 \u003c- 1: // 如果成功向chan2写入数据，则进行该case处理语句 default: // 如果上面都没有成功，则进入default处理流程 } select可以同时监听一个或多个channel，直到其中一个channel ready package main import ( \"fmt\" \"time\" ) func test1(ch chan string) { time.Sleep(time.Second * 5) ch \u003c- \"test1\" } func test2(ch chan string) { time.Sleep(time.Second * 2) ch \u003c- \"test2\" } func main() { // 2个管道 output1 := make(chan string) output2 := make(chan string) // 跑2个子协程，写数据 go test1(output1) go test2(output2) // 用select监控 select { case s1 := \u003c-output1: fmt.Println(\"s1=\", s1) case s2 := \u003c-output2: fmt.Println(\"s2=\", s2) } } 如果多个channel同时ready，则随机选择一个执行 package main import ( \"fmt\" ) func main() { // 创建2个管道 int_chan := make(chan int, 1) string_chan := make(chan string, 1) go func() { //time.Sleep(2 * time.Second) int_chan \u003c- 1 }() go func() { string_chan \u003c- \"hello\" }() select { case value := \u003c-int_chan: fmt.Println(\"int:\", value) case value := \u003c-string_chan: fmt.Println(\"string:\", value) } fmt.Println(\"main结束\") } 可以用于判断管道是否存满 package main import ( \"fmt\" \"time\" ) // 判断管道有没有存满 func main() { // 创建管道 output1 := make(chan string, 10) // 子协程写数据 go write(output1) // 取数据 for s := range output1 { fmt.Println(\"res:\", s) time.Sleep(time.Second) } } func write(ch chan string) { for { select { // 写数据 case ch \u003c- \"hello\": fmt.Println(\"write hello\") default: fmt.Println(\"channel full\") } time.Sleep(time.Millisecond * 500) } } ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:10:1","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"并发安全和锁 有时候在Go代码中可能会存在多个goroutine同时操作一个资源（临界区），这种情况会发生竞态问题（数据竞态）。类比现实生活中的例子有十字路口被各个方向的的汽车竞争；还有火车上的卫生间被车厢里的人竞争。 举个例子： var x int64 var wg sync.WaitGroup func add() { for i := 0; i \u003c 5000; i++ { x = x + 1 } wg.Done() } func main() { wg.Add(2) go add() go add() wg.Wait() fmt.Println(x) } 上面的代码中我们开启了两个goroutine去累加变量x的值，这两个goroutine在访问和修改x变量的时候就会存在数据竞争，导致最后的结果与期待的不符。 ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:11:0","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"互斥锁 互斥锁是一种常用的控制共享资源访问的方法，它能够保证同时只有一个goroutine可以访问共享资源。Go语言中使用sync包的Mutex类型来实现互斥锁。 使用互斥锁来修复上面代码的问题： var x int64 var wg sync.WaitGroup var lock sync.Mutex func add() { for i := 0; i \u003c 5000; i++ { lock.Lock() // 加锁 x = x + 1 lock.Unlock() // 解锁 } wg.Done() } func main() { wg.Add(2) go add() go add() wg.Wait() fmt.Println(x) } 使用互斥锁能够保证同一时间有且只有一个goroutine进入临界区，其他的goroutine则在等待锁；当互斥锁释放后，等待的goroutine才可以获取锁进入临界区，多个goroutine同时等待一个锁时，唤醒的策略是随机的。 ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:11:1","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"读写互斥锁 互斥锁是完全互斥的，但是有很多实际的场景下是读多写少的，当我们并发的去读取一个资源不涉及资源修改的时候是没有必要加锁的，这种场景下使用读写锁是更好的一种选择。读写锁在Go语言中使用sync包中的RWMutex类型。 读写锁分为两种：读锁和写锁。当一个goroutine获取读锁之后，其他的goroutine如果是获取读锁会继续获得锁，如果是获取写锁就会等待；当一个goroutine获取写锁之后，其他的goroutine无论是获取读锁还是写锁都会等待。 读写锁示例： var ( x int64 wg sync.WaitGroup lock sync.Mutex rwlock sync.RWMutex ) func write() { // lock.Lock() // 加互斥锁 rwlock.Lock() // 加写锁 x = x + 1 time.Sleep(10 * time.Millisecond) // 假设读操作耗时10毫秒 rwlock.Unlock() // 解写锁 // lock.Unlock() // 解互斥锁 wg.Done() } func read() { // lock.Lock() // 加互斥锁 rwlock.RLock() // 加读锁 time.Sleep(time.Millisecond) // 假设读操作耗时1毫秒 rwlock.RUnlock() // 解读锁 // lock.Unlock() // 解互斥锁 wg.Done() } func main() { start := time.Now() for i := 0; i \u003c 10; i++ { wg.Add(1) go write() } for i := 0; i \u003c 1000; i++ { wg.Add(1) go read() } wg.Wait() end := time.Now() fmt.Println(end.Sub(start)) } 需要注意的是读写锁非常适合读多写少的场景，如果读和写的操作差别不大，读写锁的优势就发挥不出来。 ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:11:2","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"Sync ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:12:0","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"sync.WaitGroup 在代码中生硬的使用time.Sleep肯定是不合适的，Go语言中可以使用sync.WaitGroup来实现并发任务的同步。 sync.WaitGroup有以下几个方法： 方法名 功能 (wg * WaitGroup) Add(delta int) 计数器+delta (wg *WaitGroup) Done() 计数器-1 (wg *WaitGroup) Wait() 阻塞直到计数器变为0 sync.WaitGroup内部维护着一个计数器，计数器的值可以增加和减少。例如当我们启动了N 个并发任务时，就将计数器值增加N。每个任务完成时通过调用Done()方法将计数器减1。通过调用Wait()来等待并发任务执行完，当计数器值为0时，表示所有并发任务已经完成。 我们利用sync.WaitGroup将上面的代码优化一下： var wg sync.WaitGroup func hello() { defer wg.Done() fmt.Println(\"Hello Goroutine!\") } func main() { wg.Add(1) go hello() // 启动另外一个goroutine去执行hello函数 fmt.Println(\"main goroutine done!\") wg.Wait() } 需要注意sync.WaitGroup是一个结构体，传递的时候要传递指针。 ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:12:1","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"sync.Once 说在前面的话：这是一个进阶知识点。 在编程的很多场景下我们需要确保某些操作在高并发的场景下只执行一次，例如只加载一次配置文件、只关闭一次通道等。 Go语言中的sync包中提供了一个针对只执行一次场景的解决方案–sync.Once。 sync.Once只有一个Do方法，其签名如下： func (o *Once) Do(f func()) {} 注意：如果要执行的函数f需要传递参数就需要搭配闭包来使用。 ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:12:2","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"加载配置文件示例 延迟一个开销很大的初始化操作到真正用到它的时候再执行是一个很好的实践。因为预先初始化一个变量（比如在init函数中完成初始化）会增加程序的启动耗时，而且有可能实际执行过程中这个变量没有用上，那么这个初始化操作就不是必须要做的。我们来看一个例子： var icons map[string]image.Image func loadIcons() { icons = map[string]image.Image{ \"left\": loadIcon(\"left.png\"), \"up\": loadIcon(\"up.png\"), \"right\": loadIcon(\"right.png\"), \"down\": loadIcon(\"down.png\"), } } // Icon 被多个goroutine调用时不是并发安全的 func Icon(name string) image.Image { if icons == nil { loadIcons() } return icons[name] } 多个goroutine并发调用Icon函数时不是并发安全的，现代的编译器和CPU可能会在保证每个goroutine都满足串行一致的基础上自由地重排访问内存的顺序。loadIcons函数可能会被重排为以下结果： func loadIcons() { icons = make(map[string]image.Image) icons[\"left\"] = loadIcon(\"left.png\") icons[\"up\"] = loadIcon(\"up.png\") icons[\"right\"] = loadIcon(\"right.png\") icons[\"down\"] = loadIcon(\"down.png\") } 在这种情况下就会出现即使判断了icons不是nil也不意味着变量初始化完成了。考虑到这种情况，我们能想到的办法就是添加互斥锁，保证初始化icons的时候不会被其他的goroutine操作，但是这样做又会引发性能问题。 使用sync.Once改造的示例代码如下： var icons map[string]image.Image var loadIconsOnce sync.Once func loadIcons() { icons = map[string]image.Image{ \"left\": loadIcon(\"left.png\"), \"up\": loadIcon(\"up.png\"), \"right\": loadIcon(\"right.png\"), \"down\": loadIcon(\"down.png\"), } } // Icon 是并发安全的 func Icon(name string) image.Image { loadIconsOnce.Do(loadIcons) return icons[name] } sync.Once其实内部包含一个互斥锁和一个布尔值，互斥锁保证布尔值和数据的安全，而布尔值用来记录初始化是否完成。这样设计就能保证初始化操作的时候是并发安全的并且初始化操作也不会被执行多次。 ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:12:3","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"sync.Map Go语言中内置的map不是并发安全的。请看下面的示例： var m = make(map[string]int) func get(key string) int { return m[key] } func set(key string, value int) { m[key] = value } func main() { wg := sync.WaitGroup{} for i := 0; i \u003c 20; i++ { wg.Add(1) go func(n int) { key := strconv.Itoa(n) set(key, n) fmt.Printf(\"k=:%v,v:=%v\\n\", key, get(key)) wg.Done() }(i) } wg.Wait() } 上面的代码开启少量几个goroutine的时候可能没什么问题，当并发多了之后执行上面的代码就会报fatal error: concurrent map writes错误。 像这种场景下就需要为map加锁来保证并发的安全性了，Go语言的sync包中提供了一个开箱即用的并发安全版map–sync.Map。开箱即用表示不用像内置的map一样使用make函数初始化就能直接使用。同时sync.Map内置了诸如Store、Load、LoadOrStore、Delete、Range等操作方法。 var m = sync.Map{} func main() { wg := sync.WaitGroup{} for i := 0; i \u003c 20; i++ { wg.Add(1) go func(n int) { key := strconv.Itoa(n) m.Store(key, n) value, _ := m.Load(key) fmt.Printf(\"k=:%v,v:=%v\\n\", key, value) wg.Done() }(i) } wg.Wait() } ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:12:4","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"原子操作 ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:13:0","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"原子操作 代码中的加锁操作因为涉及内核态的上下文切换会比较耗时、代价比较高。针对基本数据类型我们还可以使用原子操作来保证并发安全，因为原子操作是Go语言提供的方法它在用户态就可以完成，因此性能比加锁操作更好。Go语言中原子操作由内置的标准库sync/atomic提供。 ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:13:1","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"atomic包 方法 解释 func LoadInt32(addr int32) (val int32) func LoadInt64(addr int64) (val int64)\u003cbr\u003efunc LoadUint32(addruint32) (val uint32)\u003cbr\u003efunc LoadUint64(addruint64) (val uint64)\u003cbr\u003efunc LoadUintptr(addruintptr) (val uintptr)\u003cbr\u003efunc LoadPointer(addrunsafe.Pointer) (val unsafe.Pointer) 读取操作 func StoreInt32(addr *int32, val int32) func StoreInt64(addr *int64, val int64) func StoreUint32(addr *uint32, val uint32) func StoreUint64(addr *uint64, val uint64) func StoreUintptr(addr *uintptr, val uintptr) func StorePointer(addr *unsafe.Pointer, val unsafe.Pointer) 写入操作 func AddInt32(addr *int32, delta int32) (new int32) func AddInt64(addr *int64, delta int64) (new int64) func AddUint32(addr *uint32, delta uint32) (new uint32) func AddUint64(addr *uint64, delta uint64) (new uint64) func AddUintptr(addr *uintptr, delta uintptr) (new uintptr) 修改操作 func SwapInt32(addr *int32, new int32) (old int32) func SwapInt64(addr *int64, new int64) (old int64) func SwapUint32(addr *uint32, new uint32) (old uint32) func SwapUint64(addr *uint64, new uint64) (old uint64) func SwapUintptr(addr *uintptr, new uintptr) (old uintptr) func SwapPointer(addr *unsafe.Pointer, new unsafe.Pointer) (old unsafe.Pointer) 交换操作 func CompareAndSwapInt32(addr *int32, old, new int32) (swapped bool) func CompareAndSwapInt64(addr *int64, old, new int64) (swapped bool) func CompareAndSwapUint32(addr *uint32, old, new uint32) (swapped bool) func CompareAndSwapUint64(addr *uint64, old, new uint64) (swapped bool) func CompareAndSwapUintptr(addr *uintptr, old, new uintptr) (swapped bool) func CompareAndSwapPointer(addr *unsafe.Pointer, old, new unsafe.Pointer) (swapped bool) 比较并交换操作 ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:13:2","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"示例 我们填写一个示例来比较下互斥锁和原子操作的性能。 var x int64 var l sync.Mutex var wg sync.WaitGroup // 普通版加函数 func add() { // x = x + 1 x++ // 等价于上面的操作 wg.Done() } // 互斥锁版加函数 func mutexAdd() { l.Lock() x++ l.Unlock() wg.Done() } // 原子操作版加函数 func atomicAdd() { atomic.AddInt64(\u0026x, 1) wg.Done() } func main() { start := time.Now() for i := 0; i \u003c 10000; i++ { wg.Add(1) // go add() // 普通版add函数 不是并发安全的 // go mutexAdd() // 加锁版add函数 是并发安全的，但是加锁性能开销大 go atomicAdd() // 原子操作版add函数 是并发安全，性能优于加锁版 } wg.Wait() end := time.Now() fmt.Println(x) fmt.Println(end.Sub(start)) } atomic包提供了底层的原子级内存操作，对于同步算法的实现很有用。这些函数必须谨慎地保证正确使用。除了某些特殊的底层应用，使用通道或者sync包的函数/类型实现同步更好。 ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:13:3","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"GMP原理和调度 ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:14:0","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"一、Golang “调度器” 的由来？ 单进程时代不需要调度器 我们知道，一切的软件都是跑在操作系统上，真正用来干活 (计算) 的是 CPU。早期的操作系统每个程序就是一个进程，知道一个程序运行完，才能进行下一个进程，就是 “单进程时代” 一切的程序只能串行发生。 早期的单进程操作系统，面临 2 个问题： 单一的执行流程，计算机只能一个任务一个任务处理。 进程阻塞所带来的 CPU 时间浪费。 那么能不能有多个进程来宏观一起来执行多个任务呢？ 后来操作系统就具有了最早的并发能力：多进程并发，当一个进程阻塞的时候，切换到另外等待执行的进程，这样就能尽量把 CPU 利用起来，CPU 就不浪费了。 多进程 / 线程时代有了调度器需求 在多进程 / 多线程的操作系统中，就解决了阻塞的问题，因为一个进程阻塞 cpu 可以立刻切换到其他进程中去执行，而且调度 cpu 的算法可以保证在运行的进程都可以被分配到 cpu 的运行时间片。这样从宏观来看，似乎多个进程是在同时被运行。 但新的问题就又出现了，进程拥有太多的资源，进程的创建、切换、销毁，都会占用很长的时间，CPU 虽然利用起来了，但如果进程过多，CPU 有很大的一部分都被用来进行进程调度了。 怎么才能提高 CPU 的利用率呢？ 但是对于 Linux 操作系统来讲，cpu 对进程的态度和线程的态度是一样的。 很明显，CPU 调度切换的是进程和线程。尽管线程看起来很美好，但实际上多线程开发设计会变得更加复杂，要考虑很多同步竞争等问题，如锁、竞争冲突等。 协程来提高 CPU 利用率 多进程、多线程已经提高了系统的并发能力，但是在当今互联网高并发场景下，为每个任务都创建一个线程是不现实的，因为会消耗大量的内存 (进程虚拟内存会占用 4GB [32 位操作系统], 而线程也要大约 4MB)。 大量的进程 / 线程出现了新的问题 高内存占用 调度的高消耗 CPU 好了，然后工程师们就发现，其实一个线程分为 “内核态 “线程和” 用户态 “线程。 一个 “用户态线程” 必须要绑定一个 “内核态线程”，但是 CPU 并不知道有 “用户态线程” 的存在，它只知道它运行的是一个 “内核态线程”(Linux 的 PCB 进程控制块)。 这样，我们再去细化去分类一下，内核线程依然叫 “线程 (thread)”，用户线程叫 “协程 (co-routine)”. 看到这里，我们就要开脑洞了，既然一个协程 (co-routine) 可以绑定一个线程 (thread)，那么能不能多个协程 (co-routine) 绑定一个或者多个线程 (thread) 上呢。 之后，我们就看到了有 3 中协程和线程的映射关系： s=\"default\"\u003e N:1 关系 N 个协程绑定 1 个线程，优点就是协程在用户态线程即完成切换，不会陷入到内核态，这种切换非常的轻量快速。但也有很大的缺点，1 个进程的所有协程都绑定在 1 个线程上 缺点： 某个程序用不了硬件的多核加速能力 一旦某协程阻塞，造成线程阻塞，本进程的其他协程都无法执行了，根本就没有并发的能力了。 s=\"default\"\u003e 1:1 关系 1 个协程绑定 1 个线程，这种最容易实现。协程的调度都由 CPU 完成了，不存在 N:1 缺点， 缺点： 协程的创建、删除和切换的代价都由 CPU 完成，有点略显昂贵了。 s=\"default\"\u003e M:N 关系 M 个协程绑定 1 个线程，是 N:1 和 1:1 类型的结合，克服了以上 2 种模型的缺点，但实现起来最为复杂。 协程跟线程是有区别的，线程由 CPU 调度是抢占式的，协程由用户态调度是协作式的，一个协程让出 CPU 后，才执行下一个协程。 Go 语言的协程 goroutine Go 为了提供更容易使用的并发方法，使用了 goroutine 和 channel。goroutine 来自协程的概念，让一组可复用的函数运行在一组线程之上，即使有协程阻塞，该线程的其他协程也可以被 runtime 调度，转移到其他可运行的线程上。最关键的是，程序员看不到这些底层的细节，这就降低了编程的难度，提供了更容易的并发。 Go 中，协程被称为 goroutine，它非常轻量，一个 goroutine 只占几 KB，并且这几 KB 就足够 goroutine 运行完，这就能在有限的内存空间内支持大量 goroutine，支持了更多的并发。虽然一个 goroutine 的栈只占几 KB，但实际是可伸缩的，如果需要更多内容，runtime 会自动为 goroutine 分配。 Goroutine 特点： 占用内存更小（几 kb） 调度更灵活 (runtime 调度) 被废弃的 goroutine 调度器 好了，既然我们知道了协程和线程的关系，那么最关键的一点就是调度协程的调度器的实现了。 Go 目前使用的调度器是 2012 年重新设计的，因为之前的调度器性能存在问题，所以使用 4 年就被废弃了，那么我们先来分析一下被废弃的调度器是如何运作的？ 大部分文章都是会用 G 来表示 Goroutine，用 M 来表示线程，那么我们也会用这种表达的对应关系。 下面我们来看看被废弃的 golang 调度器是如何实现的？ M 想要执行、放回 G 都必须访问全局 G 队列，并且 M 有多个，即多线程访问同一资源需要加锁进行保证互斥 / 同步，所以全局 G 队列是有互斥锁进行保护的。 老调度器有几个缺点： 创建、销毁、调度 G 都需要每个 M 获取锁，这就形成了激烈的锁竞争。 M 转移 G 会造成延迟和额外的系统负载。比如当 G 中包含创建新协程的时候，M 创建了 G’，为了继续执行 G，需要把 G’交给 M’执行，也造成了很差的局部性，因为 G’和 G 是相关的，最好放在 M 上执行，而不是其他 M’。 系统调用 (CPU 在 M 之间的切换) 导致频繁的线程阻塞和取消阻塞操作增加了系统开销。 ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:14:1","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"二、Goroutine 调度器的 GMP 模型的设计思想 面对之前调度器的问题，Go 设计了新的调度器。 在新调度器中，出列 M (thread) 和 G (goroutine)，又引进了 P (Processor)。 Processor，它包含了运行 goroutine 的资源，如果线程想运行 goroutine，必须先获取 P，P 中还包含了可运行的 G 队列。 GMP 模型 在 Go 中，线程是运行 goroutine 的实体，调度器的功能是把可运行的 goroutine 分配到工作线程上。 全局队列（Global Queue）：存放等待运行的 G。 P 的本地队列：同全局队列类似，存放的也是等待运行的 G，存的数量有限，不超过 256 个。新建 G’时，G’优先加入到 P 的本地队列，如果队列满了，则会把本地队列中一半的 G 移动到全局队列。 P 列表：所有的 P 都在程序启动时创建，并保存在数组中，最多有 GOMAXPROCS(可配置) 个。 M：线程想运行任务就得获取 P，从 P 的本地队列获取 G，P 队列为空时，M 也会尝试从全局队列拿一批 G 放到 P 的本地队列，或从其他 P 的本地队列偷一半放到自己 P 的本地队列。M 运行 G，G 执行之后，M 会从 P 获取下一个 G，不断重复下去。 Goroutine 调度器和 OS 调度器是通过 M 结合起来的，每个 M 都代表了 1 个内核线程，OS 调度器负责把内核线程分配到 CPU 的核上执行。 有关 P 和 M 的个数问题： P 的数量： 由启动时环境变量 $GOMAXPROCS 或者是由 runtime 的方法 GOMAXPROCS() 决定。这意味着在程序执行的任意时刻都只有 $GOMAXPROCS 个 goroutine 在同时运行。 M 的数量: go 语言本身的限制：go 程序启动时，会设置 M 的最大数量，默认 10000. 但是内核很难支持这么多的线程数，所以这个限制可以忽略。 runtime/debug 中的 SetMaxThreads 函数，设置 M 的最大数量 一个 M 阻塞了，会创建新的 M。 M 与 P 的数量没有绝对关系，一个 M 阻塞，P 就会去创建或者切换另一个 M，所以，即使 P 的默认数量是 1，也有可能会创建很多个 M 出来。 P 和 M 何时会被创建： P 何时创建：在确定了 P 的最大数量 n 后，运行时系统会根据这个数量创建 n 个 P。 M 何时创建：没有足够的 M 来关联 P 并运行其中的可运行的 G。比如所有的 M 此时都阻塞住了，而 P 中还有很多就绪任务，就会去寻找空闲的 M，而没有空闲的，就会去创建新的 M。 调度器的设计策略 复用线程：避免频繁的创建、销毁线程，而是对线程的复用。 1）work stealing 机制 当本线程无可运行的 G 时，尝试从其他线程绑定的 P 偷取 G，而不是销毁线程。 2）hand off 机制 当本线程因为 G 进行系统调用阻塞时，线程释放绑定的 P，把 P 转移给其他空闲的线程执行。 利用并行：GOMAXPROCS 设置 P 的数量，最多有 GOMAXPROCS 个线程分布在多个 CPU 上同时运行。GOMAXPROCS 也限制了并发的程度，比如 GOMAXPROCS = 核数/2，则最多利用了一半的 CPU 核进行并行。 抢占：在 coroutine 中要等待一个协程主动让出 CPU 才执行下一个协程，在 Go 中，一个 goroutine 最多占用 CPU 10ms，防止其他 goroutine 被饿死，这就是 goroutine 不同于 coroutine 的一个地方。 全局 G 队列：在新的调度器中依然有全局 G 队列，但功能已经被弱化了，当 M 执行 work stealing 从其他 P 偷不到 G 时，它可以从全局 G 队列获取 G。 go func () 调度流程 从上图我们可以分析出几个结论： 我们通过 go func () 来创建一个 goroutine； 有两个存储 G 的队列，一个是局部调度器 P 的本地队列、一个是全局 G 队列。新创建的 G 会先保存在 P 的本地队列中，如果 P 的本地队列已经满了就会保存在全局的队列中； G 只能运行在 M 中，一个 M 必须持有一个 P，M 与 P 是 1：1 的关系。M 会从 P 的本地队列弹出一个可执行状态的 G 来执行，如果 P 的本地队列为空，就会想其他的 MP 组合偷取一个可执行的 G 来执行； 一个 M 调度 G 执行的过程是一个循环机制； 当 M 执行某一个 G 时候如果发生了 syscall 或则其余阻塞操作，M 会阻塞，如果当前有一些 G 在执行，runtime 会把这个线程 M 从 P 中摘除 (detach)，然后再创建一个新的操作系统的线程 (如果有空闲的线程可用就复用空闲线程) 来服务于这个 P； 当 M 系统调用结束时候，这个 G 会尝试获取一个空闲的 P 执行，并放入到这个 P 的本地队列。如果获取不到 P，那么这个线程 M 变成休眠状态， 加入到空闲线程中，然后这个 G 会被放入全局队列中。 调度器的生命周期 特殊的 M0 和 G0 M0 M0 是启动程序后的编号为 0 的主线程，这个 M 对应的实例会在全局变量 runtime.m0 中，不需要在 heap 上分配，M0 负责执行初始化操作和启动第一个 G， 在之后 M0 就和其他的 M 一样了。 G0 G0 是每次启动一个 M 都会第一个创建的 goroutine，G0 仅用于负责调度的 G，G0 不指向任何可执行的函数，每个 M 都会有一个自己的 G0。在调度或系统调用时会使用 G0 的栈空间，全局变量的 G0 是 M0 的 G0。 我们来跟踪一段代码 package main import \"fmt\" func main() { fmt.Println(\"Hello world\") } 接下来我们来针对上面的代码对调度器里面的结构做一个分析。 也会经历如上图所示的过程： runtime 创建最初的线程 m0 和 goroutine g0，并把 2 者关联。 调度器初始化：初始化 m0、栈、垃圾回收，以及创建和初始化由 GOMAXPROCS 个 P 构成的 P 列表。 示例代码中的 main 函数是 main.main，runtime 中也有 1 个 main 函数 ——runtime.main，代码经过编译后，runtime.main 会调用 main.main，程序启动时会为 runtime.main 创建 goroutine，称它为 main goroutine 吧，然后把 main goroutine 加入到 P 的本地队列。 启动 m0，m0 已经绑定了 P，会从 P 的本地队列获取 G，获取到 main goroutine。 G 拥有栈，M 根据 G 中的栈信息和调度信息设置运行环境 M 运行 G G 退出，再次回到 M 获取可运行的 G，这样重复下去，直到 main.main 退出，runtime.main 执行 Defer 和 Panic 处理，或调用 runtime.exit 退出程序。 调度器的生命周期几乎占满了一个 Go 程序的一生，runtime.main 的 goroutine 执行之前都是为调度器做准备工作，runtime.main 的 goroutine 运行，才是调度器的真正开始，直到 runtime.main 结束而结束。 可视化 GMP 编程 有 2 种方式可以查看一个程序的 GMP 的数据。 方式 1：go tool trace trace 记录了运行时的信息，能提供可视化的 Web 页面。 简单测试代码：main 函数创建 trace，trace 会运行在单独的 goroutine 中，然后 main 打印”Hello World” 退出。 trace.go package main import ( \"os\" \"fmt\" \"runtime/trace\" ) func main() { //创建trace文件 f, err := os.Create(\"trace.out\") if err != nil { panic(err) } defer f.Close() //启动trace goroutine err = trace.Start(f) if err != nil { panic(err) } defer trace.Stop() //main fmt.Println(\"Hello World\") } 运行程序 $ go run trace.go Hello World 会得到一个 trace.out 文件，然后我们可以用一个工具打开，来分析这个文件。 $ go tool trace trace.out 2020/02/23 10:44:11 Parsing trace... 2020/02/23 10:44:11 Splitting trace... 2020/02/23 10:44:11 Opening browser. Trace viewer is listening on http://127.0.0.1:33479 我们可以通过浏览器打开 http://127.0.0.1:33479 网址，点击 view trace 能够看见可视化的调度流程。 G 信息 点击 Goroutines 那一行可视化的数据条，我们会看到一些详细的信息。 一共有两个G在程序中，一个是特殊的G0，是每个M必","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:14:2","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"三、Go 调度器调度场景过程全解析 场景 1 P 拥有 G1，M1 获取 P 后开始运行 G1，G1 使用 go func() 创建了 G2，为了局部性 G2 优先加入到 P1 的本地队列。 场景 2 G1 运行完成后 (函数：goexit)，M 上运行的 goroutine 切换为 G0，G0 负责调度时协程的切换（函数：schedule）。从 P 的本地队列取 G2，从 G0 切换到 G2，并开始运行 G2 (函数：execute)。实现了线程 M1 的复用。 场景 3 假设每个 P 的本地队列只能存 3 个 G。G2 要创建了 6 个 G，前 3 个 G（G3, G4, G5）已经加入 p1 的本地队列，p1 本地队列满了。 场景 4 G2 在创建 G7 的时候，发现 P1 的本地队列已满，需要执行负载均衡 (把 P1 中本地队列中前一半的 G，还有新创建 G 转移到全局队列) （实现中并不一定是新的 G，如果 G 是 G2 之后就执行的，会被保存在本地队列，利用某个老的 G 替换新 G 加入全局队列） 这些 G 被转移到全局队列时，会被打乱顺序。所以 G3,G4,G7 被转移到全局队列。 场景 5 G2 创建 G8 时，P1 的本地队列未满，所以 G8 会被加入到 P1 的本地队列。 G8 加入到 P1 点本地队列的原因还是因为 P1 此时在与 M1 绑定，而 G2 此时是 M1 在执行。所以 G2 创建的新的 G 会优先放置到自己的 M 绑定的 P 上。 场景 6 规定：在创建 G 时，运行的 G 会尝试唤醒其他空闲的 P 和 M 组合去执行。 假定 G2 唤醒了 M2，M2 绑定了 P2，并运行 G0，但 P2 本地队列没有 G，M2 此时为自旋线程（没有 G 但为运行状态的线程，不断寻找 G）。 (7) 场景 7 M2 尝试从全局队列 (简称 “GQ”) 取一批 G 放到 P2 的本地队列（函数：findrunnable()）。M2 从全局队列取的 G 数量符合下面的公式： n = min(len(GQ)/GOMAXPROCS + 1, len(GQ/2)) 至少从全局队列取 1 个 g，但每次不要从全局队列移动太多的 g 到 p 本地队列，给其他 p 留点。这是从全局队列到 P 本地队列的负载均衡。 假定我们场景中一共有 4 个 P（GOMAXPROCS 设置为 4，那么我们允许最多就能用 4 个 P 来供 M 使用）。所以 M2 只从能从全局队列取 1 个 G（即 G3）移动 P2 本地队列，然后完成从 G0 到 G3 的切换，运行 G3。 场景 8 假设 G2 一直在 M1 上运行，经过 2 轮后，M2 已经把 G7、G4 从全局队列获取到了 P2 的本地队列并完成运行，全局队列和 P2 的本地队列都空了，如场景 8 图的左半部分。 全局队列已经没有 G，那 m 就要执行 work stealing (偷取)：从其他有 G 的 P 哪里偷取一半 G 过来，放到自己的 P 本地队列。P2 从 P1 的本地队列尾部取一半的 G，本例中一半则只有 1 个 G8，放到 P2 的本地队列并执行。 场景 9 G1 本地队列 G5、G6 已经被其他 M 偷走并运行完成，当前 M1 和 M2 分别在运行 G2 和 G8，M3 和 M4 没有 goroutine 可以运行，M3 和 M4 处于自旋状态，它们不断寻找 goroutine。 为什么要让 m3 和 m4 自旋，自旋本质是在运行，线程在运行却没有执行 G，就变成了浪费 CPU. 为什么不销毁现场，来节约 CPU 资源。因为创建和销毁 CPU 也会浪费时间，我们希望当有新 goroutine 创建时，立刻能有 M 运行它，如果销毁再新建就增加了时延，降低了效率。当然也考虑了过多的自旋线程是浪费 CPU，所以系统中最多有 GOMAXPROCS 个自旋的线程 (当前例子中的 GOMAXPROCS=4，所以一共 4 个 P)，多余的没事做线程会让他们休眠。 场景 10 假定当前除了 M3 和 M4 为自旋线程，还有 M5 和 M6 为空闲的线程 (没有得到 P 的绑定，注意我们这里最多就只能够存在 4 个 P，所以 P 的数量应该永远是 M\u003e=P, 大部分都是 M 在抢占需要运行的 P)，G8 创建了 G9，G8 进行了阻塞的系统调用，M2 和 P2 立即解绑，P2 会执行以下判断：如果 P2 本地队列有 G、全局队列有 G 或有空闲的 M，P2 都会立马唤醒 1 个 M 和它绑定，否则 P2 则会加入到空闲 P 列表，等待 M 来获取可用的 p。本场景中，P2 本地队列有 G9，可以和其他空闲的线程 M5 绑定。 (11) 场景 11 G8 创建了 G9，假如 G8 进行了非阻塞系统调用。 M2 和 P2 会解绑，但 M2 会记住 P2，然后 G8 和 M2 进入系统调用状态。当 G8 和 M2 退出系统调用时，会尝试获取 P2，如果无法获取，则获取空闲的 P，如果依然没有，G8 会被记为可运行状态，并加入到全局队列，M2 因为没有 P 的绑定而变成休眠状态 (长时间休眠等待 GC 回收销毁)。 ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:14:3","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"四、小结 总结，Go 调度器很轻量也很简单，足以撑起 goroutine 的调度工作，并且让 Go 具有了原生（强大）并发的能力。Go 调度本质是把大量的 goroutine 分配到少量线程上去执行，并利用多核并行，实现更强大的并发。 ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:14:4","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"典型并发任务 ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:15:0","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"只运行一次 在多线程的环境下，某一段代码只执行一次。 也就是单例模式。 在go语言里有个专门的方法 sync.Once package once_test import ( \"fmt\" \"sync\" \"testing\" \"unsafe\" ) type Singleton struct { data string } var singleInstance *Singleton var once sync.Once func GetSingletonObj() *Singleton { once.Do(func() { fmt.Println(\"Create Obj\") singleInstance = new(Singleton) }) return singleInstance } func TestGetSingletonObj(t *testing.T) { var wg sync.WaitGroup for i := 0; i \u003c 10; i++ { wg.Add(1) go func() { obj := GetSingletonObj() fmt.Printf(\"%X\\n\", unsafe.Pointer(obj)) wg.Done() }() } wg.Wait() } PS D:\\Go\\Go_WorkSpace\\go_learning-master\\code\\ch23\\singleton\u003e go test -v -run TestGetSingletonObj once_test.go === RUN TestGetSingletonObj Create Obj C00008A000 C00008A000 C00008A000 C00008A000 C00008A000 C00008A000 C00008A000 C00008A000 C00008A000 C00008A000 --- PASS: TestGetSingletonObj (0.00s) PASS ok command-line-arguments 0.550s ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:15:1","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"仅需任意任务完成 eg:并行执行很多任务，当一个任务返回的时候就可以返回给用户了。像搜索引擎返回搜索结果。 go的CSP的并发控制机制能够简单快速地实现这样的模式。 package concurrency import ( \"fmt\" \"runtime\" \"testing\" \"time\" ) func runTask(id int) string { time.Sleep(10 * time.Millisecond) return fmt.Sprintf(\"The result is from %d\", id) } func FirstResponse() string { numOfRunner := 10 ch := make(chan string, numOfRunner) for i := 0; i \u003c numOfRunner; i++ { go func(i int) { ret := runTask(i) ch \u003c- ret }(i) } return \u003c-ch } func TestFirstResponse(t *testing.T) { t.Log(\"Before:\", runtime.NumGoroutine()) t.Log(FirstResponse()) time.Sleep(time.Second * 1) t.Log(\"After:\", runtime.NumGoroutine()) } ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:15:2","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"所有任务完成 sync package 里的WaitGroup即可实现。 另一种方式：在CSP模式下如何利用channel实现？ package util_all_done import ( \"fmt\" \"runtime\" \"testing\" \"time\" ) func runTask(id int) string { time.Sleep(10 * time.Millisecond) return fmt.Sprintf(\"The result is from %d\", id) } func AllResponse() string { numOfRunner := 10 ch := make(chan string, numOfRunner) for i := 0; i \u003c numOfRunner; i++ { go func(i int) { ret := runTask(i) ch \u003c- ret }(i) } finalRet := \"\" for j := 0; j \u003c numOfRunner; j++ { finalRet += \u003c-ch + \"\\n\" } return finalRet } func TestAllResponse(t *testing.T) { t.Log(\"Before:\", runtime.NumGoroutine()) t.Log(AllResponse()) time.Sleep(time.Second * 1) t.Log(\"After:\", runtime.NumGoroutine()) } ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:15:3","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"对象池 很多场景可能会遇到对象池，比如创建一些代价比较高的对象。数据库连接、网络连接。通常会将这些对象进行池化以避免重复创建 简单地可以使用buffered channel实现对象池。在select时需要有一个超时控制（高可用系统里有个金句：slow response比quick failure更糟糕） 当然可以用空接口来实现对象池里有不同类型的对象，但每次取出对象时需要断言来确认对象的类型。实际运用时建议不同类型用不同缓冲池。 package object_pool import ( \"errors\" \"time\" ) type ReusableObj struct { } type ObjPool struct { bufChan chan *ReusableObj //用于缓冲可重用对象 } func NewObjPool(numOfObj int) *ObjPool { objPool := ObjPool{} objPool.bufChan = make(chan *ReusableObj, numOfObj) for i := 0; i \u003c numOfObj; i++ { objPool.bufChan \u003c- \u0026ReusableObj{} } return \u0026objPool } func (p *ObjPool) GetObj(timeout time.Duration) (*ReusableObj, error) { select { case ret := \u003c-p.bufChan: return ret, nil case \u003c-time.After(timeout): //超时控制 return nil, errors.New(\"time out\") } } func (p *ObjPool) ReleaseObj(obj *ReusableObj) error { select { //channel被阻塞会立即返回default case p.bufChan \u003c- obj: return nil default: return errors.New(\"overflow\") } } ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:15:4","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"sync.pool对象缓存 注意与buffered channel区别。 sync.Pool对象获取： 尝试从私有对象获取 私有对象不存在，尝试从当前 Processor 的共享池获取 如果当前 Processor 共享池也是空的，那么就尝试去其他Processor 的共享池获取 如果所有⼦池都是空的，最后就⽤⽤户指定的 New 函数产⽣⼀个新的对象返回 对象放回： 如果私有对象不存在则保存为私有对象 如果私有对象存在，放⼊当前 Processor ⼦池的共享池中 …… pool := \u0026sync.Pool{ New: func() interface{} { return 0 }, } arry := pool.Get().(int) … pool.Put(10) 为什么sync.Pool不能拿来当对象池用？ sync.Pool对象的生命周期 GC 会清除 sync.pool 缓存的对象（GC是通过系统来调度的，没办法去干预，如果要长时间的去控制一个连接的生命周期就难以做到） 对象的缓存有效期为下⼀次GC 之前 package object_pool import ( \"fmt\" \"runtime\" \"sync\" \"testing\" ) func TestSyncPool(t *testing.T) { pool := \u0026sync.Pool{ New: func() interface{} { fmt.Println(\"Create a new object.\") return 100 }, } v := pool.Get().(int) fmt.Println(v) pool.Put(3) runtime.GC() //GC 会清除sync.pool中缓存的对象 v1, _ := pool.Get().(int) fmt.Println(v1) } func TestSyncPoolInMultiGroutine(t *testing.T) { pool := \u0026sync.Pool{ New: func() interface{} { fmt.Println(\"Create a new object.\") return 10 }, } pool.Put(100) pool.Put(100) pool.Put(100) var wg sync.WaitGroup for i := 0; i \u003c 10; i++ { wg.Add(1) go func(id int) { fmt.Println(pool.Get()) wg.Done() }(i) } wg.Wait() } sync.Pool总结： 适合于通过复⽤，降低复杂对象的创建和 GC 代价 协程安全，会有锁的开销 ⽣命周期受 GC 影响，不适合于做连接池等，需⾃⼰管理⽣命周期的资源的池化 ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:15:5","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"爬虫小案例 ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:16:0","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"爬虫步骤 明确目标（确定在哪个网站搜索） 爬（爬下内容） 取（筛选想要的） 处理数据（按照你的想法去处理） package main import ( \"fmt\" \"io/ioutil\" \"net/http\" \"regexp\" ) //这个只是一个简单的版本只是获取QQ邮箱并且没有进行封装操作，另外爬出来的数据也没有进行去重操作 var ( // \\d是数字 reQQEmail = `(\\d+)@qq.com` ) // 爬邮箱 func GetEmail() { // 1.去网站拿数据 resp, err := http.Get(\"https://tieba.baidu.com/p/6051076813?red_tag=1573533731\") HandleError(err, \"http.Get url\") defer resp.Body.Close() // 2.读取页面内容 pageBytes, err := ioutil.ReadAll(resp.Body) HandleError(err, \"ioutil.ReadAll\") // 字节转字符串 pageStr := string(pageBytes) //fmt.Println(pageStr) // 3.过滤数据，过滤qq邮箱 re := regexp.MustCompile(reQQEmail) // -1代表取全部 results := re.FindAllStringSubmatch(pageStr, -1) //fmt.Println(results) // 遍历结果 for _, result := range results { fmt.Println(\"email:\", result[0]) fmt.Println(\"qq:\", result[1]) } } // 处理异常 func HandleError(err error, why string) { if err != nil { fmt.Println(why, err) } } func main() { GetEmail() } ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:16:1","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"正则表达式 文档：https://studygolang.com/pkgdoc API re := regexp.MustCompile(reStr)，传入正则表达式，得到正则表达式对象 ret := re.FindAllStringSubmatch(srcStr,-1)：用正则对象，获取页面页面，srcStr是页面内容，-1代表取全部 爬邮箱 方法抽取 爬超链接 爬手机号 http://www.zhaohaowang.com/ 如果连接失效了自己找一个有手机号的就好了 爬身份证号 http://henan.qq.com/a/20171107/069413.htm 如果连接失效了自己找一个就好了 爬图片链接 package main import ( \"fmt\" \"io/ioutil\" \"net/http\" \"regexp\" ) var ( // w代表大小写字母+数字+下划线 reEmail = `\\w+@\\w+\\.\\w+` // s?有或者没有s // +代表出1次或多次 //\\s\\S各种字符 // +?代表贪婪模式 reLinke = `href=\"(https?://[\\s\\S]+?)\"` rePhone = `1[3456789]\\d\\s?\\d{4}\\s?\\d{4}` reIdcard = `[123456789]\\d{5}((19\\d{2})|(20[01]\\d))((0[1-9])|(1[012]))((0[1-9])|([12]\\d)|(3[01]))\\d{3}[\\dXx]` reImg = `https?://[^\"]+?(\\.((jpg)|(png)|(jpeg)|(gif)|(bmp)))` ) // 处理异常 func HandleError(err error, why string) { if err != nil { fmt.Println(why, err) } } func GetEmail2(url string) { pageStr := GetPageStr(url) re := regexp.MustCompile(reEmail) results := re.FindAllStringSubmatch(pageStr, -1) for _, result := range results { fmt.Println(result) } } // 抽取根据url获取内容 func GetPageStr(url string) (pageStr string) { resp, err := http.Get(url) HandleError(err, \"http.Get url\") defer resp.Body.Close() // 2.读取页面内容 pageBytes, err := ioutil.ReadAll(resp.Body) HandleError(err, \"ioutil.ReadAll\") // 字节转字符串 pageStr = string(pageBytes) return pageStr } func main() { // 2.抽取的爬邮箱 // GetEmail2(\"https://tieba.baidu.com/p/6051076813?red_tag=1573533731\") // 3.爬链接 //GetLink(\"http://www.baidu.com/s?wd=%E8%B4%B4%E5%90%A7%20%E7%95%99%E4%B8%8B%E9%82%AE%E7%AE%B1\u0026rsv_spt=1\u0026rsv_iqid=0x98ace53400003985\u0026issp=1\u0026f=8\u0026rsv_bp=1\u0026rsv_idx=2\u0026ie=utf-8\u0026tn=baiduhome_pg\u0026rsv_enter=1\u0026rsv_dl=ib\u0026rsv_sug2=0\u0026inputT=5197\u0026rsv_sug4=6345\") // 4.爬手机号 //GetPhone(\"https://www.zhaohaowang.com/\") // 5.爬身份证号 //GetIdCard(\"https://henan.qq.com/a/20171107/069413.htm\") // 6.爬图片 // GetImg(\"http://image.baidu.com/search/index?tn=baiduimage\u0026ps=1\u0026ct=201326592\u0026lm=-1\u0026cl=2\u0026nc=1\u0026ie=utf-8\u0026word=%E7%BE%8E%E5%A5%B3\") } func GetIdCard(url string) { pageStr := GetPageStr(url) re := regexp.MustCompile(reIdcard) results := re.FindAllStringSubmatch(pageStr, -1) for _, result := range results { fmt.Println(result) } } // 爬链接 func GetLink(url string) { pageStr := GetPageStr(url) re := regexp.MustCompile(reLinke) results := re.FindAllStringSubmatch(pageStr, -1) for _, result := range results { fmt.Println(result[1]) } } //爬手机号 func GetPhone(url string) { pageStr := GetPageStr(url) re := regexp.MustCompile(rePhone) results := re.FindAllStringSubmatch(pageStr, -1) for _, result := range results { fmt.Println(result) } } func GetImg(url string) { pageStr := GetPageStr(url) re := regexp.MustCompile(reImg) results := re.FindAllStringSubmatch(pageStr, -1) for _, result := range results { fmt.Println(result[0]) } } ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:16:2","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":"并发爬取美图 下面的两个是即将要爬的网站，如果网址失效自己换一个就好了 https://www.bizhizu.cn/shouji/tag-%E5%8F%AF%E7%88%B1/1.html package main import ( \"fmt\" \"io/ioutil\" \"net/http\" \"regexp\" \"strconv\" \"strings\" \"sync\" \"time\" ) func HandleError(err error, why string) { if err != nil { fmt.Println(why, err) } } // 下载图片，传入的是图片叫什么 func DownloadFile(url string, filename string) (ok bool) { resp, err := http.Get(url) HandleError(err, \"http.get.url\") defer resp.Body.Close() bytes, err := ioutil.ReadAll(resp.Body) HandleError(err, \"resp.body\") filename = \"E:/topgoer.com/src/github.com/student/3.0/img/\" + filename // 写出数据 err = ioutil.WriteFile(filename, bytes, 0666) if err != nil { return false } else { return true } } // 并发爬思路： // 1.初始化数据管道 // 2.爬虫写出：26个协程向管道中添加图片链接 // 3.任务统计协程：检查26个任务是否都完成，完成则关闭数据管道 // 4.下载协程：从管道里读取链接并下载 var ( // 存放图片链接的数据管道 chanImageUrls chan string waitGroup sync.WaitGroup // 用于监控协程 chanTask chan string reImg = `https?://[^\"]+?(\\.((jpg)|(png)|(jpeg)|(gif)|(bmp)))` ) func main() { // myTest() // DownloadFile(\"http://i1.shaodiyejin.com/uploads/tu/201909/10242/e5794daf58_4.jpg\", \"1.jpg\") // 1.初始化管道 chanImageUrls = make(chan string, 1000000) chanTask = make(chan string, 26) // 2.爬虫协程 for i := 1; i \u003c 27; i++ { waitGroup.Add(1) go getImgUrls(\"https://www.bizhizu.cn/shouji/tag-%E5%8F%AF%E7%88%B1/\" + strconv.Itoa(i) + \".html\") } // 3.任务统计协程，统计26个任务是否都完成，完成则关闭管道 waitGroup.Add(1) go CheckOK() // 4.下载协程：从管道中读取链接并下载 for i := 0; i \u003c 5; i++ { waitGroup.Add(1) go DownloadImg() } waitGroup.Wait() } // 下载图片 func DownloadImg() { for url := range chanImageUrls { filename := GetFilenameFromUrl(url) ok := DownloadFile(url, filename) if ok { fmt.Printf(\"%s 下载成功\\n\", filename) } else { fmt.Printf(\"%s 下载失败\\n\", filename) } } waitGroup.Done() } // 截取url名字 func GetFilenameFromUrl(url string) (filename string) { // 返回最后一个/的位置 lastIndex := strings.LastIndex(url, \"/\") // 切出来 filename = url[lastIndex+1:] // 时间戳解决重名 timePrefix := strconv.Itoa(int(time.Now().UnixNano())) filename = timePrefix + \"_\" + filename return } // 任务统计协程 func CheckOK() { var count int for { url := \u003c-chanTask fmt.Printf(\"%s 完成了爬取任务\\n\", url) count++ if count == 26 { close(chanImageUrls) break } } waitGroup.Done() } // 爬图片链接到管道 // url是传的整页链接 func getImgUrls(url string) { urls := getImgs(url) // 遍历切片里所有链接，存入数据管道 for _, url := range urls { chanImageUrls \u003c- url } // 标识当前协程完成 // 每完成一个任务，写一条数据 // 用于监控协程知道已经完成了几个任务 chanTask \u003c- url waitGroup.Done() } // 获取当前页图片链接 func getImgs(url string) (urls []string) { pageStr := GetPageStr(url) re := regexp.MustCompile(reImg) results := re.FindAllStringSubmatch(pageStr, -1) fmt.Printf(\"共找到%d条结果\\n\", len(results)) for _, result := range results { url := result[0] urls = append(urls, url) } return } // 抽取根据url获取内容 func GetPageStr(url string) (pageStr string) { resp, err := http.Get(url) HandleError(err, \"http.Get url\") defer resp.Body.Close() // 2.读取页面内容 pageBytes, err := ioutil.ReadAll(resp.Body) HandleError(err, \"ioutil.ReadAll\") // 字节转字符串 pageStr = string(pageBytes) return pageStr } ","date":"2022-01-06 09:16:49","objectID":"/go_base_07/:16:3","tags":["go grammar"],"title":"Go_base_07","uri":"/go_base_07/"},{"categories":["Go"],"content":" 参考学习go语言中文网、C语言中文网、golang官方文档等 网络编程 ","date":"2022-01-06 09:16:45","objectID":"/go_base_06/:0:0","tags":["go grammar"],"title":"Go_base_06","uri":"/go_base_06/"},{"categories":["Go"],"content":"互联网协议介绍 互联网的核心是一系列协议，总称为”互联网协议”（Internet Protocol Suite），正是这一些协议规定了电脑如何连接和组网。我们理解了这些协议，就理解了互联网的原理。由于这些协议太过庞大和复杂，没有办法在这里一概而全，只能介绍一下我们日常开发中接触较多的几个协议。 ","date":"2022-01-06 09:16:45","objectID":"/go_base_06/:1:0","tags":["go grammar"],"title":"Go_base_06","uri":"/go_base_06/"},{"categories":["Go"],"content":"互联网分层模型 互联网的逻辑实现被分为好几层。每一层都有自己的功能，就像建筑物一样，每一层都靠下一层支持。用户接触到的只是最上面的那一层，根本不会感觉到下面的几层。要理解互联网就需要自下而上理解每一层的实现的功能。 如上图所示，互联网按照不同的模型划分会有不用的分层，但是不论按照什么模型去划分，越往上的层越靠近用户，越往下的层越靠近硬件。在软件开发中我们使用最多的是上图中将互联网划分为五个分层的模型。 接下来我们一层一层的自底向上介绍一下每一层。 物理层 我们的电脑要与外界互联网通信，需要先把电脑连接网络，我们可以用双绞线、光纤、无线电波等方式。这就叫做”实物理层”，它就是把电脑连接起来的物理手段。它主要规定了网络的一些电气特性，作用是负责传送0和1的电信号。 数据链路层 单纯的0和1没有任何意义，所以我们使用者会为其赋予一些特定的含义，规定解读电信号的方式：例如：多少个电信号算一组？每个信号位有何意义？这就是”数据链接层”的功能，它在”物理层”的上方，确定了物理层传输的0和1的分组方式及代表的意义。早期的时候，每家公司都有自己的电信号分组方式。逐渐地，一种叫做”以太网”（Ethernet）的协议，占据了主导地位。 以太网规定，一组电信号构成一个数据包，叫做”帧”（Frame）。每一帧分成两个部分：标头（Head）和数据（Data）。其中”标头”包含数据包的一些说明项，比如发送者、接受者、数据类型等等；”数据”则是数据包的具体内容。”标头”的长度，固定为18字节。”数据”的长度，最短为46字节，最长为1500字节。因此，整个”帧”最短为64字节，最长为1518字节。如果数据很长，就必须分割成多个帧进行发送。 那么，发送者和接受者是如何标识呢？以太网规定，连入网络的所有设备都必须具有”网卡”接口。数据包必须是从一块网卡，传送到另一块网卡。网卡的地址，就是数据包的发送地址和接收地址，这叫做MAC地址。每块网卡出厂的时候，都有一个全世界独一无二的MAC地址，长度是48个二进制位，通常用12个十六进制数表示。前6个十六进制数是厂商编号，后6个是该厂商的网卡流水号。有了MAC地址，就可以定位网卡和数据包的路径了。 我们会通过ARP协议来获取接受方的MAC地址，有了MAC地址之后，如何把数据准确的发送给接收方呢？其实这里以太网采用了一种很”原始”的方式，它不是把数据包准确送到接收方，而是向本网络内所有计算机都发送，让每台计算机读取这个包的”标头”，找到接收方的MAC地址，然后与自身的MAC地址相比较，如果两者相同，就接受这个包，做进一步处理，否则就丢弃这个包。这种发送方式就叫做”广播”（broadcasting）。 网络层 按照以太网协议的规则我们可以依靠MAC地址来向外发送数据。理论上依靠MAC地址，你电脑的网卡就可以找到身在世界另一个角落的某台电脑的网卡了，但是这种做法有一个重大缺陷就是以太网采用广播方式发送数据包，所有成员人手一”包”，不仅效率低，而且发送的数据只能局限在发送者所在的子网络。也就是说如果两台计算机不在同一个子网络，广播是传不过去的。这种设计是合理且必要的，因为如果互联网上每一台计算机都会收到互联网上收发的所有数据包，那是不现实的。 因此，必须找到一种方法区分哪些MAC地址属于同一个子网络，哪些不是。如果是同一个子网络，就采用广播方式发送，否则就采用”路由”方式发送。这就导致了”网络层”的诞生。它的作用是引进一套新的地址，使得我们能够区分不同的计算机是否属于同一个子网络。这套地址就叫做”网络地址”，简称”网址”。 “网络层”出现以后，每台计算机有了两种地址，一种是MAC地址，另一种是网络地址。两种地址之间没有任何联系，MAC地址是绑定在网卡上的，网络地址则是网络管理员分配的。网络地址帮助我们确定计算机所在的子网络，MAC地址则将数据包送到该子网络中的目标网卡。因此，从逻辑上可以推断，必定是先处理网络地址，然后再处理MAC地址。 规定网络地址的协议，叫做IP协议。它所定义的地址，就被称为IP地址。目前，广泛采用的是IP协议第四版，简称IPv4。IPv4这个版本规定，网络地址由32个二进制位组成，我们通常习惯用分成四段的十进制数表示IP地址，从0.0.0.0一直到255.255.255.255。 根据IP协议发送的数据，就叫做IP数据包。IP数据包也分为”标头”和”数据”两个部分：”标头”部分主要包括版本、长度、IP地址等信息，”数据”部分则是IP数据包的具体内容。IP数据包的”标头”部分的长度为20到60字节，整个数据包的总长度最大为65535字节。 传输层 有了MAC地址和IP地址，我们已经可以在互联网上任意两台主机上建立通信。但问题是同一台主机上会有许多程序都需要用网络收发数据，比如QQ和浏览器这两个程序都需要连接互联网并收发数据，我们如何区分某个数据包到底是归哪个程序的呢？也就是说，我们还需要一个参数，表示这个数据包到底供哪个程序（进程）使用。这个参数就叫做”端口”（port），它其实是每一个使用网卡的程序的编号。每个数据包都发到主机的特定端口，所以不同的程序就能取到自己所需要的数据。 “端口”是0到65535之间的一个整数，正好16个二进制位。0到1023的端口被系统占用，用户只能选用大于1023的端口。有了IP和端口我们就能实现唯一确定互联网上一个程序，进而实现网络间的程序通信。 我们必须在数据包中加入端口信息，这就需要新的协议。最简单的实现叫做UDP协议，它的格式几乎就是在数据前面，加上端口号。UDP数据包，也是由”标头”和”数据”两部分组成：”标头”部分主要定义了发出端口和接收端口，”数据”部分就是具体的内容。UDP数据包非常简单，”标头”部分一共只有8个字节，总长度不超过65,535字节，正好放进一个IP数据包。 UDP协议的优点是比较简单，容易实现，但是缺点是可靠性较差，一旦数据包发出，无法知道对方是否收到。为了解决这个问题，提高网络可靠性，TCP协议就诞生了。TCP协议能够确保数据不会遗失。它的缺点是过程复杂、实现困难、消耗较多的资源。TCP数据包没有长度限制，理论上可以无限长，但是为了保证网络的效率，通常TCP数据包的长度不会超过IP数据包的长度，以确保单个TCP数据包不必再分割。 应用层 应用程序收到”传输层”的数据，接下来就要对数据进行解包。由于互联网是开放架构，数据来源五花八门，必须事先规定好通信的数据格式，否则接收方根本无法获得真正发送的数据内容。”应用层”的作用就是规定应用程序使用的数据格式，例如我们TCP协议之上常见的Email、HTTP、FTP等协议，这些协议就组成了互联网协议的应用层。 如下图所示，发送方的HTTP数据经过互联网的传输过程中会依次添加各层协议的标头信息，接收方收到数据包之后再依次根据协议解包得到数据。 ","date":"2022-01-06 09:16:45","objectID":"/go_base_06/:1:1","tags":["go grammar"],"title":"Go_base_06","uri":"/go_base_06/"},{"categories":["Go"],"content":"socket编程 ","date":"2022-01-06 09:16:45","objectID":"/go_base_06/:2:0","tags":["go grammar"],"title":"Go_base_06","uri":"/go_base_06/"},{"categories":["Go"],"content":"socket 图解 Socket是BSD UNIX的进程通信机制，通常也称作”套接字”，用于描述IP地址和端口，是一个通信链的句柄。Socket可以理解为TCP/IP网络的API，它定义了许多函数或例程，程序员可以用它们来开发TCP/IP网络上的应用程序。电脑上运行的应用程序通常通过”套接字”向网络发出请求或者应答网络请求。 socket图解 Socket是应用层与TCP/IP协议族通信的中间软件抽象层。在设计模式中，Socket其实就是一个门面模式，它把复杂的TCP/IP协议族隐藏在Socket后面，对用户来说只需要调用Socket规定的相关函数，让Socket去组织符合指定的协议数据然后进行通信。 Socket又称“套接字”，应用程序通常通过“套接字”向网络发出请求或者应答网络请求 常用的Socket类型有两种：流式Socket和数据报式Socket，流式是一种面向连接的Socket，针对于面向连接的TCP服务应用，数据报式Socket是一种无连接的Socket，针对于无连接的UDP服务应用 TCP：比较靠谱，面向连接，比较慢 UDP：不是太靠谱，比较快 举个例子：TCP就像货到付款的快递，送到家还必须见到你人才算一整套流程。UDP就像某快递快递柜一扔就走管你收到收不到，一般直播用UDP。 ","date":"2022-01-06 09:16:45","objectID":"/go_base_06/:2:1","tags":["go grammar"],"title":"Go_base_06","uri":"/go_base_06/"},{"categories":["Go"],"content":"TCP编程 Go语言实现TCP通信 TCP协议 TCP/IP(Transmission Control Protocol/Internet Protocol) 即传输控制协议/网际协议，是一种面向连接（连接导向）的、可靠的、基于字节流的传输层（Transport layer）通信协议，因为是面向连接的协议，数据像水流一样传输，会存在黏包问题。 TCP服务端 一个TCP服务端可以同时连接很多个客户端，例如世界各地的用户使用自己电脑上的浏览器访问淘宝网。因为Go语言中创建多个goroutine实现并发非常方便和高效，所以我们可以每建立一次链接就创建一个goroutine去处理。 TCP服务端程序的处理流程： 监听端口 接收客户端请求建立链接 创建goroutine处理链接。 我们使用Go语言的net包实现的TCP服务端代码如下： // tcp/server/main.go // TCP server端 // 处理函数 func process(conn net.Conn) { defer conn.Close() // 关闭连接 for { reader := bufio.NewReader(conn) var buf [128]byte n, err := reader.Read(buf[:]) // 读取数据 if err != nil { fmt.Println(\"read from client failed, err:\", err) break } recvStr := string(buf[:n]) fmt.Println(\"收到client端发来的数据：\", recvStr) conn.Write([]byte(recvStr)) // 发送数据 } } func main() { listen, err := net.Listen(\"tcp\", \"127.0.0.1:20000\") if err != nil { fmt.Println(\"listen failed, err:\", err) return } for { conn, err := listen.Accept() // 建立连接 if err != nil { fmt.Println(\"accept failed, err:\", err) continue } go process(conn) // 启动一个goroutine处理连接 } } 将上面的代码保存之后编译成server或server.exe可执行文件。 TCP客户端 一个TCP客户端进行TCP通信的流程如下： 建立与服务端的链接 进行数据收发 关闭链接 使用Go语言的net包实现的TCP客户端代码如下： // tcp/client/main.go // 客户端 func main() { conn, err := net.Dial(\"tcp\", \"127.0.0.1:20000\") if err != nil { fmt.Println(\"err :\", err) return } defer conn.Close() // 关闭连接 inputReader := bufio.NewReader(os.Stdin) for { input, _ := inputReader.ReadString('\\n') // 读取用户输入 inputInfo := strings.Trim(input, \"\\r\\n\") if strings.ToUpper(inputInfo) == \"Q\" { // 如果输入q就退出 return } _, err = conn.Write([]byte(inputInfo)) // 发送数据 if err != nil { return } buf := [512]byte{} n, err := conn.Read(buf[:]) if err != nil { fmt.Println(\"recv failed, err:\", err) return } fmt.Println(string(buf[:n])) } } 将上面的代码编译成client或client.exe可执行文件，先启动server端再启动client端，在client端输入任意内容回车之后就能够在server端看到client端发送的数据，从而实现TCP通信。 ","date":"2022-01-06 09:16:45","objectID":"/go_base_06/:2:2","tags":["go grammar"],"title":"Go_base_06","uri":"/go_base_06/"},{"categories":["Go"],"content":"UDP编程 Go语言实现UDP通信 UDP协议 UDP协议（User Datagram Protocol）中文名称是用户数据报协议，是OSI（Open System Interconnection，开放式系统互联）参考模型中一种无连接的传输层协议，不需要建立连接就能直接进行数据发送和接收，属于不可靠的、没有时序的通信，但是UDP协议的实时性比较好，通常用于视频直播相关领域。 UDP服务端 使用Go语言的net包实现的UDP服务端代码如下： // UDP/server/main.go // UDP server端 func main() { listen, err := net.ListenUDP(\"udp\", \u0026net.UDPAddr{ IP: net.IPv4(0, 0, 0, 0), Port: 30000, }) if err != nil { fmt.Println(\"listen failed, err:\", err) return } defer listen.Close() for { var data [1024]byte n, addr, err := listen.ReadFromUDP(data[:]) // 接收数据 if err != nil { fmt.Println(\"read udp failed, err:\", err) continue } fmt.Printf(\"data:%v addr:%v count:%v\\n\", string(data[:n]), addr, n) _, err = listen.WriteToUDP(data[:n], addr) // 发送数据 if err != nil { fmt.Println(\"write to udp failed, err:\", err) continue } } } UDP客户端 使用Go语言的net包实现的UDP客户端代码如下： // UDP 客户端 func main() { socket, err := net.DialUDP(\"udp\", nil, \u0026net.UDPAddr{ IP: net.IPv4(0, 0, 0, 0), Port: 30000, }) if err != nil { fmt.Println(\"连接服务端失败，err:\", err) return } defer socket.Close() sendData := []byte(\"Hello server\") _, err = socket.Write(sendData) // 发送数据 if err != nil { fmt.Println(\"发送数据失败，err:\", err) return } data := make([]byte, 4096) n, remoteAddr, err := socket.ReadFromUDP(data) // 接收数据 if err != nil { fmt.Println(\"接收数据失败，err:\", err) return } fmt.Printf(\"recv:%v addr:%v count:%v\\n\", string(data[:n]), remoteAddr, n) } ","date":"2022-01-06 09:16:45","objectID":"/go_base_06/:2:3","tags":["go grammar"],"title":"Go_base_06","uri":"/go_base_06/"},{"categories":["Go"],"content":"TCP黏包 服务端代码如下： // socket_stick/server/main.go func process(conn net.Conn) { defer conn.Close() reader := bufio.NewReader(conn) var buf [1024]byte for { n, err := reader.Read(buf[:]) if err == io.EOF { break } if err != nil { fmt.Println(\"read from client failed, err:\", err) break } recvStr := string(buf[:n]) fmt.Println(\"收到client发来的数据：\", recvStr) } } func main() { listen, err := net.Listen(\"tcp\", \"127.0.0.1:30000\") if err != nil { fmt.Println(\"listen failed, err:\", err) return } defer listen.Close() for { conn, err := listen.Accept() if err != nil { fmt.Println(\"accept failed, err:\", err) continue } go process(conn) } } 客户端代码如下： // socket_stick/client/main.go func main() { conn, err := net.Dial(\"tcp\", \"127.0.0.1:30000\") if err != nil { fmt.Println(\"dial failed, err\", err) return } defer conn.Close() for i := 0; i \u003c 20; i++ { msg := `Hello, Hello. How are you?` conn.Write([]byte(msg)) } } 将上面的代码保存后，分别编译。先启动服务端再启动客户端，可以看到服务端输出结果如下： 收到client发来的数据： Hello, Hello. How are you?Hello, Hello. How are you?Hello, Hello. How are you?Hello, Hello. How are you?Hello, Hello. How are you? 收到client发来的数据： Hello, Hello. How are you?Hello, Hello. How are you?Hello, Hello. How are you?Hello, Hello. How are you?Hello, Hello. How are you?Hello, Hello. How are you?Hello, Hello. How are you?Hello, Hello. How are you? 收到client发来的数据： Hello, Hello. How are you?Hello, Hello. How are you? 收到client发来的数据： Hello, Hello. How are you?Hello, Hello. How are you?Hello, Hello. How are you? 收到client发来的数据： Hello, Hello. How are you?Hello, Hello. How are you? 客户端分10次发送的数据，在服务端并没有成功的输出10次，而是多条数据“粘”到了一起。 ","date":"2022-01-06 09:16:45","objectID":"/go_base_06/:2:4","tags":["go grammar"],"title":"Go_base_06","uri":"/go_base_06/"},{"categories":["Go"],"content":"为什么会出现粘包 主要原因就是tcp数据传递模式是流模式，在保持长连接的时候可以进行多次的收和发。 “粘包”可发生在发送端也可发生在接收端： 由Nagle算法造成的发送端的粘包：Nagle算法是一种改善网络传输效率的算法。简单来说就是当我们提交一段数据给TCP发送时，TCP并不立刻发送此段数据，而是等待一小段时间看看在等待期间是否还有要发送的数据，若有则会一次把这两段数据发送出去。 接收端接收不及时造成的接收端粘包：TCP会把接收到的数据存在自己的缓冲区中，然后通知应用层取数据。当应用层由于某些原因不能及时的把TCP的数据取出来，就会造成TCP缓冲区中存放了几段数据。 ","date":"2022-01-06 09:16:45","objectID":"/go_base_06/:2:5","tags":["go grammar"],"title":"Go_base_06","uri":"/go_base_06/"},{"categories":["Go"],"content":"解决办法 出现”粘包”的关键在于接收方不确定将要传输的数据包的大小，因此我们可以对数据包进行封包和拆包的操作。 封包：封包就是给一段数据加上包头，这样一来数据包就分为包头和包体两部分内容了(过滤非法包时封包会加入”包尾”内容)。包头部分的长度是固定的，并且它存储了包体的长度，根据包头长度固定以及包头中含有包体长度的变量就能正确的拆分出一个完整的数据包。 我们可以自己定义一个协议，比如数据包的前4个字节为包头，里面存储的是发送的数据的长度。 // socket_stick/proto/proto.go package proto import ( \"bufio\" \"bytes\" \"encoding/binary\" ) // Encode 将消息编码 func Encode(message string) ([]byte, error) { // 读取消息的长度，转换成int32类型（占4个字节） var length = int32(len(message)) var pkg = new(bytes.Buffer) // 写入消息头 err := binary.Write(pkg, binary.LittleEndian, length) if err != nil { return nil, err } // 写入消息实体 err = binary.Write(pkg, binary.LittleEndian, []byte(message)) if err != nil { return nil, err } return pkg.Bytes(), nil } // Decode 解码消息 func Decode(reader *bufio.Reader) (string, error) { // 读取消息的长度 lengthByte, _ := reader.Peek(4) // 读取前4个字节的数据 lengthBuff := bytes.NewBuffer(lengthByte) var length int32 err := binary.Read(lengthBuff, binary.LittleEndian, \u0026length) if err != nil { return \"\", err } // Buffered返回缓冲中现有的可读取的字节数。 if int32(reader.Buffered()) \u003c length+4 { return \"\", err } // 读取真正的消息数据 pack := make([]byte, int(4+length)) _, err = reader.Read(pack) if err != nil { return \"\", err } return string(pack[4:]), nil } 接下来在服务端和客户端分别使用上面定义的proto包的Decode和Encode函数处理数据。 服务端代码如下： // socket_stick/server2/main.go func process(conn net.Conn) { defer conn.Close() reader := bufio.NewReader(conn) for { msg, err := proto.Decode(reader) if err == io.EOF { return } if err != nil { fmt.Println(\"decode msg failed, err:\", err) return } fmt.Println(\"收到client发来的数据：\", msg) } } func main() { listen, err := net.Listen(\"tcp\", \"127.0.0.1:30000\") if err != nil { fmt.Println(\"listen failed, err:\", err) return } defer listen.Close() for { conn, err := listen.Accept() if err != nil { fmt.Println(\"accept failed, err:\", err) continue } go process(conn) } } 客户端代码如下： // socket_stick/client2/main.go func main() { conn, err := net.Dial(\"tcp\", \"127.0.0.1:30000\") if err != nil { fmt.Println(\"dial failed, err\", err) return } defer conn.Close() for i := 0; i \u003c 20; i++ { msg := `Hello, Hello. How are you?` data, err := proto.Encode(msg) if err != nil { fmt.Println(\"encode msg failed, err:\", err) return } conn.Write(data) } } ","date":"2022-01-06 09:16:45","objectID":"/go_base_06/:2:6","tags":["go grammar"],"title":"Go_base_06","uri":"/go_base_06/"},{"categories":["Go"],"content":"http编程 ","date":"2022-01-06 09:16:45","objectID":"/go_base_06/:3:0","tags":["go grammar"],"title":"Go_base_06","uri":"/go_base_06/"},{"categories":["Go"],"content":"web工作流程 Web服务器的工作原理可以简单地归纳为 客户机通过TCP/IP协议建立到服务器的TCP连接 客户端向服务器发送HTTP协议请求包，请求服务器里的资源文档 服务器向客户机发送HTTP协议应答包，如果请求的资源包含有动态语言的内容，那么服务器会调用动态语言的解释引擎负责处理“动态内容”，并将处理得到的数据返回给客户端 客户机与服务器断开。由客户端解释HTML文档，在客户端屏幕上渲染图形结果 ","date":"2022-01-06 09:16:45","objectID":"/go_base_06/:3:1","tags":["go grammar"],"title":"Go_base_06","uri":"/go_base_06/"},{"categories":["Go"],"content":"HTTP协议 超文本传输协议(HTTP，HyperText Transfer Protocol)是互联网上应用最为广泛的一种网络协议，它详细规定了浏览器和万维网服务器之间互相通信的规则，通过因特网传送万维网文档的数据传送协议 HTTP协议通常承载于TCP协议之上 ","date":"2022-01-06 09:16:45","objectID":"/go_base_06/:3:2","tags":["go grammar"],"title":"Go_base_06","uri":"/go_base_06/"},{"categories":["Go"],"content":"HTTP服务端 package main import ( \"fmt\" \"net/http\" ) func main() { //http://127.0.0.1:8000/go // 单独写回调函数 http.HandleFunc(\"/go\", myHandler) //http.HandleFunc(\"/ungo\",myHandler2 ) // addr：监听的地址 // handler：回调函数 http.ListenAndServe(\"127.0.0.1:8000\", nil) } // handler函数 func myHandler(w http.ResponseWriter, r *http.Request) { fmt.Println(r.RemoteAddr, \"连接成功\") // 请求方式：GET POST DELETE PUT UPDATE fmt.Println(\"method:\", r.Method) // /go fmt.Println(\"url:\", r.URL.Path) fmt.Println(\"header:\", r.Header) fmt.Println(\"body:\", r.Body) // 回复 w.Write([]byte(\"www.5lmh.com\")) } go的默认路由规则： URL 分为两种，末尾是 /：表示⼀个⼦树，后⾯可以跟其他⼦路径； 末尾不是 /，表示⼀个叶⼦，固定的路径 以/ 结尾的 URL 可以匹配它的任何⼦路径，⽐如 /images 会匹配 /images/cute-cat.jpg 它采⽤最⻓匹配原则，如果有多个匹配，⼀定采⽤匹配路径最⻓的那个进⾏处理 如果没有找到任何匹配项，会返回 404 错误 //Default Router func (sh serverHandler) ServeHTTP(rw ResponseWriter, req *Request) { handler := sh.srv.Handler if handler == nil { handler = DefaultServeMux //使⽤缺省的Router } if req.RequestURI == \"*\" \u0026\u0026 req.Method == \"OPTIONS\" { handler = globalOptionsHandler{} } handler.ServeHTTP(rw, req) } ","date":"2022-01-06 09:16:45","objectID":"/go_base_06/:3:3","tags":["go grammar"],"title":"Go_base_06","uri":"/go_base_06/"},{"categories":["Go"],"content":"HTTP客户端 package main import ( \"fmt\" \"io\" \"net/http\" ) func main() { //resp, _ := http.Get(\"http://www.baidu.com\") //fmt.Println(resp) resp, _ := http.Get(\"http://127.0.0.1:8000/go\") defer resp.Body.Close() // 200 OK fmt.Println(resp.Status) fmt.Println(resp.Header) buf := make([]byte, 1024) for { // 接收服务端信息 n, err := resp.Body.Read(buf) if err != nil \u0026\u0026 err != io.EOF { fmt.Println(err) return } else { fmt.Println(\"读取完毕\") res := string(buf[:n]) fmt.Println(res) break } } } ","date":"2022-01-06 09:16:45","objectID":"/go_base_06/:3:4","tags":["go grammar"],"title":"Go_base_06","uri":"/go_base_06/"},{"categories":["Go"],"content":"构建RESTful服务 第三方的handler 更好的router //详情见https://github.com/julienschmidt/httprouter //handler多了一个参数 func Hello(w http.ResponseWriter, r *http.Request, ps httprouter.Params) { fmt.Fprintf(w, \"hello, %s!\\n\", ps.ByName(\"name\")) } func main() { router := httprouter.New() router.GET(\"/\", Index) router.GET(\"/hello/:name\", Hello) log.Fatal(http.ListenAndServe(\":8080\", router)) } RESTful程序设计很多时候会基于面向资源的架构（resource oriented architecture） package main import ( \"encoding/json\" \"fmt\" \"log\" \"net/http\" \"github.com/julienschmidt/httprouter\" ) type Employee struct { ID string `json:\"id\"` Name string `json:\"name\"` Age int `json:\"age\"` } var employeeDB map[string]*Employee func init() { employeeDB = map[string]*Employee{} employeeDB[\"Mike\"] = \u0026Employee{\"e-1\", \"Mike\", 35} employeeDB[\"Rose\"] = \u0026Employee{\"e-2\", \"Rose\", 45} } func Index(w http.ResponseWriter, r *http.Request, _ httprouter.Params) { fmt.Fprint(w, \"Welcome!\\n\") } func GetEmployeeByName(w http.ResponseWriter, r *http.Request, ps httprouter.Params) { qName := ps.ByName(\"name\") var ( ok bool info *Employee infoJson []byte err error ) if info, ok = employeeDB[qName]; !ok { w.Write([]byte(\"{\\\"error\\\":\\\"Not Found\\\"}\")) return } if infoJson, err = json.Marshal(info); err != nil { w.Write([]byte(fmt.Sprintf(\"{\\\"error\\\":,\\\"%s\\\"}\", err))) return } w.Write(infoJson) } func main() { router := httprouter.New() router.GET(\"/\", Index) router.GET(\"/employee/:name\", GetEmployeeByName) log.Fatal(http.ListenAndServe(\":8080\", router)) } ","date":"2022-01-06 09:16:45","objectID":"/go_base_06/:3:5","tags":["go grammar"],"title":"Go_base_06","uri":"/go_base_06/"},{"categories":["Go"],"content":"WebSocket编程 ","date":"2022-01-06 09:16:45","objectID":"/go_base_06/:4:0","tags":["go grammar"],"title":"Go_base_06","uri":"/go_base_06/"},{"categories":["Go"],"content":"webSocket是什么 WebSocket是一种在单个TCP连接上进行全双工通信的协议 WebSocket使得客户端和服务器之间的数据交换变得更加简单，允许服务端主动向客户端推送数据 在WebSocket API中，浏览器和服务器只需要完成一次握手，两者之间就直接可以创建持久性的连接，并进行双向数据传输 需要安装第三方包： cmd中：go get -u -v github.com/gorilla/websocket ","date":"2022-01-06 09:16:45","objectID":"/go_base_06/:4:1","tags":["go grammar"],"title":"Go_base_06","uri":"/go_base_06/"},{"categories":["Go"],"content":"举个聊天室的小例子 在同一级目录下新建四个go文件connection.go|data.go|hub.go|server.go 运行 go run server.go hub.go data.go connection.go 运行之后执行local.html文件 server.go文件代码 package main import ( \"fmt\" \"net/http\" \"github.com/gorilla/mux\" ) func main() { router := mux.NewRouter() go h.run() router.HandleFunc(\"/ws\", myws) if err := http.ListenAndServe(\"127.0.0.1:8080\", router); err != nil { fmt.Println(\"err:\", err) } } hub.go文件代码 package main import \"encoding/json\" var h = hub{ c: make(map[*connection]bool), u: make(chan *connection), b: make(chan []byte), r: make(chan *connection), } type hub struct { c map[*connection]bool b chan []byte r chan *connection u chan *connection } func (h *hub) run() { for { select { case c := \u003c-h.r: h.c[c] = true c.data.Ip = c.ws.RemoteAddr().String() c.data.Type = \"handshake\" c.data.UserList = user_list data_b, _ := json.Marshal(c.data) c.sc \u003c- data_b case c := \u003c-h.u: if _, ok := h.c[c]; ok { delete(h.c, c) close(c.sc) } case data := \u003c-h.b: for c := range h.c { select { case c.sc \u003c- data: default: delete(h.c, c) close(c.sc) } } } } } data.go文件代码 package main type Data struct { Ip string `json:\"ip\"` User string `json:\"user\"` From string `json:\"from\"` Type string `json:\"type\"` Content string `json:\"content\"` UserList []string `json:\"user_list\"` } connection.go文件代码 package main import ( \"encoding/json\" \"fmt\" \"net/http\" \"github.com/gorilla/websocket\" ) type connection struct { ws *websocket.Conn sc chan []byte data *Data } var wu = \u0026websocket.Upgrader{ReadBufferSize: 512, WriteBufferSize: 512, CheckOrigin: func(r *http.Request) bool { return true } } func myws(w http.ResponseWriter, r *http.Request) { ws, err := wu.Upgrade(w, r, nil) if err != nil { return } c := \u0026connection{sc: make(chan []byte, 256), ws: ws, data: \u0026Data{} } h.r \u003c- c go c.writer() c.reader() defer func() { c.data.Type = \"logout\" user_list = del(user_list, c.data.User) c.data.UserList = user_list c.data.Content = c.data.User data_b, _ := json.Marshal(c.data) h.b \u003c- data_b h.r \u003c- c }() } func (c *connection) writer() { for message := range c.sc { c.ws.WriteMessage(websocket.TextMessage, message) } c.ws.Close() } var user_list = []string{} func (c *connection) reader() { for { _, message, err := c.ws.ReadMessage() if err != nil { h.r \u003c- c break } json.Unmarshal(message, \u0026c.data) switch c.data.Type { case \"login\": c.data.User = c.data.Content c.data.From = c.data.User user_list = append(user_list, c.data.User) c.data.UserList = user_list data_b, _ := json.Marshal(c.data) h.b \u003c- data_b case \"user\": c.data.Type = \"user\" data_b, _ := json.Marshal(c.data) h.b \u003c- data_b case \"logout\": c.data.Type = \"logout\" user_list = del(user_list, c.data.User) data_b, _ := json.Marshal(c.data) h.b \u003c- data_b h.r \u003c- c default: fmt.Print(\"========default================\") } } } func del(slice []string, user string) []string { count := len(slice) if count == 0 { return slice } if count == 1 \u0026\u0026 slice[0] == user { return []string{} } var n_slice = []string{} for i := range slice { if slice[i] == user \u0026\u0026 i == count { return slice[:count] } else if slice[i] == user { n_slice = append(slice[:i], slice[i+1:]...) break } } fmt.Println(n_slice) return n_slice } local.html文件代码 \u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003e\u003c/title\u003e \u003cmeta http-equiv=\"content-type\" content=\"text/html;charset=utf-8\"\u003e \u003cstyle\u003e p { text-align: left; padding-left: 20px; } \u003c/style\u003e \u003c/head\u003e \u003cbody\u003e \u003cdiv style=\"width: 800px;height: 600px;margin: 30px auto;text-align: center\"\u003e \u003ch1\u003ewww.5lmh.comy演示聊天室\u003c/h1\u003e \u003cdiv style=\"width: 800px;border: 1px solid gray;height: 300px;\"\u003e \u003cdiv style=\"width: 200px;height: 300px;float: left;text-align: left;\"\u003e \u003cp\u003e\u003cspan\u003e当前在线:\u003c/span\u003e\u003cspan id=\"user_num\"\u003e0\u003c/span\u003e\u003c/p\u003e \u003cdiv id=\"user_list\" style=\"overflow: auto;\"\u003e \u003c/div\u003e \u003c/div\u003e \u003cdiv id=\"msg_list\" style=\"width: 598px;border: 1px solid gray; height: 300px;overflow: scroll;float: left;\"\u003e \u003c/div\u003e \u003c/div\u003e \u003cbr\u003e \u003ctextarea id=\"msg_box\" rows=\"6\" cols=\"50\" onkeydown=\"confirm(event)\"\u003e\u003c/textarea\u003e\u003cbr\u003e \u003cinput type=\"button\" value=\"发送\" onclick=\"send()\"\u003e \u003c/div\u003e \u003c/body\u003e \u003c/html\u003e \u003cscr","date":"2022-01-06 09:16:45","objectID":"/go_base_06/:4:2","tags":["go grammar"],"title":"Go_base_06","uri":"/go_base_06/"},{"categories":["Go"],"content":" 参考学习go语言中文网、C语言中文网、golang官方文档等 面向对象 Is Go an object-oriented language? Yes and no. Although Go has types and methods and allows an object-oriented style of programming, there is no type hierarchy. The concept of “interface” in Go provides a different approach that we believe is easy to use and in some ways more general. Also, the lack of a type hierarchy makes “objects” in Go feel much more lightweight than in languages such as C++ or Java. 个人认为官网的大致意思就是go算是面向对象语言，没有继承，但有更通用的“接口”，没有继承也使对象比某些语言更轻量。 ","date":"2022-01-06 09:16:40","objectID":"/go_base_05/:0:0","tags":["go grammar"],"title":"Go_base_05","uri":"/go_base_05/"},{"categories":["Go"],"content":"匿名字段 go支持只提供类型而不写字段名的方式，也就是匿名字段，也称为嵌入字段 package main import \"fmt\" //- go支持只提供类型而不写字段名的方式，也就是匿名字段，也称为嵌入字段 //人 type Person struct { name string sex string age int } type Student struct { Person id int addr string } func main() { // 初始化 s1 := Student{Person{\"5lmh\", \"man\", 20}, 1, \"bj\"} fmt.Println(s1) s2 := Student{Person: Person{\"5lmh\", \"man\", 20} } fmt.Println(s2) s3 := Student{Person: Person{name: \"5lmh\"} } fmt.Println(s3) } output： { {5lmh man 20} 1 bj} { {5lmh man 20} 0 } { {5lmh 0} 0 } 同名字段的情况 package main import \"fmt\" //人 type Person struct { name string sex string age int } type Student struct { Person id int addr string //同名字段 name string } func main() { var s Student // 给自己字段赋值了 s.name = \"5lmh\" fmt.Println(s) // 若给父类同名字段赋值，如下 s.Person.name = \"枯藤\" fmt.Println(s) } output： { { 0} 0 5lmh} { {枯藤 0} 0 5lmh} 所有的内置类型和自定义类型都是可以作为匿名字段去使用 package main import \"fmt\" //人 type Person struct { name string sex string age int } // 自定义类型 type mystr string // 学生 type Student struct { Person int mystr } func main() { s1 := Student{Person{\"5lmh\", \"man\", 18}, 1, \"bj\"} fmt.Println(s1) } output： { {5lmh man 18} 1 bj} 指针类型匿名字段 package main import \"fmt\" //人 type Person struct { name string sex string age int } // 学生 type Student struct { *Person id int addr string } func main() { s1 := Student{\u0026Person{\"5lmh\", \"man\", 18}, 1, \"bj\"} fmt.Println(s1) fmt.Println(s1.name) fmt.Println(s1.Person.name) } output： {0xc00006a360 1 bj} 5lmh 5lmh ","date":"2022-01-06 09:16:40","objectID":"/go_base_05/:1:0","tags":["go grammar"],"title":"Go_base_05","uri":"/go_base_05/"},{"categories":["Go"],"content":"接口 接口（interface）定义了一个对象的行为规范，只定义规范不实现，由具体的对象来实现规范的细节。（也可以说是定义对象之间交互的协议的） ","date":"2022-01-06 09:16:40","objectID":"/go_base_05/:2:0","tags":["go grammar"],"title":"Go_base_05","uri":"/go_base_05/"},{"categories":["Go"],"content":"接口 接口类型 在Go语言中接口（interface）是一种类型，一种抽象的类型。 interface是一组method的集合，是duck-type programming的一种体现。接口做的事情就像是定义一个协议（规则），只要一台机器有洗衣服和甩干的功能，我就称它为洗衣机。不关心属性（数据），只关心行为（方法）。 为什么要使用接口 type Cat struct{} func (c Cat) Say() string { return \"喵喵喵\" } type Dog struct{} func (d Dog) Say() string { return \"汪汪汪\" } func main() { c := Cat{} fmt.Println(\"猫:\", c.Say()) d := Dog{} fmt.Println(\"狗:\", d.Say()) } 上面的代码中定义了猫和狗，然后它们都会叫，你会发现main函数中明显有重复的代码，如果我们后续再加上猪、青蛙等动物的话，我们的代码还会一直重复下去。那我们能不能把它们当成“能叫的动物”来处理呢？ 像类似的例子在我们编程过程中会经常遇到： 比如一个网上商城可能使用支付宝、微信、银联等方式去在线支付，我们能不能把它们当成“支付方式”来处理呢？ 比如三角形，四边形，圆形都能计算周长和面积，我们能不能把它们当成“图形”来处理呢？ 比如销售、行政、程序员都能计算月薪，我们能不能把他们当成“员工”来处理呢？ Go语言中为了解决类似上面的问题，就设计了接口这个概念。接口区别于我们之前所有的具体类型，接口是一种抽象的类型。当你看到一个接口类型的值时，你不知道它是什么，唯一知道的是通过它的方法能做什么。 接口的定义： （Go语言提倡面向接口编程。） 接口是一个或多个方法签名的集合。 任何类型的方法集中只要拥有该接口'对应的全部方法'签名。 就表示它 \"实现\" 了该接口，无须在该类型上显式声明实现了哪个接口。 这称为Structural Typing。 所谓对应方法，是指有相同名称、参数列表 (不包括参数名) 以及返回值。 当然，该类型还可以有其他方法。 接口只有方法声明，没有实现，没有数据字段。 接口可以匿名嵌入其他接口，或嵌入到结构中。 对象赋值给接口时，会发生拷贝，而接口内部存储的是指向这个复制品的指针，既无法修改复制品的状态，也无法获取指针。 只有当接口存储的类型和对象都为nil时，接口才等于nil。 接口调用不会做receiver的自动转换。 接口同样支持匿名字段方法。 接口也可实现类似OOP中的多态。 空接口可以作为任何类型数据的容器。 一个类型可实现多个接口。 接口命名习惯以 er 结尾。 每个接口由数个方法组成，接口的定义格式如下： type 接口类型名 interface{ 方法名1( 参数列表1 ) 返回值列表1 方法名2( 参数列表2 ) 返回值列表2 … } 其中： 接口名：使用type将接口定义为自定义的类型名。Go语言的接口在命名时，一般会在单词后面添加er，如有写操作的接口叫Writer，有字符串功能的接口叫Stringer等。接口名最好要能突出该接口的类型含义。 方法名：当方法名首字母是大写且这个接口类型名首字母也是大写时，这个方法可以被接口所在的包（package）之外的代码访问。 参数列表、返回值列表：参数列表和返回值列表中的参数变量名可以省略。 举个例子： type writer interface{ Write([]byte) error } 当你看到这个接口类型的值时，你不知道它是什么，唯一知道的就是可以通过它的Write方法来做一些事情。 实现接口的条件 一个对象只要全部实现了接口中的方法，那么就实现了这个接口。换句话说，接口就是一个需要实现的方法列表。 我们来定义一个Sayer接口： // Sayer 接口 type Sayer interface { say() } 定义dog和cat两个结构体： type dog struct {} type cat struct {} 因为Sayer接口里只有一个say方法，所以我们只需要给dog和cat 分别实现say方法就可以实现Sayer接口了。 // dog实现了Sayer接口 func (d dog) say() { fmt.Println(\"汪汪汪\") } // cat实现了Sayer接口 func (c cat) say() { fmt.Println(\"喵喵喵\") } 接口的实现就是这么简单，只要实现了接口中的所有方法，就实现了这个接口。 接口类型变量 那实现了接口有什么用呢？ 接口类型变量能够存储所有实现了该接口的实例。 例如上面的示例中，Sayer类型的变量能够存储dog和cat类型的变量。 func main() { var x Sayer // 声明一个Sayer类型的变量x a := cat{} // 实例化一个cat b := dog{} // 实例化一个dog x = a // 可以把cat实例直接赋值给x x.say() // 喵喵喵 x = b // 可以把dog实例直接赋值给x x.say() // 汪汪汪 } 值接收者和指针接收者实现接口的区别 使用值接收者实现接口和使用指针接收者实现接口有什么区别呢？接下来我们通过一个例子看一下其中的区别。 我们有一个Mover接口和一个dog结构体。 type Mover interface { move() } type dog struct {} 值接收者实现接口 func (d dog) move() { fmt.Println(\"狗会动\") } 此时实现接口的是dog类型： func main() { var x Mover var wangcai = dog{} // 旺财是dog类型 x = wangcai // x可以接收dog类型 var fugui = \u0026dog{} // 富贵是*dog类型 x = fugui // x可以接收*dog类型 x.move() } 从上面的代码中我们可以发现，使用值接收者实现接口之后，不管是dog结构体还是结构体指针*dog类型的变量都可以赋值给该接口变量。因为Go语言中有对指针类型变量求值的语法糖，dog指针fugui内部会自动求值*fugui。 指针接收者实现接口 同样的代码我们再来测试一下使用指针接收者有什么区别： func (d *dog) move() { fmt.Println(\"狗会动\") } func main() { var x Mover var wangcai = dog{} // 旺财是dog类型 x = wangcai // x不可以接收dog类型 var fugui = \u0026dog{} // 富贵是*dog类型 x = fugui // x可以接收*dog类型 } 此时实现Mover接口的是*dog类型，所以不能给x传入dog类型的wangcai，此时x只能存储*dog类型的值。 用接口实现多态 接口的最佳实践 倾向于使⽤⼩的接⼝定义，很多接⼝只包含⼀个⽅法 较⼤的接⼝定义，可以由多个⼩接⼝定义组合⽽成 只依赖于必要功能的最小接口，这样方法的复用性更强。 下面的代码是一个比较好的面试题 请问下面的代码是否能通过编译？ type People interface { Speak(string) string } type Student struct{} func (stu *Student) Speak(think string) (talk string) { if think == \"sb\" { talk = \"你是个大帅比\" } else { talk = \"您好\" } return } func main() { var peo People = Student{} think := \"bitch\" fmt.Println(peo.Speak(think)) } ","date":"2022-01-06 09:16:40","objectID":"/go_base_05/:2:1","tags":["go grammar"],"title":"Go_base_05","uri":"/go_base_05/"},{"categories":["Go"],"content":"类型与接口的关系 一个类型实现多个接口 一个类型可以同时实现多个接口，而接口间彼此独立，不知道对方的实现。 例如，狗可以叫，也可以动。我们就分别定义Sayer接口和Mover接口，如下： Mover接口。 // Sayer 接口 type Sayer interface { say() } // Mover 接口 type Mover interface { move() } dog既可以实现Sayer接口，也可以实现Mover接口。 type dog struct { name string } // 实现Sayer接口 func (d dog) say() { fmt.Printf(\"%s会叫汪汪汪\\n\", d.name) } // 实现Mover接口 func (d dog) move() { fmt.Printf(\"%s会动\\n\", d.name) } func main() { var x Sayer var y Mover var a = dog{name: \"旺财\"} x = a y = a x.say() y.move() } 多个类型实现同一接口 Go语言中不同的类型还可以实现同一接口 首先我们定义一个Mover接口，它要求必须由一个move方法。 // Mover 接口 type Mover interface { move() } 例如狗可以动，汽车也可以动，可以使用如下代码实现这个关系： type dog struct { name string } type car struct { brand string } // dog类型实现Mover接口 func (d dog) move() { fmt.Printf(\"%s会跑\\n\", d.name) } // car类型实现Mover接口 func (c car) move() { fmt.Printf(\"%s速度70迈\\n\", c.brand) } 这个时候我们在代码中就可以把狗和汽车当成一个会动的物体来处理了，不再需要关注它们具体是什么，只需要调用它们的move方法就可以了。 func main() { var x Mover var a = dog{name: \"旺财\"} var b = car{brand: \"保时捷\"} x = a x.move() x = b x.move() } 上面的代码执行结果如下： 旺财会跑 保时捷速度70迈 并且一个接口的方法，不一定需要由一个类型完全实现，接口的方法可以通过在类型中嵌入其他类型或者结构体来实现。 // WashingMachine 洗衣机 type WashingMachine interface { wash() dry() } // 甩干器 type dryer struct{} // 实现WashingMachine接口的dry()方法 func (d dryer) dry() { fmt.Println(\"甩一甩\") } // 海尔洗衣机 type haier struct { dryer //嵌入甩干器 } // 实现WashingMachine接口的wash()方法 func (h haier) wash() { fmt.Println(\"洗刷刷\") } 接口嵌套 接口与接口间可以通过嵌套创造出新的接口。 // Sayer 接口 type Sayer interface { say() } // Mover 接口 type Mover interface { move() } // 接口嵌套 type animal interface { Sayer Mover } 嵌套得到的接口的使用与普通接口一样，这里我们让cat实现animal接口： type cat struct { name string } func (c cat) say() { fmt.Println(\"喵喵喵\") } func (c cat) move() { fmt.Println(\"猫会动\") } func main() { var x animal x = cat{name: \"花花\"} x.move() x.say() } ","date":"2022-01-06 09:16:40","objectID":"/go_base_05/:2:2","tags":["go grammar"],"title":"Go_base_05","uri":"/go_base_05/"},{"categories":["Go"],"content":"空接口 空接口的定义 空接口是指没有定义任何方法的接口。因此任何类型都实现了空接口。 空接口类型的变量可以存储任意类型的变量。 func main() { // 定义一个空接口x var x interface{} s := \"pprof.cn\" x = s fmt.Printf(\"type:%T value:%v\\n\", x, x) i := 100 x = i fmt.Printf(\"type:%T value:%v\\n\", x, x) b := true x = b fmt.Printf(\"type:%T value:%v\\n\", x, x) } ","date":"2022-01-06 09:16:40","objectID":"/go_base_05/:2:3","tags":["go grammar"],"title":"Go_base_05","uri":"/go_base_05/"},{"categories":["Go"],"content":"空接口的应用 空接口作为函数的参数 使用空接口实现可以接收任意类型的函数参数。 // 空接口作为函数参数 func show(a interface{}) { fmt.Printf(\"type:%T value:%v\\n\", a, a) } 空接口作为map的值 使用空接口实现可以保存任意值的字典。 // 空接口作为map值 var studentInfo = make(map[string]interface{}) studentInfo[\"name\"] = \"李白\" studentInfo[\"age\"] = 18 studentInfo[\"married\"] = false fmt.Println(studentInfo) ","date":"2022-01-06 09:16:40","objectID":"/go_base_05/:2:4","tags":["go grammar"],"title":"Go_base_05","uri":"/go_base_05/"},{"categories":["Go"],"content":"类型断言 空接口可以存储任意类型的值，那我们如何获取其存储的具体数据呢？ 接口值 一个接口的值（简称接口值）是由一个具体类型和具体类型的值两部分组成的。这两部分分别称为接口的动态类型和动态值。 我们来看一个具体的例子： var w io.Writer w = os.Stdout w = new(bytes.Buffer) w = nil 请看下图分解（来自go中文文档）：想要判断空接口中的值这个时候就可以使用类型断言，其语法格式： x.(T) 其中： x：表示类型为interface{}的变量 T：表示断言x可能是的类型。 该语法返回两个参数，第一个参数是x转化为T类型后的变量，第二个值是一个布尔值，若为true则表示断言成功，为false则表示断言失败。 举个例子： func main() { var x interface{} x = \"pprof.cn\" v, ok := x.(string) if ok { fmt.Println(v) } else { fmt.Println(\"类型断言失败\") } } 上面的示例中如果要断言多次就需要写多个if判断，这个时候我们可以使用switch语句来实现： func justifyType(x interface{}) { switch v := x.(type) { case string: fmt.Printf(\"x is a string，value is %v\\n\", v) case int: fmt.Printf(\"x is a int is %v\\n\", v) case bool: fmt.Printf(\"x is a bool is %v\\n\", v) default: fmt.Println(\"unsupport type！\") } } 因为空接口可以存储任意类型值的特点，所以空接口在Go语言中的使用十分广泛。 关于接口需要注意的是，只有当有两个或两个以上的具体类型必须以相同的方式进行处理时才需要定义接口。不要为了接口而写接口，那样只会增加不必要的抽象，导致不必要的运行时损耗。 ","date":"2022-01-06 09:16:40","objectID":"/go_base_05/:2:5","tags":["go grammar"],"title":"Go_base_05","uri":"/go_base_05/"},{"categories":["Go"],"content":" 参考学习go语言中文网、C语言中文网、golang官方文档等 方法 ","date":"2022-01-06 09:16:37","objectID":"/go_base_04/:0:0","tags":["go grammar"],"title":"Go_base_04","uri":"/go_base_04/"},{"categories":["Go"],"content":"方法本质 一个以方法的 receiver 参数作为第一个参数的普通函数。 package main import ( \"fmt\" \"time\" ) type field struct { name string } func (p *field) print() { fmt.Println(p.name) } func main() { data1 := []*field{ {\"one\"}, {\"two\"}, {\"three\"} } for _, v := range data1 { go v.print() } data2 := []field{ {\"four\"}, {\"five\"}, {\"six\"} } for _, v := range data2 { go v.print() } time.Sleep(3 * time.Second) } one two three six six six 为什么会是这样的输出？ 根据 Go 方法的本质，也就是一个以方法的 receiver 参数作为第一个参数的普通函数，对这个程序做个等价变换 type field struct { name string } func (p *field) print() { fmt.Println(p.name) } func main() { data1 := []*field{ {\"one\"}, {\"two\"}, {\"three\"} } for _, v := range data1 { go (*field).print(v) } data2 := []field{ {\"four\"}, {\"five\"}, {\"six\"} } for _, v := range data2 { go (*field).print(\u0026v) } time.Sleep(3 * time.Second) } 我们把对 field 的方法 print 的调用，替换为 Method Expression 形式，替换前后的程序输出结果是一致的 使用 go 关键字启动一个新 Goroutine 时，method expression 形式的 print 函数是如何绑定参数的： 迭代 data1 时，由于 data1 中的元素类型是 field 指针 (*field)，因此赋值后 v 就是元素地址，与 print 的 receiver 参数类型相同，每次调用 (*field).print 函数时直接传入的 v 即可，实际上传入的也是各个 field 元素的地址； 迭代 data2 时，由于 data2 中的元素类型是 field（非指针），与 print 的 receiver 参数类型不同，因此需要将其取地址后再传入 (*field).print 函数。这样每次传入的 \u0026v 实际上是变量 v 的地址，而不是切片 data2 中各元素的地址。 ","date":"2022-01-06 09:16:37","objectID":"/go_base_04/:1:0","tags":["go grammar"],"title":"Go_base_04","uri":"/go_base_04/"},{"categories":["Go"],"content":"方法定义 Golang 方法总是绑定对象实例，并隐式将实例作为第一实参 (receiver)。 只能为当前包内命名类型定义方法。 参数 receiver 可任意命名。如方法中未曾使用 ，可省略参数名。 参数 receiver 类型可以是 T 或 *T。基类型 T 不能是接口或指针。 不支持方法重载，receiver 只是参数签名的组成部分。 可用实例 value 或 pointer 调用全部方法，编译器自动转换。 方法表达式（Method Expression）: 直接以类型名 T 调用方法的表达方式，被称为 Method Expression。通过 Method Expression 这种形式，类型 T 只能调用 T 的方法集合（Method Set）中的方法，同理类型 *T 也只能调用 *T 的方法集合中的方法 一个方法就是一个包含了接受者的函数，接受者可以是命名类型或者结构体类型的一个值或者是一个指针。 所有给定类型的方法属于该类型的方法集。 func (recevier type) methodName(参数列表)(返回值列表){} //参数和返回值可以省略 package main type Test struct{} // 无参数、无返回值 func (t Test) method0() { } // 单参数、无返回值 func (t Test) method1(i int) { } // 多参数、无返回值 func (t Test) method2(x, y int) { } // 无参数、单返回值 func (t Test) method3() (i int) { return } // 多参数、多返回值 func (t Test) method4(x, y int) (z int, err error) { return } // 无参数、无返回值 func (t *Test) method5() { } // 单参数、无返回值 func (t *Test) method6(i int) { } // 多参数、无返回值 func (t *Test) method7(x, y int) { } // 无参数、单返回值 func (t *Test) method8() (i int) { return } // 多参数、多返回值 func (t *Test) method9(x, y int) (z int, err error) { return } func main() {} 下面定义一个结构体类型和该类型的一个方法： package main import ( \"fmt\" ) //结构体 type User struct { Name string Email string } //方法 func (u User) Notify() { fmt.Printf(\"%v : %v \\n\", u.Name, u.Email) } func main() { // 值类型调用方法 u1 := User{\"golang\", \"golang@golang.com\"} u1.Notify() // 指针类型调用方法 u2 := User{\"go\", \"go@go.com\"} u3 := \u0026u2 u3.Notify() } output： golang : golang@golang.com go : go@go.com 解释： 首先我们定义了一个叫做 User 的结构体类型，然后定义了一个该类型的方法叫做 Notify，该方法的接受者是一个 User 类型的值。要调用 Notify 方法我们需要一个 User 类型的值或者指针。 在这个例子中当我们使用指针时，Go 调整和解引用指针使得调用可以被执行。注意，当接受者不是一个指针时，该方法操作对应接受者的值的副本(意思就是即使你使用了指针调用函数，但是函数的接受者是值类型，所以函数内部操作还是对副本的操作，而不是指针操作。 我们修改 Notify 方法，让它的接受者使用指针类型： package main import ( \"fmt\" ) //结构体 type User struct { Name string Email string } //方法 func (u *User) Notify() { fmt.Printf(\"%v : %v \\n\", u.Name, u.Email) } func main() { // 值类型调用方法 u1 := User{\"golang\", \"golang@golang.com\"} u1.Notify() // 指针类型调用方法 u2 := User{\"go\", \"go@go.com\"} u3 := \u0026u2 u3.Notify() } output： golang : golang@golang.com go : go@go.com 注意：当接受者是指针时，即使用值类型调用那么函数内部也是对指针的操作。 方法不过是一种特殊的函数，只需将其还原，就知道 receiver T 和 *T 的差别。 package main import \"fmt\" type Data struct { x int } func (self Data) ValueTest() { // func ValueTest(self Data); fmt.Printf(\"Value: %p\\n\", \u0026self) } func (self *Data) PointerTest() { // func PointerTest(self *Data); fmt.Printf(\"Pointer: %p\\n\", self) } func main() { d := Data{} p := \u0026d fmt.Printf(\"Data: %p\\n\", p) d.ValueTest() // ValueTest(d) d.PointerTest() // PointerTest(\u0026d) p.ValueTest() // ValueTest(*p) p.PointerTest() // PointerTest(p) } output: Data: 0xc42007c008 Value: 0xc42007c018 Pointer: 0xc42007c008 Value: 0xc42007c020 Pointer: 0xc42007c008 普通函数与方法的区别 1.对于普通函数，接收者为值类型时，不能将指针类型的数据直接传递，反之亦然。 2.对于方法（如struct的方法），接收者为值类型时，可以直接用指针类型的变量调用方法，反过来同样也可以。 package main //普通函数与方法的区别（在接收者分别为值类型和指针类型的时候） import ( \"fmt\" ) //1.普通函数 //接收值类型参数的函数 func valueIntTest(a int) int { return a + 10 } //接收指针类型参数的函数 func pointerIntTest(a *int) int { return *a + 10 } func structTestValue() { a := 2 fmt.Println(\"valueIntTest:\", valueIntTest(a)) //函数的参数为值类型，则不能直接将指针作为参数传递 //fmt.Println(\"valueIntTest:\", valueIntTest(\u0026a)) //compile error: cannot use \u0026a (type *int) as type int in function argument b := 5 fmt.Println(\"pointerIntTest:\", pointerIntTest(\u0026b)) //同样，当函数的参数为指针类型时，也不能直接将值类型作为参数传递 //fmt.Println(\"pointerIntTest:\", pointerIntTest(b)) //compile error:cannot use b (type int) as type *int in function argument } //2.方法 type PersonD struct { id int name string } //接收者为值类型 func (p PersonD) valueShowName() { fmt.Println(p.name) } //接收者为指针类型 func (p *PersonD) pointShowName() { fmt.Println(p.name) } func structTestFunc() { //值类型调用方法 personValue := PersonD{101, \"hello world\"} personValue.valueShowName() personValue.pointShowName() //指针类型调用方法 personPointer := \u0026PersonD{102, \"hello golang\"} personPointer.valueShowName() personPointer.pointShowName() //与普通函数不同，接收者为指针类型和值类型的方法，指针类型和值类型的变量均可相互调用 } func main() { structTestValue() structTestFunc() } output： valueIntTest: 12 ","date":"2022-01-06 09:16:37","objectID":"/go_base_04/:2:0","tags":["go grammar"],"title":"Go_base_04","uri":"/go_base_04/"},{"categories":["Go"],"content":"匿名字段 Golang匿名字段 ：可以像字段成员那样访问匿名字段方法，编译器负责查找。 package main import \"fmt\" type User struct { id int name string } type Manager struct { User } func (self *User) ToString() string { // receiver = \u0026(Manager.User) return fmt.Sprintf(\"User: %p, %v\", self, self) } func main() { m := Manager{User{1, \"Tom\"} } fmt.Printf(\"Manager: %p\\n\", \u0026m) fmt.Println(m.ToString()) } output: Manager: 0xc42000a060 User: 0xc42000a060, \u0026{1 Tom} 通过匿名字段，可获得和继承类似的复用能力。依据编译器查找次序，只需在外层定义同名方法，就可以实现 “override”。 package main import \"fmt\" type User struct { id int name string } type Manager struct { User title string } func (self *User) ToString() string { return fmt.Sprintf(\"User: %p, %v\", self, self) } func (self *Manager) ToString() string { return fmt.Sprintf(\"Manager: %p, %v\", self, self) } func main() { m := Manager{User{1, \"Tom\"}, \"Administrator\"} fmt.Println(m.ToString()) fmt.Println(m.User.ToString()) } output: Manager: 0xc420074180, \u0026\\{\\{1 Tom} Administrator} User: 0xc420074180, \u0026{1 Tom} ","date":"2022-01-06 09:16:37","objectID":"/go_base_04/:3:0","tags":["go grammar"],"title":"Go_base_04","uri":"/go_base_04/"},{"categories":["Go"],"content":"方法集以及如何选择 receiver 参数的类型。 Golang方法集 ：每个类型都有与之关联的方法集，这会影响到接口实现规则。 类型 T 方法集包含全部 receiver T 方法。 类型 *T 方法集包含全部 receiver T + *T 方法。 如类型 S 包含匿名字段 T，则 S 和 *S 方法集包含 T 方法。 如类型 S 包含匿名字段 *T，则 S 和 *S 方法集包含 T + *T 方法。 不管嵌入 T 或 *T，*S 方法集总是包含 T + *T 方法。 用实例 value 和 pointer 调用方法 (含匿名字段) 不受方法集约束，编译器总是查找全部方法，并自动转换 receiver 实参。 Go 语言中内部类型方法集提升的规则： 类型 T 方法集包含全部 receiver T 方法。 package main import ( \"fmt\" ) type T struct { int } func (t T) test() { fmt.Println(\"类型 T 方法集包含全部 receiver T 方法。\") } func main() { t1 := T{1} fmt.Printf(\"t1 is : %v\\n\", t1) t1.test() } output： t1 is : {1} 类型 T 方法集包含全部 receiver T 方法。 类型 *T 方法集包含全部 receiver T + *T 方法。 package main import ( \"fmt\" ) type T struct { int } func (t T) testT() { fmt.Println(\"类型 *T 方法集包含全部 receiver T 方法。\") } func (t *T) testP() { fmt.Println(\"类型 *T 方法集包含全部 receiver *T 方法。\") } func main() { t1 := T{1} t2 := \u0026t1 fmt.Printf(\"t2 is : %v\\n\", t2) t2.testT() t2.testP() } output： t2 is : \u0026{1} 类型 *T 方法集包含全部 receiver T 方法。 类型 *T 方法集包含全部 receiver *T 方法。 给定一个结构体类型 S 和一个命名为 T 的类型，方法提升像下面规定的这样被包含在结构体方法集中： 如类型 S 包含匿名字段 T，则 S 和 *S 方法集包含 T 方法。 这条规则说的是当我们嵌入一个类型，嵌入类型的接受者为值类型的方法将被提升，可以被外部类型的值和指针调用。 package main import ( \"fmt\" ) type S struct { T } type T struct { int } func (t T) testT() { fmt.Println(\"如类型 S 包含匿名字段 T，则 S 和 *S 方法集包含 T 方法。\") } func main() { s1 := S{T{1} } s2 := \u0026s1 fmt.Printf(\"s1 is : %v\\n\", s1) s1.testT() fmt.Printf(\"s2 is : %v\\n\", s2) s2.testT() } output： s1 is : { {1} } 如类型 S 包含匿名字段 T，则 S 和 *S 方法集包含 T 方法。 s2 is : \u0026{ {1} } 如类型 S 包含匿名字段 T，则 S 和 *S 方法集包含 T 方法。 如类型 S 包含匿名字段 *T，则 S 和 *S 方法集包含 T + *T 方法。 这条规则说的是当我们嵌入一个类型的指针，嵌入类型的接受者为值类型或指针类型的方法将被提升，可以被外部类型的值或者指针调用。 package main import ( \"fmt\" ) type S struct { T } type T struct { int } func (t T) testT() { fmt.Println(\"如类型 S 包含匿名字段 *T，则 S 和 *S 方法集包含 T 方法\") } func (t *T) testP() { fmt.Println(\"如类型 S 包含匿名字段 *T，则 S 和 *S 方法集包含 *T 方法\") } func main() { s1 := S{T{1} } s2 := \u0026s1 fmt.Printf(\"s1 is : %v\\n\", s1) s1.testT() s1.testP() fmt.Printf(\"s2 is : %v\\n\", s2) s2.testT() s2.testP() } output： s1 is : { {1} } 如类型 S 包含匿名字段 *T，则 S 和 *S 方法集包含 T 方法 如类型 S 包含匿名字段 *T，则 S 和 *S 方法集包含 *T 方法 s2 is : \u0026{ {1} } 如类型 S 包含匿名字段 *T，则 S 和 *S 方法集包含 T 方法 如类型 S 包含匿名字段 *T，则 S 和 *S 方法集包含 *T 方法 func (t T) M1() \u003c=\u003e F1(t T) func (t *T) M2() \u003c=\u003e F2(t *T) 当 receiver 参数的类型为 T 时： 当我们的方法 M1 采用类型为 T 的 receiver 参数时，代表 T 类型实例的 receiver 参数以值传递方式传递到 M1 方法体中的，实际上是 T 类型实例的副本，M1 方法体中对副本的任何修改操作，都不会影响到原 T 类型实例。 当 receiver 参数的类型为 *T 时： 方法 M2 采用类型为 *T 的 receiver 参数时，代表 *T 类型实例的 receiver 参数以值传递方式传递到 M2 方法体中的，实际上是 T 类型实例的地址，M2 方法体通过该地址可以对原 T 类型实例进行任何修改操作。 选择 receiver 参数类型的第一个原则：*如果 Go 方法要把对 receiver 参数代表的类型实例的修改，反映到原类型实例上，那么我们应该选择 T 作为 receiver 参数的类型。 无论是 T 类型实例，还是 *T 类型实例，都既可以调用 receiver 为 T 类型的方法，也可以调用 receiver 为 *T 类型的方法。 选择 receiver 参数类型的第二个原则： 一般情况下，我们通常会为 receiver 参数选择 T 类型，因为这样可以缩窄外部修改类型实例内部状态的“接触面”，也就是尽量少暴露可以修改类型内部状态的方法。 考虑到 Go 方法调用时，receiver 参数是以值拷贝的形式传入方法中的。那么，如果 receiver 参数类型的 size 较大，以值拷贝形式传入就会导致较大的性能开销，这时我们选择 *T 作为 receiver 类型可能更好些。 选择 receiver 参数类型的第三个原则：（其实是应该首先考虑的一点） 如果 T 类型需要实现某个接口，那我们就要使用 T 作为 receiver 参数的类型，来满足接口类型方法集合中的所有方法。 如果 T 不需要实现某一接口，但 *T 需要实现该接口，那么根据方法集合概念，*T 的方法集合是包含 T 的方法集合的，这样我们在确定 Go 方法的 receiver 的类型时，参考原则一和原则二就可以了。 ","date":"2022-01-06 09:16:37","objectID":"/go_base_04/:4:0","tags":["go grammar"],"title":"Go_base_04","uri":"/go_base_04/"},{"categories":["Go"],"content":"表达式 Golang 表达式 ：根据调用者不同，方法分为两种表现形式: instance.method(args...) ---\u003e \u003ctype\u003e.func(instance, args...) 前者称为 method value，后者 method expression。 两者都可像普通函数那样赋值和传参，区别在于 method value 绑定实例，而 method expression 则须显式传参。 package main import \"fmt\" type User struct { id int name string } func (self *User) Test() { fmt.Printf(\"%p, %v\\n\", self, self) } func main() { u := User{1, \"Tom\"} u.Test() mValue := u.Test mValue() // 隐式传递 receiver mExpression := (*User).Test mExpression(\u0026u) // 显式传递 receiver } output: 0xc42000a060, \u0026{1 Tom} 0xc42000a060, \u0026{1 Tom} 0xc42000a060, \u0026{1 Tom} 需要注意，method value 会复制 receiver。 package main import \"fmt\" type User struct { id int name string } func (self User) Test() { fmt.Println(self) } func main() { u := User{1, \"Tom\"} mValue := u.Test // 立即复制 receiver，因为不是指针类型，不受后续修改影响。 u.id, u.name = 2, \"Jack\" u.Test() mValue() } output: {2 Jack} {1 Tom} 在汇编层面，method value 和闭包的实现方式相同，实际返回 FuncVal 类型对象。 FuncVal { method_address, receiver_copy } 可依据方法集转换 method expression，注意 receiver 类型的差异。 package main import \"fmt\" type User struct { id int name string } func (self *User) TestPointer() { fmt.Printf(\"TestPointer: %p, %v\\n\", self, self) } func (self User) TestValue() { fmt.Printf(\"TestValue: %p, %v\\n\", \u0026self, self) } func main() { u := User{1, \"Tom\"} fmt.Printf(\"User: %p, %v\\n\", \u0026u, u) mv := User.TestValue mv(u) mp := (*User).TestPointer mp(\u0026u) mp2 := (*User).TestValue // *User 方法集包含 TestValue。签名变为 func TestValue(self *User)。实际依然是 receiver value copy。 mp2(\u0026u) } output: User: 0xc42000a060, {1 Tom} TestValue: 0xc42000a0a0, {1 Tom} TestPointer: 0xc42000a060, \u0026{1 Tom} TestValue: 0xc42000a100, {1 Tom} 将方法 “还原” 成函数，就容易理解下面的代码了。 package main type Data struct{} func (Data) TestValue() {} func (*Data) TestPointer() {} func main() { var p *Data = nil p.TestPointer() (*Data)(nil).TestPointer() // method value (*Data).TestPointer(nil) // method expression // p.TestValue() // invalid memory address or nil pointer dereference // (Data)(nil).TestValue() // cannot convert nil to type Data // Data.TestValue(nil) // cannot use nil as type Data in function argument } ","date":"2022-01-06 09:16:37","objectID":"/go_base_04/:5:0","tags":["go grammar"],"title":"Go_base_04","uri":"/go_base_04/"},{"categories":["Go"],"content":"自定义error ","date":"2022-01-06 09:16:37","objectID":"/go_base_04/:6:0","tags":["go grammar"],"title":"Go_base_04","uri":"/go_base_04/"},{"categories":["Go"],"content":"抛异常和处理异常 系统抛 package main import \"fmt\" // 系统抛 func test01() { a := [5]int{0, 1, 2, 3, 4} a[1] = 123 fmt.Println(a) //a[10] = 11 index := 10 a[index] = 10 fmt.Println(a) } func getCircleArea(radius float32) (area float32) { if radius \u003c 0 { // 自己抛 panic(\"半径不能为负\") } return 3.14 * radius * radius } func test02() { getCircleArea(-5) } // func test03() { // 延时执行匿名函数 // 延时到何时？（1）程序正常结束 （2）发生异常时 defer func() { // recover() 恢复 // 会返回程序为什么挂了 if err := recover(); err != nil { fmt.Println(err) } }() getCircleArea(-5) fmt.Println(\"这里有没有执行\") } func test04() { test03() fmt.Println(\"test04\") } func main() { test04() } 返回异常 package main import ( \"errors\" \"fmt\" ) func getCircleArea(radius float32) (area float32, err error) { if radius \u003c 0 { // 构建个异常对象 err = errors.New(\"半径不能为负\") return } area = 3.14 * radius * radius return } func main() { area, err := getCircleArea(-5) if err != nil { fmt.Println(err) } else { fmt.Println(area) } } 自定义error： package main import ( \"fmt\" \"os\" \"time\" ) type PathError struct { path string op string createTime string message string } func (p *PathError) Error() string { return fmt.Sprintf(\"path=%s \\nop=%s \\ncreateTime=%s \\nmessage=%s\", p.path, p.op, p.createTime, p.message) } func Open(filename string) error { file, err := os.Open(filename) if err != nil { return \u0026PathError{ path: filename, op: \"read\", message: err.Error(), createTime: fmt.Sprintf(\"%v\", time.Now()), } } defer file.Close() return nil } func main() { err := Open(\"/Users/5lmh/Desktop/go/src/test.txt\") switch v := err.(type) { case *PathError: fmt.Println(\"get path error,\", v) default: } } output： get path error, path=/Users/pprof/Desktop/go/src/test.txt op=read createTime=2018-04-05 11:25:17.331915 +0800 CST m=+0.000441790 message=open /Users/pprof/Desktop/go/src/test.txt: no such file or directory ","date":"2022-01-06 09:16:37","objectID":"/go_base_04/:6:1","tags":["go grammar"],"title":"Go_base_04","uri":"/go_base_04/"},{"categories":["Go"],"content":" 参考学习go语言中文网、C语言中文网、golang官方文档等 函数 ","date":"2022-01-06 09:16:34","objectID":"/go_base_03/:0:0","tags":["go grammar"],"title":"Go_base_03","uri":"/go_base_03/"},{"categories":["Go"],"content":"函数定义 go的函数特点： 无需声明原型。 支持不定参、变参。 支持多返回值。 支持命名返回参数。 支持匿名函数和闭包。（闭包详见后文） 函数也是一种类型，一个函数可以赋值给变量。 有返回值的函数，必须有明确的终止语句，否则会引发编译错误。 不支持 嵌套 (nested) 一个包不能有两个名字一样的函数。 不支持 重载 (overload) （区别于重写，重载(overloading) 是在一个类里面，方法名字相同，而参数不同。返回类型可以相同也可以不同。每个重载的方法（或者构造函数）都必须有一个独一无二的参数类型列表。最常用的地方就是构造器的重载。来自菜鸟教程java。） 不支持 默认参数 (default parameter)。 没有函数体的函数声明，表示该函数不是以Go实现的。这样的声明定义了函数标识符。 所有参数都是值传递：slice，map，channel 会有传引⽤的错觉 string、切片、map 这些类型它们的内存表示对应的是它们数据内容的“描述符”。当这些类型作为实参类型时，值传递拷贝的也是它们数据内容的“描述符”，不包括数据内容本身，所以这些类型传递的开销是固定的，与数据内容大小无关。这种只拷贝“描述符”，不拷贝实际数据内容的拷贝过程，也被称为“浅拷贝”。 当函数的形参为接口类型，或者形参是变长参数时，简单的值传递就不能满足要求了，这时 Go 编译器会介入：对于类型为接口类型的形参，Go 编译器会把传递的实参赋值给对应的接口类型形参；对于为变长参数的形参，Go 编译器会将零个或多个实参按一定形式转换为对应的变长形参。 在 Go 中，变长参数实际上是通过切片来实现的。所以，我们在函数体中，就可以使用切片支持的所有操作来操作变长参数 关于函数的返回值： Go 标准库以及大多数项目代码中的函数，都选择了使用普通的非具名返回值形式。但在一些特定场景下，具名返回值也会得到应用。比如，当函数使用 defer，而且还在 defer 函数中修改外部函数返回值时，具名返回值可以让代码显得更优雅清晰。当函数的返回值个数较多时，每次显式使用 return 语句时都会接一长串返回值，这时，我们用具名返回值可以让函数实现的可读性更好一些 // $GOROOT/src/time/format.go func parseNanoseconds(value string, nbytes int) (ns int, rangeErrString string, err error) { if !commaOrPeriod(value[0]) { err = errBad return } if ns, err = atoi(value[1:nbytes]); err != nil { return } if ns \u003c 0 || 1e9 \u003c= ns { rangeErrString = \"fractional second\" return } scaleDigits := 10 - nbytes for i := 0; i \u003c scaleDigits; i++ { ns *= 10 } return } 函数是第一类对象，可作为参数传递。建议将复杂签名定义为函数类型，以便于阅读。 import \"fmt\" func test(fn func() int) int { return fn() } // 定义函数类型。 type FormatFunc func(s string, x, y int) string func format(fn FormatFunc, s string, x, y int) string { return fn(s, x, y) } func main() { s1 := test(func() int { return 100 }) // 直接将匿名函数当参数。 s2 := format(func(s string, x, y int) string { return fmt.Sprintf(s, x, y) }, \"%d, %d\", 10, 20) println(s1, s2) } output: 100 10,20 fmt里的一些格式化输入输出函数： func Printf(format string, a ...interface{}) (n int, err error) func Fprintf(w io.Writer, format string, a ...interface{}) (n int, err error) func Sprintf(format string, a ...interface{}) string func Print(a ...interface{}) (n int, err error) func Fprint(w io.Writer, a ...interface{}) (n int, err error) func Sprint(a ...interface{}) string func Println(a ...interface{}) (n int, err error) func Fprintln(w io.Writer, a ...interface{}) (n int, err error) func Sprintln(a ...interface{}) string func Errorf(format string, a ...interface{}) error func Scanf(format string, a ...interface{}) (n int, err error) func Fscanf(r io.Reader, format string, a ...interface{}) (n int, err error) func Sscanf(str string, format string, a ...interface{}) (n int, err error) func Scan(a ...interface{}) (n int, err error) func Fscan(r io.Reader, a ...interface{}) (n int, err error) func Sscan(str string, a ...interface{}) (n int, err error) func Scanln(a ...interface{}) (n int, err error) func Fscanln(r io.Reader, a ...interface{}) (n int, err error) func Sscanln(str string, a ...interface{}) (n int, err error) ","date":"2022-01-06 09:16:34","objectID":"/go_base_03/:1:0","tags":["go grammar"],"title":"Go_base_03","uri":"/go_base_03/"},{"categories":["Go"],"content":"参数 map、slice、chan、指针、interface默认以引用的方式传递，其他的在默认情况下，使用的是值传递. 无论是值传递，还是引用传递，传递给函数的都是变量的副本，不过，值传递是值的拷贝。引用传递是地址的拷贝，一般来说，地址拷贝更为高效。而值拷贝取决于拷贝的对象大小，对象越大，则性能越低。 ","date":"2022-01-06 09:16:34","objectID":"/go_base_03/:2:0","tags":["go grammar"],"title":"Go_base_03","uri":"/go_base_03/"},{"categories":["Go"],"content":"不定参 就是函数的参数不是固定的，后面的类型是固定的。（可变参数） Golang 可变参数本质上就是 slice。只能有一个，且必须是最后一个。 在参数赋值时可以不用用一个一个的赋值，可以直接传递一个数组或者切片，特别注意的是在参数后加上“…”即可。 func myfunc(args ...int) { //0个或多个参数 } func add(a int, args…int) int { //1个或多个参数 } func add(a int, b int, args…int) int { //2个或多个参数 } 注意：其中args是一个slice，我们可以通过arg[index]依次访问所有参数,通过len(arg)来判断传递参数的个数. 任意类型的不定参数：就是函数的参数和每个参数的类型都不是固定的。 用interface{}传递任意类型数据是Go语言的惯例用法，而且interface{}是类型安全的。 func myfunc(args ...interface{}) { } func test(s string, n ...int) string { var x int for _, i := range n { x += i } return fmt.Sprintf(s, x) } func main() { s := []int{1, 2, 3} res := test(\"sum: %d\", s...) // slice... 展开slice,而不是只写变量名 println(res) } ","date":"2022-01-06 09:16:34","objectID":"/go_base_03/:2:1","tags":["go grammar"],"title":"Go_base_03","uri":"/go_base_03/"},{"categories":["Go"],"content":"返回值 Go 的返回值可以被命名，并且就像在函数体开头声明的变量那样使用。 返回值的名称应当具有一定的意义，可以作为文档使用。 没有参数的 return 语句返回各个返回变量的当前值。这种用法被称作 “裸”返回。 package main import ( \"fmt\" ) func add(a, b int) (c int) { c = a + b return } func calc(a, b int) (sum int, avg int) { sum = a + b avg = (a + b) / 2 return } func main() { var a, b int = 1, 2 c := add(a, b) sum, avg := calc(a, b) fmt.Println(a, b, c, sum, avg) } 命名返回参数可被同名局部变量遮蔽，此时需要显式返回。 Golang返回值不能用容器对象接收多返回值。只能用多个变量，或 “_” 忽略。或者多返回值可直接作为其他函数调用实参。 func test() (int, int) { return 1, 2 } func add(x, y int) int { return x + y } func sum(n ...int) int { var x int for _, i := range n { x += i } return x } func main() { println(add(test())) println(sum(test())) } 命名返回参数允许 defer 延迟调用通过闭包读取和修改。 package main func add(x, y int) (z int) { defer func() { z += 100 }() z = x + y return } func main() { println(add(1, 2)) } output:103 ","date":"2022-01-06 09:16:34","objectID":"/go_base_03/:3:0","tags":["go grammar"],"title":"Go_base_03","uri":"/go_base_03/"},{"categories":["Go"],"content":"利用多返回值进行错误处理： ","date":"2022-01-06 09:16:34","objectID":"/go_base_03/:4:0","tags":["go grammar"],"title":"Go_base_03","uri":"/go_base_03/"},{"categories":["Go"],"content":"匿名函数 匿名函数的优越性在于可以直接使用函数内的变量，不必申明。Golang匿名函数可赋值给变量，做为结构字段，或者在 channel 里传送。 package main func main() { // --- function variable --- fn := func() { println(\"Hello, World!\") } fn() // --- function collection --- fns := [](func(x int) int){ func(x int) int { return x + 1 }, func(x int) int { return x + 2 }, } println(fns[0](100)) // --- function as field --- d := struct { fn func() string }{ fn: func() string { return \"Hello, World!\" }, } println(d.fn()) // --- channel of function --- fc := make(chan func() string, 2) fc \u003c- func() string { return \"Hello, World!\" } println((\u003c-fc)()) output: Hello, World! 101 Hello, World! Hello, World! } ","date":"2022-01-06 09:16:34","objectID":"/go_base_03/:5:0","tags":["go grammar"],"title":"Go_base_03","uri":"/go_base_03/"},{"categories":["Go"],"content":"闭包、递归 ","date":"2022-01-06 09:16:34","objectID":"/go_base_03/:6:0","tags":["go grammar"],"title":"Go_base_03","uri":"/go_base_03/"},{"categories":["Go"],"content":"闭包 闭包是由函数及其相关引用环境组合而成的实体。 “官方”的解释是：所谓“闭包”，指的是一个拥有许多变量和绑定了这些变量的环境的表达式（通常是一个函数），因而这些变量也是该表达式的一部分。 维基百科讲，闭包（Closure），是引用了自由变量的函数。这个被引用的自由变量将和这个函数一同存在，即使已经离开了创造它的环境也不例外。所以，有另一种说法认为闭包是由函数和与其相关的引用环境组合而成的实体。闭包在运行时可以有多个实例，不同的引用环境和相同的函数组合可以产生不同的实例。 目前在JavaScript、Go、PHP、Scala、Scheme、Common Lisp、Smalltalk、Groovy、Ruby、 Python、Lua、objective c、Swift 以及Java8以上等语言中都能找到对闭包不同程度的支持。 通过支持闭包的语法可以发现一个特点，他们都有垃圾回收(GC)机制。 go的闭包： package main import ( \"fmt\" ) func a() func() int { i := 0 b := func() int { i++ fmt.Println(i) return i } return b } func main() { c := a() c() c() c() a() //不会输出i } output: 1 2 3 当函数a()的内部函数b()被函数a()外的一个变量引用的时候，就创建了一个闭包。 闭包复制的是原对象指针，这就很容易解释延迟引用现象。（延迟引用，引用的只是某个变量的“最终值”，延迟闭包里引用的变量是原变量指针，这解释了后面为什么derfer碰上闭包的输出都是同一值） package main import \"fmt\" func test() func() { x := 100 fmt.Printf(\"x (%p) = %d\\n\", \u0026x, x) return func() { fmt.Printf(\"x (%p) = %d\\n\", \u0026x, x) } } func main() { f := test() f() } output: x (0xc42007c008) = 100 x (0xc42007c008) = 100 在汇编层 ，test 实际返回的是 FuncVal 对象，其中包含了匿名函数地址、闭包对象指针。当调用匿名函数时，只需以某个寄存器传递该对象即可。 Funcval对象： FuncVal { func_address, closure_var_pointer ... } 外部引用函数参数局部变量: package main import \"fmt\" // 外部引用函数参数局部变量 func add(base int) func(int) int { return func(i int) int { base += i return base } } func main() { tmp1 := add(10) fmt.Println(tmp1(1), tmp1(2)) // 此时tmp1和tmp2不是一个实体了 tmp2 := add(100) fmt.Println(tmp2(1), tmp2(2)) } 返回两个闭包： package main import \"fmt\" // 返回2个函数类型的返回值 func test01(base int) (func(int) int, func(int) int) { // 定义2个函数，并返回 // 相加 add := func(i int) int { base += i return base } // 相减 sub := func(i int) int { base -= i return base } // 返回 return add, sub } func main() { f1, f2 := test01(10) // base一直是没有消 fmt.Println(f1(1), f2(2)) // 此时base是9 fmt.Println(f1(3), f2(4)) } ","date":"2022-01-06 09:16:34","objectID":"/go_base_03/:6:1","tags":["go grammar"],"title":"Go_base_03","uri":"/go_base_03/"},{"categories":["Go"],"content":"go递归函数 构成递归的两个条件： 子问题须与原始问题为同样的事，且更为简单。 不能无限制地调用本身，须有个出口，化简为非递归状况处理。 go的递归和其他语言基本无差别。 ","date":"2022-01-06 09:16:34","objectID":"/go_base_03/:6:2","tags":["go grammar"],"title":"Go_base_03","uri":"/go_base_03/"},{"categories":["Go"],"content":"延迟调用（defer） 特性： 关键字 defer 用于注册延迟调用。 这些调用直到 return 前才被执行。因此，可以用来做资源清理。 多个defer语句，按先进后出的方式执行。（因为后面的defer可能会用到前面的资源） defer语句中的变量，在defer声明时就决定了。 发生panic依然会执行defer，但不是任何情况都会执行，比如：os.Exit()不会调用defer。os.Exit()退出时不输出当前调用栈信息 Go1.13前的版本defer的开销还是非常大的，在后续团队优化后现在的开销比较小可以放心使用 用途： 关闭文件句柄、锁资源释放、数据库连接释放 使用 defer 可以跟踪函数的执行过程 // trace.go package main func Trace(name string) func() { println(\"enter:\", name) return func() { println(\"exit:\", name) } } func foo() { defer Trace(\"foo\")() bar() } func bar() { defer Trace(\"bar\")() } func main() { defer Trace(\"main\")() foo() } 不足：调用 Trace 时需手动显式传入要跟踪的函数名；如果是并发应用，不同 Goroutine 中函数链跟踪混在一起无法分辨；输出的跟踪结果缺少层次感，调用关系不易识别；对要跟踪的函数，需手动调用 Trace 函数。 实现一个自动注入跟踪代码，并输出有层次感的函数调用链跟踪命令行工具： 自动获取所跟踪函数的函数名 充当“断言”，提示潜在bug defer功能强大，对于资源管理非常方便，但是如果没用好，也会有陷阱。 defer碰上闭包： package main import \"fmt\" func main() { var whatever [5]struct{} for i := range whatever { defer func() { fmt.Println(i) }() } } output: 4 4 4 4 4 延迟引用，闭包里的i是原变量指针。 defer.f.Close: package main import \"fmt\" type Test struct { name string } func (t *Test) Close() { fmt.Println(t.name, \" closed\") } func main() { ts := []Test{\"a\", \"b\", \"c\"} for _, t := range ts { defer t.Close() } } output: c closed c closed c closed package main import \"fmt\" type Test struct { name string } func (t *Test) Close() { fmt.Println(t.name, \" closed\") } func Close(t Test) { t.Close() } func main() { ts := []Test\"a\", \"b\", \"c\"} for _, t := range ts { defer Close(t) } //或者for _, t := range ts { // t2 := t // defer t2.Close() // } } output: c closed b closed a closed 结论： defer后面的语句在执行的时候，函数调用的参数会被保存起来，但是不执行。也就是复制了一份。但是并没有说struct这里的this指针如何处理，通过这个例子可以看出go语言并没有把这个明确写出来的this指针当作参数来看待。 多个 defer 注册，按 FILO 次序执行 ( 先进后出 )。哪怕函数或某个延迟调用发生错误，比如发生panic，这些defer调用依旧会被执行。 package main func test(x int) { defer println(\"a\") defer println(\"b\") defer func() { println(100 / x) // div0 异常未被捕获，逐步往外传递，最终终止进程。 }() defer println(\"c\") } func main() { test(0) } output: c b a panic: runtime error: integer divide by zero 延迟调用参数在注册时求值或复制，可用指针或闭包 “延迟” 读取。 package main func test() { x, y := 10, 20 defer func(i int) { println(\"defer:\", i, y) // y 闭包引用 }(x) // x 被复制 x += 10 y += 100 println(\"x =\", x, \"y =\", y) } func main() { test() } output: x = 20 y = 120 defer: 10 120 滥用 defer 可能会导致性能问题，尤其是在一个 “大循环” 里。 package main import ( \"fmt\" \"sync\" \"time\" ) var lock sync.Mutex func test() { lock.Lock() lock.Unlock() } func testdefer() { lock.Lock() defer lock.Unlock() } func main() { func() { t1 := time.Now() for i := 0; i \u003c 10000; i++ { test() } elapsed := time.Since(t1) fmt.Println(\"test elapsed: \", elapsed) }() func() { t1 := time.Now() for i := 0; i \u003c 10000; i++ { testdefer() } elapsed := time.Since(t1) fmt.Println(\"testdefer elapsed: \", elapsed) }() } output: test elapsed: 223.162µs testdefer elapsed: 781.304µs ","date":"2022-01-06 09:16:34","objectID":"/go_base_03/:7:0","tags":["go grammar"],"title":"Go_base_03","uri":"/go_base_03/"},{"categories":["Go"],"content":"defer陷阱 defer 与 closure： package main import ( \"errors\" \"fmt\" ) func foo(a, b int) (i int, err error) { defer fmt.Printf(\"first defer err %v\\n\", err) defer func(err error) { fmt.Printf(\"second defer err %v\\n\", err) }(err) defer func() { fmt.Printf(\"third defer err %v\\n\", err) }() if b == 0 { err = errors.New(\"divided by zero!\") return } i = a / b return } func main() { foo(2, 0) } output： third defer err divided by zero! second defer err \u003cnil\u003e first defer err \u003cnil\u003e 解释：如果 defer 后面跟的不是一个 closure 最后执行的时候我们得到的并不是最新的值。 defer 与 return: package main import \"fmt\" func foo() (i int) { i = 0 defer func() { fmt.Println(i) }() return 2 } func main() { foo() } output： 2 解释：在有具名返回值的函数中（这里具名返回值为 i），执行 return 2 的时候实际上已经将 i 的值重新赋值为 2。所以defer closure 输出结果为 2 而不是 1。 defer nil 函数: package main import ( \"fmt\" ) func test() { var run func() = nil defer run() fmt.Println(\"runs\") } func main() { defer func() { if err := recover(); err != nil { fmt.Println(err) } }() test() } output： runs runtime error: invalid memory address or nil pointer dereference 解释：名为 test 的函数一直运行至结束，然后 defer 函数会被执行且会因为值为 nil 而产生 panic 异常。然而值得注意的是，run() 的声明是没有问题，因为在test函数运行完成后它才会被调用。 在错误的位置使用 defer: 当 http.Get 失败时会抛出异常。 package main import \"net/http\" func do() error { res, err := http.Get(\"http://www.google.com\") defer res.Body.Close() if err != nil { return err } // ..code... return nil } func main() { do() } output： panic: runtime error: invalid memory address or nil pointer dereference 因为在这里我们并没有检查我们的请求是否成功执行，当它失败的时候，我们访问了 Body 中的空变量 res ，因此会抛出异常 解决方案： 总是在一次成功的资源分配下面使用 defer ，对于这种情况来说意味着：当且仅当 http.Get 成功执行时才使用 defer package main import \"net/http\" func do() error { res, err := http.Get(\"http://xxxxxxxxxx\") if res != nil { defer res.Body.Close() } if err != nil { return err } // ..code... return nil } func main() { do() } 在上述的代码中，当有错误的时候，err 会被返回，否则当整个函数返回的时候，会关闭 res.Body 。 解释：在这里，你同样需要检查 res 的值是否为 nil ，这是 http.Get 中的一个警告。通常情况下，出错的时候，返回的内容应为空并且错误会被返回，可当你获得的是一个重定向 error 时， res 的值并不会为 nil ，但其又会将错误返回。上面的代码保证了无论如何 Body 都会被关闭，如果你没有打算使用其中的数据，那么你还需要丢弃已经接收的数据。 不检查错误: 在这里，f.Close() 可能会返回一个错误，可这个错误会被我们忽略掉。 package main import \"os\" func do() error { f, err := os.Open(\"book.txt\") if err != nil { return err } if f != nil { defer f.Close() } // ..code... return nil } func main() { do() } 改进一下： package main import \"os\" func do() error { f, err := os.Open(\"book.txt\") if err != nil { return err } if f != nil { defer func() { if err := f.Close(); err != nil { // log etc } }() } // ..code... return nil } func main() { do() } 再改进一下：通过命名的返回变量来返回defer内的错误。 package main import \"os\" func do() (err error) { f, err := os.Open(\"book.txt\") if err != nil { return err } if f != nil { defer func() { if ferr := f.Close(); ferr != nil { err = ferr } }() } // ..code... return nil } func main() { do() } 释放相同的资源 如果你尝试使用相同的变量释放不同的资源，那么这个操作可能无法正常执行。 package main import ( \"fmt\" \"os\" ) func do() error { f, err := os.Open(\"book.txt\") if err != nil { return err } if f != nil { defer func() { if err := f.Close(); err != nil { fmt.Printf(\"defer close book.txt err %v\\n\", err) } }() } // ..code... f, err = os.Open(\"another-book.txt\") if err != nil { return err } if f != nil { defer func() { if err := f.Close(); err != nil { fmt.Printf(\"defer close another-book.txt err %v\\n\", err) } }() } return nil } func main() { do() } 输出结果： defer close book.txt err close ./another-book.txt: file already closed 当延迟函数执行时，只有最后一个变量会被用到，因此，f 变量 会成为最后那个资源 (another-book.txt)。而且两个 defer 都会将这个资源作为最后的资源来关闭 解决方案： package main import ( \"fmt\" \"io\" \"os\" ) func do() error { f, err := os.Open(\"book.txt\") if err != nil { return err } if f != nil { defer func(f io.Closer) { if err := f.Close(); err != nil { fmt.Printf(\"defer close book.txt err %v\\n\", err) } }(f) } // ..code... f, err = os.Open(\"another-book.txt\") if err != nil { return err } if f != nil { defer func(f io.Closer) { if err := f.Close(); err != nil { fmt.Printf(\"defer close another-book.txt err %v\\n\", err) } }(f) } return nil } func main() { do() } ","date":"2022-01-06 09:16:34","objectID":"/go_base_03/:7:1","tags":["go grammar"],"title":"Go_base_03","uri":"/go_base_03/"},{"categories":["Go"],"content":"异常处理，错误处理 提倡及早失败，避免嵌套 Golang 没有结构化异常，使用 panic 抛出错误，recover 捕获错误。 异常的使用场景简单描述：Go中可以抛出一个panic的异常，然后在defer中通过recover捕获这个异常，然后正常处理。 panic: 内置函数 假如函数F中书写了panic语句，会终止其后要执行的代码，在panic所在函数F内如果存在要执行的defer函数列表，按照defer的逆序执行 返回函数F的调用者G，在G中，调用函数F语句之后的代码不会执行，假如函数G中存在要执行的defer函数列表，按照defer的逆序执行 直到goroutine整个退出，并报告错误 recover: 内置函数 用来控制一个goroutine的panicking行为，捕获panic，从而影响应用的行为 一般的调用建议 只能用在defer函数中，通过recever来终止一个goroutine的panicking过程，从而恢复正常代码的执行 可以获取通过panic传递的error 注意： 利用recover处理panic指令，defer 必须放在 panic 之前定义，另外 recover 只有在 defer 调用的函数中才有效。否则当panic时，recover无法捕获到panic，无法防止panic扩散。 recover 处理异常后，逻辑并不会恢复到 panic 那个点去，函数跑到 defer 之后的那个点。 多个 defer 会形成 defer 栈，后定义的 defer 语句会被最先调用。 当心recoer成为恶魔，因为recover并不会检测发生了什么错误。可能是系统的某些核心资源消耗完了，强制恢复之后系统依然无法正常工作的。还会导致一些健康检查程序无法检测出错误，health check无法检测出错误（很多health check程序只是检查这个进程在还是不在），形成僵尸服务进程（存在着但不能提供服务）。不如采用一种可恢复的设计模式，“Let it Crash”，干脆让进程crash掉，然后就会帮我们重新把服务进程提起来，如同重启。（重启是恢复不确定性最好的方法） package main func main() { test() } func test() { defer func() { if err := recover(); err != nil { println(err.(string)) // 将 interface{} 转型为具体类型。 } }() panic(\"panic error!\") } output: panic error! 由于 panic、recover 参数类型为 interface{}，因此可抛出任何类型对象。 func panic(v interface{}) func recover() interface{} 向已关闭的通道发送数据会引发panic package main import ( \"fmt\" ) func main() { defer func() { if err := recover(); err != nil { fmt.Println(err) } }() var ch chan int = make(chan int, 10) close(ch) ch \u003c- 1 } output: send on closed channel 延迟调用中引发的错误，可被后续延迟调用捕获，但仅最后一个错误可被捕获。 package main import \"fmt\" func test() { defer func() { fmt.Println(recover()) }() defer func() { panic(\"defer panic\") }() panic(\"test panic\") } func main() { test() } output: defer panic 捕获函数 recover 只有在延迟调用内直接调用才会终止错误，否则总是返回 nil。任何未捕获的错误都会沿调用堆栈向外传递。 package main import \"fmt\" func test() { defer func() { fmt.Println(recover()) //有效 }() defer recover() //无效！ defer fmt.Println(recover()) //无效！ defer func() { func() { println(\"defer inner\") recover() //无效！ }() }() panic(\"test panic\") } func main() { test() } output: defer inner \u003cnil\u003e test panic 使用延迟匿名函数或下面这样都是有效的。 package main import ( \"fmt\" ) func except() { fmt.Println(recover()) } func test() { defer except() panic(\"test panic\") } func main() { test() } output： test panic 如果需要保护代码段，可将代码块重构成匿名函数，如此可确保后续代码被执行。 package main import \"fmt\" func test(x, y int) { var z int func() { defer func() { if recover() != nil { z = 0 } }() panic(\"test panic\") z = x / y return }() fmt.Printf(\"x / y = %d\\n\", z) } func main() { test(2, 1) } output： x / y = 0 除用 panic 引发中断性错误外，还可返回 error 类型错误对象来表示函数调用状态。（error类型实现了error接口） type error interface { Error() string } 标准库 errors.New 和 fmt.Errorf 函数用于创建实现 error 接口的错误对象。通过判断错误对象实例来确定具体错误类型。 package main import ( \"errors\" \"fmt\" ) //定义预置错误 var ErrDivByZero = errors.New(\"division by zero\") func div(x, y int) (int, error) { if y == 0 { return 0, ErrDivByZero } return x / y, nil } func main() { defer func() { fmt.Println(recover()) }() switch z, err := div(10, 0); err { case nil: println(z) case ErrDivByZero: panic(err) } } output: division by zero Go实现类似 try catch 的异常处理。 package main import \"fmt\" func Try(fun func(), handler func(interface{})) { defer func() { if err := recover(); err != nil { handler(err) } }() fun() } func main() { Try(func() { panic(\"test panic\") }, func(err interface{}) { fmt.Println(err) }) } output： test panic 如何区别使用 panic 和 error 两种方式? 惯例是:导致关键流程出现不可修复性错误的使用 panic，其他使用 error。 几种错误处理策略： 透明错误处理策略 err := doSomething() if err != nil { // 不关心err变量底层错误值所携带的具体上下文信息 // 执行简单错误处理逻辑并返回 ... ... return err } “哨兵” 当错误处理方不能只根据“透明的错误值”就做出错误处理路径选取的情况下，错误处理方会尝试对返回的错误值进行检视，于是就有可能出现下面代码中的反模式： 反模式就是，错误处理方以透明错误值所能提供的唯一上下文信息（描述错误的字符串），作为错误处理路径选择的依据。但这种“反模式”会造成严重的隐式耦合。这也就意味着，错误值构造方不经意间的一次错误描述字符串的改动，都会造成错误处理方处理行为的变化，并且这种通过字符串比较的方式，对错误值进行检视的性能也很差。 data, err := b.Peek(1) if err != nil { switch err.Error() { case \"bufio: negative count\": // ... ... return case \"bufio: buffer full\": // ... ... return case \"bufio: invalid use of UnreadByte\": // ... ... return default: // ... ... return } } Go 标准库采用了定义导出的（Exported）“哨兵”错误值的方式，来辅助错误","date":"2022-01-06 09:16:34","objectID":"/go_base_03/:8:0","tags":["go grammar"],"title":"Go_base_03","uri":"/go_base_03/"},{"categories":["Go"],"content":"为啥说函数是Go语言的一等公民： 引用一下 wiki 发明人、C2 站点作者沃德·坎宁安 (Ward Cunningham)对“一等公民”的解释： 如果一门编程语言对某种语言元素的创建和使用没有限制，我们可以像对待值（value）一样对待这种语法元素，那么我们就称这种语法元素是这门编程语言的“一等公民”。拥有“一等公民”待遇的语法元素可以存储在变量中，可以作为参数传递给函数，可以在函数内部创建并可以作为返回值从函数返回 Go 函数可以存储在变量中。 支持在函数内创建并通过返回值返回。 作为参数传入函数。 拥有自己的类型。 应用go函数的这些灵活性： 函数类型的妙用 函数也可以被显式转型，见下面web server的例子。 func greeting(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \"Welcome, Gopher!\\n\") } func main() { //greeting这个函数被显示转化为HandleFunc类型，ListenAndServe的第二个参数是个需要实现ServeHTTP方法（即需要实现Handle接口）的类型 http.ListenAndServe(\":8080\", http.HandlerFunc(greeting)) } …… // $GOROOT/src/net/http/server.go type HandlerFunc func(ResponseWriter, *Request) // ServeHTTP calls f(w, r). func (f HandlerFunc) ServeHTTP(w ResponseWriter, r *Request) { f(w, r) } 利用闭包简化函数调用。 func partialTimes(x int) func(int) int { return func(y int) int { return times(x, y) } } func main() { timesTwo := partialTimes(2) // 以高频乘数2为固定乘数的乘法函数 timesThree := partialTimes(3) // 以高频乘数3为固定乘数的乘法函数 fmt.Println(timesTwo(5)) // 10，等价于times(2, 5) fmt.Println(timesTwo(6)) // 12，等价于times(2, 6) fmt.Println(timesThree(5)) // 15，等价于times(3, 5) fmt.Println(timesThree(6)) // 18，等价于times(3, 6) } ","date":"2022-01-06 09:16:34","objectID":"/go_base_03/:9:0","tags":["go grammar"],"title":"Go_base_03","uri":"/go_base_03/"},{"categories":["Go"],"content":"单元测试 单元测试还是挺重要的。 ","date":"2022-01-06 09:16:34","objectID":"/go_base_03/:10:0","tags":["go grammar"],"title":"Go_base_03","uri":"/go_base_03/"},{"categories":["Go"],"content":"go test工具 Go语言中的测试依赖go test命令。编写测试代码和编写普通的Go代码过程是类似的，并不需要学习新的语法、规则或工具。 go test命令是一个按照一定约定和组织的测试代码的驱动程序。在包目录内，所有以_test.go为后缀名的源代码文件都是go test测试的一部分，不会被go build编译到最终的可执行文件中。 在*_test.go文件中有三种类型的函数，单元测试函数、基准测试函数和示例函数。 类型 格式 作用 测试函数 函数名前缀为Test 测试程序的一些逻辑行为是否正确 基准函数 函数名前缀为Benchmark 测试函数的性能 示例函数 函数名前缀为Example 为文档提供示例文档 go test命令会遍历所有的*_test.go文件中符合上述命名规则的函数，然后生成一个临时的main包用于调用相应的测试函数，然后构建并运行、报告测试结果，最后清理测试中生成的临时文件。 Golang单元测试对文件名和方法名，参数都有很严格的要求。 文件名必须以xx_test.go命名 方法必须是Test[^a-z]开头 方法参数必须 t *testing.T 使用go test执行单元测试 go test的参数解读： go test是go语言自带的测试工具，其中包含的是两类，单元测试和性能测试 通过go help test可以看到go test的使用说明： 格式形如： go test [-c] [-i] [build flags] [packages] [flags for test binary] 参数解读： -c : 编译go test成为可执行的二进制文件，但是不运行测试。 -i : 安装测试包依赖的package，但是不运行测试。 关于build flags，调用go help build，这些是编译运行过程中需要使用到的参数，一般设置为空 关于packages，调用go help packages，这些是关于包的管理，一般设置为空 关于flags for test binary，调用go help testflag，这些是go test过程中经常使用到的参数 -test.v : 是否输出全部的单元测试用例（不管成功或者失败），默认没有加上，所以只输出失败的单元测试用例。 -test.run pattern: 只跑哪些单元测试用例 -test.bench patten: 只跑那些性能测试用例 -test.benchmem : 是否在性能测试的时候输出内存情况 -test.benchtime t : 性能测试运行的时间，默认是1s -test.cpuprofile cpu.out : 是否输出cpu性能分析文件 -test.memprofile mem.out : 是否输出内存性能分析文件 -test.blockprofile block.out : 是否输出内部goroutine阻塞的性能分析文件 -test.memprofilerate n : 内存性能分析的时候有一个分配了多少的时候才打点记录的问题。这个参数就是设置打点的内存分配间隔，也就是profile中一个sample代表的内存大小。默认是设置为512 * 1024的。如果你将它设置为1，则每分配一个内存块就会在profile中有个打点，那么生成的profile的sample就会非常多。如果你设置为0，那就是不做打点了。 你可以通过设置memprofilerate=1和GOGC=off来关闭内存回收，并且对每个内存块的分配进行观察。 -test.blockprofilerate n: 基本同上，控制的是goroutine阻塞时候打点的纳秒数。默认不设置就相当于-test.blockprofilerate=1，每一纳秒都打点记录一下 -test.parallel n : 性能测试的程序并行cpu数，默认等于GOMAXPROCS。 -test.timeout t : 如果测试用例运行时间超过t，则抛出panic -test.cpu 1,2,4 : 程序运行在哪些CPU上面，使用二进制的1所在位代表，和nginx的nginx_worker_cpu_affinity是一个道理 -test.short : 将那些运行时间较长的测试用例运行时间缩短 目录结构： test | —— calc.go | —— calc_test.go ","date":"2022-01-06 09:16:34","objectID":"/go_base_03/:10:1","tags":["go grammar"],"title":"Go_base_03","uri":"/go_base_03/"},{"categories":["Go"],"content":"性能分析工具 可以安装go-torch 通过⽂件⽅式输出 Profile - 灵活性⾼，适⽤于特定代码段的分析 - 通过⼿动调⽤ runtime/pprof 的 API - API 相关⽂档 https://studygolang.com/static/pkgdoc/pkg/runtime_pprof.htm - go tool pprof [binary] [binary.prof] 通过 HTTP ⽅式输出 Profile - 简单，适合于持续性运⾏的应⽤ - 在应⽤程序中导⼊ import _ \"net/http/pprof\"，并启动 http server 即可 - http://\u003chost\u003e:\u003cport\u003e/debug/pprof/ - go tool pprof http://\u003chost\u003e:\u003cport\u003e/debug/pprof/profile?seconds=10 （默认值为30秒） - go-torch -seconds 10 http://\u003chost\u003e:\u003cport\u003e/debug/pprof/profile Go ⽀持的多种 Profile go help testflag https://golang.org/src/runtime/pprof/pprof.go 性能调优 性能调优过程： 常⻅分析指标 Wall Time CPU Time Block Time Memory allocation GC times/time spent ch47 ","date":"2022-01-06 09:16:34","objectID":"/go_base_03/:10:2","tags":["go grammar"],"title":"Go_base_03","uri":"/go_base_03/"},{"categories":["Go"],"content":"测试函数 测试函数的格式 每个测试函数必须导入testing包，测试函数的基本格式（签名）如下： func TestName(t *testing.T){ // ... } 测试函数的名字必须以Test开头，可选的后缀名必须以大写字母开头，举几个例子：\\ func TestAdd(t *testing.T){ ... } func TestSum(t *testing.T){ ... } func TestLog(t *testing.T){ ... } 其中参数t用于报告测试失败和附加的日志信息。 testing.T的拥有的方法如下： func (c *T) Error(args ...interface{}) func (c *T) Errorf(format string, args ...interface{}) func (c *T) Fail() func (c *T) FailNow() func (c *T) Failed() bool func (c *T) Fatal(args ...interface{}) func (c *T) Fatalf(format string, args ...interface{}) func (c *T) Log(args ...interface{}) func (c *T) Logf(format string, args ...interface{}) func (c *T) Name() string func (t *T) Parallel() func (t *T) Run(name string, f func(t *T)) bool func (c *T) Skip(args ...interface{}) func (c *T) SkipNow() func (c *T) Skipf(format string, args ...interface{}) func (c *T) Skipped() bool 测试函数示例 就像细胞是构成我们身体的基本单位，一个软件程序也是由很多单元组件构成的。单元组件可以是函数、结构体、方法和最终用户可能依赖的任意东西。总之我们需要确保这些组件是能够正常运行的。单元测试是一些利用各种方法测试单元组件的程序，它会将结果与预期输出进行比较。 接下来，我们定义一个split的包，包中定义了一个Split函数，具体实现如下： // split/split.go package split import \"strings\" // split package with a single split function. // Split slices s into all substrings separated by sep and // returns a slice of the substrings between those separators. func Split(s, sep string) (result []string) { i := strings.Index(s, sep) for i \u003e -1 { result = append(result, s[:i]) s = s[i+1:] i = strings.Index(s, sep) } result = append(result, s) return } 在当前目录下，我们创建一个split_test.go的测试文件，并定义一个测试函数如下：（表格测试法） // split/split_test.go package split import ( \"reflect\" \"testing\" ) func TestSplit(t *testing.T) { // 测试函数名必须以Test开头，必须接收一个*testing.T类型参数 got := Split(\"a🅱c\", \":\") // 程序输出的结果 want := []string{\"a\", \"b\", \"c\"} // 期望的结果 if !reflect.DeepEqual(want, got) { // 因为slice不能比较直接，借助反射包中的方法比较 t.Errorf(\"excepted:%v, got:%v\", want, got) // 测试失败输出错误提示 } } 此时split这个包中的文件如下： split $ ls -l total 16 -rw-r--r-- 1 pprof staff 408 4 29 15:50 split.go -rw-r--r-- 1 pprof staff 466 4 29 16:04 split_test.go 在split包路径下，执行go test命令，可以看到输出结果如下： split $ go test PASS ok github.com/pprof/studygo/code_demo/test_demo/split 0.005s 一个测试用例有点单薄，我们再编写一个测试使用多个字符切割字符串的例子，在split_test.go中添加如下测试函数： func TestMoreSplit(t *testing.T) { got := Split(\"abcd\", \"bc\") want := []string{\"a\", \"d\"} if !reflect.DeepEqual(want, got) { t.Errorf(\"excepted:%v, got:%v\", want, got) } } 再次运行go test命令，输出结果如下： split $ go test --- FAIL: TestMultiSplit (0.00s) split_test.go:20: excepted:[a d], got:[a cd] FAIL exit status 1 FAIL github.com/pprof/studygo/code_demo/test_demo/split 0.006s 这一次，我们的测试失败了。我们可以为go test命令添加-v参数，查看测试函数名称和运行时间： split $ go test -v === RUN TestSplit --- PASS: TestSplit (0.00s) === RUN TestMoreSplit --- FAIL: TestMoreSplit (0.00s) split_test.go:21: excepted:[a d], got:[a cd] FAIL exit status 1 FAIL github.com/pprof/studygo/code_demo/test_demo/split 0.005s 这一次我们能清楚的看到是TestMoreSplit这个测试没有成功。 还可以在go test命令后添加-run参数，它对应一个正则表达式，只有函数名匹配上的测试函数才会被go test命令执行。 split $ go test -v -run=\"More\" === RUN TestMoreSplit --- FAIL: TestMoreSplit (0.00s) split_test.go:21: excepted:[a d], got:[a cd] FAIL exit status 1 FAIL github.com/pprof/studygo/code_demo/test_demo/split 0.006s 现在我们回过头来解决我们程序中的问题。很显然我们最初的split函数并没有考虑到sep为多个字符的情况，我们来修复下这个Bug： package split import \"strings\" // split package with a single split function. // Split slices s into all substrings separated by sep and // returns a slice of the substrings between those separators. func Split(s, sep string) (result []string) { i := strings.Index(s, sep) for i \u003e -1 { result = append(result, s[:i]) s = s[i+len(sep):] // 这里使用len(sep)获取sep的长度 i = strings.Index(s, sep) } result = append(result, s) return } 这一次我们再来测试一下，我们的程序。注意，当我们修改了我们的代码之后不要仅仅执行那些失败的测试函数，我们应该完整的运行所有的测试，保证不会因为修改代码而引入了新的问题。 split $ go test -v === RUN TestSplit --- PASS: TestSplit (0.00s) === RUN TestMoreSplit --- PASS: TestMoreSplit (0.00s) PASS ok github.com/pprof/studygo/code_demo/test_demo/split 0.006s 这一次我们的测试都通过了 ","date":"2022-01-06 09:16:34","objectID":"/go_base_03/:10:3","tags":["go grammar"],"title":"Go_base_03","uri":"/go_base_03/"},{"categories":["Go"],"content":"测试组 我们现在还想要测试一下split函数对中文字符串的支持，这个时候我们可以再编写一个TestChineseSplit测试函数，但是我们也可以使用如下更友好的一种方式来添加更多的测试用例。 func TestSplit(t *testing.T) { // 定义一个测试用例类型 type test struct { input string sep string want []string } // 定义一个存储测试用例的切片 tests := []test{ {input: \"a🅱c\", sep: \":\", want: []string{\"a\", \"b\", \"c\"} }, {input: \"a🅱c\", sep: \",\", want: []string{\"a🅱c\"} }, {input: \"abcd\", sep: \"bc\", want: []string{\"a\", \"d\"} }, {input: \"枯藤老树昏鸦\", sep: \"老\", want: []string{\"枯藤\", \"树昏鸦\"} }, } // 遍历切片，逐一执行测试用例 for _, tc := range tests { got := Split(tc.input, tc.sep) if !reflect.DeepEqual(got, tc.want) { t.Errorf(\"excepted:%v, got:%v\", tc.want, got) } } } 我们通过上面的代码把多个测试用例合到一起，再次执行go test命令。 split $ go test -v === RUN TestSplit --- FAIL: TestSplit (0.00s) split_test.go:42: excepted:[枯藤 树昏鸦], got:[ 枯藤 树昏鸦] FAIL exit status 1 FAIL github.com/pprof/studygo/code_demo/test_demo/split 0.006s 我们的测试出现了问题，仔细看打印的测试失败提示信息：excepted:[枯藤 树昏鸦], got:[ 枯藤 树昏鸦]，你会发现[ 枯藤 树昏鸦]中有个不明显的空串，这种情况下十分推荐使用%#v的格式化方式。 我们修改下测试用例的格式化输出错误提示部分： func TestSplit(t *testing.T) { ... for _, tc := range tests { got := Split(tc.input, tc.sep) if !reflect.DeepEqual(got, tc.want) { t.Errorf(\"excepted:%#v, got:%#v\", tc.want, got) } } } 此时运行go test命令后就能看到比较明显的提示信息了： split $ go test -v === RUN TestSplit --- FAIL: TestSplit (0.00s) split_test.go:42: excepted:[]string{\"枯藤\", \"树昏鸦\"}, got:[]string{\"\", \"枯藤\", \"树昏鸦\"} FAIL exit status 1 FAIL github.com/Q1mi/studygo/code_demo/test_demo/split 0.006s ","date":"2022-01-06 09:16:34","objectID":"/go_base_03/:10:4","tags":["go grammar"],"title":"Go_base_03","uri":"/go_base_03/"},{"categories":["Go"],"content":"子测试 看起来都挺不错的，但是如果测试用例比较多的时候，我们是没办法一眼看出来具体是哪个测试用例失败了。我们可能会想到下面的解决办法 func TestSplit(t *testing.T) { type test struct { // 定义test结构体 input string sep string want []string } tests := map[string]test{ // 测试用例使用map存储 \"simple\": {input: \"a🅱c\", sep: \":\", want: []string{\"a\", \"b\", \"c\"} }, \"wrong sep\": {input: \"a🅱c\", sep: \",\", want: []string{\"a🅱c\"} }, \"more sep\": {input: \"abcd\", sep: \"bc\", want: []string{\"a\", \"d\"} }, \"leading sep\": {input: \"枯藤老树昏鸦\", sep: \"老\", want: []string{\"枯藤\", \"树昏鸦\"} }, } for name, tc := range tests { got := Split(tc.input, tc.sep) if !reflect.DeepEqual(got, tc.want) { t.Errorf(\"name:%s excepted:%#v, got:%#v\", name, tc.want, got) // 将测试用例的name格式化输出 } } } 上面的做法是能够解决问题的。同时Go1.7+中新增了子测试，我们可以按照如下方式使用t.Run执行子测试： func TestSplit(t *testing.T) { type test struct { // 定义test结构体 input string sep string want []string } tests := map[string]test{ // 测试用例使用map存储 \"simple\": {input: \"a🅱c\", sep: \":\", want: []string{\"a\", \"b\", \"c\"} }, \"wrong sep\": {input: \"a🅱c\", sep: \",\", want: []string{\"a🅱c\"} }, \"more sep\": {input: \"abcd\", sep: \"bc\", want: []string{\"a\", \"d\"} }, \"leading sep\": {input: \"枯藤老树昏鸦\", sep: \"老\", want: []string{\"枯藤\", \"树昏鸦\"} }, } for name, tc := range tests { t.Run(name, func(t *testing.T) { // 使用t.Run()执行子测试 got := Split(tc.input, tc.sep) if !reflect.DeepEqual(got, tc.want) { t.Errorf(\"excepted:%#v, got:%#v\", tc.want, got) } }) } } 此时我们再执行go test命令就能够看到更清晰的输出内容了： split $ go test -v === RUN TestSplit === RUN TestSplit/leading_sep === RUN TestSplit/simple === RUN TestSplit/wrong_sep === RUN TestSplit/more_sep --- FAIL: TestSplit (0.00s) --- FAIL: TestSplit/leading_sep (0.00s) split_test.go:83: excepted:[]string{\"枯藤\", \"树昏鸦\"}, got:[]string{\"\", \"枯藤\", \"树昏鸦\"} --- PASS: TestSplit/simple (0.00s) --- PASS: TestSplit/wrong_sep (0.00s) --- PASS: TestSplit/more_sep (0.00s) FAIL exit status 1 FAIL github.com/pprof/studygo/code_demo/test_demo/split 0.006s 这个时候我们要把测试用例中的错误修改回来： func TestSplit(t *testing.T) { ... tests := map[string]test{ // 测试用例使用map存储 \"simple\": {input: \"a🅱c\", sep: \":\", want: []string{\"a\", \"b\", \"c\"} }, \"wrong sep\": {input: \"a🅱c\", sep: \",\", want: []string{\"a🅱c\"} }, \"more sep\": {input: \"abcd\", sep: \"bc\", want: []string{\"a\", \"d\"} }, \"leading sep\": {input: \"枯藤老树昏鸦\", sep: \"老\", want: []string{\"\", \"枯藤\", \"树昏鸦\"} }, } ... } 我们都知道可以通过-run=RegExp来指定运行的测试用例，还可以通过/来指定要运行的子测试用例，例如：go test -v -run=Split/simple只会运行simple对应的子测试用例。 ","date":"2022-01-06 09:16:34","objectID":"/go_base_03/:10:5","tags":["go grammar"],"title":"Go_base_03","uri":"/go_base_03/"},{"categories":["Go"],"content":"测试覆盖率 测试覆盖率是你的代码被测试套件覆盖的百分比。通常我们使用的都是语句的覆盖率，也就是在测试中至少被运行一次的代码占总代码的比例。 Go提供内置功能来检查你的代码覆盖率。我们可以使用go test -cover来查看测试覆盖率。例如： split $ go test -cover PASS coverage: 100.0% of statements ok github.com/pprof/studygo/code_demo/test_demo/split 0.005s 从上面的结果可以看到我们的测试用例覆盖了100%的代码。 Go还提供了一个额外的-coverprofile参数，用来将覆盖率相关的记录信息输出到一个文件。例如： split $ go test -cover -coverprofile=c.out PASS coverage: 100.0% of statements ok github.com/pprof/studygo/code_demo/test_demo/split 0.005s 上面的命令会将覆盖率相关的信息输出到当前文件夹下面的c.out文件中，然后我们执行go tool cover -html=c.out，使用cover工具来处理生成的记录信息，该命令会打开本地的浏览器窗口生成一个HTML报告。 ","date":"2022-01-06 09:16:34","objectID":"/go_base_03/:10:6","tags":["go grammar"],"title":"Go_base_03","uri":"/go_base_03/"},{"categories":["Go"],"content":"基准测试 基准测试函数格式 基准测试就是在一定的工作负载之下检测程序性能的一种方法。基准测试的基本格式如下： func BenchmarkName(b *testing.B){ // ... } 基准测试以Benchmark为前缀，需要一个*testing.B类型的参数b，基准测试必须要执行b.N次，这样的测试才有对照性，b.N的值是系统根据实际情况去调整的，从而保证测试的稳定性。 testing.B拥有的方法如下： func (c *B) Error(args ...interface{}) func (c *B) Errorf(format string, args ...interface{}) func (c *B) Fail() func (c *B) FailNow() func (c *B) Failed() bool func (c *B) Fatal(args ...interface{}) func (c *B) Fatalf(format string, args ...interface{}) func (c *B) Log(args ...interface{}) func (c *B) Logf(format string, args ...interface{}) func (c *B) Name() string func (b *B) ReportAllocs() func (b *B) ResetTimer() func (b *B) Run(name string, f func(b *B)) bool func (b *B) RunParallel(body func(*PB)) func (b *B) SetBytes(n int64) func (b *B) SetParallelism(p int) func (c *B) Skip(args ...interface{}) func (c *B) SkipNow() func (c *B) Skipf(format string, args ...interface{}) func (c *B) Skipped() bool func (b *B) StartTimer() func (b *B) StopTimer() 基准测试示例 我们为split包中的Split函数编写基准测试如下： func BenchmarkSplit(b *testing.B) { for i := 0; i \u003c b.N; i++ { Split(\"枯藤老树昏鸦\", \"老\") } } 基准测试并不会默认执行，需要增加-bench参数，所以我们通过执行go test -bench=Split命令执行基准测试，输出结果如下： split $ go test -bench=Split goos: darwin goarch: amd64 pkg: github.com/pprof/studygo/code_demo/test_demo/split BenchmarkSplit-8 10000000 203 ns/op PASS ok github.com/pprof/studygo/code_demo/test_demo/split 2.255s 其中BenchmarkSplit-8表示对Split函数进行基准测试，数字8表示GOMAXPROCS的值，这个对于并发基准测试很重要。10000000和203ns/op表示每次调用Split函数耗时203ns，这个结果是10000000次调用的平均值。 我们还可以为基准测试添加-benchmem参数，来获得内存分配的统计数据。 split $ go test -bench=Split -benchmem goos: darwin goarch: amd64 pkg: github.com/pprof/studygo/code_demo/test_demo/split BenchmarkSplit-8 10000000 215 ns/op 112 B/op 3 allocs/op PASS ok github.com/pprof/studygo/code_demo/test_demo/split 2.394s 其中，112 B/op表示每次操作内存分配了112字节，3 allocs/op则表示每次操作进行了3次内存分配。 我们将我们的Split函数优化如下： func Split(s, sep string) (result []string) { result = make([]string, 0, strings.Count(s, sep)+1) i := strings.Index(s, sep) for i \u003e -1 { result = append(result, s[:i]) s = s[i+len(sep):] // 这里使用len(sep)获取sep的长度 i = strings.Index(s, sep) } result = append(result, s) return } 这一次我们提前使用make函数将result初始化为一个容量足够大的切片，而不再像之前一样通过调用append函数来追加。我们来看一下这个改进会带来多大的性能提升： split $ go test -bench=Split -benchmem goos: darwin goarch: amd64 pkg: github.com/pprof/studygo/code_demo/test_demo/split BenchmarkSplit-8 10000000 127 ns/op 48 B/op 1 allocs/op PASS ok github.com/pprof/studygo/code_demo/test_demo/split 1.423s 这个使用make函数提前分配内存的改动，减少了2/3的内存分配次数，并且减少了一半的内存分配。 ","date":"2022-01-06 09:16:34","objectID":"/go_base_03/:10:7","tags":["go grammar"],"title":"Go_base_03","uri":"/go_base_03/"},{"categories":["Go"],"content":"x性能比较函数 上面的基准测试只能得到给定操作的绝对耗时，但是在很多性能问题是发生在两个不同操作之间的相对耗时，比如同一个函数处理1000个元素的耗时与处理1万甚至100万个元素的耗时的差别是多少？再或者对于同一个任务究竟使用哪种算法性能最佳？我们通常需要对两个不同算法的实现使用相同的输入来进行基准比较测试。 性能比较函数通常是一个带有参数的函数，被多个不同的Benchmark函数传入不同的值来调用。举个例子如下： func benchmark(b *testing.B, size int){/* ... */} func Benchmark10(b *testing.B){ benchmark(b, 10) } func Benchmark100(b *testing.B){ benchmark(b, 100) } func Benchmark1000(b *testing.B){ benchmark(b, 1000) } 例如我们编写了一个计算斐波那契数列的函数如下： // fib.go // Fib 是一个计算第n个斐波那契数的函数 func Fib(n int) int { if n \u003c 2 { return n } return Fib(n-1) + Fib(n-2) } 我们编写的性能比较函数如下： // fib_test.go func benchmarkFib(b *testing.B, n int) { for i := 0; i \u003c b.N; i++ { Fib(n) } } func BenchmarkFib1(b *testing.B) { benchmarkFib(b, 1) } func BenchmarkFib2(b *testing.B) { benchmarkFib(b, 2) } func BenchmarkFib3(b *testing.B) { benchmarkFib(b, 3) } func BenchmarkFib10(b *testing.B) { benchmarkFib(b, 10) } func BenchmarkFib20(b *testing.B) { benchmarkFib(b, 20) } func BenchmarkFib40(b *testing.B) { benchmarkFib(b, 40) } 运行基准测试： split $ go test -bench=. goos: darwin goarch: amd64 pkg: github.com/pprof/studygo/code_demo/test_demo/fib BenchmarkFib1-8 1000000000 2.03 ns/op BenchmarkFib2-8 300000000 5.39 ns/op BenchmarkFib3-8 200000000 9.71 ns/op BenchmarkFib10-8 5000000 325 ns/op BenchmarkFib20-8 30000 42460 ns/op BenchmarkFib40-8 2 638524980 ns/op PASS ok github.com/pprof/studygo/code_demo/test_demo/fib 12.944s 这里需要注意的是，默认情况下，每个基准测试至少运行1秒。如果在Benchmark函数返回时没有到1秒，则b.N的值会按1,2,5,10,20,50，…增加，并且函数再次运行。 最终的BenchmarkFib40只运行了两次，每次运行的平均值只有不到一秒。像这种情况下我们应该可以使用-benchtime标志增加最小基准时间，以产生更准确的结果。例如： split $ go test -bench=Fib40 -benchtime=20s goos: darwin goarch: amd64 pkg: github.com/pprof/studygo/code_demo/test_demo/fib BenchmarkFib40-8 50 663205114 ns/op PASS ok github.com/pprof/studygo/code_demo/test_demo/fib 33.849s 这一次BenchmarkFib40函数运行了50次，结果就会更准确一些了。 使用性能比较函数做测试的时候一个容易犯的错误就是把b.N作为输入的大小，例如以下两个例子都是错误的示范： // 错误示范1 func BenchmarkFibWrong(b *testing.B) { for n := 0; n \u003c b.N; n++ { Fib(n) } } // 错误示范2 func BenchmarkFibWrong2(b *testing.B) { Fib(b.N) } ","date":"2022-01-06 09:16:34","objectID":"/go_base_03/:10:8","tags":["go grammar"],"title":"Go_base_03","uri":"/go_base_03/"},{"categories":["Go"],"content":"重置时间 b.ResetTimer之前的处理不会放到执行时间里，也不会输出到报告中，所以可以在之前做一些不计划作为测试报告的操作。例如： func BenchmarkSplit(b *testing.B) { time.Sleep(5 * time.Second) // 假设需要做一些耗时的无关操作 b.ResetTimer() // 重置计时器 for i := 0; i \u003c b.N; i++ { Split(\"枯藤老树昏鸦\", \"老\") } } ","date":"2022-01-06 09:16:34","objectID":"/go_base_03/:10:9","tags":["go grammar"],"title":"Go_base_03","uri":"/go_base_03/"},{"categories":["Go"],"content":"并行测试 func (b B) RunParallel(body func(PB))会以并行的方式执行给定的基准测试。 RunParallel会创建出多个goroutine，并将b.N分配给这些goroutine执行， 其中goroutine数量的默认值为GOMAXPROCS。用户如果想要增加非CPU受限（non-CPU-bound）基准测试的并行性， 那么可以在RunParallel之前调用SetParallelism 。RunParallel通常会与-cpu标志一同使用。 func BenchmarkSplitParallel(b *testing.B) { // b.SetParallelism(1) // 设置使用的CPU数 b.RunParallel(func(pb *testing.PB) { for pb.Next() { Split(\"枯藤老树昏鸦\", \"老\") } }) } 执行一下基准测试： split $ go test -bench=. goos: darwin goarch: amd64 pkg: github.com/pprof/studygo/code_demo/test_demo/split BenchmarkSplit-8 10000000 131 ns/op BenchmarkSplitParallel-8 50000000 36.1 ns/op PASS ok github.com/pprof/studygo/code_demo/test_demo/split 3.308s 还可以通过在测试命令后添加-cpu参数如go test -bench=. -cpu 1来指定使用的CPU数量。 ","date":"2022-01-06 09:16:34","objectID":"/go_base_03/:10:10","tags":["go grammar"],"title":"Go_base_03","uri":"/go_base_03/"},{"categories":["Go"],"content":"Setup与TearDown 测试程序有时需要在测试之前进行额外的设置（setup）或在测试之后进行拆卸（teardown）。 TestMain 通过在*_test.go文件中定义TestMain函数来可以在测试之前进行额外的设置（setup）或在测试之后进行拆卸（teardown）操作。 如果测试文件包含函数:func TestMain(m *testing.M)那么生成的测试会先调用 TestMain(m)，然后再运行具体测试。TestMain运行在主goroutine中, 可以在调用 m.Run前后做任何设置（setup）和拆卸（teardown）。退出测试的时候应该使用m.Run的返回值作为参数调用os.Exit。 一个使用TestMain来设置Setup和TearDown的示例如下： func TestMain(m *testing.M) { fmt.Println(\"write setup code here...\") // 测试之前的做一些设置 // 如果 TestMain 使用了 flags，这里应该加上flag.Parse() retCode := m.Run() // 执行测试 fmt.Println(\"write teardown code here...\") // 测试之后做一些拆卸工作 os.Exit(retCode) // 退出测试 } 需要注意的是：在调用TestMain时, flag.Parse并没有被调用。所以如果TestMain 依赖于command-line标志 (包括 testing 包的标记), 则应该显示的调用flag.Parse。 子测试的Setup与Teardown 有时候我们可能需要为每个测试集设置Setup与Teardown，也有可能需要为每个子测试设置Setup与Teardown。下面我们定义两个函数工具函数如下： // 测试集的Setup与Teardown func setupTestCase(t *testing.T) func(t *testing.T) { t.Log(\"如有需要在此执行:测试之前的setup\") return func(t *testing.T) { t.Log(\"如有需要在此执行:测试之后的teardown\") } } // 子测试的Setup与Teardown func setupSubTest(t *testing.T) func(t *testing.T) { t.Log(\"如有需要在此执行:子测试之前的setup\") return func(t *testing.T) { t.Log(\"如有需要在此执行:子测试之后的teardown\") } } 使用方式如下： func TestSplit(t *testing.T) { type test struct { // 定义test结构体 input string sep string want []string } tests := map[string]test{ // 测试用例使用map存储 \"simple\": {input: \"a🅱c\", sep: \":\", want: []string{\"a\", \"b\", \"c\"} }, \"wrong sep\": {input: \"a🅱c\", sep: \",\", want: []string{\"a🅱c\"} }, \"more sep\": {input: \"abcd\", sep: \"bc\", want: []string{\"a\", \"d\"} }, \"leading sep\": {input: \"枯藤老树昏鸦\", sep: \"老\", want: []string{\"\", \"枯藤\", \"树昏鸦\"} }, } teardownTestCase := setupTestCase(t) // 测试之前执行setup操作 defer teardownTestCase(t) // 测试之后执行testdoen操作 for name, tc := range tests { t.Run(name, func(t *testing.T) { // 使用t.Run()执行子测试 teardownSubTest := setupSubTest(t) // 子测试之前执行setup操作 defer teardownSubTest(t) // 测试之后执行testdoen操作 got := Split(tc.input, tc.sep) if !reflect.DeepEqual(got, tc.want) { t.Errorf(\"excepted:%#v, got:%#v\", tc.want, got) } }) } } 测试结果如下： split $ go test -v === RUN TestSplit === RUN TestSplit/simple === RUN TestSplit/wrong_sep === RUN TestSplit/more_sep === RUN TestSplit/leading_sep --- PASS: TestSplit (0.00s) split_test.go:71: 如有需要在此执行:测试之前的setup --- PASS: TestSplit/simple (0.00s) split_test.go:79: 如有需要在此执行:子测试之前的setup split_test.go:81: 如有需要在此执行:子测试之后的teardown --- PASS: TestSplit/wrong_sep (0.00s) split_test.go:79: 如有需要在此执行:子测试之前的setup split_test.go:81: 如有需要在此执行:子测试之后的teardown --- PASS: TestSplit/more_sep (0.00s) split_test.go:79: 如有需要在此执行:子测试之前的setup split_test.go:81: 如有需要在此执行:子测试之后的teardown --- PASS: TestSplit/leading_sep (0.00s) split_test.go:79: 如有需要在此执行:子测试之前的setup split_test.go:81: 如有需要在此执行:子测试之后的teardown split_test.go:73: 如有需要在此执行:测试之后的teardown === RUN ExampleSplit --- PASS: ExampleSplit (0.00s) PASS ok github.com/Q1mi/studygo/code_demo/test_demo/split 0.006s ","date":"2022-01-06 09:16:34","objectID":"/go_base_03/:10:11","tags":["go grammar"],"title":"Go_base_03","uri":"/go_base_03/"},{"categories":["Go"],"content":"示例函数 示例函数的格式 被go test特殊对待的第三种函数就是示例函数，它们的函数名以Example为前缀。它们既没有参数也没有返回值。标准格式如下： func ExampleName() { // ... } 示例函数示例 下面的代码是我们为Split函数编写的一个示例函数： func ExampleSplit() { fmt.Println(split.Split(\"a🅱c\", \":\")) fmt.Println(split.Split(\"枯藤老树昏鸦\", \"老\")) // Output: // [a b c] // [ 枯藤 树昏鸦] } 为你的代码编写示例代码有如下三个用处： 示例函数能够作为文档直接使用，例如基于web的godoc中能把示例函数与对应的函数或包相关联。 示例函数只要包含了// Output:也是可以通过go test运行的可执行测试。 split $ go test -run Example PASS ok github.com/pprof/studygo/code_demo/test_demo/split 0.006s 示例函数提供了可以直接运行的示例代码，可以直接在golang.org的godoc文档服务器上使用Go Playground运行示例代码。下图为strings.ToUpper函数在Playground的示例函数效果 ","date":"2022-01-06 09:16:34","objectID":"/go_base_03/:10:12","tags":["go grammar"],"title":"Go_base_03","uri":"/go_base_03/"},{"categories":["Go"],"content":"func ToUpper func ToUpper(s string) string ToUpper returms a copy of the sring s with all Unicode ltters mapped to their upper case. Example: package main import ( \"fnt\" \"strings\" ) func main() { fmt. Println(strings . ToUpper(\"Gopher\")) } ","date":"2022-01-06 09:16:34","objectID":"/go_base_03/:10:13","tags":["go grammar"],"title":"Go_base_03","uri":"/go_base_03/"},{"categories":["Go"],"content":"压力测试 ","date":"2022-01-06 09:16:34","objectID":"/go_base_03/:11:0","tags":["go grammar"],"title":"Go_base_03","uri":"/go_base_03/"},{"categories":["Go"],"content":"Go怎么写测试用例 开发程序其中很重要的一点是测试，我们如何保证代码的质量，如何保证每个函数是可运行，运行结果是正确的，又如何保证写出来的代码性能是好的，我们知道单元测试的重点在于发现程序设计或实现的逻辑错误，使问题及早暴露，便于问题的定位解决，而性能测试的重点在于发现程序设计上的一些问题，让线上的程序能够在高并发的情况下还能保持稳定。本小节将带着这一连串的问题来讲解Go语言中如何来实现单元测试和性能测试。 Go语言中自带有一个轻量级的测试框架testing和自带的go test命令来实现单元测试和性能测试，testing框架和其他语言中的测试框架类似，你可以基于这个框架写针对相应函数的测试用例，也可以基于该框架写相应的压力测试用例，那么接下来让我们一一来看一下怎么写。 另外建议安装gotests插件自动生成测试代码: go get -u -v github.com/cweill/gotests/... ","date":"2022-01-06 09:16:34","objectID":"/go_base_03/:11:1","tags":["go grammar"],"title":"Go_base_03","uri":"/go_base_03/"},{"categories":["Go"],"content":"如何编写测试用例 由于go test命令只能在一个相应的目录下执行所有文件，所以我们接下来新建一个项目目录gotest,这样我们所有的代码和测试代码都在这个目录下。 接下来我们在该目录下面创建两个文件：gotest.go和gotest_test.go gotest.go:这个文件里面我们是创建了一个包，里面有一个函数实现了除法运算: package gotest import ( \"errors\" ) func Division(a, b float64) (float64, error) { if b == 0 { return 0, errors.New(\"除数不能为0\") } return a / b, nil } gotest_test.go:这是我们的单元测试文件，但是记住下面的这些原则： 文件名必须是_test.go结尾的，这样在执行go test的时候才会执行到相应的代码 你必须import testing这个包 所有的测试用例函数必须是Test开头 测试用例会按照源代码中写的顺序依次执行 测试函数TestXxx()的参数是testing.T，我们可以使用该类型来记录错误或者是测试状态 测试格式：func TestXxx (t *testing.T),Xxx部分可以为任意的字母数字的组合，但是首字母不能是小写字母[a-z]，例如Testintdiv是错误的函数名。 函数中通过调用testing.T的Error, Errorf, FailNow, Fatal, FatalIf方法，说明测试不通过，调用Log方法用来记录测试的信息。 下面是我们的测试用例的代码： package gotest import ( \"testing\" ) func Test_Division_1(t *testing.T) { if i, e := Division(6, 2); i != 3 || e != nil { //try a unit test on function t.Error(\"除法函数测试没通过\") // 如果不是如预期的那么就报错 } else { t.Log(\"第一个测试通过了\") //记录一些你期望记录的信息 } } func Test_Division_2(t *testing.T) { t.Error(\"就是不通过\") } 我们在项目目录下面执行go test,就会显示如下信息： --- FAIL: Test_Division_2 (0.00 seconds) gotest_test.go:16: 就是不通过 FAIL exit status 1 FAIL gotest 0.013s 从这个结果显示测试没有通过，因为在第二个测试函数中我们写死了测试不通过的代码t.Error，那么我们的第一个函数执行的情况怎么样呢？默认情况下执行go test是不会显示测试通过的信息的，我们需要带上参数go test -v，这样就会显示如下信息： === RUN Test_Division_1 --- PASS: Test_Division_1 (0.00 seconds) gotest_test.go:11: 第一个测试通过了 === RUN Test_Division_2 --- FAIL: Test_Division_2 (0.00 seconds) gotest_test.go:16: 就是不通过 FAIL exit status 1 FAIL gotest 0.012s 上面的输出详细的展示了这个测试的过程，我们看到测试函数1Test_Division_1测试通过，而测试函数2Test_Division_2测试失败了，最后得出结论测试不通过。接下来我们把测试函数2修改成如下代码： func Test_Division_2(t *testing.T) { if _, e := Division(6, 0); e == nil { //try a unit test on function t.Error(\"Division did not work as expected.\") // 如果不是如预期的那么就报错 } else { t.Log(\"one test passed.\", e) //记录一些你期望记录的信息 } } 然后我们执行go test -v，就显示如下信息，测试通过了： === RUN Test_Division_1 --- PASS: Test_Division_1 (0.00 seconds) gotest_test.go:11: 第一个测试通过了 === RUN Test_Division_2 --- PASS: Test_Division_2 (0.00 seconds) gotest_test.go:20: one test passed. 除数不能为0 PASS ok gotest 0.013s //一般 go test -v -run funcName fileName.go go test -v -cover -run funcName fileName.go ","date":"2022-01-06 09:16:34","objectID":"/go_base_03/:11:2","tags":["go grammar"],"title":"Go_base_03","uri":"/go_base_03/"},{"categories":["Go"],"content":"如何编写压力测试 压力测试用来检测函数(方法）的性能，和编写单元功能测试的方法类似,此处不再赘述，但需要注意以下几点： 压力测试用例必须遵循如下格式，其中XXX可以是任意字母数字的组合，但是首字母不能是小写字母 func BenchmarkXXX(b *testing.B) { ... } go test不会默认执行压力测试的函数，如果要执行压力测试需要带上参数-test.bench，语法:-test.bench=”test_name_regex”,例如go test -test.bench=”.*“表示测试全部的压力测试函数 在压力测试用例中,请记得在循环体内使用testing.B.N,以使测试可以正常的运行 文件名也必须以_test.go结尾 下面我们新建一个压力测试文件webbench_test.go，代码如下所示： import ( \"testing\" ) func Benchmark_Division(b *testing.B) { for i := 0; i \u003c b.N; i++ { //use b.N for looping Division(4, 5) } } func Benchmark_TimeConsumingFunction(b *testing.B) { b.StopTimer() //调用该函数停止压力测试的时间计数 //做一些初始化的工作,例如读取文件数据,数据库连接之类的, //这样这些时间不影响我们测试函数本身的性能 b.StartTimer() //重新开始时间 for i := 0; i \u003c b.N; i++ { Division(4, 5) } } 我们执行命令go test webbench_test.go -test.bench=”.*\"，可以看到如下结果： Benchmark_Division-4 500000000 7.76 ns/op 456 B/op 14 allocs/op Benchmark_TimeConsumingFunction-4 500000000 7.80 ns/op 224 B/op 4 allocs/op PASS ok gotest 9.364s 上面的结果显示我们没有执行任何TestXXX的单元测试函数，显示的结果只执行了压力测试函数，第一条显示了Benchmark_Division执行了500000000次，每次的执行平均时间是7.76纳秒，第二条显示了Benchmark_TimeConsumingFunction执行了500000000，每次的平均执行时间是7.80纳秒。最后一条显示总共的执行时间。 ","date":"2022-01-06 09:16:34","objectID":"/go_base_03/:11:3","tags":["go grammar"],"title":"Go_base_03","uri":"/go_base_03/"},{"categories":["Go"],"content":"BDD Behavior Driven Development行为驱动开发 行为驱动开发（Behavior-Driven Development）（简写BDD），在软件工程中，BDD是一种敏捷软件开发的技术。行为驱动开发(BDD)是测试驱动开发的延伸，开发使用简单的，特定于领域的脚本语言。这些DSL将结构化自然语言语句转换为可执行测试。结果是与给定功能的验收标准以及用于验证该功能的测试之间的关系更密切。因此，它一般是测试驱动开发(TDD)测试的自然延伸。（摘自百度百科） BDD in Go 一个测试框架 项⽬⽹站 https://github.com/smartystreets/goconvey 安装 go get -u github.com/smartystreets/goconvey/convey 启动 WEB UI $GOPATH/bin/goconvey package testing import ( \"testing\" . \"github.com/smartystreets/goconvey/convey\" ) func TestSpec(t *testing.T) { // Only pass t into top-level Convey calls Convey(\"Given 2 even numbers\", t, func() { a := 3 b := 4 Convey(\"When add the two numbers\", func() { c := a + b Convey(\"Then the result is still even\", func() { So(c%2, ShouldEqual, 0) }) }) }) } convey这个pkg还提供了一个web界面，在gopath下的bin目录里面有二进制程序goconvey。 ","date":"2022-01-06 09:16:34","objectID":"/go_base_03/:12:0","tags":["go grammar"],"title":"Go_base_03","uri":"/go_base_03/"},{"categories":["Go"],"content":" 参考学习go语言中文网、C语言中文网、golang官方文档等 流程控制 ","date":"2022-01-06 09:16:07","objectID":"/go_base_02/:0:0","tags":["go grammar"],"title":"Go_base_02","uri":"/go_base_02/"},{"categories":["Go"],"content":"if Go 编程语言中 if 语句的语法如下： 可省略条件表达式括号。 持初始化语句，可定义代码块局部变量，也叫做if语句的自用变量，而这自用变量作用域在其声明所在的代码块，但不能在该if语句块之外。 代码块左花括号必须在条件表达式尾部。 可嵌套 if 布尔表达式 { /* 在布尔表达式为 true 时执行 */ } if分支有三种：单分支、二分支、多分支，要减少多分支结构，甚至是二分支结构的使用。这样的代码更优雅、简洁、易读、易维护。单分支结构的使用被称为符合“快乐路径”原则。 Go不支持三元操作符(三目运算符) “a \u003e b ? a : b” ","date":"2022-01-06 09:16:07","objectID":"/go_base_02/:1:0","tags":["go grammar"],"title":"Go_base_02","uri":"/go_base_02/"},{"categories":["Go"],"content":"switch Golang switch 分支表达式可以是任意类型，不限于常量。可省略 break，默认自动终止。 可以同时测试多个可能符合条件的值，使用逗号分割它们，例如：case val1, val2, val3。 switch 语句支持声明临时变量。 如： switch { case grade == \"A\" : fmt.Printf(\"优秀!\\n\" ) case grade == \"B\", grade == \"C\" : fmt.Printf(\"良好\\n\" ) case grade == \"D\" : fmt.Printf(\"及格\\n\" ) case grade == \"F\": fmt.Printf(\"不及格\\n\" ) default: fmt.Printf(\"差\\n\" ) } ","date":"2022-01-06 09:16:07","objectID":"/go_base_02/:2:0","tags":["go grammar"],"title":"Go_base_02","uri":"/go_base_02/"},{"categories":["Go"],"content":"Type Switch switch 语句还可以被用于 type-switch 来判断某个 interface 变量中实际存储的变量类型。 switch x.(type){ case type1: statement(s) case type2: statement(s) /* 你可以定义任意个数的case */ default: /* 可选 */ statement(s) } ","date":"2022-01-06 09:16:07","objectID":"/go_base_02/:2:1","tags":["go grammar"],"title":"Go_base_02","uri":"/go_base_02/"},{"categories":["Go"],"content":"select select 语句类似于 switch 语句，但是select会随机执行一个可运行的case。如果没有case可运行，且没有default语句，它将阻塞，直到有case可运行。 每个case都必须是一个通信 所有channel表达式都会被求值 所有被发送的表达式都会被求值 如果任意某个通信可以进行，它就执行；其他被忽略。 如果有多个case都可以运行，Select会随机公平地选出一个执行。其他不会执行。 否则： 如果有default子句，则执行该语句。 如果没有default字句，select将阻塞，直到某个通信可以运行；Go不会重新对channel或值进行求值。 select可以监听channel的数据流动 select的用法与switch语法非常类似，由select开始的一个新的选择块，每个选择条件由case语句来描述 与switch语句可以选择任何使用相等比较的条件相比，select有比较多的限制，其中最大的一条限制就是每个case语句里必须是一个IO操作 select { //不停的在这里检测 case \u003c-chanl : //检测有没有数据可以读 //如果chanl成功读取到数据，则进行该case处理语句 case chan2 \u003c- 1 : //检测有没有可以写 //如果成功向chan2写入数据，则进行该case处理语句 //假如没有default，那么在以上两个条件都不成立的情况下，就会在此阻塞//一般default会不写在里面，select中的default子句总是可运行的，因为会很消耗CPU资源 default: //如果以上都没有符合条件，那么则进行default处理流程 } 在一个select语句中，Go会按顺序从头到尾评估每一个发送和接收的语句。 如果其中的任意一个语句可以继续执行（即没有被阻塞），那么就从那些可以执行的语句中任意选择一条来使用。 如果没有任意一条语句可以执行（即所有的通道都被阻塞），那么有两种可能的情况： ①如果给出了default语句，那么就会执行default的流程，同时程序的执行会从select语句后的语句中恢复。 ②如果没有default语句，那么select语句将被阻塞，直到至少有一个case可以进行下去。 ","date":"2022-01-06 09:16:07","objectID":"/go_base_02/:3:0","tags":["go grammar"],"title":"Go_base_02","uri":"/go_base_02/"},{"categories":["Go"],"content":"基本使用 select是Go中的一个控制结构，类似于switch语句，用于处理异步IO操作。select会监听case语句中channel的读写操作，当case中channel读写操作为非阻塞状态（即能读写）时，将会触发相应的动作。 select中的case语句必须是一个channel操作 select中的default子句总是可运行的。 如果有多个case都可以运行，select会随机公平地选出一个执行，其他不会执行。 如果没有可运行的case语句，且有default语句，那么就会执行default的动作。 如果没有可运行的case语句，且没有default语句，select将阻塞，直到某个case通信可以运行 例如： package main import \"fmt\" func main() { var c1, c2, c3 chan int var i1, i2 int select { case i1 = \u003c-c1: fmt.Printf(\"received \", i1, \" from c1\\n\") case c2 \u003c- i2: fmt.Printf(\"sent \", i2, \" to c2\\n\") case i3, ok := (\u003c-c3): // same as: i3, ok := \u003c-c3 if ok { fmt.Printf(\"received \", i3, \" from c3\\n\") } else { fmt.Printf(\"c3 is closed\\n\") } default: fmt.Printf(\"no communication\\n\") } } //输出：no communication ","date":"2022-01-06 09:16:07","objectID":"/go_base_02/:3:1","tags":["go grammar"],"title":"Go_base_02","uri":"/go_base_02/"},{"categories":["Go"],"content":"典型用法 超时判断： //比如在下面的场景中，使用全局resChan来接受response，如果时间超过3S,resChan中还没有数据返回，则第二条case将执行 var resChan = make(chan int) // do request func test() { select { case data := \u003c-resChan: doData(data) case \u003c-time.After(time.Second * 3): fmt.Println(\"request time out\") } } func doData(data int) { //... } 退出 //主线程（协程）中如下： var shouldQuit=make(chan struct{}) fun main(){ { //loop } //...out of the loop select { case \u003c-c.shouldQuit: cleanUp() return default: } //... } //再另外一个协程中，如果运行遇到非法操作或不可处理的错误，就向shouldQuit发送数据通知程序停止运行 close(shouldQuit) 判断channel是否阻塞 //在某些情况下是存在不希望channel缓存满了的需求的，可以用如下方法判断 ch := make (chan int, 5) //... data：=0 select { case ch \u003c- data: default: //做相应操作，比如丢弃data。视需求而定 } ","date":"2022-01-06 09:16:07","objectID":"/go_base_02/:3:2","tags":["go grammar"],"title":"Go_base_02","uri":"/go_base_02/"},{"categories":["Go"],"content":"for Go语言的For循环有3中形式，只有其中的一种使用分号。 for init; condition; post { } for condition { } for { } init： 一般为赋值表达式，给控制变量赋初值； condition： 关系表达式或逻辑表达式，循环控制条件； post： 一般为赋值表达式，给控制变量增量或减量。 for语句执行过程如下： ①先对表达式 init 赋初值； ②判别赋值表达式 init 是否满足给定 condition 条件，若其值为真，满足循环条件，则执行循环体内语句，然后执行 post，进入第二次循环，再判别 condition；否则判断 condition 的值为假，不满足条件，就终止for循环，执行循环体外语句。 可嵌套，可无限循环。 ","date":"2022-01-06 09:16:07","objectID":"/go_base_02/:4:0","tags":["go grammar"],"title":"Go_base_02","uri":"/go_base_02/"},{"categories":["Go"],"content":"range Golang range类似迭代器操作，返回 (索引, 值) 或 (键, 值)。 for 循环的 range 格式可以对 slice、map、数组、字符串等进行迭代循环。格式如下： for key, value := range oldMap { newMap[key] = value } ****注意range会复制对象： package main import \"fmt\" func main() { a := [3]int{0, 1, 2} for i, v := range a { // index、value 都是从复制品中取出。 if i == 0 { // 在修改前，我们先修改原数组。 a[1], a[2] = 999, 999 fmt.Println(a) // 确认修改有效，输出 [0, 999, 999]。 } a[i] = v + 100 // 使用复制品中取出的 value 修改原数组。 } fmt.Println(a) // 输出 [100, 101, 102]。 } output: [0 999 999] [100 101 102] 这说明开始执行range时就已经保存了当下的数组，所以在循环里修改数组也不会改动遍历时的使用的数组的值。 改用引用类型，其底层数据不会被复制： package main func main() { s := []int{1, 2, 3, 4, 5} for i, v := range s { // 复制 struct slice { pointer, len, cap }。 if i == 0 { s = s[:3] // 对 slice 的修改，不会影响 range。 s[2] = 100 // 对底层数据的修改。 } println(i, v) } } output: 0 1 1 2 2 100 3 4 4 5 另外两种引用类型 map、channel 也能应用于for range遍历上，是指针包装，而不像 slice 是 struct。 for 和 for range有什么区别? 主要是使用场景不同 for可以 遍历array和slice 遍历key为整型递增的map 遍历string for range可以完成所有for可以做的事情，却能做到for不能做的，包括 遍历key为string类型的map并同时获取key和value 遍历channel ","date":"2022-01-06 09:16:07","objectID":"/go_base_02/:5:0","tags":["go grammar"],"title":"Go_base_02","uri":"/go_base_02/"},{"categories":["Go"],"content":"Goto Break Continue 循环控制语句： Goto、Break、Continue 三个语句都可以配合标签(label)使用 标签名区分大小写，定以后若不使用会造成编译错误 continue、break配合标签(label)可用于多层循环跳出 goto是调整执行位置，与continue、break配合标签(label)的结果并不相同 ","date":"2022-01-06 09:16:07","objectID":"/go_base_02/:6:0","tags":["go grammar"],"title":"Go_base_02","uri":"/go_base_02/"},{"categories":["Coding"],"content":" 学习代码随想录笔记 动态规划 有很多重叠子问题，优先考虑使用动态规划。 与贪心的区别：贪心不会考虑之前的状态而只考虑局部最优。 ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:0:0","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"理论基础 dp步骤： 确定dp数组（dp table）以及下标的含义 确定递推公式 dp数组如何初始化 确定遍历顺序 举例推导dp数组 debug:把dp数组打印出来 ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:1:0","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"斐波那契数 func fib(n int) int { if n \u003c 2 { return n } a, b, c := 0, 1, 0 for i := 1; i \u003c n; i++ { c = a + b a, b = b, c } return c } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:2:0","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"爬楼梯 假设你正在爬楼梯。需要 n 阶你才能到达楼顶。 每次你可以爬 1 或 2 个台阶。你有多少种不同的方法可以爬到楼顶呢？ 注意：给定 n 是一个正整数。 示例 1： 输入： 2 输出： 2 解释： 有两种方法可以爬到楼顶。 1 阶 + 1 阶 2 阶 func climbStairs(n int) int { if n==1{ return 1 } dp:=make([]int,n+1) dp[1]=1 dp[2]=2 for i:=3;i\u003c=n;i++{ dp[i]=dp[i-1]+dp[i-2] } return dp[n] } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:3:0","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"使用最小花费爬楼梯 数组的每个下标作为一个阶梯，第 i 个阶梯对应着一个非负数的体力花费值 cost[i]（下标从 0 开始）。 每当你爬上一个阶梯你都要花费对应的体力值，一旦支付了相应的体力值，你就可以选择向上爬一个阶梯或者爬两个阶梯。 请你找出达到楼层顶部的最低花费。在开始时，你可以选择从下标为 0 或 1 的元素作为初始阶梯。 示例 1： 输入：cost = [10, 15, 20] 输出：15 解释：最低花费是从 cost[1] 开始，然后走两步即可到阶梯顶，一共花费 15 func minCostClimbingStairs(cost []int) int { dp := make([]int, len(cost)) dp[0], dp[1] = cost[0], cost[1] for i := 2; i \u003c len(cost); i++ { dp[i] = min(dp[i-1], dp[i-2]) + cost[i] } return min(dp[len(cost)-1], dp[len(cost)-2]) } func min(a, b int) int { if a \u003c b { return a } return b } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:3:1","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"不同路径 ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:4:0","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"I 一个机器人位于一个 m x n 网格的左上角 （起始点在下图中标记为 “Start” ）。 机器人每次只能向下或者向右移动一步。机器人试图达到网格的右下角（在下图中标记为 “Finish” ）。 问总共有多少条不同的路径？ func uniquePaths(m int, n int) int { dp := make([][]int, m) for i := range dp { dp[i] = make([]int, n) dp[i][0] = 1 } for j := 0; j \u003c n; j++ { dp[0][j] = 1 } for i := 1; i \u003c m; i++ { for j := 1; j \u003c n; j++ { dp[i][j] = dp[i-1][j] + dp[i][j-1] } } return dp[m-1][n-1] } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:4:1","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"II 一个机器人位于一个 m x n 网格的左上角 （起始点在下图中标记为“Start” ）。 机器人每次只能向下或者向右移动一步。机器人试图达到网格的右下角（在下图中标记为“Finish”）。 现在考虑网格中有障碍物。那么从左上角到右下角将会有多少条不同的路径？ func uniquePathsWithObstacles(obstacleGrid [][]int) int { m,n:= len(obstacleGrid),len(obstacleGrid[0]) // 定义一个dp数组 dp := make([][]int,m) for i,_ := range dp { dp[i] = make([]int,n) } // 初始化 for i:=0;i\u003cm;i++ { // 如果是障碍物, 后面的就都是0, 不用循环了 if obstacleGrid[i][0] == 1 { break } dp[i][0]=1 } for i:=0;i\u003cn;i++ { if obstacleGrid[0][i] == 1 { break } dp[0][i]=1 } // dp数组推导过程 for i:=1;i\u003cm;i++ { for j:=1;j\u003cn;j++ { // 如果obstacleGrid[i][j]这个点是障碍物, 那么我们的dp[i][j]保持为0 if obstacleGrid[i][j] != 1 { // 否则我们需要计算当前点可以到达的路径数 dp[i][j] = dp[i-1][j]+dp[i][j-1] } } } // debug遍历dp //for i,_ := range dp { // for j,_ := range dp[i] { // fmt.Printf(\"%.2v,\",dp[i][j]) // } // fmt.Println() //} return dp[m-1][n-1] } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:4:2","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"整数拆分 给定一个正整数 n，将其拆分为至少两个正整数的和，并使这些整数的乘积最大化。 返回你可以获得的最大乘积。 func integerBreak(n int) int { /** 动态五部曲 1.确定dp下标及其含义 2.确定递推公式 3.确定dp初始化 4.确定遍历顺序 5.打印dp **/ dp:=make([]int,n+1) dp[1]=1 dp[2]=1 for i:=3;i\u003cn+1;i++{ for j:=1;j\u003ci-1;j++{ // i可以差分为i-j和j。由于需要最大值，故需要通过j遍历所有存在的值，取其中最大的值作为当前i的最大值，在求最大值的时候，一个是j与i-j相乘，一个是j与dp[i-j]. dp[i]=max(dp[i],max(j*(i-j),j*dp[i-j])) } } return dp[n] } func max(a,b int) int{ if a\u003eb{ return a } return b } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:5:0","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"不同的二叉搜索树 给定一个整数 n，求以 1 … n 为节点组成的二叉搜索树有多少种？ func numTrees(n int)int{ dp:=make([]int,n+1) dp[0]=1 for i:=1;i\u003c=n;i++{ for j:=1;j\u003c=i;j++{ dp[i]+=dp[j-1]*dp[i-j] } } return dp[n] } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:6:0","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"0-1背包理论基础 ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:7:0","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"I 暴力的解法是指数级别的时间复杂度。进而才需要动态规划的解法来进行优化 代码随想录详解 func test_2_wei_bag_problem1(weight, value []int, bagweight int) int { // 定义dp数组 dp := make([][]int, len(weight)) for i, _ := range dp { dp[i] = make([]int, bagweight+1) } // 初始化 for j := bagweight; j \u003e= weight[0]; j-- { dp[0][j] = dp[0][j-weight[0]] + value[0] } // 递推公式 for i := 1; i \u003c len(weight); i++ { //正序,也可以倒序 for j := weight[i];j\u003c= bagweight ; j++ { dp[i][j] = max(dp[i-1][j], dp[i-1][j-weight[i]]+value[i]) } } return dp[len(weight)-1][bagweight] } func max(a,b int) int { if a \u003e b { return a } return b } func main() { weight := []int{1,3,4} value := []int{15,20,30} test_2_wei_bag_problem1(weight,value,4) } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:7:1","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"II 代码随想录详解 func test_1_wei_bag_problem(weight, value []int, bagWeight int) int { // 定义 and 初始化 dp := make([]int,bagWeight+1) // 递推顺序 for i := 0 ;i \u003c len(weight) ; i++ { // 这里必须倒序,区别二维,因为二维dp保存了i的状态 for j:= bagWeight; j \u003e= weight[i] ; j-- { // 递推公式 dp[j] = max(dp[j], dp[j-weight[i]]+value[i]) } } //fmt.Println(dp) return dp[bagWeight] } func max(a,b int) int { if a \u003e b { return a } return b } func main() { weight := []int{1,3,4} value := []int{15,20,30} test_1_wei_bag_problem(weight,value,4) } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:7:2","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"分割等和子集 给定一个只包含正整数的非空数组。是否可以将这个数组分割成两个子集，使得两个子集的元素和相等。 注意: 每个数组中的元素不会超过 100 数组的大小不会超过 200 示例 1: 输入: [1, 5, 11, 5] 输出: true 解释: 数组可以分割成 [1, 5, 5] 和 [11]. 示例 2: 输入: [1, 2, 3, 5] 输出: false 解释: 数组不能分割成两个元素和相等的子集. // 分割等和子集 动态规划 // 时间复杂度O(n^2) 空间复杂度O(n) func canPartition(nums []int) bool { sum := 0 for _, num := range nums { sum += num } // 如果 nums 的总和为奇数则不可能平分成两个子集 if sum % 2 == 1 { return false } target := sum / 2 dp := make([]int, target + 1) for _, num := range nums { for j := target; j \u003e= num; j-- { if dp[j] \u003c dp[j - num] + num { dp[j] = dp[j - num] + num } } } return dp[target] == target } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:8:0","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"最后一块石头的重量II 有一堆石头，每块石头的重量都是正整数。 每一回合，从中选出任意两块石头，然后将它们一起粉碎。假设石头的重量分别为 x 和 y，且 x \u003c= y。那么粉碎的可能结果如下： 如果 x == y，那么两块石头都会被完全粉碎； 如果 x != y，那么重量为 x 的石头将会完全粉碎，而重量为 y 的石头新重量为 y-x。 最后，最多只会剩下一块石头。返回此石头最小的可能重量。如果没有石头剩下，就返回 0。 示例： 输入：[2,7,4,1,8,1] 输出：1 解释： 组合 2 和 4，得到 2，所以数组转化为 [2,7,1,8,1]， 组合 7 和 8，得到 1，所以数组转化为 [2,1,1,1]， 组合 2 和 1，得到 1，所以数组转化为 [1,1,1]， 组合 1 和 1，得到 0，所以数组转化为 [1]，这就是最优值。 func lastStoneWeightII(stones []int) int { // 15001 = 30 * 1000 /2 +1 dp := make([]int, 15001) // 求target sum := 0 for _, v := range stones { sum += v } target := sum / 2 // 遍历顺序 for i := 0; i \u003c len(stones); i++ { for j := target; j \u003e= stones[i]; j-- { // 推导公式 dp[j] = max(dp[j], dp[j-stones[i]]+stones[i]) } } return sum - 2 * dp[target] } func max(a, b int) int { if a \u003e b { return a } return b } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:9:0","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"目标和 给定一个非负整数数组，a1, a2, …, an, 和一个目标数，S。现在你有两个符号 + 和 -。对于数组中的任意一个整数，你都可以从 + 或 -中选择一个符号添加在前面。 返回可以使最终数组和为目标数 S 的所有添加符号的方法数。 示例： 输入：nums: [1, 1, 1, 1, 1], S: 3 输出：5 解释： -1+1+1+1+1 = 3 +1-1+1+1+1 = 3 +1+1-1+1+1 = 3 +1+1+1-1+1 = 3 +1+1+1+1-1 = 3 一共有5种方法让最终目标和为3。 可回溯可dp func findTargetSumWays(nums []int, target int) int { sum := 0 for _, v := range nums { sum += v } if target \u003e sum { return 0 } if (sum+target)%2 == 1 { return 0 } // 计算背包大小 bag := (sum + target) / 2 // 定义dp数组 dp := make([]int, bag+1) // 初始化 dp[0] = 1 // 遍历顺序 for i := 0; i \u003c len(nums); i++ { for j := bag; j \u003e= nums[i]; j-- { //推导公式 dp[j] += dp[j-nums[i]] //fmt.Println(dp) } } return dp[bag] } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:10:0","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"一和零 给你一个二进制字符串数组 strs 和两个整数 m 和 n 。 请你找出并返回 strs 的最大子集的大小，该子集中 最多 有 m 个 0 和 n 个 1 。 如果 x 的所有元素也是 y 的元素，集合 x 是集合 y 的 子集 。 示例 1： 输入：strs = [“10”, “0001”, “111001”, “1”, “0”], m = 5, n = 3 输出：4 解释：最多有 5 个 0 和 3 个 1 的最大子集是 {“10”,“0001”,“1”,“0”} ，因此答案是 4 。 其他满足题意但较小的子集包括 {“0001”,“1”} 和 {“10”,“1”,“0”} 。{“111001”} 不满足题意，因为它含 4 个 1 ，大于 n 的值 3 。 func findMaxForm(strs []string, m int, n int) int { // 定义数组 dp := make([][]int, m+1) for i,_ := range dp { dp[i] = make([]int, n+1 ) } // 遍历 for i:=0;i\u003clen(strs);i++ { zeroNum,oneNum := 0 , 0 //计算0,1 个数 //或者直接strings.Count(strs[i],\"0\") for _,v := range strs[i] { if v == '0' { zeroNum++ } } oneNum = len(strs[i])-zeroNum // 从后往前 遍历背包容量 for j:= m ; j \u003e= zeroNum;j-- { for k:=n ; k \u003e= oneNum;k-- { // 推导公式 dp[j][k] = max(dp[j][k],dp[j-zeroNum][k-oneNum]+1) } } //fmt.Println(dp) } return dp[m][n] } func max(a,b int) int { if a \u003e b { return a } return b } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:11:0","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"完全背包理论基础 每件物品都有无限个（也就是可以放入背包多次） // test_CompletePack1 先遍历物品, 在遍历背包 func test_CompletePack1(weight, value []int, bagWeight int) int { // 定义dp数组 和初始化 dp := make([]int, bagWeight+1) // 遍历顺序 for i := 0; i \u003c len(weight); i++ { // 正序会多次添加 value[i] for j := weight[i]; j \u003c= bagWeight; j++ { // 推导公式 dp[j] = max(dp[j], dp[j-weight[i]]+value[i]) // debug //fmt.Println(dp) } } return dp[bagWeight] } // test_CompletePack2 先遍历背包, 在遍历物品 func test_CompletePack2(weight, value []int, bagWeight int) int { // 定义dp数组 和初始化 dp := make([]int, bagWeight+1) // 遍历顺序 // j从0 开始 for j := 0; j \u003c= bagWeight; j++ { for i := 0; i \u003c len(weight); i++ { if j \u003e= weight[i] { // 推导公式 dp[j] = max(dp[j], dp[j-weight[i]]+value[i]) } // debug //fmt.Println(dp) } } return dp[bagWeight] } func max(a, b int) int { if a \u003e b { return a } return b } func main() { weight := []int{1, 3, 4} price := []int{15, 20, 30} fmt.Println(test_CompletePack1(weight, price, 4)) fmt.Println(test_CompletePack2(weight, price, 4)) } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:12:0","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"零钱兑换II 给定不同面额的硬币和一个总金额。写出函数来计算可以凑成总金额的硬币组合数。假设每一种面额的硬币有无限个。 示例 1: 输入: amount = 5, coins = [1, 2, 5] 输出: 4 解释: 有四种方式可以凑成总金额: 5=5 5=2+2+1 5=2+1+1+1 5=1+1+1+1+1 func change(amount int, coins []int) int { // 定义dp数组 dp := make([]int, amount+1) // 初始化,0大小的背包, 当然是不装任何东西了, 就是1种方法 dp[0] = 1 // 遍历顺序 // 遍历物品 for i := 0 ;i \u003c len(coins);i++ { // 遍历背包 for j:= coins[i] ; j \u003c= amount ;j++ { // 推导公式 dp[j] += dp[j-coins[i]] } } return dp[amount] } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:13:0","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"组合总和（IV） 给定一个由正整数组成且不存在重复数字的数组，找出和为给定目标正整数的组合的个数。 示例: nums = [1, 2, 3] target = 4 所有可能的组合为： (1, 1, 1, 1) (1, 1, 2) (1, 2, 1) (1, 3) (2, 1, 1) (2, 2) (3, 1) 请注意，顺序不同的序列被视作不同的组合。 因此输出为 7 func combinationSum4(nums []int, target int) int { //定义dp数组 dp := make([]int, target+1) // 初始化 dp[0] = 1 // 遍历顺序, 先遍历背包,再循环遍历物品 for j:=0;j\u003c=target;j++ { for i:=0 ;i \u003c len(nums);i++ { if j \u003e= nums[i] { dp[j] += dp[j-nums[i]] } } } return dp[target] } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:14:0","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"爬楼梯（进阶） 假设你正在爬楼梯。需要 n 阶你才能到达楼顶。 每次你可以爬 1 或 2 个台阶。你有多少种不同的方法可以爬到楼顶呢？ 注意：给定 n 是一个正整数。 示例 1： 输入： 2 输出： 2 解释： 有两种方法可以爬到楼顶。 1 阶 + 1 阶 2 阶 func climbStairs(n int) int { //定义 dp := make([]int, n+1) //初始化 dp[0] = 1 // 本题物品只有两个1,2 m := 2 // 遍历顺序 for j := 1; j \u003c= n; j++ { //先遍历背包 for i := 1; i \u003c= m; i++ { //再遍历物品 if j \u003e= i { dp[j] += dp[j-i] } //fmt.Println(dp) } } return dp[n] } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:15:0","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"零钱兑换 给定不同面额的硬币 coins 和一个总金额 amount。编写一个函数来计算可以凑成总金额所需的最少的硬币个数。如果没有任何一种硬币组合能组成总金额，返回 -1。 你可以认为每种硬币的数量是无限的。 示例 1： 输入：coins = [1, 2, 5], amount = 11 输出：3 解释：11 = 5 + 5 + 1 // 版本一, 先遍历物品,再遍历背包 func coinChange1(coins []int, amount int) int { dp := make([]int, amount+1) // 初始化dp[0] dp[0] = 0 // 初始化为math.MaxInt32 for j := 1; j \u003c= amount; j++ { dp[j] = math.MaxInt32 } // 遍历物品 for i := 0; i \u003c len(coins); i++ { // 遍历背包 for j := coins[i]; j \u003c= amount; j++ { if dp[j-coins[i]] != math.MaxInt32 { // 推导公式 dp[j] = min(dp[j], dp[j-coins[i]]+1) //fmt.Println(dp,j,i) } } } // 没找到能装满背包的, 就返回-1 if dp[amount] == math.MaxInt32 { return -1 } return dp[amount] } // 版本二,先遍历背包,再遍历物品 func coinChange2(coins []int, amount int) int { dp := make([]int, amount+1) // 初始化dp[0] dp[0] = 0 // 遍历背包,从1开始 for j := 1; j \u003c= amount; j++ { // 初始化为math.MaxInt32 dp[j] = math.MaxInt32 // 遍历物品 for i := 0; i \u003c len(coins); i++ { if j \u003e= coins[i] \u0026\u0026 dp[j-coins[i]] != math.MaxInt32 { // 推导公式 dp[j] = min(dp[j], dp[j-coins[i]]+1) //fmt.Println(dp) } } } // 没找到能装满背包的, 就返回-1 if dp[amount] == math.MaxInt32 { return -1 } return dp[amount] } func min(a, b int) int { if a \u003c b { return a } return b } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:16:0","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"完全平方数 给定正整数 n，找到若干个完全平方数（比如 1, 4, 9, 16, …）使得它们的和等于 n。你需要让组成和的完全平方数的个数最少。 给你一个整数 n ，返回和为 n 的完全平方数的 最少数量 。 完全平方数 是一个整数，其值等于另一个整数的平方；换句话说，其值等于一个整数自乘的积。例如，1、4、9 和 16 都是完全平方数，而 3 和 11 不是。 示例 1： 输入：n = 12 输出：3 解释：12 = 4 + 4 + 4 // 版本一,先遍历物品, 再遍历背包 func numSquares1(n int) int { //定义 dp := make([]int, n+1) // 初始化 dp[0] = 0 for i := 1; i \u003c= n; i++ { dp[i] = math.MaxInt32 } // 遍历物品 for i := 1; i \u003c= n; i++ { // 遍历背包 for j := i*i; j \u003c= n; j++ { dp[j] = min(dp[j], dp[j-i*i]+1) } } return dp[n] } // 版本二,先遍历背包, 再遍历物品 func numSquares2(n int) int { //定义 dp := make([]int, n+1) // 初始化 dp[0] = 0 // 遍历背包 for j := 1; j \u003c= n; j++ { //初始化 dp[j] = math.MaxInt32 // 遍历物品 for i := 1; i \u003c= n; i++ { if j \u003e= i*i { dp[j] = min(dp[j], dp[j-i*i]+1) } } } return dp[n] } func min(a, b int) int { if a \u003c b { return a } return b } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:17:0","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"单词拆分 给定一个非空字符串 s 和一个包含非空单词的列表 wordDict，判定 s 是否可以被空格拆分为一个或多个在字典中出现的单词。 说明： 拆分时可以重复使用字典中的单词。 你可以假设字典中没有重复的单词。 示例 1： 输入: s = “leetcode”, wordDict = [“leet”, “code”] 输出: true 解释: 返回 true 因为 “leetcode” 可以被拆分成 “leet code”。 func wordBreak(s string,wordDict []string) bool { wordDictSet:=make(map[string]bool) for _,w:=range wordDict{ wordDictSet[w]=true } dp:=make([]bool,len(s)+1) dp[0]=true for i:=1;i\u003c=len(s);i++{ for j:=0;j\u003ci;j++{ if dp[j]\u0026\u0026 wordDictSet[s[j:i]]{ dp[i]=true break } } } return dp[len(s)] } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:18:0","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"打家劫舍 ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:19:0","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"I 你是一个专业的小偷，计划偷窃沿街的房屋。每间房内都藏有一定的现金，影响你偷窃的唯一制约因素就是相邻的房屋装有相互连通的防盗系统，如果两间相邻的房屋在同一晚上被小偷闯入，系统会自动报警。 给定一个代表每个房屋存放金额的非负整数数组，计算你 不触动警报装置的情况下 ，一夜之内能够偷窃到的最高金额。 示例 1： 输入：[1,2,3,1] 输出：4 解释：偷窃 1 号房屋 (金额 = 1) ，然后偷窃 3 号房屋 (金额 = 3)。 偷窃到的最高金额 = 1 + 3 = 4 。 func rob(nums []int) int { if len(nums)\u003c1{ return 0 } if len(nums)==1{ return nums[0] } if len(nums)==2{ return max(nums[0],nums[1]) } dp :=make([]int,len(nums)) dp[0]=nums[0] dp[1]=max(nums[0],nums[1]) for i:=2;i\u003clen(nums);i++{ dp[i]=max(dp[i-2]+nums[i],dp[i-1]) } return dp[len(dp)-1] } func max(a, b int) int { if a\u003eb{ return a } return b } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:19:1","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"II 你是一个专业的小偷，计划偷窃沿街的房屋，每间房内都藏有一定的现金。这个地方所有的房屋都 围成一圈 ，这意味着第一个房屋和最后一个房屋是紧挨着的。同时，相邻的房屋装有相互连通的防盗系统，如果两间相邻的房屋在同一晚上被小偷闯入，系统会自动报警 。 给定一个代表每个房屋存放金额的非负整数数组，计算你 在不触动警报装置的情况下 ，能够偷窃到的最高金额。 示例 1： 输入：nums = [2,3,2] 输出：3 解释：你不能先偷窃 1 号房屋（金额 = 2），然后偷窃 3 号房屋（金额 = 2）, 因为他们是相邻的。 // 打家劫舍Ⅱ 动态规划 // 时间复杂度O(n) 空间复杂度O(n) func rob(nums []int) int { if len(nums) == 1 { return nums[0] } if len(nums) == 2 { return max(nums[0], nums[1]) } result1 := robRange(nums, 0) result2 := robRange(nums, 1) return max(result1, result2) } // 偷盗指定的范围 func robRange(nums []int, start int) int { dp := make([]int, len(nums)) dp[1] = nums[start] for i := 2; i \u003c len(nums); i++ { dp[i] = max(dp[i - 2] + nums[i - 1 + start], dp[i - 1]) } return dp[len(nums) - 1] } func max(a, b int) int { if a \u003e b { return a } return b } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:19:2","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"III 在上次打劫完一条街道之后和一圈房屋后，小偷又发现了一个新的可行窃的地区。这个地区只有一个入口，我们称之为“根”。 除了“根”之外，每栋房子有且只有一个“父“房子与之相连。一番侦察之后，聪明的小偷意识到“这个地方的所有房屋的排列类似于一棵二叉树”。 如果两个直接相连的房子在同一天晚上被打劫，房屋将自动报警。 计算在不触动警报的情况下，小偷一晚能够盗取的最高金额。 动态规划 func rob(root *TreeNode) int { res := robTree(root) return max(res[0], res[1]) } func max(a, b int) int { if a \u003e b { return a } return b } func robTree(cur *TreeNode) []int { if cur == nil { return []int{0, 0} } // 后序遍历 left := robTree(cur.Left) right := robTree(cur.Right) // 考虑去偷当前的屋子 robCur := cur.Val + left[0] + right[0] // 考虑不去偷当前的屋子 notRobCur := max(left[0], left[1]) + max(right[0], right[1]) // **注意**顺序：0:不偷，1:去偷 return []int{notRobCur, robCur} } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:19:3","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"买卖股票的最佳时机 ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:20:0","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"I 给定一个数组 prices ，它的第 i 个元素 prices[i] 表示一支给定股票第 i 天的价格。 你只能选择 某一天 买入这只股票，并选择在 未来的某一个不同的日子 卖出该股票。设计一个算法来计算你所能获取的最大利润。 返回你可以从这笔交易中获取的最大利润。如果你不能获取任何利润，返回 0 。 示例 1： 输入：[7,1,5,3,6,4] 输出：5 解释：在第 2 天（股票价格 = 1）的时候买入，在第 5 天（股票价格 = 6）的时候卖出，最大利润 = 6-1 = 5 。**注意**利润不能是 7-1 = 6, 因为卖出价格需要大于买入价格；同时，你不能在买入前卖出股票。 func maxProfit(prices []int) int { length:=len(prices) if length==0{return 0} dp:=make([][]int,length) for i:=0;i\u003clength;i++{ dp[i]=make([]int,2) } dp[0][0]=-prices[0] dp[0][1]=0 for i:=1;i\u003clength;i++{ dp[i][0]=max(dp[i-1][0],-prices[i]) dp[i][1]=max(dp[i-1][1],dp[i-1][0]+prices[i]) } return dp[length-1][1] } func max(a,b int)int { if a\u003eb{ return a } return b } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:20:1","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"II 给定一个数组，它的第 i 个元素是一支给定股票第 i 天的价格。 设计一个算法来计算你所能获取的最大利润。你可以尽可能地完成更多的交易（多次买卖一支股票）。 注意：你不能同时参与多笔交易（你必须在再次购买前出售掉之前的股票）。 示例 1: 输入: [7,1,5,3,6,4] 输出: 7 解释: 在第 2 天（股票价格 = 1）的时候买入，在第 3 天（股票价格 = 5）的时候卖出, 这笔交易所能获得利润 = 5-1 = 4。随后，在第 4 天（股票价格 = 3）的时候买入，在第 5 天（股票价格 = 6）的时候卖出, 这笔交易所能获得利润 = 6-3 = 3 。 // 买卖股票的最佳时机Ⅱ 动态规划 // 时间复杂度：O(n) 空间复杂度：O(n) func maxProfit(prices []int) int { dp := make([][]int, len(prices)) status := make([]int, len(prices) * 2) for i := range dp { dp[i] = status[:2] status = status[2:] } dp[0][0] = -prices[0] for i := 1; i \u003c len(prices); i++ { dp[i][0] = max(dp[i - 1][0], dp[i - 1][1] - prices[i]) dp[i][1] = max(dp[i - 1][1], dp[i - 1][0] + prices[i]) } return dp[len(prices) - 1][1] } func max(a, b int) int { if a \u003e b { return a } return b } func maxProfit(prices []int) int { //创建数组 dp:=make([][]int,len(prices)) for i:=0;i\u003clen(prices);i++{ dp[i]=make([]int,2) } dp[0][0]=-prices[0] dp[0][1]=0 for i:=1;i\u003clen(prices);i++{ dp[i][0]=max(dp[i-1][0],dp[i-1][1]-prices[i]) dp[i][1]=max(dp[i-1][1],dp[i-1][0]+prices[i]) } return dp[len(prices)-1][1] } func max(a,b int)int{ if a\u003cb{ return b } return a } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:20:2","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"III 给定一个数组，它的第 i 个元素是一支给定的股票在第 i 天的价格。 设计一个算法来计算你所能获取的最大利润。你最多可以完成 两笔 交易。 注意：你不能同时参与多笔交易（你必须在再次购买前出售掉之前的股票）。 示例 1: 输入：prices = [3,3,5,0,0,3,1,4] 输出：6 解释：在第 4 天（股票价格 = 0）的时候买入，在第 6 天（股票价格 = 3）的时候卖出，这笔交易所能获得利润 = 3-0 = 3 。随后，在第 7 天（股票价格 = 1）的时候买入，在第 8 天 （股票价格 = 4）的时候卖出，这笔交易所能获得利润 = 4-1 = 3。 func maxProfit(prices []int) int { dp:=make([][]int,len(prices)) for i:=0;i\u003clen(prices);i++{ dp[i]=make([]int,5) } dp[0][0]=0 dp[0][1]=-prices[0] dp[0][2]=0 dp[0][3]=-prices[0] dp[0][4]=0 for i:=1;i\u003clen(prices);i++{ dp[i][0]=dp[i-1][0] dp[i][1]=max(dp[i-1][1],dp[i-1][0]-prices[i]) dp[i][2]=max(dp[i-1][2],dp[i-1][1]+prices[i]) dp[i][3]=max(dp[i-1][3],dp[i-1][2]-prices[i]) dp[i][4]=max(dp[i-1][4],dp[i-1][3]+prices[i]) } return dp[len(prices)-1][4] } func max(a,b int)int{ if a\u003eb{ return a } return b } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:20:3","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"IV 给定一个整数数组 prices ，它的第 i 个元素 prices[i] 是一支给定的股票在第 i 天的价格。 设计一个算法来计算你所能获取的最大利润。你最多可以完成 k 笔交易。 注意：你不能同时参与多笔交易（你必须在再次购买前出售掉之前的股票）。 示例 1： 输入：k = 2, prices = [2,4,1] 输出：2 解释：在第 1 天 (股票价格 = 2) 的时候买入，在第 2 天 (股票价格 = 4) 的时候卖出，这笔交易所能获得利润 = 4-2 = 2。 版本一： // 买卖股票的最佳时机IV 动态规划 // 时间复杂度O(kn) 空间复杂度O(kn) func maxProfit(k int, prices []int) int { if k == 0 || len(prices) == 0 { return 0 } dp := make([][]int, len(prices)) status := make([]int, (2 * k + 1) * len(prices)) for i := range dp { dp[i] = status[:2 * k + 1] status = status[2 * k + 1:] } for j := 1; j \u003c 2 * k; j += 2 { dp[0][j] = -prices[0] } for i := 1; i \u003c len(prices); i++ { for j := 0; j \u003c 2 * k; j += 2 { dp[i][j + 1] = max(dp[i - 1][j + 1], dp[i - 1][j] - prices[i]) dp[i][j + 2] = max(dp[i - 1][j + 2], dp[i - 1][j + 1] + prices[i]) } } return dp[len(prices) - 1][2 * k] } func max(a, b int) int { if a \u003e b { return a } return b } func maxProfit(k int, prices []int) int { if len(prices)==0{ return 0 } dp:=make([][]int,len(prices)) for i:=0;i\u003clen(prices);i++{ dp[i]=make([]int,2*k+1) } for i:=1;i\u003clen(dp[0]);i++{ if i%2!=0{ dp[0][i]=-prices[0] } } for i:=1;i\u003clen(prices);i++{ dp[i][0]=dp[i-1][0] for j:=1;j\u003clen(dp[0]);j++{ if j%2!=0{ dp[i][j]=max(dp[i-1][j],dp[i-1][j-1]-prices[i]) }else { dp[i][j]=max(dp[i-1][j],dp[i-1][j-1]+prices[i]) } } } return dp[len(prices)-1][2*k] } func max(a,b int)int{ if a\u003eb{ return a } return b } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:20:4","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"最佳买卖股票时机含冷冻期 给定一个整数数组，其中第 i 个元素代表了第 i 天的股票价格 。 设计一个算法计算出最大利润。在满足以下约束条件下，你可以尽可能地完成更多的交易（多次买卖一支股票）: 你不能同时参与多笔交易（你必须在再次购买前出售掉之前的股票）。 卖出股票后，你无法在第二天买入股票 (即冷冻期为 1 天)。 示例: 输入: [1,2,3,0,2] 输出: 3 解释: 对应的交易状态为: [买入, 卖出, 冷冻期, 买入, 卖出] // 最佳买卖股票时机含冷冻期 动态规划 // 时间复杂度O(n) 空间复杂度O(n) func maxProfit(prices []int) int { n := len(prices) if n \u003c 2 { return 0 } dp := make([][]int, n) status := make([]int, n * 4) for i := range dp { dp[i] = status[:4] status = status[4:] } dp[0][0] = -prices[0] for i := 1; i \u003c n; i++ { dp[i][0] = max(dp[i - 1][0], max(dp[i - 1][1] - prices[i], dp[i - 1][3] - prices[i])) dp[i][1] = max(dp[i - 1][1], dp[i - 1][3]) dp[i][2] = dp[i - 1][0] + prices[i] dp[i][3] = dp[i - 1][2] } return max(dp[n - 1][1], max(dp[n - 1][2], dp[n - 1][3])) } func max(a, b int) int { if a \u003e b { return a } return b } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:20:5","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"最佳买卖股票时机含手续费 给定一个整数数组 prices，其中第 i 个元素代表了第 i 天的股票价格 ；非负整数 fee 代表了交易股票的手续费用。 你可以无限次地完成交易，但是你每笔交易都需要付手续费。如果你已经购买了一个股票，在卖出它之前你就不能再继续购买股票了。 返回获得利润的最大值。 注意：这里的一笔交易指买入持有并卖出股票的整个过程，每笔交易你只需要为支付一次手续费。 示例 1: 输入: prices = [1, 3, 2, 8, 4, 9], fee = 2 输出: 8 解释: 能够达到的最大利润: 在此处买入 prices[0] = 1 在此处卖出 prices[3] = 8 在此处买入 prices[4] = 4 在此处卖出 prices[5] = 9 总利润: ((8 - 1) - 2) + ((9 - 4) - 2) = 8. // 买卖股票的最佳时机含手续费 动态规划 // 时间复杂度O(n) 空间复杂度O(n) func maxProfit(prices []int, fee int) int { n := len(prices) dp := make([][2]int, n) dp[0][0] = -prices[0] for i := 1; i \u003c n; i++ { dp[i][1] = max(dp[i-1][1], dp[i-1][0] + prices[i] - fee) dp[i][0] = max(dp[i-1][0], dp[i-1][1] - prices[i]) } return dp[n-1][1] } func max(a, b int) int { if a \u003e b { return a } return b } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:20:6","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"股票问题总结 代码随想录 ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:21:0","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"最长上升子序列 给你一个整数数组 nums ，找到其中最长严格递增子序列的长度。 子序列是由数组派生而来的序列，删除（或不删除）数组中的元素而不改变其余元素的顺序。例如，[3,6,2,7] 是数组 [0,3,1,6,2,2,7] 的子序列。 示例 1： 输入：nums = [10,9,2,5,3,7,101,18] 输出：4 解释：最长递增子序列是 [2,3,7,101]，因此长度为 4 。 func lengthOfLIS(nums []int ) int { dp := []int{} for _, num := range nums { if len(dp) ==0 || dp[len(dp) - 1] \u003c num { dp = append(dp, num) } else { l, r := 0, len(dp) - 1 pos := r for l \u003c= r { mid := (l + r) \u003e\u003e 1 if dp[mid] \u003e= num { pos = mid; r = mid - 1 } else { l = mid + 1 } } dp[pos] = num }//二分查找 } return len(dp) } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:22:0","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"最长连续递增序列 给定一个未经排序的整数数组，找到最长且 连续递增的子序列，并返回该序列的长度。 连续递增的子序列 可以由两个下标 l 和 r（l \u003c r）确定，如果对于每个 l \u003c= i \u003c r，都有 nums[i] \u003c nums[i + 1] ，那么子序列 [nums[l], nums[l + 1], …, nums[r - 1], nums[r]] 就是连续递增子序列。 示例 1： 输入：nums = [1,3,5,4,7] 输出：3 解释：最长连续递增序列是 [1,3,5], 长度为3。 尽管 [1,3,5,7] 也是升序的子序列, 但它不是连续的，因为 5 和 7 在原数组里被 4 隔开。 动态规划： class Solution: def findLengthOfLCIS(self, nums: List[int]) -\u003e int: if len(nums) == 0: return 0 result = 1 dp = [1] * len(nums) for i in range(len(nums)-1): if nums[i+1] \u003e nums[i]: #连续记录 dp[i+1] = dp[i] + 1 result = max(result, dp[i+1]) return result 贪心法： class Solution: def findLengthOfLCIS(self, nums: List[int]) -\u003e int: if len(nums) == 0: return 0 result = 1 #连续子序列最少也是1 count = 1 for i in range(len(nums)-1): if nums[i+1] \u003e nums[i]: #连续记录 count += 1 else: #不连续，count从头开始 count = 1 result = max(result, count) return result ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:23:0","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"最长重复子数组 给两个整数数组 A 和 B ，返回两个数组中公共的、长度最长的子数组的长度。 示例： 输入： A: [1,2,3,2,1] B: [3,2,1,4,7] 输出：3 解释： 长度最长的公共子数组是 [3, 2, 1] 。 func findLength(A []int, B []int) int { m, n := len(A), len(B) res := 0 dp := make([][]int, m+1) for i := 0; i \u003c= m; i++ { dp[i] = make([]int, n+1) } for i := 1; i \u003c= m; i++ { for j := 1; j \u003c= n; j++ { if A[i-1] == B[j-1] { dp[i][j] = dp[i-1][j-1] + 1 } if dp[i][j] \u003e res { res = dp[i][j] } } } return res } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:24:0","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"最长公共子序列 给定两个字符串 text1 和 text2，返回这两个字符串的最长公共子序列的长度。 一个字符串的 子序列 是指这样一个新的字符串：它是由原字符串在不改变字符的相对顺序的情况下删除某些字符（也可以不删除任何字符）后组成的新字符串。 例如，“ace” 是 “abcde” 的子序列，但 “aec” 不是 “abcde” 的子序列。两个字符串的「公共子序列」是这两个字符串所共同拥有的子序列。 若这两个字符串没有公共子序列，则返回 0。 示例 1: 输入：text1 = \"abcde\", text2 = \"ace\" 输出：3 解释：最长公共子序列是 \"ace\"，它的长度为 3。 func longestCommonSubsequence(text1 string, text2 string) int { t1 := len(text1) t2 := len(text2) dp:=make([][]int,t1+1) for i:=range dp{ dp[i]=make([]int,t2+1) } for i := 1; i \u003c= t1; i++ { for j := 1; j \u003c=t2; j++ { if text1[i-1]==text2[j-1]{ dp[i][j]=dp[i-1][j-1]+1 }else{ dp[i][j]=max(dp[i-1][j],dp[i][j-1]) } } } return dp[t1][t2] } func max(a,b int)int { if a\u003eb{ return a } return b } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:25:0","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"不相交的线 我们在两条独立的水平线上按给定的顺序写下 A 和 B 中的整数。 现在，我们可以绘制一些连接两个数字 A[i] 和 B[j] 的直线，只要 A[i] == B[j]，且我们绘制的直线不与任何其他连线（非水平线）相交。 以这种方法绘制线条，并返回我们可以绘制的最大连线数。 func maxUncrossedLines(A []int, B []int) int { m, n := len(A), len(B) dp := make([][]int, m+1) for i := range dp { dp[i] = make([]int, n+1) } for i := 1; i \u003c= len(A); i++ { for j := 1; j \u003c= len(B); j++ { if (A[i - 1] == B[j - 1]) { dp[i][j] = dp[i - 1][j - 1] + 1 } else { dp[i][j] = max(dp[i - 1][j], dp[i][j - 1]) } } } return dp[m][n] } func max(a, b int) int { if a \u003e b { return a } return b } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:26:0","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"最大子序和 给定一个整数数组 nums ，找到一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。 示例: 输入: [-2,1,-3,4,-1,2,1,-5,4] 输出: 6 解释: 连续子数组 [4,-1,2,1] 的和最大，为 6 // solution // 1, dp // 2, 贪心 func maxSubArray(nums []int) int { n := len(nums) // 这里的dp[i] 表示，最大的连续子数组和，包含num[i] 元素 dp := make([]int,n) // 初始化，由于dp 状态转移方程依赖dp[0] dp[0] = nums[0] // 初始化最大的和 mx := nums[0] for i:=1;i\u003cn;i++ { // 这里的状态转移方程就是：求最大和 // 会面临2种情况，一个是带前面的和，一个是不带前面的和 dp[i] = max(dp[i-1]+nums[i],nums[i]) mx = max(mx,dp[i]) } return mx } func max(a,b int) int{ if a\u003eb { return a } return b } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:27:0","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"判断子序列 给定字符串 s 和 t ，判断 s 是否为 t 的子序列。 字符串的一个子序列是原始字符串删除一些（也可以不删除）字符而不改变剩余字符相对位置形成的新字符串。（例如，“ace\"是\"abcde\"的一个子序列，而\"aec\"不是）。 示例 1： 输入：s = “abc”, t = “ahbgdc” 输出：true 示例 2： 输入：s = “axc”, t = “ahbgdc” 输出：false func isSubsequence(s string, t string) bool { dp := make([][]int,len(s)+1) for i:=0;i\u003clen(dp);i++{ dp[i] = make([]int,len(t)+1) } for i:=1;i\u003clen(dp);i++{ for j:=1;j\u003clen(dp[i]);j++{ if s[i-1] == t[j-1]{ dp[i][j] = dp[i-1][j-1] +1 }else{ dp[i][j] = dp[i][j-1] } } } return dp[len(s)][len(t)]==len(s) } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:28:0","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"不同的子序列 给定一个字符串 s 和一个字符串 t ，计算在 s 的子序列中 t 出现的个数。 字符串的一个 子序列 是指，通过删除一些（也可以不删除）字符且不干扰剩余字符相对位置所组成的新字符串。（例如，“ACE” 是 “ABCDE” 的一个子序列，而 “AEC” 不是） 题目数据保证答案符合 32 位带符号整数范围。 func numDistinct(s string, t string) int { dp:= make([][]int,len(s)+1) for i:=0;i\u003clen(dp);i++{ dp[i] = make([]int,len(t)+1) } // 初始化 for i:=0;i\u003clen(dp);i++{ dp[i][0] = 1 } // dp[0][j] 为 0，默认值，因此不需要初始化 for i:=1;i\u003clen(dp);i++{ for j:=1;j\u003clen(dp[i]);j++{ if s[i-1] == t[j-1]{ dp[i][j] = dp[i-1][j-1] + dp[i-1][j] }else{ dp[i][j] = dp[i-1][j] } } } return dp[len(dp)-1][len(dp[0])-1] } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:29:0","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"两个字符串的删除操作 给定两个单词 word1 和 word2，找到使得 word1 和 word2 相同所需的最小步数，每步可以删除任意一个字符串中的一个字符。 示例： 输入: \"sea\", \"eat\" 输出: 2 解释: 第一步将\"sea\"变为\"ea\"，第二步将\"eat\"变为\"ea\" ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:30:0","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"编辑距离 给你两个单词 word1 和 word2，请你计算出将 word1 转换成 word2 所使用的最少操作数 。 你可以对一个单词进行如下三种操作： 插入一个字符 删除一个字符 替换一个字符 示例 1： 输入：word1 = “horse”, word2 = “ros” 输出：3 解释： horse -\u003e rorse (将 ‘h’ 替换为 ‘r’) rorse -\u003e rose (删除 ‘r’) rose -\u003e ros (删除 ‘e’) func minDistance(word1 string, word2 string) int { m, n := len(word1), len(word2) dp := make([][]int, m+1) for i := range dp { dp[i] = make([]int, n+1) } for i := 0; i \u003c m+1; i++ { dp[i][0] = i // word1[i] 变成 word2[0], 删掉 word1[i], 需要 i 部操作 } for j := 0; j \u003c n+1; j++ { dp[0][j] = j // word1[0] 变成 word2[j], 插入 word1[j]，需要 j 部操作 } for i := 1; i \u003c m+1; i++ { for j := 1; j \u003c n+1; j++ { if word1[i-1] == word2[j-1] { dp[i][j] = dp[i-1][j-1] } else { // Min(插入，删除，替换) dp[i][j] = Min(dp[i][j-1], dp[i-1][j], dp[i-1][j-1]) + 1 } } } return dp[m][n] } func Min(args ...int) int { min := args[0] for _, item := range args { if item \u003c min { min = item } } return min } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:31:0","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"编辑距离总结 代码随想录 ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:31:1","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"回文子串 给定一个字符串，你的任务是计算这个字符串中有多少个回文子串。 具有不同开始位置或结束位置的子串，即使是由相同的字符组成，也会被视作不同的子串。 示例 1： 输入：“abc” 输出：3 解释：三个回文子串: “a”, “b”, “c” func countSubstrings(s string) int { res:=0 dp:=make([][]bool,len(s)) for i:=0;i\u003clen(s);i++{ dp[i]=make([]bool,len(s)) } for i:=len(s)-1;i\u003e=0;i--{ for j:=i;j\u003clen(s);j++{ if s[i]==s[j]{ if j-i\u003c=1{ res++ dp[i][j]=true }else if dp[i+1][j-1]{ res++ dp[i][j]=true } } } } return res } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:32:0","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"最长回文子序列 给定一个字符串 s ，找到其中最长的回文子序列，并返回该序列的长度。可以假设 s 的最大长度为 1000 。 示例 1: 输入: “bbbab” 输出: 4 一个可能的最长回文子序列为 “bbbb”。 示例 2: 输入:“cbbd” 输出: 2 一个可能的最长回文子序列为 “bb”。 func longestPalindromeSubseq(s string) int { lenth:=len(s) dp:=make([][]int,lenth) for i:=0;i\u003clenth;i++{ for j:=0;j\u003clenth;j++{ if dp[i]==nil{ dp[i]=make([]int,lenth) } if i==j{ dp[i][j]=1 } } } for i:=lenth-1;i\u003e=0;i--{ for j:=i+1;j\u003clenth;j++{ if s[i]==s[j]{ dp[i][j]=dp[i+1][j-1]+2 }else { dp[i][j]=max(dp[i+1][j],dp[i][j-1]) } } } return dp[0][lenth-1] } ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:33:0","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"DP总结 代码随想录 ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:34:0","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"开篇词｜为什么大厂都爱考动态规划？ 你好，我是卢誉声，很高兴能在这个专栏与你见面，和你一起搞定动态规划。开门见山，我先做一个自我介绍。最开始，我在思科系统（Cisco Systems）工作，曾参与设计和开发了下一代视频会议系统的核心数据交换服务。我的工作涵盖了协议栈开发、微服务设计、分布式系统编配以及弹性算法设计。这段经历让我形成了一个认知：算法对设计关键服务来说十分重要，它决定了系统的稳定性、弹性以及可扩展性。后来，我加入了 Autodesk，成为了一款三维设计旗舰软件的框架和平台软件工程师。负责开发了基于大规模结构化数据的高性能搜索引擎，首次将灵活的多线程和异步框架带入产品框架层面，在原有的底层内存模型上采用了改进后的检索引擎，相较于原有的搜索功能，实现了超过 300 倍的性能提升。除此之外，我还改进并维护了用于改进用户体验的数据处理系统，在平台框架层面的工作，让我积累了大量的工程实践经验。现在，我在 Autodesk 数据平台就职，负责设计和开发大规模数据的分析、丰富化以及流化分布式服务。我发现自己的职业发展一直围绕着数据在不断前进。基于此，我常说的一句话是：“数据即是正义”。那直到今天，我的态度依然没有变。数据为媒，算法为介，而在极其重要的算法中，动态规划其实占了很大的比重。 事实上，如果你平常关注大厂面试的话，你会发现，但凡是研发岗位，无论是招聘初级还是高级工程师，大厂都倾向于安排一轮或多轮专门的算法面试环节，而且在面试环节提出动态规划相关问题的这种趋势已经愈发明显。这是为什么呢？我来谈谈我的看法。 先说算法这件事吧。我想请你回想一下，当处理数据结构相关的问题时，你有没有这样的经历？你本能地到工具函数或者库函数中寻找有没有现成的工具。如果问题得到快速解决，它是不是迅速就成了过眼云烟？如果这个问题看起来比较棘手，它不是一个典型的算法问题，那么就寻求搜索引擎的帮助，或者干脆访问 Stack Overflow 这样的“智库”寻找前人留下的解决方案？虽然平时工作中表现优异，但当你想换工作参加大厂面试时，又发现自己难以解决面试官提出的算法问题，无从下手，面对白板“望洋兴叹”？ 相信我，你不是一个人！这种现象很普遍。其实，对于开发人员来说，算法和数据结构就是我们的基本功。我们常常自嘲软件研发人员的工作就是复制粘贴，搬砖就是日常工作的全部。但当公司或部门要求你去研究一个全新的技术，或者快速阅读一份开发多年且成熟的开源项目代码，并对其改造来服务于自己的产品功能时，你的压力会让你明白基本功到底有多重要！关于基本功这事儿，我要插个故事进来，再多说几句。我曾有幸与 C++ 之父 Bjarne Stroustrup 先生进行过面对面的交流。我问了他一个问题：“如今新生代技术人员倾向于学习 Java、Go 或 Python 这些更容易上手的编程语言，您是如何看待这个现象的？”Stroustrup 先生的回答大概是这样的：“如果一个人只了解一种编程语言，那么他不能称自己是专业人士，而从我的角度上看，将 C++ 作为基础，能让你深入洞察各种各样编程语言背后的思想和设计思路。” 我作为面试官曾接触过许多优秀的候选人，他们有着各种各样的背景，既有潜力又非常努力，但在面对算法问题和解决问题时没有太多思路，始终无法更上一层楼，十分遗憾。而动态规划恰恰是解决问题的重要方法论，面对很多数据处理的应用场景，它在降低时间复杂度上极具优势，因此成为了考察重点。不仅如此，动态规划问题还能很好地考察面试者的数学模型抽象能力和逻辑思维能力，可以反应个人在算法上的综合能力。所以我觉得，大厂之所以如此看中一个面试者的算法基础，特别是动态规划问题的解决能力，是因为他们更加看中一位面试者解决问题的思路与逻辑思维能力，而不只是工具与技能的熟练程度。 不同于普通算法，如排序或递归，动态规划从名字上看就显得很特别，有些“高端、大气、上档次”的味道在里面。但其实它离我们很近。我举个例子你就明白了，在云计算平台上一个解决方案的计算能力（容量）肯定是有限的，那么为了高效服务那些重要程度或优先级最高的客户，同时又不想浪费计算资源（说白了为了省钱），我们该怎么办？这个问题其实可以通过队列这样的分发方式来进行一个简单的编配。但是这不够好，如果我们能够事先知道一个计算任务的重要程度和所需的计算时长，就可以通过动态规划算法来进行预演算，从数学角度推导出一个严谨的编排结果，实现有限资源的最大化利用。 你看，似乎遥不可及的动态规划问题，其实就是求最优解问题，它无时无刻都在我们身边，总是戏剧般地提高了最优化问题的性能！这再一次凸显出大厂为何青睐于动态规划问题，而且成为了区别面试者的一个隐形门槛。甚至可以说，掌握动态规划思想，在工作面试、技术等级晋升上都扮演了核心角色。总之一句话，动归必学。 模块一：初识动态规划我会为你讲解复杂面试题的思考和解决方式。从贪心算法开始，一步步阐述动态规划的由来，并通过一个贯穿全篇的例子来展现动态规划的强大之处。学习和掌握这些经典的处理方法，能够为你后续掌握动态规划打下一个坚实基础。通过这部分内容，你会系统了解到动态规划问题的特点和解题经验。模块二：动态规划的套路我会为你讲解动态规划问题的解题框架和套路，你可以把这个套路理解成是解决动归问题的模板。在此模板的基础上，我会向你讲解面试真题，有针对性地套用解题框架。而应对面试题的纷繁复杂，我会为你进行有效的分类，并针对每一种动态规划问题进行深入而全面的讲解。通过这部分内容，你会快速掌握常见面试题的解题套路。模块三：举一反三，突破套路我会针对几种特别易考的动态规划面试题进行总结，帮助你攻破套路。并在这些高级话题的基础上，提出设计动态规划算法的关键问题。另外，还有刷题指南，所谓孰能生巧，必要的练习我们还是要的。通过这部分内容，你会快速掌握动态规划面试题的进阶法门。 ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:35:0","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"什么样的问题应该使用动态规划？ 动态规划问题的典型特点：求“最”优解问题（最大值和最小值）、求可行性（True 或 False）、求方案总数、数据结构不可排序（Unsortable）、算法不可使用交换（Non-swappable）。 数据不可排序（Unsortable） 假设我们有一个无序数列，希望求出这个数列中最大的两个数字之和。很多初学者刚刚学完动态规划会走火入魔到看到最优化问题就想用动态规划来求解，嗯，那么这样应该也是可以的吧……不，等等，这个问题不是简单做一个排序或者做一个遍历就可以求解出来了吗？ 数据不可交换（Non-swapable） 还有一类问题，可以归类到我们总结的几类问题里去，但是不存在动态规划要求的重叠子问题（比如经典的八皇后问题），那么这类问题就无法通过动态规划求解。这种情况需要避免被套进去。 ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:36:0","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":"常见的动态规划面试题串烧 简单的路径规划、带障碍的路径规划、跳跃游戏（题目：给出一个非负整数数组 A，你最初定位在数组的第一个位置。数组中的每个元素代表你在那个位置可以跳跃的最大长度。判断你是否能到达数组的最后一个位置。） ","date":"2022-01-06 08:27:39","objectID":"/algorithm_dynamicprogramming/:37:0","tags":["data structure"],"title":"Algorithm_dynamicProgramming","uri":"/algorithm_dynamicprogramming/"},{"categories":["Coding"],"content":" 学习代码随想录笔记 贪心算法 ","date":"2022-01-06 08:23:51","objectID":"/algorithm_greedy/:0:0","tags":["data structure"],"title":"Algorithm_greedy","uri":"/algorithm_greedy/"},{"categories":["Coding"],"content":"理论基础 贪心算法一般分为如下四步： 将问题分解为若干个子问题 找出适合的贪心策略 求解每一个子问题的最优解 将局部最优解堆叠成全局最优解 ","date":"2022-01-06 08:23:51","objectID":"/algorithm_greedy/:1:0","tags":["data structure"],"title":"Algorithm_greedy","uri":"/algorithm_greedy/"},{"categories":["Coding"],"content":"分发饼干 假设你是一位很棒的家长，想要给你的孩子们一些小饼干。但是，每个孩子最多只能给一块饼干。 对每个孩子 i，都有一个胃口值 g[i]，这是能让孩子们满足胃口的饼干的最小尺寸；并且每块饼干 j，都有一个尺寸 s[j] 。如果 s[j] \u003e= g[i]，我们可以将这个饼干 j 分配给孩子 i ，这个孩子会得到满足。你的目标是尽可能满足越多数量的孩子，并输出这个最大数值。 示例 1: 输入: g = [1,2,3], s = [1,1] 输出: 1 解释:你有三个孩子和两块小饼干，3个孩子的胃口值分别是：1,2,3。虽然你有两块小饼干，由于他们的尺寸都是1，你只能让胃口值是1的孩子满足。所以你应该输出1。 //排序后，局部最优 func findContentChildren(g []int, s []int) int { sort.Ints(g) sort.Ints(s) // 从小到大 child := 0 for sIdx := 0; child \u003c len(g) \u0026\u0026 sIdx \u003c len(s); sIdx++ { if s[sIdx] \u003e= g[child] {//如果饼干的大小大于或等于孩子的为空则给与，否则不给予，继续寻找选一个饼干是否符合 child++ } } return child } ","date":"2022-01-06 08:23:51","objectID":"/algorithm_greedy/:2:0","tags":["data structure"],"title":"Algorithm_greedy","uri":"/algorithm_greedy/"},{"categories":["Coding"],"content":"摆动序列 如果连续数字之间的差严格地在正数和负数之间交替，则数字序列称为摆动序列。第一个差（如果存在的话）可能是正数或负数。少于两个元素的序列也是摆动序列。 例如， [1,7,4,9,2,5] 是一个摆动序列，因为差值 (6,-3,5,-7,3) 是正负交替出现的。相反, [1,4,7,2,5] 和 [1,7,4,5,5] 不是摆动序列，第一个序列是因为它的前两个差值都是正数，第二个序列是因为它的最后一个差值为零。 给定一个整数序列，返回作为摆动序列的最长子序列的长度。 通过从原始序列中删除一些（也可以不删除）元素来获得子序列，剩下的元素保持其原始顺序。 示例 1: 输入: [1,7,4,9,2,5] 输出: 6 解释: 整个序列均为摆动序列。 示例 2: 输入: [1,17,5,10,13,15,10,5,16,8] 输出: 7 解释: 这个序列包含几个长度为 7 摆动序列，其中一个可为[1,17,10,13,10,16,8]。 贪心或者dp func wiggleMaxLength(nums []int) int { var count,preDiff,curDiff int count=1 if len(nums)\u003c2{ return count } for i:=0;i\u003clen(nums)-1;i++{ curDiff=nums[i+1]-nums[i] //如果有正有负则更新下标值||或者只有前一个元素为0（针对两个不等元素的序列也视作摆动序列，且摆动长度为2） if (curDiff \u003e 0 \u0026\u0026 preDiff \u003c= 0) || (preDiff \u003e= 0 \u0026\u0026 curDiff \u003c 0){ preDiff=curDiff count++ } } return count } ","date":"2022-01-06 08:23:51","objectID":"/algorithm_greedy/:3:0","tags":["data structure"],"title":"Algorithm_greedy","uri":"/algorithm_greedy/"},{"categories":["Coding"],"content":"最大子序和 给定一个整数数组 nums ，找到一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。 示例: 输入: [-2,1,-3,4,-1,2,1,-5,4] 输出: 6 解释: 连续子数组 [4,-1,2,1] 的和最大，为 6 贪心或者dp func maxSubArray(nums []int) int { maxSum := nums[0] for i := 1; i \u003c len(nums); i++ { if nums[i] + nums[i-1] \u003e nums[i] { nums[i] += nums[i-1] } if nums[i] \u003e maxSum { maxSum = nums[i] } } return maxSum } ","date":"2022-01-06 08:23:51","objectID":"/algorithm_greedy/:4:0","tags":["data structure"],"title":"Algorithm_greedy","uri":"/algorithm_greedy/"},{"categories":["Coding"],"content":"买卖股票的最佳时机II 给定一个数组，它的第 i 个元素是一支给定股票第 i 天的价格。 设计一个算法来计算你所能获取的最大利润。你可以尽可能地完成更多的交易（多次买卖一支股票）。 注意：你不能同时参与多笔交易（你必须在再次购买前出售掉之前的股票）。 示例 1: 输入: [7,1,5,3,6,4] 输出: 7 解释: 在第 2 天（股票价格 = 1）的时候买入，在第 3 天（股票价格 = 5）的时候卖出, 这笔交易所能获得利润 = 5-1 = 4。随后，在第 4 天（股票价格 = 3）的时候买入，在第 5 天（股票价格 = 6）的时候卖出, 这笔交易所能获得利润 = 6-3 = 3 。 示例 2: 输入: [1,2,3,4,5] 输出: 4 解释: 在第 1 天（股票价格 = 1）的时候买入，在第 5 天 （股票价格 = 5）的时候卖出, 这笔交易所能获得利润 = 5-1 = 4 。**注意**你不能在第 1 天和第 2 天接连购买股票，之后再将它们卖出。因为这样属于同时参与了多笔交易，你必须在再次购买前出售掉之前的股票。 示例 3: 输入: [7,6,4,3,1] 输出: 0 解释: 在这种情况下, 没有交易完成, 所以最大利润为 0 贪心或者dp //贪心算法 func maxProfit(prices []int) int { var sum int for i := 1; i \u003c len(prices); i++ { // 累加每次大于0的交易 if prices[i]-prices[i-1] \u003e 0 { sum += prices[i]-prices[i-1] } } return sum } //确定售卖点 func maxProfit(prices []int) int { var result,buy int prices=append(prices,0)//在price末尾加个0，防止price一直递增 /** 思路：检查后一个元素是否大于当前元素，如果小于，则表明这是一个售卖点，当前元素的值减去购买时候的值 如果不小于，说明后面有更好的售卖点， **/ for i:=0;i\u003clen(prices)-1;i++{ if prices[i]\u003eprices[i+1]{ result+=prices[i]-prices[buy] buy=i+1 }else if prices[buy]\u003eprices[i]{//更改最低购买点 buy=i } } return result } ","date":"2022-01-06 08:23:51","objectID":"/algorithm_greedy/:5:0","tags":["data structure"],"title":"Algorithm_greedy","uri":"/algorithm_greedy/"},{"categories":["Coding"],"content":"跳跃游戏 ","date":"2022-01-06 08:23:51","objectID":"/algorithm_greedy/:6:0","tags":["data structure"],"title":"Algorithm_greedy","uri":"/algorithm_greedy/"},{"categories":["Coding"],"content":"I 给定一个非负整数数组，你最初位于数组的第一个位置。 数组中的每个元素代表你在该位置可以跳跃的最大长度。 判断你是否能够到达最后一个位置。 func canJUmp(nums []int) bool { if len(nums)\u003c=1{ return true } dp:=make([]bool,len(nums)) dp[0]=true for i:=1;i\u003clen(nums);i++{ for j:=i-1;j\u003e=0;j--{ if dp[j]\u0026\u0026nums[j]+j\u003e=i{ dp[i]=true break } } } return dp[len(nums)-1] } ","date":"2022-01-06 08:23:51","objectID":"/algorithm_greedy/:6:1","tags":["data structure"],"title":"Algorithm_greedy","uri":"/algorithm_greedy/"},{"categories":["Coding"],"content":"II 给定一个非负整数数组，你最初位于数组的第一个位置。 数组中的每个元素代表你在该位置可以跳跃的最大长度。 你的目标是使用最少的跳跃次数到达数组的最后一个位置。 func jump(nums []int) int { dp:=make([]int ,len(nums)) dp[0]=0 for i:=1;i\u003clen(nums);i++{ dp[i]=i for j:=0;j\u003ci;j++{ if nums[j]+j\u003ei{ dp[i]=min(dp[j]+1,dp[i]) } } } return dp[len(nums)-1] } ","date":"2022-01-06 08:23:51","objectID":"/algorithm_greedy/:6:2","tags":["data structure"],"title":"Algorithm_greedy","uri":"/algorithm_greedy/"},{"categories":["Coding"],"content":"K次取反后最大化的数组和 给定一个整数数组 A，我们只能用以下方法修改该数组：我们选择某个索引 i 并将 A[i] 替换为 -A[i]，然后总共重复这个过程 K 次。（我们可以多次选择同一个索引 i。） 以这种方式修改数组后，返回数组可能的最大和。 func largestSumAfterKNegations(nums []int, K int) int { sort.Slice(nums, func(i, j int) bool { return math.Abs(float64(nums[i])) \u003e math.Abs(float64(nums[j])) }) for i := 0; i \u003c len(nums); i++ { if K \u003e 0 \u0026\u0026 nums[i] \u003c 0 { nums[i] = -nums[i] K-- } } if K%2 == 1 { nums[len(nums)-1] = -nums[len(nums)-1] } result := 0 for i := 0; i \u003c len(nums); i++ { result += nums[i] } return result } ","date":"2022-01-06 08:23:51","objectID":"/algorithm_greedy/:7:0","tags":["data structure"],"title":"Algorithm_greedy","uri":"/algorithm_greedy/"},{"categories":["Coding"],"content":"加油站 在一条环路上有 N 个加油站，其中第 i 个加油站有汽油 gas[i] 升。 你有一辆油箱容量无限的的汽车，从第 i 个加油站开往第 i+1 个加油站需要消耗汽油 cost[i] 升。你从其中的一个加油站出发，开始时油箱为空。 如果你可以绕环路行驶一周，则返回出发时加油站的编号，否则返回 -1。 如果题目有解，该答案即为唯一答案。 输入数组均为非空数组，且长度相同。 输入数组中的元素均为非负数。 func canCompleteCircuit(gas []int, cost []int) int { curSum := 0 totalSum := 0 start := 0 for i := 0; i \u003c len(gas); i++ { curSum += gas[i] - cost[i] totalSum += gas[i] - cost[i] if curSum \u003c 0 { start = i+1 curSum = 0 } } if totalSum \u003c 0 { return -1 } return start } ","date":"2022-01-06 08:23:51","objectID":"/algorithm_greedy/:8:0","tags":["data structure"],"title":"Algorithm_greedy","uri":"/algorithm_greedy/"},{"categories":["Coding"],"content":"分发糖果 老师想给孩子们分发糖果，有 N 个孩子站成了一条直线，老师会根据每个孩子的表现，预先给他们评分。 你需要按照以下要求，帮助老师给这些孩子分发糖果： 每个孩子至少分配到 1 个糖果。 相邻的孩子中，评分高的孩子必须获得更多的糖果。 那么这样下来，老师至少需要准备多少颗糖果呢？ 示例 1: 输入: [1,0,2] 输出: 5 解释: 你可以分别给这三个孩子分发 2、1、2 颗糖果。 示例 2: 输入: [1,2,2] 输出: 4 解释: 你可以分别给这三个孩子分发 1、2、1 颗糖果。第三个孩子只得到 1 颗糖果，这已满足上述两个条件。 func candy(ratings []int) int { /**先确定一边，再确定另外一边 1.先从左到右，当右边的大于左边的就加1 2.再从右到左，当左边的大于右边的就再加1 **/ need:=make([]int,len(ratings)) sum:=0 //初始化(每个人至少一个糖果) for i:=0;i\u003clen(ratings);i++{ need[i]=1 } //1.先从左到右，当右边的大于左边的就加1 for i:=0;i\u003clen(ratings)-1;i++{ if ratings[i]\u003cratings[i+1]{ need[i+1]=need[i]+1 } } //2.再从右到左，当左边的大于右边的就右边加1，但要花费糖果最少，所以需要做下判断 for i:=len(ratings)-1;i\u003e0;i--{ if ratings[i-1]\u003eratings[i]{ need[i-1]=findMax(need[i-1],need[i]+1) } } //计算总共糖果 for i:=0;i\u003clen(ratings);i++{ sum+=need[i] } return sum } func findMax(num1 int ,num2 int) int{ if num1\u003enum2{ return num1 } return num2 } ","date":"2022-01-06 08:23:51","objectID":"/algorithm_greedy/:9:0","tags":["data structure"],"title":"Algorithm_greedy","uri":"/algorithm_greedy/"},{"categories":["Coding"],"content":"柠檬水找零 在柠檬水摊上，每一杯柠檬水的售价为 5 美元。 顾客排队购买你的产品，（按账单 bills 支付的顺序）一次购买一杯。 每位顾客只买一杯柠檬水，然后向你付 5 美元、10 美元或 20 美元。你必须给每个顾客正确找零，也就是说净交易是每位顾客向你支付 5 美元。 注意，一开始你手头没有任何零钱。 如果你能给每位顾客正确找零，返回 true ，否则返回 false 。 示例 1： 输入：[5,5,5,10,20] 输出：true 解释： 前 3 位顾客那里，我们按顺序收取 3 张 5 美元的钞票。 第 4 位顾客那里，我们收取一张 10 美元的钞票，并返还 5 美元。 第 5 位顾客那里，我们找还一张 10 美元的钞票和一张 5 美元的钞票。 由于所有客户都得到了正确的找零，所以我们输出 true。 示例 2： 输入：[5,5,10] 输出：true func lemonadeChange(bills []int) bool { //left表示还剩多少 下标0位5元的个数 ，下标1为10元的个数 left:=[2]int{0,0} //第一个元素不为5，直接退出 if bills[0]!=5{ return false } for i:=0;i\u003clen(bills);i++{ //先统计5元和10元的个数 if bills[i]==5{ left[0]+=1 } if bills[i]==10{ left[1]+=1 } //接着处理找零的 tmp:=bills[i]-5 if tmp==5{ if left[0]\u003e0{ left[0]-=1 }else { return false } } if tmp==15{ if left[1]\u003e0\u0026\u0026left[0]\u003e0{ left[0]-=1 left[1]-=1 }else if left[1]==0\u0026\u0026left[0]\u003e2{ left[0]-=3 }else{ return false } } } return true } ","date":"2022-01-06 08:23:51","objectID":"/algorithm_greedy/:10:0","tags":["data structure"],"title":"Algorithm_greedy","uri":"/algorithm_greedy/"},{"categories":["Coding"],"content":"根据身高重建队列 假设有打乱顺序的一群人站成一个队列，数组 people 表示队列中一些人的属性（不一定按顺序）。每个 people[i] = [hi, ki] 表示第 i 个人的身高为 hi ，前面 正好 有 ki 个身高大于或等于 hi 的人。 请你重新构造并返回输入数组 people 所表示的队列。返回的队列应该格式化为数组 queue ，其中 queue[j] = [hj, kj] 是队列中第 j 个人的属性（queue[0] 是排在队列前面的人）。 示例 1： 输入：people = [[7,0],[4,4],[7,1],[5,0],[6,1],[5,2]] 输出：[[5,0],[7,0],[5,2],[6,1],[4,4],[7,1]] 解释： 编号为 0 的人身高为 5 ，没有身高更高或者相同的人排在他前面。 编号为 1 的人身高为 7 ，没有身高更高或者相同的人排在他前面。 编号为 2 的人身高为 5 ，有 2 个身高更高或者相同的人排在他前面，即编号为 0 和 1 的人。 编号为 3 的人身高为 6 ，有 1 个身高更高或者相同的人排在他前面，即编号为 1 的人。 编号为 4 的人身高为 4 ，有 4 个身高更高或者相同的人排在他前面，即编号为 0、1、2、3 的人。 编号为 5 的人身高为 7 ，有 1 个身高更高或者相同的人排在他前面，即编号为 1 的人。 因此 [[5,0],[7,0],[5,2],[6,1],[4,4],[7,1]] 是重新构造后的队列。 func reconstructQueue(people [][]int) [][]int { //先将身高从大到小排序，确定最大个子的相对位置 sort.Slice(people,func(i,j int)bool{ if people[i][0]==people[j][0]{ return people[i][1]\u003cpeople[j][1]//这个才是当身高相同时，将K按照从小到大排序 } return people[i][0]\u003epeople[j][0]//这个只是确保身高按照由大到小的顺序来排，并不确定K是按照从小到大排序的 }) //再按照K进行插入排序，优先插入K小的 result := make([][]int, 0) for _, info := range people { result = append(result, info) copy(result[info[1] +1:], result[info[1]:])//将插入位置之后的元素后移动一位（意思是腾出空间） result[info[1]] = info//将插入元素位置插入元素 } return result } //链表法 func reconstructQueue(people [][]int) [][]int { sort.Slice(people,func (i,j int) bool { if people[i][0]==people[j][0]{ return people[i][1]\u003cpeople[j][1]//当身高相同时，将K按照从小到大排序 } //先将身高从大到小排序，确定最大个子的相对位置 return people[i][0]\u003epeople[j][0] }) l:=list.New()//创建链表 for i:=0;i\u003clen(people);i++{ position:=people[i][1] mark:=l.PushBack(people[i])//插入元素 e:=l.Front() for position!=0{//获取相对位置 position-- e=e.Next() } l.MoveBefore(mark,e)//移动位置 } res:=[][]int{} for e:=l.Front();e!=nil;e=e.Next(){ res=append(res,e.Value.([]int)) } return res } ","date":"2022-01-06 08:23:51","objectID":"/algorithm_greedy/:11:0","tags":["data structure"],"title":"Algorithm_greedy","uri":"/algorithm_greedy/"},{"categories":["Coding"],"content":"用最少数量的箭引爆气球 在二维空间中有许多球形的气球。对于每个气球，提供的输入是水平方向上，气球直径的开始和结束坐标。由于它是水平的，所以纵坐标并不重要，因此只要知道开始和结束的横坐标就足够了。开始坐标总是小于结束坐标。 一支弓箭可以沿着 x 轴从不同点完全垂直地射出。在坐标 x 处射出一支箭，若有一个气球的直径的开始和结束坐标为 xstart，xend， 且满足 xstart ≤ x ≤ xend，则该气球会被引爆。可以射出的弓箭的数量没有限制。 弓箭一旦被射出之后，可以无限地前进。我们想找到使得所有气球全部被引爆，所需的弓箭的最小数量。 给你一个数组 points ，其中 points [i] = [xstart,xend] ，返回引爆所有气球所必须射出的最小弓箭数。 示例 1： 输入：points = [[10,16],[2,8],[1,6],[7,12]] 输出：2 解释：对于该样例，x = 6 可以射爆 [2,8],[1,6] 两个气球，以及 x = 11 射爆另外两个气球 示例 2： 输入：points = [[1,2],[3,4],[5,6],[7,8]] 输出：4 示例 3： 输入：points = [[1,2],[2,3],[3,4],[4,5]] 输出：2 示例 4： 输入：points = [[1,2]] 输出：1 示例 5： 输入：points = [[2,3],[2,3]] 输出：1 提示： 0 \u003c= points.length \u003c= 10^4 points[i].length == 2 -2^31 \u003c= xstart \u003c xend \u003c= 2^31 - 1 func findMinArrowShots(points [][]int) int { var res int =1//弓箭数 //先按照第一位排序 sort.Slice(points,func (i,j int) bool{ return points[i][0]\u003cpoints[j][0] }) for i:=1;i\u003clen(points);i++{ if points[i-1][1]\u003cpoints[i][0]{//如果前一位的右边界小于后一位的左边界，则一定不重合 res++ }else{ points[i][1] = min(points[i - 1][1], points[i][1]); // 更新重叠气球最小右边界,覆盖该位置的值，留到下一步使用 } } return res } func min(a,b int) int{ if a\u003eb{ return b } return a } ","date":"2022-01-06 08:23:51","objectID":"/algorithm_greedy/:12:0","tags":["data structure"],"title":"Algorithm_greedy","uri":"/algorithm_greedy/"},{"categories":["Coding"],"content":"无重叠区间 给定一个区间的集合，找到需要移除区间的最小数量，使剩余区间互不重叠。 注意: 可以认为区间的终点总是大于它的起点。 区间 [1,2] 和 [2,3] 的边界相互“接触”，但没有相互重叠。 示例 1: 输入: [ [1,2], [2,3], [3,4], [1,3] ] 输出: 1 解释: 移除 [1,3] 后，剩下的区间没有重叠。 func eraseOverlapIntervals(intervals [][]int) int { var flag int //先排序 sort.Slice(intervals,func(i,j int)bool{ return intervals[i][0]\u003cintervals[j][0] }) fmt.Println(intervals) for i:=1;i\u003clen(intervals);i++{ if intervals[i-1][1]\u003eintervals[i][0]{ flag++ intervals[i][1]=min(intervals[i-1][1],intervals[i][1])//由于是先排序的，所以，第一位是递增顺序，故只需要将临近两个元素的第二个值最小值更新到该元素的第二个值即可作之后的判断 } } return flag } func min(a,b int)int{ if a\u003eb{ return b } return a } ","date":"2022-01-06 08:23:51","objectID":"/algorithm_greedy/:13:0","tags":["data structure"],"title":"Algorithm_greedy","uri":"/algorithm_greedy/"},{"categories":["Coding"],"content":"划分字母区间 字符串 S 由小写字母组成。我们要把这个字符串划分为尽可能多的片段，同一字母最多出现在一个片段中。返回一个表示每个字符串片段的长度的列表。 示例： 输入：S = “ababcbacadefegdehijhklij” 输出：[9,7,8] 解释： 划分结果为 “ababcbaca”, “defegde”, “hijhklij”。 每个字母最多出现在一个片段中。 像 “ababcbacadefegde”, “hijhklij” 的划分是错误的，因为划分的片段数较少。 func partitionLabels(s string) []int { var res []int; var marks [26]int; size, left, right := len(s), 0, 0; for i := 0; i \u003c size; i++ { marks[s[i] - 'a'] = i; } for i := 0; i \u003c size; i++ { right = max(right, marks[s[i] - 'a']); if i == right { res = append(res, right - left + 1); left = i + 1; } } return res; } func max(a, b int) int { if a \u003c b { a = b; } return a; } ","date":"2022-01-06 08:23:51","objectID":"/algorithm_greedy/:14:0","tags":["data structure"],"title":"Algorithm_greedy","uri":"/algorithm_greedy/"},{"categories":["Coding"],"content":"合并区间 给出一个区间的集合，请合并所有重叠的区间。 func merge(intervals [][]int) [][]int { //先从小到大排序 sort.Slice(intervals,func(i,j int)bool{ return intervals[i][0]\u003cintervals[j][0] }) //再弄重复的 for i:=0;i\u003clen(intervals)-1;i++{ if intervals[i][1]\u003e=intervals[i+1][0]{ intervals[i][1]=max(intervals[i][1],intervals[i+1][1])//赋值最大值 intervals=append(intervals[:i+1],intervals[i+2:]...) i-- } } return intervals } func max(a,b int)int{ if a\u003eb{ return a } return b } ","date":"2022-01-06 08:23:51","objectID":"/algorithm_greedy/:15:0","tags":["data structure"],"title":"Algorithm_greedy","uri":"/algorithm_greedy/"},{"categories":["Coding"],"content":"单调递增的数字 给定一个非负整数 N，找出小于或等于 N 的最大的整数，同时这个整数需要满足其各个位数上的数字是单调递增 示例： 输入: N = 332 输出: 299 func monotoneIncreasingDigits(N int) int { s := strconv.Itoa(N)//将数字转为字符串，方便使用下标 ss := []byte(s)//将字符串转为byte数组，方便更改。 n := len(ss) if n \u003c= 1 { return N } for i:=n-1 ; i\u003e0; i-- { if ss[i-1] \u003e ss[i] {//前一个大于后一位,前一位减1，后面的全部置为9 ss[i-1] -= 1 for j := i ; j \u003c n; j++ {//后面的全部置为9 ss[j] = '9' } } } res, _ := strconv.Atoi(string(ss)) return res } ","date":"2022-01-06 08:23:51","objectID":"/algorithm_greedy/:16:0","tags":["data structure"],"title":"Algorithm_greedy","uri":"/algorithm_greedy/"},{"categories":["Coding"],"content":"买卖股票的最佳时机含手续费 给定一个整数数组 prices，其中第 i 个元素代表了第 i 天的股票价格 ；非负整数 fee 代表了交易股票的手续费用。 你可以无限次地完成交易，但是你每笔交易都需要付手续费。如果你已经购买了一个股票，在卖出它之前你就不能再继续购买股票了。 返回获得利润的最大值。 注意：这里的一笔交易指买入持有并卖出股票的整个过程，每笔交易你只需要为支付一次手续费。 示例 1: 输入: prices = [1, 3, 2, 8, 4, 9], fee = 2 输出: 8 解释: 能够达到的最大利润: 在此处买入 prices[0] = 1 在此处卖出 prices[3] = 8 在此处买入 prices[4] = 4 在此处卖出 prices[5] = 9 总利润: ((8 - 1) - 2) + ((9 - 4) - 2) = 8. 贪心或者dp func maxProfit(prices []int, fee int) int { var minBuy int = prices[0] //第一天买入 var res int for i:=0;i\u003clen(prices);i++{ //如果当前价格小于最低价，则在此处买入 if prices[i]\u003cminBuy{ minBuy=prices[i] } //如果以当前价格卖出亏本，则不卖，继续找下一个可卖点 if prices[i]\u003e=minBuy\u0026\u0026prices[i]-fee-minBuy\u003c=0{ continue } //可以售卖了 if prices[i]\u003eminBuy+fee{ //累加每天的收益 res+=prices[i]-minBuy-fee //更新最小值（如果还在收获利润的区间里，表示并不是真正的卖出，而计算利润每次都要减去手续费，所以要让minBuy = prices[i] - fee;，这样在明天收获利润的时候，才不会多减一次手续费！） minBuy=prices[i]-fee } } return res } ","date":"2022-01-06 08:23:51","objectID":"/algorithm_greedy/:17:0","tags":["data structure"],"title":"Algorithm_greedy","uri":"/algorithm_greedy/"},{"categories":["Coding"],"content":"监控二叉树 给定一个二叉树，我们在树的节点上安装摄像头。 节点上的每个摄影头都可以监视其父对象、自身及其直接子对象。 计算监控树的所有节点所需的最小摄像头数量。 const inf = math.MaxInt64 / 2 func minCameraCover(root *TreeNode) int { var dfs func(*TreeNode) (a, b, c int) dfs = func(node *TreeNode) (a, b, c int) { if node == nil { return inf, 0, 0 } lefta, leftb, leftc := dfs(node.Left) righta, rightb, rightc := dfs(node.Right) a = leftc + rightc + 1 b = min(a, min(lefta+rightb, righta+leftb)) c = min(a, leftb+rightb) return } _, ans, _ := dfs(root) return ans } func min(a, b int) int { if a \u003c= b { return a } return b } ","date":"2022-01-06 08:23:51","objectID":"/algorithm_greedy/:18:0","tags":["data structure"],"title":"Algorithm_greedy","uri":"/algorithm_greedy/"},{"categories":["Coding"],"content":" 学习代码随想录笔记 回溯算法 ","date":"2022-01-06 08:22:27","objectID":"/algorithm_backtracking/:0:0","tags":["data structure"],"title":"Algorithm_backTracking","uri":"/algorithm_backtracking/"},{"categories":["Coding"],"content":"理论基础 也叫回溯搜索算法。 回溯是递归的副产品，只要有递归就会有回溯 回溯的本质是穷举，穷举所有可能，然后选出我们想要的答案，并不算高效。加一些剪枝操作或许会高效一点。 一般用来解决除了暴力搜索无可奈何的情况。 回溯法，一般可以解决如下几种问题： 组合问题：N个数里面按一定规则找出k个数的集合 切割问题：一个字符串按一定规则有几种切割方式 子集问题：一个N个数的集合里有多少符合条件的子集 排列问题：N个数按一定规则全排列，有几种排列方式 棋盘问题：N皇后，解数独等等 回溯法解决的问题都可以抽象为树形结构 因为回溯法解决的都是在集合中递归查找子集，集合的大小就构成了树的宽度，递归的深度，都构成的树的深度。 回溯模板： void backtracking(参数) { if (终止条件) { 存放结果; return; } for (选择：本层集合中元素（树中节点孩子的数量就是集合的大小）) { 处理节点; backtracking(路径，选择列表); // 递归 回溯，撤销处理结果 } } ","date":"2022-01-06 08:22:27","objectID":"/algorithm_backtracking/:1:0","tags":["data structure"],"title":"Algorithm_backTracking","uri":"/algorithm_backtracking/"},{"categories":["Coding"],"content":"*组合问题及其优化 给定两个整数 n 和 k，返回 1 … n 中所有可能的 k 个数的组合。 回溯法三部曲：函数参数、终止条件和单层搜索 剪枝优化： 可以剪枝的地方就在递归中每一层的for循环所选择的起始位置。 如果for循环选择的起始位置之后的元素个数已经不足我们需要的元素个数了，那么就没有必要搜索了。 var res [][]int func combine(n int, k int) [][]int { res=[][]int{} if n \u003c= 0 || k \u003c= 0 || k \u003e n { return res } backtrack(n, k, 1, []int{}) return res } func backtrack(n,k,start int,track []int){ if len(track)==k{ temp:=make([]int,k) copy(temp,track) res=append(res,temp) } if len(track)+n-start+1 \u003c k { return } for i:=start;i\u003c=n;i++{ track=append(track,i) backtrack(n,k,i+1,track) track=track[:len(track)-1] } } 剪枝：go语言的剪枝优化会爆内存溢出，不知道是为啥…… var res [][]int func combine(n int, k int) [][]int { res=[][]int{} if n \u003c= 0 || k \u003c= 0 || k \u003e n { return res } backtrack(n, k, 1, []int{}) return res } func backtrack(n,k,start int,track []int){ if len(track)==k{ temp:=make([]int,k) copy(temp,track) res=append(res,temp) } if len(track)+n-start+1 \u003c k { return } for i:=start;i\u003c=(n-k+len(track)+1);i++{ track=append(track,i) backtrack(n,k,i+1,track) track=track[:len(track)-1] } } ","date":"2022-01-06 08:22:27","objectID":"/algorithm_backtracking/:2:0","tags":["data structure"],"title":"Algorithm_backTracking","uri":"/algorithm_backtracking/"},{"categories":["Coding"],"content":"组合总和III 找出所有相加之和为 n 的 k 个数的组合。组合中只允许含有 1 - 9 的正整数，并且每种组合中不存在重复的数字。 说明： 所有数字都是正整数。 解集不能包含重复的组合。 回溯+减枝 func combinationSum3(k int, n int) [][]int { var track []int// 遍历路径 var result [][]int// 存放结果集 backTree(n,k,1,\u0026track,\u0026result) return result } func backTree(n,k,startIndex int,track *[]int,result *[][]int){ if len(*track)==k{ var sum int tmp:=make([]int,k) for k,v:=range *track{ sum+=v tmp[k]=v } if sum==n{ *result=append(*result,tmp) } return } for i:=startIndex;i\u003c=9-(k-len(*track))+1;i++{//减枝（k-len(*track)表示还剩多少个可填充的元素） *track=append(*track,i)//记录路径 backTree(n,k,i+1,track,result)//递归 *track=(*track)[:len(*track)-1]//回溯 } } ","date":"2022-01-06 08:22:27","objectID":"/algorithm_backtracking/:3:0","tags":["data structure"],"title":"Algorithm_backTracking","uri":"/algorithm_backtracking/"},{"categories":["Coding"],"content":"电话号码的字母组合 给定一个仅包含数字 2-9 的字符串，返回所有它能表示的字母组合。 给出数字到字母的映射如电话按键。注意 1 不对应任何字母。 主要在于递归中传递下一个数字 func letterCombinations(digits string) []string { lenth:=len(digits) if lenth==0 ||lenth\u003e4{ return nil } digitsMap:= [10]string{ \"\", // 0 \"\", // 1 \"abc\", // 2 \"def\", // 3 \"ghi\", // 4 \"jkl\", // 5 \"mno\", // 6 \"pqrs\", // 7 \"tuv\", // 8 \"wxyz\", // 9 } res:=make([]string,0) recursion(\"\",digits,0,digitsMap,\u0026res) return res } func recursion(tempString ,digits string, Index int,digitsMap [10]string, res *[]string) {//index表示第几个数字 if len(tempString)==len(digits){//终止条件，字符串长度等于digits的长度 *res=append(*res,tempString) return } tmpK:=digits[Index]-'0' // 将index指向的数字转为int（确定下一个数字） letter:=digitsMap[tmpK]// 取数字对应的字符集 for i:=0;i\u003clen(letter);i++{ tempString=tempString+string(letter[i])//拼接结果 recursion(tempString,digits,Index+1,digitsMap,res) tempString=tempString[:len(tempString)-1]//回溯 } } ","date":"2022-01-06 08:22:27","objectID":"/algorithm_backtracking/:4:0","tags":["data structure"],"title":"Algorithm_backTracking","uri":"/algorithm_backtracking/"},{"categories":["Coding"],"content":"组合总和 给定一个无重复元素的数组 candidates 和一个目标数 target ，找出 candidates 中所有可以使数字和为 target 的组合。candidates 中的数字可以无限制重复被选取。 主要在于递归中传递下一个数字 func combinationSum(candidates []int, target int) [][]int { var trcak []int var res [][]int backtracking(0,0,target,candidates,trcak,\u0026res) return res } func backtracking(startIndex,sum,target int,candidates,trcak []int,res *[][]int){ //终止条件 if sum==target{ tmp:=make([]int,len(trcak)) copy(tmp,trcak)//拷贝 *res=append(*res,tmp)//放入结果集 return } if sum\u003etarget{return} //回溯 for i:=startIndex;i\u003clen(candidates);i++{ //更新路径集合和sum trcak=append(trcak,candidates[i]) sum+=candidates[i] //递归 backtracking(i,sum,target,candidates,trcak,res) //回溯 trcak=trcak[:len(trcak)-1] sum-=candidates[i] } } ","date":"2022-01-06 08:22:27","objectID":"/algorithm_backtracking/:5:0","tags":["data structure"],"title":"Algorithm_backTracking","uri":"/algorithm_backtracking/"},{"categories":["Coding"],"content":"组合总和II 给定一个数组 candidates 和一个目标数 target ，找出 candidates 中所有可以使数字和为 target 的组合。 candidates 中的每个数字在每个组合中只能使用一次。 主要在于如何在回溯中去重 使用used数组 func combinationSum2(candidates []int, target int) [][]int { var trcak []int var res [][]int var history map[int]bool history=make(map[int]bool) sort.Ints(candidates) backtracking(0,0,target,candidates,trcak,\u0026res,history) return res } func backtracking(startIndex,sum,target int,candidates,trcak []int,res *[][]int,history map[int]bool){ //终止条件 if sum==target{ tmp:=make([]int,len(trcak)) copy(tmp,trcak)//拷贝 *res=append(*res,tmp)//放入结果集 return } if sum\u003etarget{return} //回溯 // used[i - 1] == true，说明同一树枝candidates[i - 1]使用过 // used[i - 1] == false，说明同一树层candidates[i - 1]使用过 for i:=startIndex;i\u003clen(candidates);i++{ if i\u003e0\u0026\u0026candidates[i]==candidates[i-1]\u0026\u0026history[i-1]==false{ continue } //更新路径集合和sum trcak=append(trcak,candidates[i]) sum+=candidates[i] history[i]=true //递归 backtracking(i+1,sum,target,candidates,trcak,res,history) //回溯 trcak=trcak[:len(trcak)-1] sum-=candidates[i] history[i]=false } } 不使用used数组 func combinationSum2(candidates []int, target int) [][]int { var trcak []int var res [][]int sort.Ints(candidates) backtracking(0,0,target,candidates,trcak,\u0026res) return res } func backtracking(startIndex,sum,target int,candidates,trcak []int,res *[][]int){ //终止条件 if sum==target{ tmp:=make([]int,len(trcak)) //拷贝 copy(tmp,trcak) //放入结果集 *res=append(*res,tmp) return } //回溯 for i:=startIndex;i\u003clen(candidates) \u0026\u0026 sum+candidates[i]\u003c=target;i++{ // 若当前树层有使用过相同的元素，则跳过 if i\u003estartIndex\u0026\u0026candidates[i]==candidates[i-1]{ continue } //更新路径集合和sum trcak=append(trcak,candidates[i]) sum+=candidates[i] backtracking(i+1,sum,target,candidates,trcak,res) //回溯 trcak=trcak[:len(trcak)-1] sum-=candidates[i] } } ","date":"2022-01-06 08:22:27","objectID":"/algorithm_backtracking/:6:0","tags":["data structure"],"title":"Algorithm_backTracking","uri":"/algorithm_backtracking/"},{"categories":["Coding"],"content":"分割回文串 给定一个字符串 s，将 s 分割成一些子串，使每个子串都是回文串。 返回 s 所有可能的分割方案。 示例: 输入: \"aab\" 输出: [ [\"aa\",\"b\"], [\"a\",\"a\",\"b\"] ] 注意切片（go切片是披着值类型外衣的引用类型） func partition(s string) [][]string { var tmpString []string//切割字符串集合 var res [][]string//结果集合 backTracking(s,tmpString,0,\u0026res) return res } func backTracking(s string,tmpString []string,startIndex int,res *[][]string){ if startIndex==len(s){//到达字符串末尾了 //进行一次切片拷贝，怕之后的操作影响tmpString切片内的值 t := make([]string, len(tmpString)) copy(t, tmpString) *res=append(*res,t) } for i:=startIndex;i\u003clen(s);i++{ //处理（首先通过startIndex和i判断切割的区间，进而判断该区间的字符串是否为回文，若为回文，则加入到tmpString，否则继续后移，找到回文区间）（这里为一层处理） if isPartition(s,startIndex,i){ tmpString=append(tmpString,s[startIndex:i+1]) }else{ continue } //递归 backTracking(s,tmpString,i+1,res) //回溯 tmpString=tmpString[:len(tmpString)-1] } } //判断是否为回文 func isPartition(s string,startIndex,end int)bool{ left:=startIndex right:=end for ;left\u003cright;{ if s[left]!=s[right]{ return false } //移动左右指针 left++ right-- } return true } ","date":"2022-01-06 08:22:27","objectID":"/algorithm_backtracking/:7:0","tags":["data structure"],"title":"Algorithm_backTracking","uri":"/algorithm_backtracking/"},{"categories":["Coding"],"content":"复原IP地址 给定一个只包含数字的字符串，复原它并返回所有可能的 IP 地址格式。 有效的 IP 地址 正好由四个整数（每个整数位于 0 到 255 之间组成，且不能含有前导 0），整数之间用 ‘.’ 分隔。 例如：“0.1.2.201” 和 “192.168.1.1” 是 有效的 IP 地址，但是 “0.011.255.245”、“192.168.1.312” 和 “192.168@1.1” 是 无效的 IP 地址。 示例 1： 输入：s = \"25525511135\" 输出：[\"255.255.11.135\",\"255.255.111.35\"] 示例 2： 输入：s = \"0000\" 输出：[\"0.0.0.0\"] 回溯（对于前导 0的IP（特别注意s[startIndex]=='0'的判断，不应该写成s[startIndex]==0，因为s截取出来不是数字）） func restoreIpAddresses(s string) []string { var res,path []string backTracking(s,path,0,\u0026res) return res } func backTracking(s string,path []string,startIndex int,res *[]string){ //终止条件 if startIndex==len(s)\u0026\u0026len(path)==4{ tmpIpString:=path[0]+\".\"+path[1]+\".\"+path[2]+\".\"+path[3] *res=append(*res,tmpIpString) } for i:=startIndex;i\u003clen(s);i++{ //处理 path:=append(path,s[startIndex:i+1]) if i-startIndex+1\u003c=3\u0026\u0026len(path)\u003c=4\u0026\u0026isNormalIp(s,startIndex,i){ //递归 backTracking(s,path,i+1,res) }else {//如果首尾超过了3个，或路径多余4个，或前导为0，或大于255，直接回退 return } //回溯 path=path[:len(path)-1] } } func isNormalIp(s string,startIndex,end int)bool{ checkInt,_:=strconv.Atoi(s[startIndex:end+1]) if end-startIndex+1\u003e1\u0026\u0026s[startIndex]=='0'{//对于前导 0的IP（特别**注意**s[startIndex]=='0'的判断，不应该写成s[startIndex]==0，因为s截取出来不是数字） return false } if checkInt\u003e255{ return false } return true } ","date":"2022-01-06 08:22:27","objectID":"/algorithm_backtracking/:8:0","tags":["data structure"],"title":"Algorithm_backTracking","uri":"/algorithm_backtracking/"},{"categories":["Coding"],"content":"子集问题 给定一组不含重复元素的整数数组 nums，返回该数组所有可能的子集（幂集）。 var res [][]int func subset(nums []int) [][]int { res = make([][]int, 0) sort.Ints(nums) Dfs([]int{}, nums, 0) return res } func Dfs(temp, nums []int, start int){ tmp := make([]int, len(temp)) copy(tmp, temp) res = append(res, tmp) for i := start; i \u003c len(nums); i++{ //if i\u003estart\u0026\u0026nums[i]==nums[i-1]{ // continue //} temp = append(temp, nums[i]) Dfs(temp, nums, i+1) temp = temp[:len(temp)-1] } } ","date":"2022-01-06 08:22:27","objectID":"/algorithm_backtracking/:9:0","tags":["data structure"],"title":"Algorithm_backTracking","uri":"/algorithm_backtracking/"},{"categories":["Coding"],"content":"子集II 给定一个可能包含重复元素的整数数组 nums，返回该数组所有可能的子集（幂集）。 var res[][]int func subsetsWithDup(nums []int)[][]int { res=make([][]int,0) sort.Ints(nums) dfs([]int{},nums,0) return res } func dfs(temp, num []int, start int) { tmp:=make([]int,len(temp)) copy(tmp,temp) res=append(res,tmp) for i:=start;i\u003clen(num);i++{ if i\u003estart\u0026\u0026num[i]==num[i-1]{ continue } temp=append(temp,num[i]) dfs(temp,num,i+1) temp=temp[:len(temp)-1] } } ","date":"2022-01-06 08:22:27","objectID":"/algorithm_backtracking/:10:0","tags":["data structure"],"title":"Algorithm_backTracking","uri":"/algorithm_backtracking/"},{"categories":["Coding"],"content":"递增子序列 给定一个整型数组, 你的任务是找到所有该数组的递增子序列，递增子序列的长度至少是2。给定数组中可能包含重复数字，相等的数字应该被视为递增的一种情况 func findSubsequences(nums []int) [][]int { var subRes []int var res [][]int backTring(0,nums,subRes,\u0026res) return res } func backTring(startIndex int,nums,subRes []int,res *[][]int){ if len(subRes)\u003e1{ tmp:=make([]int,len(subRes)) copy(tmp,subRes) *res=append(*res,tmp) } history:=[201]int{}//记录本层元素使用记录 for i:=startIndex;i\u003clen(nums);i++{ //分两种情况判断：一，当前取的元素小于子集的最后一个元素，则继续寻找下一个适合的元素 // 或者二，当前取的元素在本层已经出现过了，所以跳过该元素，继续寻找 if len(subRes)\u003e0\u0026\u0026nums[i]\u003csubRes[len(subRes)-1]||history[nums[i] + 100]==1{ continue } history[nums[i] + 100]=1//表示本层该元素使用过了 subRes=append(subRes,nums[i]) backTring(i+1,nums,subRes,res) subRes=subRes[:len(subRes)-1] } } ","date":"2022-01-06 08:22:27","objectID":"/algorithm_backtracking/:11:0","tags":["data structure"],"title":"Algorithm_backTracking","uri":"/algorithm_backtracking/"},{"categories":["Coding"],"content":"全排列 给定一个 没有重复 数字的序列，返回其所有可能的全排列。 var res [][]int func permute(nums []int) [][]int { res = [][]int{} backTrack(nums,len(nums),[]int{}) return res } func backTrack(nums []int,numsLen int,path []int) { if len(nums)==0{ p:=make([]int,len(path)) copy(p,path) res = append(res,p) } for i:=0;i\u003cnumsLen;i++{ cur:=nums[i] path = append(path,cur) nums = append(nums[:i],nums[i+1:]...)//直接使用切片 backTrack(nums,len(nums),path) nums = append(nums[:i],append([]int{cur},nums[i:]...)...)//回溯的时候切片也要复原，元素位置不能变 path = path[:len(path)-1] } } ","date":"2022-01-06 08:22:27","objectID":"/algorithm_backtracking/:12:0","tags":["data structure"],"title":"Algorithm_backTracking","uri":"/algorithm_backtracking/"},{"categories":["Coding"],"content":"全排列II 给定一个可包含重复数字的序列 nums ，按任意顺序 返回所有不重复的全排列。 var res [][]int func permute(nums []int) [][]int { res = [][]int{} backTrack(nums,len(nums),[]int{}) return res } func backTrack(nums []int,numsLen int,path []int) { if len(nums)==0{ p:=make([]int,len(path)) copy(p,path) res = append(res,p) } used := [21]int{}//跟前一题唯一的区别，同一层不使用重复的数。关于used的思想carl在递增子序列那一题中提到过 for i:=0;i\u003cnumsLen;i++{ if used[nums[i]+10]==1{ continue } cur:=nums[i] path = append(path,cur) used[nums[i]+10]=1 nums = append(nums[:i],nums[i+1:]...) backTrack(nums,len(nums),path) nums = append(nums[:i],append([]int{cur},nums[i:]...)...) path = path[:len(path)-1] } } ","date":"2022-01-06 08:22:27","objectID":"/algorithm_backtracking/:13:0","tags":["data structure"],"title":"Algorithm_backTracking","uri":"/algorithm_backtracking/"},{"categories":["Coding"],"content":"回溯算法去重问题的另一种写法 https://programmercarl.com/%E5%9B%9E%E6%BA%AF%E7%AE%97%E6%B3%95%E5%8E%BB%E9%87%8D%E9%97%AE%E9%A2%98%E7%9A%84%E5%8F%A6%E4%B8%80%E7%A7%8D%E5%86%99%E6%B3%95.html#_90-%E5%AD%90%E9%9B%86ii 看c++版的 ","date":"2022-01-06 08:22:27","objectID":"/algorithm_backtracking/:14:0","tags":["data structure"],"title":"Algorithm_backTracking","uri":"/algorithm_backtracking/"},{"categories":["Coding"],"content":"重新安排行程 深搜和回溯也是相辅相成的，都用了递归。 给定一个机票的字符串二维数组 [from, to]，子数组中的两个成员分别表示飞机出发和降落的机场地点，对该行程进行重新规划排序。所有这些机票都属于一个从 JFK（肯尼迪国际机场）出发的先生，所以该行程必须从 JFK 开始。 提示： 如果存在多种有效的行程，请你按字符自然排序返回最小的行程组合。例如，行程 [“JFK”, “LGA”] 与 [“JFK”, “LGB”] 相比就更小，排序更靠前 所有的机场都用三个大写字母表示（机场代码）。 假定所有机票至少存在一种合理的行程。 所有的机票必须都用一次 且 只能用一次。 示例 1： 输入：[[\"MUC\", \"LHR\"], [\"JFK\", \"MUC\"], [\"SFO\", \"SJC\"], [\"LHR\", \"SFO\"]] 输出：[\"JFK\", \"MUC\", \"LHR\", \"SFO\", \"SJC\"] 示例 2： 输入：[[\"JFK\",\"SFO\"],[\"JFK\",\"ATL\"],[\"SFO\",\"ATL\"],[\"ATL\",\"JFK\"],[\"ATL\",\"SFO\"]] 输出：[\"JFK\",\"ATL\",\"JFK\",\"SFO\",\"ATL\",\"SFO\"] 解释：另一种有效的行程是 [\"JFK\",\"SFO\",\"ATL\",\"JFK\",\"ATL\",\"SFO\"]。但是它自然排序更大更靠后 class Solution { private: // unordered_map\u003c出发机场, map\u003c到达机场, 航班次数\u003e\u003e targets unordered_map\u003cstring, map\u003cstring, int\u003e\u003e targets; bool backtracking(int ticketNum, vector\u003cstring\u003e\u0026 result) { if (result.size() == ticketNum + 1) { return true; } for (pair\u003cconst string, int\u003e\u0026 target : targets[result[result.size() - 1]]) { if (target.second \u003e 0 ) { // 记录到达机场是否飞过了 result.push_back(target.first); target.second--; if (backtracking(ticketNum, result)) return true; result.pop_back(); target.second++; } } return false; } public: vector\u003cstring\u003e findItinerary(vector\u003cvector\u003cstring\u003e\u003e\u0026 tickets) { targets.clear(); vector\u003cstring\u003e result; for (const vector\u003cstring\u003e\u0026 vec : tickets) { targets[vec[0]][vec[1]]++; // 记录映射关系 } result.push_back(\"JFK\"); // 起始机场 backtracking(tickets.size(), result); return result; } }; ","date":"2022-01-06 08:22:27","objectID":"/algorithm_backtracking/:15:0","tags":["data structure"],"title":"Algorithm_backTracking","uri":"/algorithm_backtracking/"},{"categories":["Coding"],"content":"N皇后 n 皇后问题 研究的是如何将 n 个皇后放置在 n×n 的棋盘上，并且使皇后彼此之间不能相互攻击。 给你一个整数 n ，返回所有不同的 n 皇后问题 的解决方案。 每一种解法包含一个不同的 n 皇后问题 的棋子放置方案，该方案中 ‘Q’ 和 ‘.’ 分别代表了皇后和空位。 import \"strings\" var res [][]string func isValid(board [][]string, row, col int) (res bool){ n := len(board) for i:=0; i \u003c row; i++ { if board[i][col] == \"Q\" { return false } } for i := 0; i \u003c n; i++{ if board[row][i] == \"Q\" { return false } } for i ,j := row, col; i \u003e= 0 \u0026\u0026 j \u003e=0 ; i, j = i - 1, j- 1{ if board[i][j] == \"Q\"{ return false } } for i, j := row, col; i \u003e=0 \u0026\u0026 j \u003c n; i,j = i-1, j+1 { if board[i][j] == \"Q\" { return false } } return true } func backtrack(board [][]string, row int) { size := len(board) if row == size{ temp := make([]string, size) for i := 0; i\u003csize;i++{ temp[i] = strings.Join(board[i],\"\") } res =append(res,temp) return } for col := 0; col \u003c size; col++ { if !isValid(board, row, col){ continue } board[row][col] = \"Q\" backtrack(board, row+1) board[row][col] = \".\" } } func solveNQueens(n int) [][]string { res = [][]string{} board := make([][]string, n) for i := 0; i \u003c n; i++{ board[i] = make([]string, n) } for i := 0; i \u003c n; i++{ for j := 0; j\u003cn;j++{ board[i][j] = \".\" } } backtrack(board, 0) return res } ","date":"2022-01-06 08:22:27","objectID":"/algorithm_backtracking/:16:0","tags":["data structure"],"title":"Algorithm_backTracking","uri":"/algorithm_backtracking/"},{"categories":["Coding"],"content":"解数独 编写一个程序，通过填充空格来解决数独问题。 func solveSudoku(board [][]byte) { var backtracking func(board [][]byte) bool backtracking=func(board [][]byte) bool{ for i:=0;i\u003c9;i++{ for j:=0;j\u003c9;j++{ //判断此位置是否适合填数字 if board[i][j]!='.'{ continue } //尝试填1-9 for k:='1';k\u003c='9';k++{ if isvalid(i,j,byte(k),board)==true{//如果满足要求就填 board[i][j]=byte(k) if backtracking(board)==true{ return true } board[i][j]='.' } } return false } } return true } backtracking(board) } //判断填入数字是否满足要求 func isvalid(row,col int,k byte,board [][]byte)bool{ for i:=0;i\u003c9;i++{//行 if board[row][i]==k{ return false } } for i:=0;i\u003c9;i++{//列 if board[i][col]==k{ return false } } //方格 startrow:=(row/3)*3 startcol:=(col/3)*3 for i:=startrow;i\u003cstartrow+3;i++{ for j:=startcol;j\u003cstartcol+3;j++{ if board[i][j]==k{ return false } } } return true } ","date":"2022-01-06 08:22:27","objectID":"/algorithm_backtracking/:17:0","tags":["data structure"],"title":"Algorithm_backTracking","uri":"/algorithm_backtracking/"},{"categories":["Coding"],"content":" 学习代码随想录笔记 二叉树 ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:0:0","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"理论基础 一般主要会碰到满二叉树以及完全二叉树。 完全二叉树的定义如下：在完全二叉树中，除了最底层节点可能没填满外，其余每层节点数都达到最大值，并且最下面一层的节点都集中在该层最左边的若干位置。若最底层为第 h 层，则该层包含 1~ 2^h -1 个节点。 优先级队列其实是一个堆，堆就是一棵完全二叉树，同时保证父子节点的顺序关系。 二叉搜索树： 与前面两个树不同，该树有节点权值。 有序树，左节点 \u003c 中节点 \u003c 右节点 平衡二叉搜索树：又被称为AVL（Adelson-Velsky and Landis）树，且具有以下性质：它是一棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。 二叉树可以链式存储，也可以顺序存储。 深度优先遍历 前序遍历（递归法，迭代法） 中序遍历（递归法，迭代法） 后序遍历（递归法，迭代法） 广度优先遍历 层次遍历（迭代法） type TreeNode struct { Val int Left *TreeNode Right *TreeNode } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:1:0","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"递归遍历 递归的实现就是：每一次递归调用都会把函数的局部变量、参数值和返回地址等压入调用栈中，然后递归返回的时候，从栈顶弹出上一次递归的各项参数，所以这就是递归为什么可以返回上一层位置的原因。 写递归还是得有方法论。 确定递归函数的参数和返回值： 确定哪些参数是递归的过程中需要处理的，那么就在递归函数里加上这个参数， 并且还要明确每次递归的返回值是什么进而确定递归函数的返回类型。 确定终止条件： 写完了递归算法, 运行的时候，经常会遇到栈溢出的错误，就是没写终止条件或者终止条件写的不对，操作系统也是用一个栈的结构来保存每一层递归的信息，如果递归没有终止，操作系统的内存栈必然就会溢出。 确定单层递归的逻辑： 确定每一层递归需要处理的信息。在这里也就会重复调用自己来实现递归的过程。 前序遍历： func preorderTraversal(root *TreeNode) (res []int) { var traversal func(node *TreeNode) traversal = func(node *TreeNode) { if node == nil { return } res = append(res,node.Val) traversal(node.Left) traversal(node.Right) } traversal(root) return res } func pre(r *TreeNode)(res []int){ } 中序遍历： func inorderTraversal(root *TreeNode) (res []int) { var traversal func(node *TreeNode) traversal = func(node *TreeNode) { if node == nil { return } traversal(node.Left) res = append(res,node.Val) traversal(node.Right) } traversal(root) return res } 后序遍历: func postorderTraversal(root *TreeNode) (res []int) { var traversal func(node *TreeNode) traversal = func(node *TreeNode) { if node == nil { return } traversal(node.Left) traversal(node.Right) res = append(res,node.Val) } traversal(root) return res } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:2:0","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"迭代遍历 迭代法前序遍历 func preorderTraversal(root *TreeNode) []int { ans := []int{} if root == nil { return ans } st := list.New() st.PushBack(root) for st.Len() \u003e 0 { node := st.Remove(st.Back()).(*TreeNode) ans = append(ans, node.Val) if node.Right != nil { st.PushBack(node.Right) } if node.Left != nil { st.PushBack(node.Left) } } return ans } 迭代法后序遍历 func postorderTraversal(root *TreeNode) []int { ans := []int{} if root == nil { return ans } st := list.New() st.PushBack(root) for st.Len() \u003e 0 { node := st.Remove(st.Back()).(*TreeNode) ans = append(ans, node.Val) if node.Left != nil { st.PushBack(node.Left) } if node.Right != nil { st.PushBack(node.Right) } } reverse(ans) return ans } func reverse(a []int) { l, r := 0, len(a) - 1 for l \u003c r { a[l], a[r] = a[r], a[l] l, r = l+1, r-1 } } 迭代法中序遍历 func inorderTraversal(root *TreeNode) []int { ans := []int{} if root == nil { return ans } st := list.New() cur := root for cur != nil || st.Len() \u003e 0 { if cur != nil { st.PushBack(cur) cur = cur.Left } else { cur = st.Remove(st.Back()).(*TreeNode) ans = append(ans, cur.Val) cur = cur.Right } } return ans } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:3:0","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"统一迭代 迭代法实现的先中后序，其实风格也不是那么统一，除了先序和后序，有关联，中序完全就是另一个风格了，一会用栈遍历，一会又用指针来遍历。 使用迭代法实现先中后序遍历，很难写出统一的代码，不像是递归法，实现了其中的一种遍历方式，其他两种只要稍稍改一下节点顺序就可以了。 要处理的节点放入栈之后，紧接着放入一个空指针作为标记。 这种方法也可以叫做标记法 前序遍历统一迭代法 /** type Element struct { // 元素保管的值 Value interface{} // 内含隐藏或非导出字段 } func (l *List) Back() *Element 前序遍历：中左右 压栈顺序：右左中 **/ func preorderTraversal(root *TreeNode) []int { if root == nil { return nil } var stack = list.New()//栈 res:=[]int{}//结果集 stack.PushBack(root) var node *TreeNode for stack.Len()\u003e0{ e := stack.Back() stack.Remove(e)//弹出元素 if e.Value==nil{// 如果为空，则表明是需要处理中间节点 e=stack.Back()//弹出元素（即中间节点） stack.Remove(e)//删除中间节点 node=e.Value.(*TreeNode) res=append(res,node.Val)//将中间节点加入到结果集中 continue//继续弹出栈中下一个节点 } node = e.Value.(*TreeNode) //压栈顺序：右左中 if node.Right!=nil{ stack.PushBack(node.Right) } if node.Left!=nil{ stack.PushBack(node.Left) } stack.PushBack(node)//中间节点压栈后再压入nil作为中间节点的标志符 stack.PushBack(nil) } return res } 中序遍历统一迭代法 /** * Definition for a binary tree node. * type TreeNode struct { * Val int * Left *TreeNode * Right *TreeNode * } */ //中序遍历：左中右 //压栈顺序：右中左 func inorderTraversal(root *TreeNode) []int { if root==nil{ return nil } stack:=list.New()//栈 res:=[]int{}//结果集 stack.PushBack(root) var node *TreeNode for stack.Len()\u003e0{ e := stack.Back() stack.Remove(e) if e.Value==nil{// 如果为空，则表明是需要处理中间节点 e=stack.Back()//弹出元素（即中间节点） stack.Remove(e)//删除中间节点 node=e.Value.(*TreeNode) res=append(res,node.Val)//将中间节点加入到结果集中 continue//继续弹出栈中下一个节点 } node = e.Value.(*TreeNode) //压栈顺序：右中左 if node.Right!=nil{ stack.PushBack(node.Right) } stack.PushBack(node)//中间节点压栈后再压入nil作为中间节点的标志符 stack.PushBack(nil) if node.Left!=nil{ stack.PushBack(node.Left) } } return res } 后序遍历统一迭代法 //后续遍历：左右中 //压栈顺序：中右左 func postorderTraversal(root *TreeNode) []int { if root == nil { return nil } var stack = list.New()//栈 res:=[]int{}//结果集 stack.PushBack(root) var node *TreeNode for stack.Len()\u003e0{ e := stack.Back() stack.Remove(e) if e.Value==nil{// 如果为空，则表明是需要处理中间节点 e=stack.Back()//弹出元素（即中间节点） stack.Remove(e)//删除中间节点 node=e.Value.(*TreeNode) res=append(res,node.Val)//将中间节点加入到结果集中 continue//继续弹出栈中下一个节点 } node = e.Value.(*TreeNode) //压栈顺序：中右左 stack.PushBack(node)//中间节点压栈后再压入nil作为中间节点的标志符 stack.PushBack(nil) if node.Right!=nil{ stack.PushBack(node.Right) } if node.Left!=nil{ stack.PushBack(node.Left) } } return res } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:4:0","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"层序遍历 ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:5:0","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"102.二叉树的层序遍历 https://leetcode-cn.com/problems/binary-tree-level-order-traversal/ /** 102. 二叉树的层序遍历 */ func levelOrder(root *TreeNode) [][]int { res:=[][]int{} if root==nil{//防止为空 return res } queue:=list.New() queue.PushBack(root) var tmpArr []int for queue.Len()\u003e0 { length:=queue.Len()//保存当前层的长度，然后处理当前层（十分重要，防止添加下层元素影响判断层中元素的个数） for i:=0;i\u003clength;i++{ node:=queue.Remove(queue.Front()).(*TreeNode)//出队列 if node.Left!=nil{ queue.PushBack(node.Left) } if node.Right!=nil{ queue.PushBack(node.Right) } tmpArr=append(tmpArr,node.Val)//将值加入本层切片中 } res=append(res,tmpArr)//放入结果集 tmpArr=[]int{}//清空层的数据 } return res } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:5:1","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"107.二叉树的层次遍历II https://leetcode-cn.com/problems/binary-tree-level-order-traversal-ii/ /** 107. 二叉树的层序遍历 II */ func levelOrderBottom(root *TreeNode) [][]int { queue:=list.New() res:=[][]int{} if root==nil{ return res } queue.PushBack(root) for queue.Len()\u003e0{ length:=queue.Len() tmp:=[]int{} for i:=0;i\u003clength;i++{ node:=queue.Remove(queue.Front()).(*TreeNode) if node.Left!=nil{ queue.PushBack(node.Left) } if node.Right!=nil{ queue.PushBack(node.Right) } tmp=append(tmp,node.Val) } res=append(res,tmp) } //反转结果集 for i:=0;i\u003clen(res)/2;i++{ res[i],res[len(res)-i-1]=res[len(res)-i-1],res[i] } return res } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:5:2","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"199.二叉树的右视图 https://leetcode-cn.com/problems/binary-tree-right-side-view/ func rightSideView(root *TreeNode) []int { queue:=list.New() res:=[][]int{} var finaRes []int if root==nil{ return finaRes } queue.PushBack(root) for queue.Len()\u003e0{ length:=queue.Len() tmp:=[]int{} for i:=0;i\u003clength;i++{ node:=queue.Remove(queue.Front()).(*TreeNode) if node.Left!=nil{ queue.PushBack(node.Left) } if node.Right!=nil{ queue.PushBack(node.Right) } tmp=append(tmp,node.Val) } res=append(res,tmp) } //取每一层的最后一个元素 for i:=0;i\u003clen(res);i++{ finaRes=append(finaRes,res[i][len(res[i])-1]) } return finaRes } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:5:3","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"637.二叉树的层平均值 https://leetcode-cn.com/problems/average-of-levels-in-binary-tree/ /** 637. 二叉树的层平均值 */ func averageOfLevels(root *TreeNode) []float64 { res:=[][]int{} var finRes []float64 if root==nil{//防止为空 return finRes } queue:=list.New() queue.PushBack(root) var tmpArr []int for queue.Len()\u003e0 { length:=queue.Len()//保存当前层的长度，然后处理当前层（十分重要，防止添加下层元素影响判断层中元素的个数） for i:=0;i\u003clength;i++{ node:=queue.Remove(queue.Front()).(*TreeNode)//出队列 if node.Left!=nil{ queue.PushBack(node.Left) } if node.Right!=nil{ queue.PushBack(node.Right) } tmpArr=append(tmpArr,node.Val)//将值加入本层切片中 } res=append(res,tmpArr)//放入结果集 tmpArr=[]int{}//清空层的数据 } //计算每层的平均值 length:=len(res) for i:=0;i\u003clength;i++{ var sum int for j:=0;j\u003clen(res[i]);j++{ sum+=res[i][j] } tmp:=float64(sum)/float64(len(res[i])) finRes=append(finRes,tmp)//将平均值放入结果集合 } return finRes } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:5:4","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"429.N叉树的层序遍历 https://leetcode-cn.com/problems/n-ary-tree-level-order-traversal/ func levelOrder(root *Node) [][]int { queue:=list.New() res:=[][]int{}//结果集 if root==nil{ return res } queue.PushBack(root) for queue.Len()\u003e0{ length:=queue.Len()//记录当前层的数量 var tmp []int for T:=0;T\u003clength;T++{//该层的每个元素：一添加到该层的结果集中；二找到该元素的下层元素加入到队列中，方便下次使用 myNode:=queue.Remove(queue.Front()).(*Node) tmp=append(tmp,myNode.Val) for i:=0;i\u003clen(myNode.Children);i++{ queue.PushBack(myNode.Children[i]) } } res=append(res,tmp) } return res } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:5:5","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"515.在每个树行中找最大值 https://leetcode-cn.com/problems/find-largest-value-in-each-tree-row/ /** 515. 在每个树行中找最大值 */ func largestValues(root *TreeNode) []int { res:=[][]int{} var finRes []int if root==nil{//防止为空 return finRes } queue:=list.New() queue.PushBack(root) var tmpArr []int //层次遍历 for queue.Len()\u003e0 { length:=queue.Len()//保存当前层的长度，然后处理当前层（十分重要，防止添加下层元素影响判断层中元素的个数） for i:=0;i\u003clength;i++{ node:=queue.Remove(queue.Front()).(*TreeNode)//出队列 if node.Left!=nil{ queue.PushBack(node.Left) } if node.Right!=nil{ queue.PushBack(node.Right) } tmpArr=append(tmpArr,node.Val)//将值加入本层切片中 } res=append(res,tmpArr)//放入结果集 tmpArr=[]int{}//清空层的数据 } //找到每层的最大值 for i:=0;i\u003clen(res);i++{ finRes=append(finRes,max(res[i]...)) } return finRes } func max(vals...int) int { max:=int(math.Inf(-1))//负无穷 for _, val := range vals { if val \u003e max { max = val } } return max } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:5:6","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"116.填充每个节点的下一个右侧节点指针 https://leetcode-cn.com/problems/populating-next-right-pointers-in-each-node/ /** 116. 填充每个节点的下一个右侧节点指针 117. 填充每个节点的下一个右侧节点指针 II */ func connect(root *Node) *Node { res:=[][]*Node{} if root==nil{//防止为空 return root } queue:=list.New() queue.PushBack(root) var tmpArr []*Node for queue.Len()\u003e0 { length:=queue.Len()//保存当前层的长度，然后处理当前层（十分重要，防止添加下层元素影响判断层中元素的个数） for i:=0;i\u003clength;i++{ node:=queue.Remove(queue.Front()).(*Node)//出队列 if node.Left!=nil{ queue.PushBack(node.Left) } if node.Right!=nil{ queue.PushBack(node.Right) } tmpArr=append(tmpArr,node)//将值加入本层切片中 } res=append(res,tmpArr)//放入结果集 tmpArr=[]*Node{}//清空层的数据 } //遍历每层元素,指定next for i:=0;i\u003clen(res);i++{ for j:=0;j\u003clen(res[i])-1;j++{ res[i][j].Next=res[i][j+1] } } return root } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:5:7","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"117.填充每个节点的下一个右侧节点指针II https://leetcode-cn.com/problems/populating-next-right-pointers-in-each-node-ii/ /** 116. 填充每个节点的下一个右侧节点指针 117. 填充每个节点的下一个右侧节点指针 II */ func connect(root *Node) *Node { res:=[][]*Node{} if root==nil{//防止为空 return root } queue:=list.New() queue.PushBack(root) var tmpArr []*Node for queue.Len()\u003e0 { length:=queue.Len()//保存当前层的长度，然后处理当前层（十分重要，防止添加下层元素影响判断层中元素的个数） for i:=0;i\u003clength;i++{ node:=queue.Remove(queue.Front()).(*Node)//出队列 if node.Left!=nil{ queue.PushBack(node.Left) } if node.Right!=nil{ queue.PushBack(node.Right) } tmpArr=append(tmpArr,node)//将值加入本层切片中 } res=append(res,tmpArr)//放入结果集 tmpArr=[]*Node{}//清空层的数据 } //遍历每层元素,指定next for i:=0;i\u003clen(res);i++{ for j:=0;j\u003clen(res[i])-1;j++{ res[i][j].Next=res[i][j+1] } } return root } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:5:8","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"104.二叉树的最大深度 https://leetcode-cn.com/problems/maximum-depth-of-binary-tree/ /** * Definition for a binary tree node. * type TreeNode struct { * Val int * Left *TreeNode * Right *TreeNode * } */ func maxDepth(root *TreeNode) int { ans:=0 if root==nil{ return 0 } queue:=list.New() queue.PushBack(root) for queue.Len()\u003e0{ length:=queue.Len() for i:=0;i\u003clength;i++{ node:=queue.Remove(queue.Front()).(*TreeNode) if node.Left!=nil{ queue.PushBack(node.Left) } if node.Right!=nil{ queue.PushBack(node.Right) } } ans++//记录深度，其他的是层序遍历的板子 } return ans } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:5:9","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"111.二叉树的最小深度 https://leetcode-cn.com/problems/minimum-depth-of-binary-tree/ /** * Definition for a binary tree node. * type TreeNode struct { * Val int * Left *TreeNode * Right *TreeNode * } */ func minDepth(root *TreeNode) int { ans:=0 if root==nil{ return 0 } queue:=list.New() queue.PushBack(root) for queue.Len()\u003e0{ length:=queue.Len() for i:=0;i\u003clength;i++{ node:=queue.Remove(queue.Front()).(*TreeNode) if node.Left==nil\u0026\u0026node.Right==nil{//当前节点没有左右节点，则代表此层是最小层 return ans+1//返回当前层 ans代表是上一层 } if node.Left!=nil{ queue.PushBack(node.Left) } if node.Right!=nil{ queue.PushBack(node.Right) } } ans++//记录层数 } return ans+1 } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:5:10","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"翻转二叉树 二叉树，当然是左右翻转。 递归版本的前序遍历 func invertTree(root *TreeNode) *TreeNode { if root ==nil{ return nil } temp:=root.Left root.Left=root.Right root.Right=temp invertTree(root.Left) invertTree(root.Right) return root } 递归版本的后序遍历 func invertTree(root *TreeNode) *TreeNode { if root==nil{ return root } invertTree(root.Left)//遍历左节点 invertTree(root.Right)//遍历右节点 root.Left,root.Right=root.Right,root.Left//交换 return root } 迭代版本的前序遍历 func invertTree(root *TreeNode) *TreeNode { stack:=[]*TreeNode{} node:=root for node!=nil||len(stack)\u003e0{ for node!=nil{ node.Left,node.Right=node.Right,node.Left//交换 stack=append(stack,node) node=node.Left } node=stack[len(stack)-1] stack=stack[:len(stack)-1] node=node.Right } return root } 迭代版本的后序遍历 func invertTree(root *TreeNode) *TreeNode { stack:=[]*TreeNode{} node:=root var prev *TreeNode for node!=nil||len(stack)\u003e0{ for node!=nil{ stack=append(stack,node) node=node.Left } node=stack[len(stack)-1] stack=stack[:len(stack)-1] if node.Right==nil||node.Right==prev{ node.Left,node.Right=node.Right,node.Left//交换 prev=node node=nil }else { stack=append(stack,node) node=node.Right } } return root } 层序遍历 func invertTree(root *TreeNode) *TreeNode { if root==nil{ return root } queue:=list.New() node:=root queue.PushBack(node) for queue.Len()\u003e0{ length:=queue.Len() for i:=0;i\u003clength;i++{ e:=queue.Remove(queue.Front()).(*TreeNode) e.Left,e.Right=e.Right,e.Left//交换 if e.Left!=nil{ queue.PushBack(e.Left) } if e.Right!=nil{ queue.PushBack(e.Right) } } } return root } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:6:0","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"对称二叉树 检查二叉树是否镜像对称。 /** * Definition for a binary tree node. * type TreeNode struct { * Val int * Left *TreeNode * Right *TreeNode * } */ // 递归 func defs(left *TreeNode, right *TreeNode) bool { if left == nil \u0026\u0026 right == nil { return true; }; if left == nil || right == nil { return false; }; if left.Val != right.Val { return false; } return defs(left.Left, right.Right) \u0026\u0026 defs(right.Left, left.Right); } func isSymmetric(root *TreeNode) bool { return defs(root.Left, root.Right); } // 迭代 func isSymmetric(root *TreeNode) bool { var queue []*TreeNode; if root != nil { queue = append(queue, root.Left, root.Right); } for len(queue) \u003e 0 { left := queue[0]; right := queue[1]; queue = queue[2:]; if left == nil \u0026\u0026 right == nil { continue; } if left == nil || right == nil || left.Val != right.Val { return false; }; queue = append(queue, left.Left, right.Right, right.Left, left.Right); } return true; } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:7:0","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"最大深度 /** * definition for a binary tree node. * type treenode struct { * val int * left *treenode * right *treenode * } */ func max (a, b int) int { if a \u003e b { return a; } return b; } // 递归 func maxdepth(root *treenode) int { if root == nil { return 0; } return max(maxdepth(root.left), maxdepth(root.right)) + 1; } // 遍历 func maxdepth(root *treenode) int { levl := 0; queue := make([]*treenode, 0); if root != nil { queue = append(queue, root); } for l := len(queue); l \u003e 0; { for ;l \u003e 0;l-- { node := queue[0]; if node.left != nil { queue = append(queue, node.left); } if node.right != nil { queue = append(queue, node.right); } queue = queue[1:]; } levl++; l = len(queue); } return levl; } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:8:0","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"最小深度 /** * Definition for a binary tree node. * type TreeNode struct { * Val int * Left *TreeNode * Right *TreeNode * } */ func min(a, b int) int { if a \u003c b { return a; } return b; } // 递归 func minDepth(root *TreeNode) int { if root == nil { return 0; } if root.Left == nil \u0026\u0026 root.Right != nil { return 1 + minDepth(root.Right); } if root.Right == nil \u0026\u0026 root.Left != nil { return 1 + minDepth(root.Left); } return min(minDepth(root.Left), minDepth(root.Right)) + 1; } // 迭代 func minDepth(root *TreeNode) int { dep := 0; queue := make([]*TreeNode, 0); if root != nil { queue = append(queue, root); } for l := len(queue); l \u003e 0; { dep++; for ; l \u003e 0; l-- { node := queue[0]; if node.Left == nil \u0026\u0026 node.Right == nil { return dep; } if node.Left != nil { queue = append(queue, node.Left); } if node.Right != nil { queue = append(queue, node.Right); } queue = queue[1:]; } l = len(queue); } return dep; } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:9:0","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"完全二叉树的节点个数 递归版本 /** * Definition for a binary tree node. * type TreeNode struct { * Val int * Left *TreeNode * Right *TreeNode * } */ //本题直接就是求有多少个节点，无脑存进数组算长度就行了。 func countNodes(root *TreeNode) int { if root == nil { return 0 } res := 1 if root.Right != nil { res += countNodes(root.Right) } if root.Left != nil { res += countNodes(root.Left) } return res } 利用完全二叉树特性的递归解法 func countNodes(root *TreeNode) int { if root == nil { return 0 } leftH, rightH := 0, 0 leftNode := root.Left rightNode := root.Right for leftNode != nil { leftNode = leftNode.Left leftH++ } for rightNode != nil { rightNode = rightNode.Right rightH++ } if leftH == rightH { return (2 \u003c\u003c leftH) - 1 } return countNodes(root.Left) + countNodes(root.Right) + 1 } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:10:0","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"平衡二叉树 给定一个二叉树，判断它是否是高度平衡的二叉树。 本题中，一棵高度平衡二叉树定义为：一个二叉树每个节点 的左右两个子树的高度差的绝对值不超过1。 func isBalanced(root *TreeNode) bool { if root==nil{ return true } if !isBalanced(root.Left) || !isBalanced(root.Right){ return false } LeftH:=maxdepth(root.Left)+1 RightH:=maxdepth(root.Right)+1 if abs(LeftH-RightH)\u003e1{ return false } return true } func maxdepth(root *TreeNode)int{ if root==nil{ return 0 } return max(maxdepth(root.Left),maxdepth(root.Right))+1 } func max(a,b int)int{ if a\u003eb{ return a } return b } func abs(a int)int{ if a\u003c0{ return -a } return a } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:11:0","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"二叉树的所有路径 递归法： func binaryTreePaths(root *TreeNode) []string { res := make([]string, 0) var travel func(node *TreeNode, s string) travel = func(node *TreeNode, s string) { if node.Left == nil \u0026\u0026 node.Right == nil { v := s + strconv.Itoa(node.Val) res = append(res, v) return } s = s + strconv.Itoa(node.Val) + \"-\u003e\" if node.Left != nil { travel(node.Left, s) } if node.Right != nil { travel(node.Right, s) } } travel(root, \"\") return res } 迭代法： func binaryTreePaths(root *TreeNode) []string { stack := []*TreeNode{} paths := make([]string, 0) res := make([]string, 0) if root != nil { stack = append(stack, root) paths = append(paths, \"\") } for len(stack) \u003e 0 { l := len(stack) node := stack[l-1] path := paths[l-1] stack = stack[:l-1] paths = paths[:l-1] if node.Left == nil \u0026\u0026 node.Right == nil { res = append(res, path+strconv.Itoa(node.Val)) continue } if node.Right != nil { stack = append(stack, node.Right) paths = append(paths, path+strconv.Itoa(node.Val)+\"-\u003e\") } if node.Left != nil { stack = append(stack, node.Left) paths = append(paths, path+strconv.Itoa(node.Val)+\"-\u003e\") } } return res } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:12:0","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"二叉树的递归+回溯 100.相同的树 /** * Definition for a binary tree node. * type TreeNode struct { * Val int * Left *TreeNode * Right *TreeNode * } */ func isSameTree(p *TreeNode, q *TreeNode) bool { switch { case p == nil \u0026\u0026 q == nil: return true case p == nil || q == nil: fallthrough case p.Val != q.Val: return false } return isSameTree(p.Left, q.Left) \u0026\u0026 isSameTree(p.Right, q.Right) } 257.二叉的所有路径 递归法 /** * Definition for a binary tree node. * type TreeNode struct { * Val int * Left *TreeNode * Right *TreeNode * } */ func binaryTreePaths(root *TreeNode) []string { var result []string traversal(root,\u0026result,\"\") return result } func traversal(root *TreeNode,result *[]string,pathStr string){ //判断是否为第一个元素 if len(pathStr)!=0{ pathStr=pathStr+\"-\u003e\"+strconv.Itoa(root.Val) }else{ pathStr=strconv.Itoa(root.Val) } //判断是否为叶子节点 if root.Left==nil\u0026\u0026root.Right==nil{ *result=append(*result,pathStr) return } //左右 if root.Left!=nil{ traversal(root.Left,result,pathStr) } if root.Right!=nil{ traversal(root.Right,result,pathStr) } } 回溯法 /** * Definition for a binary tree node. * type TreeNode struct { * Val int * Left *TreeNode * Right *TreeNode * } */ func binaryTreePaths(root *TreeNode) []string { var result []string var path []int traversal(root,\u0026result,\u0026path) return result } func traversal(root *TreeNode,result *[]string,path *[]int){ *path=append(*path,root.Val) //判断是否为叶子节点 if root.Left==nil\u0026\u0026root.Right==nil{ pathStr:=strconv.Itoa((*path)[0]) for i:=1;i\u003clen(*path);i++{ pathStr=pathStr+\"-\u003e\"+strconv.Itoa((*path)[i]) } *result=append(*result,pathStr) return } //左右 if root.Left!=nil{ traversal(root.Left,result,path) *path=(*path)[:len(*path)-1]//回溯到上一个节点（因为traversal会加下一个节点值到path中） } if root.Right!=nil{ traversal(root.Right,result,path) *path=(*path)[:len(*path)-1]//回溯 } } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:13:0","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"左叶子之和 递归法 func sumOfLeftLeaves(root *TreeNode) int { var res int findLeft(root,\u0026res) return res } func findLeft(root *TreeNode,res *int){ //左节点 if root.Left!=nil\u0026\u0026root.Left.Left==nil\u0026\u0026root.Left.Right==nil{ *res=*res+root.Left.Val } if root.Left!=nil{ findLeft(root.Left,res) } if root.Right!=nil{ findLeft(root.Right,res) } } 迭代法 func sumOfLeftLeaves(root *TreeNode) int { var res int queue:=list.New() queue.PushBack(root) for queue.Len()\u003e0{ length:=queue.Len() for i:=0;i\u003clength;i++{ node:=queue.Remove(queue.Front()).(*TreeNode) if node.Left!=nil\u0026\u0026node.Left.Left==nil\u0026\u0026node.Left.Right==nil{ res=res+node.Left.Val } if node.Left!=nil{ queue.PushBack(node.Left) } if node.Right!=nil{ queue.PushBack(node.Right) } } } return res } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:14:0","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"找树左下角的值 给定一个二叉树，在树的最后一行找到最左边的值。 递归法： var maxDeep int // 全局变量 深度 var value int //全局变量 最终值 func findBottomLeftValue(root *TreeNode) int { if root.Left==nil\u0026\u0026root.Right==nil{//需要提前判断一下（不要这个if的话提交结果会出错，但执行代码不会。防止这种情况出现，故先判断是否只有一个节点） return root.Val } findLeftValue (root,maxDeep) return value } func findLeftValue (root *TreeNode,deep int){ //最左边的值在左边 if root.Left==nil\u0026\u0026root.Right==nil{ if deep\u003emaxDeep{ value=root.Val maxDeep=deep } } //递归 if root.Left!=nil{ deep++ findLeftValue(root.Left,deep) deep--//回溯 } if root.Right!=nil{ deep++ findLeftValue(root.Right,deep) deep--//回溯 } } 迭代法： func findBottomLeftValue(root *TreeNode) int { queue:=list.New() var gradation int queue.PushBack(root) for queue.Len()\u003e0{ length:=queue.Len() for i:=0;i\u003clength;i++{ node:=queue.Remove(queue.Front()).(*TreeNode) if i==0{gradation=node.Val} if node.Left!=nil{ queue.PushBack(node.Left) } if node.Right!=nil{ queue.PushBack(node.Right) } } } return gradation } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:15:0","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"路径总和 给定一个二叉树和一个目标和，判断该树中是否存在根节点到叶子节点的路径，这条路径上所有节点值相加等于目标和 路径总和 //递归法 /** * definition for a binary tree node. * type treenode struct { * val int * left *treenode * right *treenode * } */ func haspathsum(root *treenode, targetsum int) bool { var flage bool //找没找到的标志 if root==nil{ return flage } pathsum(root,0,targetsum,\u0026flage) return flage } func pathsum(root *treenode, sum int,targetsum int,flage *bool){ sum+=root.val if root.left==nil\u0026\u0026root.right==nil\u0026\u0026sum==targetsum{ *flage=true return } if root.left!=nil\u0026\u0026!(*flage){//左节点不为空且还没找到 pathsum(root.left,sum,targetsum,flage) } if root.right!=nil\u0026\u0026!(*flage){//右节点不为空且没找到 pathsum(root.right,sum,targetsum,flage) } } 113 递归法 /** * definition for a binary tree node. * type treenode struct { * val int * left *treenode * right *treenode * } */ func pathsum(root *treenode, targetsum int) [][]int { var result [][]int//最终结果 if root==nil{ return result } var sumnodes []int//经过路径的节点集合 haspathsum(root,\u0026sumnodes,targetsum,\u0026result) return result } func haspathsum(root *treenode,sumnodes *[]int,targetsum int,result *[][]int){ *sumnodes=append(*sumnodes,root.val) if root.left==nil\u0026\u0026root.right==nil{//叶子节点 fmt.println(*sumnodes) var sum int var number int for k,v:=range *sumnodes{//求该路径节点的和 sum+=v number=k } tempnodes:=make([]int,number+1)//新的nodes接受指针里的值，防止最终指针里的值发生变动，导致最后的结果都是最后一个sumnodes的值 for k,v:=range *sumnodes{ tempnodes[k]=v } if sum==targetsum{ *result=append(*result,tempnodes) } } if root.left!=nil{ haspathsum(root.left,sumnodes,targetsum,result) *sumnodes=(*sumnodes)[:len(*sumnodes)-1]//回溯 } if root.right!=nil{ haspathsum(root.right,sumnodes,targetsum,result) *sumnodes=(*sumnodes)[:len(*sumnodes)-1]//回溯 } } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:16:0","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"从中序、后序遍历序列构造二叉树 106 从中序与后序遍历序列构造二叉树 /** * Definition for a binary tree node. * type TreeNode struct { * Val int * Left *TreeNode * Right *TreeNode * } */ func buildTree(inorder []int, postorder []int) *TreeNode { if len(inorder)\u003c1||len(postorder)\u003c1{return nil} //先找到根节点（后续遍历的最后一个就是根节点） nodeValue:=postorder[len(postorder)-1] //从中序遍历中找到一分为二的点，左边为左子树，右边为右子树 left:=findRootIndex(inorder,nodeValue) //构造root root:=\u0026TreeNode{Val: nodeValue, Left: buildTree(inorder[:left],postorder[:left]),//将后续遍历一分为二，左边为左子树，右边为右子树 Right: buildTree(inorder[left+1:],postorder[left:len(postorder)-1])} return root } func findRootIndex(inorder []int,target int) (index int){ for i:=0;i\u003clen(inorder);i++{ if target==inorder[i]{ return i } } return -1 } 105 从前序与中序遍历序列构造二叉树 /** * Definition for a binary tree node. * type TreeNode struct { * Val int * Left *TreeNode * Right *TreeNode * } */ func buildTree(preorder []int, inorder []int) *TreeNode { if len(preorder)\u003c1||len(inorder)\u003c1{return nil} left:=findRootIndex(preorder[0],inorder) root:=\u0026TreeNode{ Val: preorder[0], Left: buildTree(preorder[1:left+1],inorder[:left]), Right: buildTree(preorder[left+1:],inorder[left+1:])} return root } func findRootIndex(target int,inorder []int) int{ for i:=0;i\u003clen(inorder);i++{ if target==inorder[i]{ return i } } return -1 } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:17:0","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"最大二叉树 给定一个不含重复元素的整数数组。一个以此数组构建的最大二叉树定义如下： 二叉树的根是数组中的最大元素。 左子树是通过数组中最大值左边部分构造出的最大二叉树。 右子树是通过数组中最大值右边部分构造出的最大二叉树。 /** * Definition for a binary tree node. * type TreeNode struct { * Val int * Left *TreeNode * Right *TreeNode * } */ func constructMaximumBinaryTree(nums []int) *TreeNode { if len(nums)\u003c1{return nil} //首选找到最大值 index:=findMax(nums) //其次构造二叉树 root:=\u0026TreeNode{ Val: nums[index], Left:constructMaximumBinaryTree(nums[:index]),//左半边 Right:constructMaximumBinaryTree(nums[index+1:]),//右半边 } return root } func findMax(nums []int) (index int){ for i:=0;i\u003clen(nums);i++{ if nums[i]\u003enums[index]{ index=i } } return } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:18:0","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"合并二叉树 /** * Definition for a binary tree node. * type TreeNode struct { * Val int * Left *TreeNode * Right *TreeNode * } */ //前序遍历（递归遍历，跟105 106差不多的思路） func mergeTrees(t1 *TreeNode, t2 *TreeNode) *TreeNode { var value int var nullNode *TreeNode//空node，便于遍历 nullNode=\u0026TreeNode{ Val:0, Left:nil, Right:nil} switch { case t1==nil\u0026\u0026t2==nil: return nil//终止条件 default : //如果其中一个节点为空，则将该节点置为nullNode，方便下次遍历 if t1==nil{ value=t2.Val t1=nullNode }else if t2==nil{ value=t1.Val t2=nullNode }else { value=t1.Val+t2.Val } } root:=\u0026TreeNode{//构造新的二叉树 Val: value, Left: mergeTrees(t1.Left,t2.Left), Right: mergeTrees(t1.Right,t2.Right)} return root } // 前序遍历简洁版 func mergeTrees(root1 *TreeNode, root2 *TreeNode) *TreeNode { if root1 == nil { return root2 } if root2 == nil { return root1 } root1.Val += root2.Val root1.Left = mergeTrees(root1.Left, root2.Left) root1.Right = mergeTrees(root1.Right, root2.Right) return root1 } // 迭代版本 func mergeTrees(root1 *TreeNode, root2 *TreeNode) *TreeNode { queue := make([]*TreeNode,0) if root1 == nil{ return root2 } if root2 == nil{ return root1 } queue = append(queue,root1) queue = append(queue,root2) for size:=len(queue);size\u003e0;size=len(queue){ node1 := queue[0] queue = queue[1:] node2 := queue[0] queue = queue[1:] node1.Val += node2.Val // 左子树都不为空 if node1.Left != nil \u0026\u0026 node2.Left != nil{ queue = append(queue,node1.Left) queue = append(queue,node2.Left) } // 右子树都不为空 if node1.Right !=nil \u0026\u0026 node2.Right !=nil{ queue = append(queue,node1.Right) queue = append(queue,node2.Right) } // 树 1 的左子树为 nil，直接接上树 2 的左子树 if node1.Left == nil{ node1.Left = node2.Left } // 树 1 的右子树为 nil，直接接上树 2 的右子树 if node1.Right == nil{ node1.Right = node2.Right } } return root1 } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:19:0","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"二叉搜索树 ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:20:0","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"搜索 给定二叉搜索树（BST）的根节点和一个值。 你需要在BST中找到节点值等于给定值的节点。 返回以该节点为根的子树。 如果节点不存在，则返回 NULL。 递归法： //递归法 func searchBST(root *TreeNode, val int) *TreeNode { if root==nil||root.Val==val{ return root } if root.Val\u003eval{ return searchBST(root.Left,val) } return searchBST(root.Right,val) } 迭代法： //迭代法 func searchBST(root *TreeNode, val int) *TreeNode { for root!=nil{ if root.Val\u003eval{ root=root.Left }else if root.Val\u003cval{ root=root.Right }else{ break } } return root } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:20:1","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"验证 给定一个二叉树，判断其是否是一个有效的二叉搜索树。 假设一个二叉搜索树具有如下特征： 节点的左子树只包含小于当前节点的数。 节点的右子树只包含大于当前节点的数。 所有左子树和右子树自身必须也是二叉搜索树。 import \"math\" func isValidBST(root *TreeNode) bool { // 二叉搜索树也可以是空树 if root == nil { return true } // 由题目中的数据限制可以得出min和max return check(root,math.MinInt64,math.MaxInt64) } func check(node *TreeNode,min,max int64) bool { if node == nil { return true } if min \u003e= int64(node.Val) || max \u003c= int64(node.Val) { return false } // 分别对左子树和右子树递归判断，如果左子树和右子树都符合则返回true return check(node.Right,int64(node.Val),max) \u0026\u0026 check(node.Left,min,int64(node.Val)) } // 中序遍历解法 func isValidBST(root *TreeNode) bool { // 保存上一个指针 var prev *TreeNode var travel func(node *TreeNode) bool travel = func(node *TreeNode) bool { if node == nil { return true } leftRes := travel(node.Left) // 当前值小于等于前一个节点的值，返回false if prev != nil \u0026\u0026 node.Val \u003c= prev.Val { return false } prev = node rightRes := travel(node.Right) return leftRes \u0026\u0026 rightRes } return travel(root) } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:20:2","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"最小绝对差 给你一棵所有节点为非负值的二叉搜索树，请你计算树中任意两节点的差的绝对值的最小值。 中序遍历，然后计算最小差值 func getMinimumDifference(root *TreeNode) int { var res []int findMIn(root,\u0026res) min:=1000000//一个比较大的值 for i:=1;i\u003clen(res);i++{ tempValue:=res[i]-res[i-1] if tempValue\u003cmin{ min=tempValue } } return min } //中序遍历 func findMIn(root *TreeNode,res *[]int){ if root==nil{return} findMIn(root.Left,res) *res=append(*res,root.Val) findMIn(root.Right,res) } // 中序遍历的同时计算最小值 func getMinimumDifference(root *TreeNode) int { // 保留前一个节点的指针 var prev *TreeNode // 定义一个比较大的值 min := math.MaxInt64 var travel func(node *TreeNode) travel = func(node *TreeNode) { if node == nil { return } travel(node.Left) if prev != nil \u0026\u0026 node.Val - prev.Val \u003c min { min = node.Val - prev.Val } prev = node travel(node.Right) } travel(root) return min } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:20:3","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"众数 给定一个有相同值的二叉搜索树（BST），找出 BST 中的所有众数（出现频率最高的元素）。 暴力法 func findMode(root *TreeNode) []int { var history map[int]int var maxValue int var maxIndex int var result []int history=make(map[int]int) traversal(root,history) for k,value:=range history{ if value\u003emaxValue{ maxValue=value maxIndex=k } } for k,value:=range history{ if value==history[maxIndex]{ result=append(result,k) } } return result } func traversal(root *TreeNode,history map[int]int){ if root.Left!=nil{ traversal(root.Left,history) } if value,ok:=history[root.Val];ok{ history[root.Val]=value+1 }else{ history[root.Val]=1 } if root.Right!=nil{ traversal(root.Right,history) } } 计数法，不使用额外空间，利用二叉树性质，中序遍历 func findMode(root *TreeNode) []int { res := make([]int, 0) count := 1 max := 1 var prev *TreeNode var travel func(node *TreeNode) travel = func(node *TreeNode) { if node == nil { return } travel(node.Left) if prev != nil \u0026\u0026 prev.Val == node.Val { count++ } else { count = 1 } if count \u003e= max { if count \u003e max \u0026\u0026 len(res) \u003e 0 { res = []int{node.Val} } else { res = append(res, node.Val) } max = count } prev = node travel(node.Right) } travel(root) return res } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:20:4","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"二叉树最近公共祖先 给定一个二叉树, 找到该树中两个指定节点的最近公共祖先（可以是自己） func lowestCommonAncestor(root, p, q *TreeNode) *TreeNode { // check if root == nil { return root } // 相等 直接返回root节点即可 if root == p || root == q { return root } // Divide left := lowestCommonAncestor(root.Left, p, q) right := lowestCommonAncestor(root.Right, p, q) // Conquer // 左右两边都不为空，则根节点为祖先 if left != nil \u0026\u0026 right != nil { return root } if left != nil { return left } if right != nil { return right } return nil } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:20:5","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"二叉搜索树的最近公共祖先 递归法： //利用BSL的性质（前序遍历有序） func lowestCommonAncestor(root, p, q *TreeNode) *TreeNode { if root==nil{return nil} if root.Val\u003ep.Val\u0026\u0026root.Val\u003eq.Val{//当前节点的值大于给定的值，则说明满足条件的在左边 return lowestCommonAncestor(root.Left,p,q) }else if root.Val\u003cp.Val\u0026\u0026root.Val\u003cq.Val{//当前节点的值小于各点的值，则说明满足条件的在右边 return lowestCommonAncestor(root.Right,p,q) }else {return root}//当前节点的值在给定值的中间（或者等于），即为最深的祖先 } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:20:6","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"插入操作 给定二叉搜索树（BST）的根节点和要插入树中的值，将值插入二叉搜索树。 返回插入后二叉搜索树的根节点。 输入数据保证，新值和原始二叉搜索树中的任意节点值都不同。 递归法 func insertIntoBST(root *TreeNode, val int) *TreeNode { if root == nil { root = \u0026TreeNode{Val: val} return root } if root.Val \u003e val { root.Left = insertIntoBST(root.Left, val) } else { root.Right = insertIntoBST(root.Right, val) } return root } 迭代法 func insertIntoBST(root *TreeNode, val int) *TreeNode { if root == nil { return \u0026TreeNode{Val:val} } node := root var pnode *TreeNode for node != nil { if val \u003e node.Val { pnode = node node = node.Right } else { pnode = node node = node.Left } } if val \u003e pnode.Val { pnode.Right = \u0026TreeNode{Val: val} } else { pnode.Left = \u0026TreeNode{Val: val} } return root } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:20:7","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"删除节点 搜索树的节点删除要比节点增加复杂的多。 // 递归版本 func deleteNode(root *TreeNode, key int) *TreeNode { if root==nil{ return nil } if key\u003croot.Val{ root.Left=deleteNode(root.Left,key) return root } if key\u003eroot.Val{ root.Right=deleteNode(root.Right,key) return root } if root.Right==nil{ return root.Left } if root.Left==nil{ return root.Right } minnode:=root.Right for minnode.Left!=nil{ minnode=minnode.Left } root.Val=minnode.Val root.Right=deleteNode1(root.Right) return root } func deleteNode1(root *TreeNode)*TreeNode{ if root.Left==nil{ pRight:=root.Right root.Right=nil return pRight } root.Left=deleteNode1(root.Left) return root } // 迭代版本 func deleteOneNode(target *TreeNode) *TreeNode { if target == nil { return target } if target.Right == nil { return target.Left } cur := target.Right for cur.Left != nil { cur = cur.Left } cur.Left = target.Left return target.Right } func deleteNode(root *TreeNode, key int) *TreeNode { // 特殊情况处理 if root == nil { return root } cur := root var pre *TreeNode for cur != nil { if cur.Val == key { break } pre = cur if cur.Val \u003e key { cur = cur.Left } else { cur = cur.Right } } if pre == nil { return deleteOneNode(cur) } // pre 要知道是删除左孩子还有右孩子 if pre.Left != nil \u0026\u0026 pre.Left.Val == key { pre.Left = deleteOneNode(cur) } if pre.Right != nil \u0026\u0026 pre.Right.Val == key { pre.Right = deleteOneNode(cur) } return root } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:20:8","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"修剪 给定一个二叉搜索树，同时给定最小边界L 和最大边界 R。通过修剪二叉搜索树，使得所有节点的值在[L, R]中 (R\u003e=L) 。你可能需要改变树的根节点，所以结果应当返回修剪好的二叉搜索树的新的根节点。 // 递归 func trimBST(root *TreeNode, low int, high int) *TreeNode { if root==nil{ return nil } if root.Val\u003clow{//如果该节点值小于最小值，则该节点更换为该节点的右节点值，继续遍历 right:=trimBST(root.Right,low,high) return right } if root.Val\u003ehigh{//如果该节点的值大于最大值，则该节点更换为该节点的左节点值，继续遍历 left:=trimBST(root.Left,low,high) return left } root.Left=trimBST(root.Left,low,high) root.Right=trimBST(root.Right,low,high) return root } // 迭代 func trimBST(root *TreeNode, low int, high int) *TreeNode { if root == nil { return nil } // 处理 root，让 root 移动到[low, high] 范围内，**注意**是左闭右闭 for root != nil \u0026\u0026 (root.Val\u003clow||root.Val\u003ehigh){ if root.Val \u003c low{ root = root.Right }else{ root = root.Left } } cur := root // 此时 root 已经在[low, high] 范围内，处理左孩子元素小于 low 的情况（左节点是一定小于 root.Val，因此天然小于 high） for cur != nil{ for cur.Left!=nil \u0026\u0026 cur.Left.Val \u003c low{ cur.Left = cur.Left.Right } cur = cur.Left } cur = root // 此时 root 已经在[low, high] 范围内，处理右孩子大于 high 的情况 for cur != nil{ for cur.Right!=nil \u0026\u0026 cur.Right.Val \u003e high{ cur.Right = cur.Right.Left } cur = cur.Right } return root } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:20:9","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"将有序数组转化为二叉搜索树 将一个按照升序排列的有序数组，转换为一棵高度平衡二叉搜索树。 本题中，一个高度平衡二叉树是指一个二叉树每个节点 的左右两个子树的高度差的绝对值不超过 1。 递归（隐含回溯） func sortedArrayToBST(nums []int) *TreeNode { if len(nums)==0{return nil}//终止条件，最后数组为空则可以返回 root:=\u0026TreeNode{nums[len(nums)/2],nil,nil}//按照BSL的特点，从中间构造节点 root.Left=sortedArrayToBST(nums[:len(nums)/2])//数组的左边为左子树 root.Right=sortedArrayToBST(nums[len(nums)/2+1:])//数字的右边为右子树 return root } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:20:10","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":"把二叉搜索树转化为累加树 给出二叉 搜索 树的根节点，该树的节点值各不相同，请你将其转换为累加树（Greater Sum Tree），使每个节点 node 的新值等于原树中大于或等于 node.val 的值之和。 弄一个sum暂存其和值 //右中左 func bstToGst(root *TreeNode) *TreeNode { var sum int RightMLeft(root,\u0026sum) return root } func RightMLeft(root *TreeNode,sum *int) *TreeNode { if root==nil{return nil}//终止条件，遇到空节点就返回 RightMLeft(root.Right,sum)//先遍历右边 temp:=*sum//暂存总和值 *sum+=root.Val//将总和值变更 root.Val+=temp//更新节点值 RightMLeft(root.Left,sum)//遍历左节点 return root } ","date":"2022-01-06 08:21:45","objectID":"/algorithm_binarytree/:20:11","tags":["data structure"],"title":"Algorithm_binaryTree","uri":"/algorithm_binarytree/"},{"categories":["Coding"],"content":" 学习代码随想录笔记 栈和队列 需要知道栈和队列的底层实现，不同编程语言不同STL的实现原理都是不尽相同的。 ","date":"2022-01-06 08:20:54","objectID":"/algorithm_stackandqueue/:0:0","tags":["data structure"],"title":"Algorithm_stackAndQueue","uri":"/algorithm_stackandqueue/"},{"categories":["Coding"],"content":"理论基础(c++) 栈其实就是递归的一种实现结构。 栈（本身可以说是一个容器适配器）是以底层容器（数组或者链表）完成其所有的工作，对外提供统一的接口，底层容器是可插拔的（也就是说我们可以控制使用哪种容器来实现栈的功能）。 SGI -- Silicon Graphics [Computer System] Inc. 硅图[计算机系统] 公司. STL -- Standard Template Library 标准模板库。 SGI STL -- SGI的标准模板库。 SGI的全称 -- 硅图[计算机系统] 公司。 我们常用的SGI STL，如果没有指定底层实现的话，默认是以deque为缺省情况下栈的低层结构。 deque是一个双向队列，只要封住一段，只开通另一端就可以实现栈的逻辑了。 SGI STL中 队列底层实现缺省情况下一样使用deque实现的。 我们也可以指定vector为栈的底层实现，初始化语句如下： std::stack\u003cint, std::vector\u003cint\u003e \u003e third; // 使用vector为底层容器的栈 对应的队列的情况是一样的。 队列中先进先出的数据结构，同样不允许有遍历行为，不提供迭代器, SGI STL中队列一样是以deque为缺省情况下的底部结构。 也可以指定list 为起底层实现，初始化queue的语句如下： std::queue\u003cint, std::list\u003cint\u003e\u003e third; // 定义以list为底层容器的队列 所以STL 队列也不被归类为容器，而被归类为container adapter（ 容器适配器）。 ","date":"2022-01-06 08:20:54","objectID":"/algorithm_stackandqueue/:1:0","tags":["data structure"],"title":"Algorithm_stackAndQueue","uri":"/algorithm_stackandqueue/"},{"categories":["Coding"],"content":"用栈实现队列 使用栈实现队列的下列操作： push(x) – 将一个元素放入队列的尾部。 pop() – 从队列首部移除元素。 peek() – 返回队列首部的元素。 empty() – 返回队列是否为空。 示例: MyQueue queue = new MyQueue(); queue.push(1); queue.push(2); queue.peek(); // 返回 1 queue.pop(); // 返回 1 queue.empty(); // 返回 false 说明: 你只能使用标准的栈操作 – 也就是只有 push to top, peek/pop from top, size, 和 is empty 操作是合法的。 你所使用的语言也许不支持栈。你可以使用 list 或者 deque（双端队列）来模拟一个栈，只要是标准的栈操作即可。 假设所有操作都是有效的 （例如，一个空的队列不会调用 pop 或者 peek 操作） type MyQueue struct { stack []int back []int } /** Initialize your data structure here. */ func Constructor() MyQueue { return MyQueue{ stack: make([]int, 0), back: make([]int, 0), } } /** Push element x to the back of queue. */ func (this *MyQueue) Push(x int) { for len(this.back) != 0 { val := this.back[len(this.back)-1] this.back = this.back[:len(this.back)-1] this.stack = append(this.stack, val) } this.stack = append(this.stack, x) } /** Removes the element from in front of queue and returns that element. */ func (this *MyQueue) Pop() int { for len(this.stack) != 0 { val := this.stack[len(this.stack)-1] this.stack = this.stack[:len(this.stack)-1] this.back = append(this.back, val) } if len(this.back) == 0 { return 0 } val := this.back[len(this.back)-1] this.back = this.back[:len(this.back)-1] return val } /** Get the front element. */ func (this *MyQueue) Peek() int { for len(this.stack) != 0 { val := this.stack[len(this.stack)-1] this.stack = this.stack[:len(this.stack)-1] this.back = append(this.back, val) } if len(this.back) == 0 { return 0 } val := this.back[len(this.back)-1] return val } /** Returns whether the queue is empty. */ func (this *MyQueue) Empty() bool { return len(this.stack) == 0 \u0026\u0026 len(this.back) == 0 } ","date":"2022-01-06 08:20:54","objectID":"/algorithm_stackandqueue/:2:0","tags":["data structure"],"title":"Algorithm_stackAndQueue","uri":"/algorithm_stackandqueue/"},{"categories":["Coding"],"content":"用队列实现栈 使用队列实现栈的下列操作： push(x) -- 元素 x 入栈 pop() -- 移除栈顶元素 top() -- 获取栈顶元素 empty() -- 返回栈是否为空 注意: 你只能使用队列的基本操作– 也就是 push to back, peek/pop from front, size, 和 is empty 这些操作是合法的。 你所使用的语言也许不支持队列。 你可以使用 list 或者 deque（双端队列）来模拟一个队列 , 只要是标准的队列操作即可。 你可以假设所有操作都是有效的（例如, 对一个空的栈不会调用 pop 或者 top 操作） 用两个队列实现： type MyStack struct { //创建两个队列 queue1 []int queue2 []int } func Constructor() MyStack { return MyStack{ //初始化 queue1:make([]int,0), queue2:make([]int,0), } } func (this *MyStack) Push(x int) { //先将数据存在queue2中 this.queue2 = append(this.queue2,x) //将queue1中所有元素移到queue2中，再将两个队列进行交换 this.Move() } func (this *MyStack) Move(){ if len(this.queue1) == 0{ //交换，queue1置为queue2,queue2置为空 this.queue1,this.queue2 = this.queue2,this.queue1 }else{ //queue1元素从头开始一个一个追加到queue2中 this.queue2 = append(this.queue2,this.queue1[0]) this.queue1 = this.queue1[1:] //去除第一个元素 this.Move() //重复 } } func (this *MyStack) Pop() int { val := this.queue1[0] this.queue1 = this.queue1[1:] //去除第一个元素 return val } func (this *MyStack) Top() int { return this.queue1[0] //直接返回 } func (this *MyStack) Empty() bool { return len(this.queue1) == 0 } /** * Your MyStack object will be instantiated and called as such: * obj := Constructor(); * obj.Push(x); * param_2 := obj.Pop(); * param_3 := obj.Top(); * param_4 := obj.Empty(); */ 用一个队列实现： type MyStack struct { queue []int//创建一个队列 } /** Initialize your data structure here. */ func Constructor() MyStack { return MyStack{ //初始化 queue:make([]int,0), } } /** Push element x onto stack. */ func (this *MyStack) Push(x int) { //添加元素 this.queue=append(this.queue,x) } /** Removes the element on top of the stack and returns that element. */ func (this *MyStack) Pop() int { n:=len(this.queue)-1//判断长度 for n!=0{ //除了最后一个，其余的都重新添加到队列里 val:=this.queue[0] this.queue=this.queue[1:] this.queue=append(this.queue,val) n-- } //弹出元素 val:=this.queue[0] this.queue=this.queue[1:] return val } /** Get the top element. */ func (this *MyStack) Top() int { //利用Pop函数，弹出来的元素重新添加 val:=this.Pop() this.queue=append(this.queue,val) return val } /** Returns whether the stack is empty. */ func (this *MyStack) Empty() bool { return len(this.queue)==0 } /** * Your MyStack object will be instantiated and called as such: * obj := Constructor(); * obj.Push(x); * param_2 := obj.Pop(); * param_3 := obj.Top(); * param_4 := obj.Empty(); */ ","date":"2022-01-06 08:20:54","objectID":"/algorithm_stackandqueue/:3:0","tags":["data structure"],"title":"Algorithm_stackAndQueue","uri":"/algorithm_stackandqueue/"},{"categories":["Coding"],"content":"有效的括号 给定一个只包括 ‘('，')'，'{'，'}'，'['，']’ 的字符串，判断字符串是否有效。 有效字符串需满足： 左括号必须用相同类型的右括号闭合。 左括号必须以正确的顺序闭合。 注意空字符串可被认为是有效字符串。 栈的经典问题。 func isValid(s string) bool { hash := map[byte]byte{')':'(', ']':'[', '}':'{'} stack := make([]byte, 0) if s == \"\" { return true } for i := 0; i \u003c len(s); i++ { if s[i] == '(' || s[i] == '[' || s[i] == '{' { stack = append(stack, s[i]) } else if len(stack) \u003e 0 \u0026\u0026 stack[len(stack)-1] == hash[s[i]] { stack = stack[:len(stack)-1] } else { return false } } return len(stack) == 0 } ","date":"2022-01-06 08:20:54","objectID":"/algorithm_stackandqueue/:4:0","tags":["data structure"],"title":"Algorithm_stackAndQueue","uri":"/algorithm_stackandqueue/"},{"categories":["Coding"],"content":"删除字符串中的所有相邻重复项 给出由小写字母组成的字符串 S，重复项删除操作会选择两个相邻且相同的字母，并删除它们。 在 S 上反复执行重复项删除操作，直到无法继续删除。 在完成所有重复项删除操作后返回最终的字符串。答案保证唯一。 示例： 输入：\"abbaca\" 输出：\"ca\" 解释：例如，在 \"abbaca\" 中，我们可以删除 \"bb\" 由于两字母相邻且相同，这是此时唯一可以执行删除操作的重复项。之后我们得到字符串 \"aaca\"，其中又只有 \"aa\" 可以执行重复项删除操作，所以最后的字符串为 \"ca\"。 提示： 1 \u003c= S.length \u003c= 20000 S 仅由小写英文字母组成 func removeDuplicates(s string) string { var stack []byte for i := 0; i \u003c len(s);i++ { // 栈不空 且 与栈顶元素不等 if len(stack) \u003e 0 \u0026\u0026 stack[len(stack)-1] == s[i] { // 弹出栈顶元素 并 忽略当前元素(s[i]) stack = stack[:len(stack)-1] }else{ // 入栈 stack = append(stack, s[i]) } } return string(stack) } ","date":"2022-01-06 08:20:54","objectID":"/algorithm_stackandqueue/:5:0","tags":["data structure"],"title":"Algorithm_stackAndQueue","uri":"/algorithm_stackandqueue/"},{"categories":["Coding"],"content":"逆波兰表达式求值 根据 逆波兰表示法，求表达式的值。 有效的运算符包括 + , - , * , / 。每个运算对象可以是整数，也可以是另一个逆波兰表达式。 说明： 整数除法只保留整数部分。 给定逆波兰表达式总是有效的。换句话说，表达式总会得出有效数值且不存在除数为 0 的情况。 示例 1： 输入: [\"2\", \"1\", \"+\", \"3\", \" * \"] 输出: 9 解释: 该算式转化为常见的中缀算术表达式为：((2 + 1) * 3) = 9 逆波兰表达式：是一种后缀表达式，所谓后缀就是指算符写在后面。 平常使用的算式则是一种中缀表达式，如 ( 1 + 2 ) * ( 3 + 4 ) 。 该算式的逆波兰表达式写法为 ( ( 1 2 + ) ( 3 4 + ) * ) 。 逆波兰表达式主要有以下两个优点： 去掉括号后表达式无歧义，上式即便写成 1 2 + 3 4 + * 也可以依据次序计算出正确结果。 适合用栈操作运算：遇到数字则入栈；遇到算符则取出栈顶两个数字进行计算，并将结果压入栈中 func evalRPN(tokens []string) int { stack := []int{} for _, token := range tokens { val, err := strconv.Atoi(token) if err == nil { stack = append(stack, val) } else { num1, num2 := stack[len(stack)-2], stack[(len(stack))-1] stack = stack[:len(stack)-2] switch token { case \"+\": stack = append(stack, num1+num2) case \"-\": stack = append(stack, num1-num2) case \"*\": stack = append(stack, num1*num2) case \"/\": stack = append(stack, num1/num2) } } } return stack[0] } ","date":"2022-01-06 08:20:54","objectID":"/algorithm_stackandqueue/:6:0","tags":["data structure"],"title":"Algorithm_stackAndQueue","uri":"/algorithm_stackandqueue/"},{"categories":["Coding"],"content":"滑动窗口最大值 给定一个数组 nums，有一个大小为 k 的滑动窗口从数组的最左侧移动到数组的最右侧。你只可以看到在滑动窗口内的 k 个数字。滑动窗口每次只向右移动一位。 每个窗口都有一个最大值，返回滑动窗口中的最大值数组。 进阶：你能在线性时间复杂度内解决此题吗？ // 封装单调队列的方式解题 type MyQueue struct { queue []int } func NewMyQueue() *MyQueue { return \u0026MyQueue{ queue: make([]int, 0), } } func (m *MyQueue) Front() int { return m.queue[0] } func (m *MyQueue) Back() int { return m.queue[len(m.queue)-1] } func (m *MyQueue) Empty() bool { return len(m.queue) == 0 } func (m *MyQueue) Push(val int) { for !m.Empty() \u0026\u0026 val \u003e m.Back() { m.queue = m.queue[:len(m.queue)-1] } m.queue = append(m.queue, val) } func (m *MyQueue) Pop(val int) { if !m.Empty() \u0026\u0026 val == m.Front() { m.queue = m.queue[1:] } } func maxSlidingWindow(nums []int, k int) []int { queue := NewMyQueue() length := len(nums) res := make([]int, 0) // 先将前k个元素放入队列 for i := 0; i \u003c k; i++ { queue.Push(nums[i]) } // 记录前k个元素的最大值 res = append(res, queue.Front()) for i := k; i \u003c length; i++ { // 滑动窗口移除最前面的元素 queue.Pop(nums[i-k]) // 滑动窗口添加最后面的元素 queue.Push(nums[i]) // 记录最大值 res = append(res, queue.Front()) } return res } ","date":"2022-01-06 08:20:54","objectID":"/algorithm_stackandqueue/:7:0","tags":["data structure"],"title":"Algorithm_stackAndQueue","uri":"/algorithm_stackandqueue/"},{"categories":["Coding"],"content":"前K个高频元素 给定一个非空的整数数组，返回其中出现频率前 k 高的元素。 示例 1: 输入: nums = [1,1,1,2,2,3], k = 2 输出: [1,2] //方法一：小顶堆 func topKFrequent(nums []int, k int) []int { map_num:=map[int]int{} //记录每个元素出现的次数 for _,item:=range nums{ map_num[item]++ } h:=\u0026IHeap{} heap.Init(h) //所有元素入堆，堆的长度为k for key,value:=range map_num{ heap.Push(h,[2]int{key,value}) if h.Len()\u003ek{ heap.Pop(h) } } res:=make([]int,k) //按顺序返回堆中的元素 for i:=0;i\u003ck;i++{ res[k-i-1]=heap.Pop(h).([2]int)[0] } return res } //构建小顶堆 type IHeap [][2]int func (h IHeap) Len()int { return len(h) } func (h IHeap) Less (i,j int) bool { return h[i][1]\u003ch[j][1] } func (h IHeap) Swap(i,j int) { h[i],h[j]=h[j],h[i] } func (h *IHeap) Push(x interface{}){ *h=append(*h,x.([2]int)) } func (h *IHeap) Pop() interface{}{ old:=*h n:=len(old) x:=old[n-1] *h=old[0:n-1] return x } //方法二:利用O(logn)排序 func topKFrequent(nums []int, k int) []int { ans:=[]int{} map_num:=map[int]int{} for _,item:=range nums { map_num[item]++ } for key,_:=range map_num{ ans=append(ans,key) } //核心思想：排序 //可以不用包函数，自己实现快排 sort.Slice(ans,func (a,b int)bool{ return map_num[ans[a]]\u003emap_num[ans[b]] }) return ans[:k] } ","date":"2022-01-06 08:20:54","objectID":"/algorithm_stackandqueue/:8:0","tags":["data structure"],"title":"Algorithm_stackAndQueue","uri":"/algorithm_stackandqueue/"},{"categories":["Coding"],"content":" 学习代码随想录笔记 双指针法 双指针法（快慢指针法）在数组和链表的操作中是非常常见的，很多考察数组、链表、字符串等操作的面试题，都使用双指针法。 ","date":"2022-01-06 08:19:19","objectID":"/algorithm_doublepointer/:0:0","tags":["data structure"],"title":"Algorithm_doublePointer","uri":"/algorithm_doublepointer/"},{"categories":["Coding"],"content":"移除元素 给你一个数组 nums 和一个值 val，你需要原地移除所有数值等于 val 的元素，并返回移除后数组的新长度。 不要使用额外的数组空间，你必须仅使用 $O(1)$ 额外空间并原地修改输入数组。 元素的顺序可以改变。你不需要考虑数组中超出新长度后面的元素。 示例 1: 给定 nums = [3,2,2,3], val = 3, 函数应该返回新的长度 2, 并且 nums 中的前两个元素均为 2。 你不需要考虑数组中超出新长度后面的元素。 示例 2: 给定 nums = [0,1,2,2,3,0,4,2], val = 2, 函数应该返回新的长度 5, 并且 nums 中的前五个元素为 0, 1, 3, 0, 4。 你不需要考虑数组中超出新长度后面的元素。 func removeElement(nums []int, val int) int { length:=len(nums) res:=0 for i:=0;i\u003clength;i++{ if nums[i]!=val { nums[res]=nums[i] res++ } } return res } ","date":"2022-01-06 08:19:19","objectID":"/algorithm_doublepointer/:1:0","tags":["data structure"],"title":"Algorithm_doublePointer","uri":"/algorithm_doublepointer/"},{"categories":["Coding"],"content":"反转字符串 func reverseString(s []byte) { left:=0 right:=len(s)-1 for left\u003cright{ s[left],s[right]=s[right],s[left] left++ right-- } } ","date":"2022-01-06 08:19:19","objectID":"/algorithm_doublepointer/:2:0","tags":["data structure"],"title":"Algorithm_doublePointer","uri":"/algorithm_doublepointer/"},{"categories":["Coding"],"content":"替换空格 // 遍历添加 func replaceSpace(s string) string { b := []byte(s) result := make([]byte, 0) for i := 0; i \u003c len(b); i++ { if b[i] == ' ' { result = append(result, []byte(\"%20\")...) } else { result = append(result, b[i]) } } return string(result) } // 原地修改 func replaceSpace(s string) string { b := []byte(s) length := len(b) spaceCount := 0 // 计算空格数量 for _, v := range b { if v == ' ' { spaceCount++ } } // 扩展原有切片 resizeCount := spaceCount * 2 tmp := make([]byte, resizeCount) b = append(b, tmp...) i := length - 1 j := len(b) - 1 for i \u003e= 0 { if b[i] != ' ' { b[j] = b[i] i-- j-- } else { b[j] = '0' b[j-1] = '2' b[j-2] = '%' i-- j = j - 3 } } return string(b) } ","date":"2022-01-06 08:19:19","objectID":"/algorithm_doublepointer/:3:0","tags":["data structure"],"title":"Algorithm_doublePointer","uri":"/algorithm_doublepointer/"},{"categories":["Coding"],"content":"翻转字符串里的单词 import ( \"fmt\" ) func reverseWords(s string) string { //1.使用双指针删除冗余的空格 slowIndex, fastIndex := 0, 0 b := []byte(s) //删除头部冗余空格 for len(b) \u003e 0 \u0026\u0026 fastIndex \u003c len(b) \u0026\u0026 b[fastIndex] == ' ' { fastIndex++ } //删除单词间冗余空格 for ; fastIndex \u003c len(b); fastIndex++ { if fastIndex-1 \u003e 0 \u0026\u0026 b[fastIndex-1] == b[fastIndex] \u0026\u0026 b[fastIndex] == ' ' { continue } b[slowIndex] = b[fastIndex] slowIndex++ } //删除尾部冗余空格 if slowIndex-1 \u003e 0 \u0026\u0026 b[slowIndex-1] == ' ' { b = b[:slowIndex-1] } else { b = b[:slowIndex] } //2.反转整个字符串 reverse(\u0026b, 0, len(b)-1) //3.反转单个单词 i单词开始位置，j单词结束位置 i := 0 for i \u003c len(b) { j := i for ; j \u003c len(b) \u0026\u0026 b[j] != ' '; j++ { } reverse(\u0026b, i, j-1) i = j i++ } return string(b) } func reverse(b *[]byte, left, right int) { for left \u003c right { (*b)[left], (*b)[right] = (*b)[right], (*b)[left] left++ right-- } } ","date":"2022-01-06 08:19:19","objectID":"/algorithm_doublepointer/:4:0","tags":["data structure"],"title":"Algorithm_doublePointer","uri":"/algorithm_doublepointer/"},{"categories":["Coding"],"content":"翻转链表 //双指针 func reverseList(head *ListNode) *ListNode { var pre *ListNode cur := head for cur != nil { next := cur.Next cur.Next = pre pre = cur cur = next } return pre } //递归 func reverseList(head *ListNode) *ListNode { return help(nil, head) } func help(pre, head *ListNode)*ListNode{ if head == nil { return pre } next := head.Next head.Next = pre return help(head, next) } ","date":"2022-01-06 08:19:19","objectID":"/algorithm_doublepointer/:5:0","tags":["data structure"],"title":"Algorithm_doublePointer","uri":"/algorithm_doublepointer/"},{"categories":["Coding"],"content":"删除链表的倒数第N个节点 /** * Definition for singly-linked list. * type ListNode struct { * Val int * Next *ListNode * } */ func removeNthFromEnd(head *ListNode, n int) *ListNode { dummyHead := \u0026ListNode{} dummyHead.Next = head cur := head prev := dummyHead i := 1 for cur != nil { cur = cur.Next if i \u003e n { prev = prev.Next } i++ } prev.Next = prev.Next.Next return dummyHead.Next } ","date":"2022-01-06 08:19:19","objectID":"/algorithm_doublepointer/:6:0","tags":["data structure"],"title":"Algorithm_doublePointer","uri":"/algorithm_doublepointer/"},{"categories":["Coding"],"content":"链表相交 给你两个单链表的头节点 headA 和 headB ，请你找出并返回两个单链表相交的起始节点。如果两个链表没有交点，返回 null 。 func getIntersectionNode(headA, headB *ListNode) *ListNode { curA := headA curB := headB lenA, lenB := 0, 0 // 求A，B的长度 for curA != nil { curA = curA.Next lenA++ } for curB != nil { curB = curB.Next lenB++ } var step int var fast, slow *ListNode // 请求长度差，并且让更长的链表先走相差的长度 if lenA \u003e lenB { step = lenA - lenB fast, slow = headA, headB } else { step = lenB - lenA fast, slow = headB, headA } for i:=0; i \u003c step; i++ { fast = fast.Next } // 遍历两个链表遇到相同则跳出遍历 for fast != slow { fast = fast.Next slow = slow.Next } return fast } ","date":"2022-01-06 08:19:19","objectID":"/algorithm_doublepointer/:7:0","tags":["data structure"],"title":"Algorithm_doublePointer","uri":"/algorithm_doublepointer/"},{"categories":["Coding"],"content":"环形链表II 题意： 给定一个链表，返回链表开始入环的第一个节点。 如果链表无环，则返回 null。 func detectCycle(head *ListNode) *ListNode { slow, fast := head, head for fast != nil \u0026\u0026 fast.Next != nil { slow = slow.Next fast = fast.Next.Next if slow == fast { for slow != head { slow = slow.Next head = head.Next } return head } } return nil } ","date":"2022-01-06 08:19:19","objectID":"/algorithm_doublepointer/:8:0","tags":["data structure"],"title":"Algorithm_doublePointer","uri":"/algorithm_doublepointer/"},{"categories":["Coding"],"content":"三数之和 给你一个包含 n 个整数的数组 nums，判断 nums 中是否存在三个元素 a，b，c ，使得 a + b + c = 0 ？请你找出所有满足条件且不重复的三元组。 注意： 答案中不可以包含重复的三元组。 示例： 给定数组 nums = [-1, 0, 1, 2, -1, -4]， 满足要求的三元组集合为： [ [-1, 0, 1], [-1, -1, 2] ] func threeSum(nums []int)[][]int{ sort.Ints(nums) res:=[][]int{} for i:=0;i\u003clen(nums)-2;i++{ n1:=nums[i] if n1\u003e0{ break } if i\u003e0\u0026\u0026n1==nums[i-1]{ continue } l,r:=i+1,len(nums)-1 for l\u003cr{ n2,n3:=nums[l],nums[r] if n1+n2+n3==0{ res=append(res,[]int{n1,n2,n3}) for l\u003cr\u0026\u0026nums[l]==n2{ l++ } for l\u003cr\u0026\u0026nums[r]==n3{ r-- } }else if n1+n2+n3\u003c0{ l++ }else { r-- } } } return res } ","date":"2022-01-06 08:19:19","objectID":"/algorithm_doublepointer/:9:0","tags":["data structure"],"title":"Algorithm_doublePointer","uri":"/algorithm_doublepointer/"},{"categories":["Coding"],"content":"四数之和 题意：给定一个包含 n 个整数的数组 nums 和一个目标值 target，判断 nums 中是否存在四个元素 a，b，c 和 d ，使得 a + b + c + d 的值与 target 相等？找出所有满足条件且不重复的四元组。 注意： 答案中不可以包含重复的四元组。 示例： 给定数组 nums = [1, 0, -1, 0, -2, 2]，和 target = 0。 满足要求的四元组集合为： [ [-1, 0, 0, 1], [-2, -1, 1, 2], [-2, 0, 0, 2] ] func fourSum(nums []int, target int) [][]int { if len(nums) \u003c 4 { return nil } sort.Ints(nums) var res [][]int for i := 0; i \u003c len(nums)-3; i++ { n1 := nums[i] // if n1 \u003e target { // 不能这样写,因为可能是负数 // break // } if i \u003e 0 \u0026\u0026 n1 == nums[i-1] { continue } for j := i + 1; j \u003c len(nums)-2; j++ { n2 := nums[j] if j \u003e i+1 \u0026\u0026 n2 == nums[j-1] { continue } l := j + 1 r := len(nums) - 1 for l \u003c r { n3 := nums[l] n4 := nums[r] sum := n1 + n2 + n3 + n4 if sum \u003c target { l++ } else if sum \u003e target { r-- } else { res = append(res, []int{n1, n2, n3, n4}) for l \u003c r \u0026\u0026 n3 == nums[l+1] { // 去重 l++ } for l \u003c r \u0026\u0026 n4 == nums[r-1] { // 去重 r-- } // 找到答案时,双指针同时靠近 r-- l++ } } } } return res } ","date":"2022-01-06 08:19:19","objectID":"/algorithm_doublepointer/:10:0","tags":["data structure"],"title":"Algorithm_doublePointer","uri":"/algorithm_doublepointer/"},{"categories":["Coding"],"content":"双指针总结 总结 ","date":"2022-01-06 08:19:19","objectID":"/algorithm_doublepointer/:11:0","tags":["data structure"],"title":"Algorithm_doublePointer","uri":"/algorithm_doublepointer/"},{"categories":["Coding"],"content":" 学习代码随想录笔记 字符串 库函数是工具，基础更重要。 ","date":"2022-01-06 08:18:50","objectID":"/algorithm_string/:0:0","tags":["data structure"],"title":"Algorithm_string","uri":"/algorithm_string/"},{"categories":["Coding"],"content":"反转字符串 ","date":"2022-01-06 08:18:50","objectID":"/algorithm_string/:1:0","tags":["data structure"],"title":"Algorithm_string","uri":"/algorithm_string/"},{"categories":["Coding"],"content":"I 和反转链表相同，都用双指针法。 func reverseString(s []byte) { left:=0 right:=len(s)-1 for left\u003cright{ s[left],s[right]=s[right],s[left] left++ right-- } } ","date":"2022-01-06 08:18:50","objectID":"/algorithm_string/:1:1","tags":["data structure"],"title":"Algorithm_string","uri":"/algorithm_string/"},{"categories":["Coding"],"content":"II 给定一个字符串 s 和一个整数 k，你需要对从字符串开头算起的每隔 2k 个字符的前 k 个字符进行反转。 如果剩余字符少于 k 个，则将剩余字符全部反转。 如果剩余字符小于 2k 但大于或等于 k 个，则反转前 k 个字符，其余字符保持原样。 示例: 输入: s = \"abcdefg\", k = 2 输出: \"bacdfeg\" func reverseStr(s string, k int) string { ss := []byte(s) length := len(s) for i := 0; i \u003c length; i += 2 * k { if i + k \u003c= length { reverse(ss[i:i+k]) } else { reverse(ss[i:length]) } } return string(ss) } func reverse(b []byte) { left := 0 right := len(b) - 1 for left \u003c right { b[left], b[right] = b[right], b[left] left++ right-- } } ","date":"2022-01-06 08:18:50","objectID":"/algorithm_string/:1:2","tags":["data structure"],"title":"Algorithm_string","uri":"/algorithm_string/"},{"categories":["Coding"],"content":"替换空格 // 遍历添加 func replaceSpace(s string) string { b := []byte(s) result := make([]byte, 0) for i := 0; i \u003c len(b); i++ { if b[i] == ' ' { result = append(result, []byte(\"%20\")...) } else { result = append(result, b[i]) } } return string(result) } // 原地修改 func replaceSpace(s string) string { b := []byte(s) length := len(b) spaceCount := 0 // 计算空格数量 for _, v := range b { if v == ' ' { spaceCount++ } } // 扩展原有切片 resizeCount := spaceCount * 2 tmp := make([]byte, resizeCount) b = append(b, tmp...) i := length - 1 j := len(b) - 1 for i \u003e= 0 { if b[i] != ' ' { b[j] = b[i] i-- j-- } else { b[j] = '0' b[j-1] = '2' b[j-2] = '%' i-- j = j - 3 } } return string(b) } ","date":"2022-01-06 08:18:50","objectID":"/algorithm_string/:2:0","tags":["data structure"],"title":"Algorithm_string","uri":"/algorithm_string/"},{"categories":["Coding"],"content":"翻转字符串里的单词 给定一个字符串，逐个翻转字符串中的每个单词。 输入: \"the sky is blue\" 输出: \"blue is sky the\" import ( \"fmt\" ) func reverseWords(s string) string { //1.使用双指针删除冗余的空格 slowIndex, fastIndex := 0, 0 b := []byte(s) //删除头部冗余空格 for len(b) \u003e 0 \u0026\u0026 fastIndex \u003c len(b) \u0026\u0026 b[fastIndex] == ' ' { fastIndex++ } //删除单词间冗余空格 for ; fastIndex \u003c len(b); fastIndex++ { if fastIndex-1 \u003e 0 \u0026\u0026 b[fastIndex-1] == b[fastIndex] \u0026\u0026 b[fastIndex] == ' ' { continue } b[slowIndex] = b[fastIndex] slowIndex++ } //删除尾部冗余空格 if slowIndex-1 \u003e 0 \u0026\u0026 b[slowIndex-1] == ' ' { b = b[:slowIndex-1] } else { b = b[:slowIndex] } //2.反转整个字符串 reverse(\u0026b, 0, len(b)-1) //3.反转单个单词 i单词开始位置，j单词结束位置 i := 0 for i \u003c len(b) { j := i for ; j \u003c len(b) \u0026\u0026 b[j] != ' '; j++ { } reverse(\u0026b, i, j-1) i = j i++ } return string(b) } func reverse(b *[]byte, left, right int) { for left \u003c right { (*b)[left], (*b)[right] = (*b)[right], (*b)[left] left++ right-- } } ","date":"2022-01-06 08:18:50","objectID":"/algorithm_string/:3:0","tags":["data structure"],"title":"Algorithm_string","uri":"/algorithm_string/"},{"categories":["Coding"],"content":"左旋转字符串 输入: s = \"abcdefg\", k = 2 输出: \"cdefgab\" func reverseLeftWords(s string, n int) string { b := []byte(s) // 1. 反转前n个字符 // 2. 反转第n到end字符 // 3. 反转整个字符 reverse(b, 0, n-1) reverse(b, n, len(b)-1) reverse(b, 0, len(b)-1) return string(b) } // 切片是引用传递 func reverse(b []byte, left, right int){ for left \u003c right{ b[left], b[right] = b[right],b[left] left++ right-- } } ","date":"2022-01-06 08:18:50","objectID":"/algorithm_string/:4:0","tags":["data structure"],"title":"Algorithm_string","uri":"/algorithm_string/"},{"categories":["Coding"],"content":"实现strStr() 给定一个 haystack 字符串和一个 needle 字符串，在 haystack 字符串中找出 needle 字符串出现的第一个位置 (从0开始)。如果不存在，则返回 -1。 示例 1: 输入: haystack = “hello”, needle = “ll” 输出: 2 示例 2: 输入: haystack = “aaaaa”, needle = “bba” 输出: -1 说明: 当 needle 是空字符串时，我们应当返回什么值呢？这是一个在面试中很好的问题。 对于本题而言，当 needle 是空字符串时我们应当返回 0 。这与C语言的 strstr() 以及 Java的 indexOf() 定义相符。 ","date":"2022-01-06 08:18:50","objectID":"/algorithm_string/:5:0","tags":["data structure"],"title":"Algorithm_string","uri":"/algorithm_string/"},{"categories":["Coding"],"content":"什么是KMP KMP算法是一种改进的字符串匹配算法，由D.E.Knuth，J.H.Morris和V.R.Pratt提出的，因此人们称它为克努特—莫里斯—普拉特操作（简称KMP算法）。KMP算法的核心是利用匹配失败后的信息，尽量减少模式串与主串的匹配次数以达到快速匹配的目的。具体实现就是通过一个next()函数实现，函数本身包含了模式串的局部匹配信息。KMP算法的时间复杂度O(m+n) [1] 。（来自百度百科） KMP的经典思想就是:当出现字符串不匹配时，可以记录一部分之前已经匹配的文本内容，利用这些信息避免从头再去做匹配。 如何记录已经匹配的文本内容，是KMP的重点，也是next数组的任务。 ","date":"2022-01-06 08:18:50","objectID":"/algorithm_string/:5:1","tags":["data structure"],"title":"Algorithm_string","uri":"/algorithm_string/"},{"categories":["Coding"],"content":"什么是前缀表与next数组 next数组就是一个前缀表。 前缀表是用来回退的，它记录了模式串与主串(文本串)不匹配的时候，模式串应该从哪里开始重新匹配。 什么是前缀表：记录下标i之前（包括i）的字符串中，有多大长度的相同前缀后缀。 最长公共前后缀：字符串aa的最长相等前后缀为1。 字符串aaa的最长相等前后缀为2。 等等….. 前缀表要求的就是最长相同前后缀的长度。它能告诉我们上次匹配的位置。 下标5之前这部分的字符串（也就是字符串aabaa）的最长相等的前缀和后缀字符串是子字符串aa ，因为找到了最长相等的前缀和后缀，匹配失败的位置是后缀子串的后面，那么我们找到与其相同的前缀的后面从新匹配就可以了。 前缀表与next数组有什么关系： next数组即可以就是前缀表，也可以是前缀表统一减一（右移一位，初始位置为-1）。 ","date":"2022-01-06 08:18:50","objectID":"/algorithm_string/:5:2","tags":["data structure"],"title":"Algorithm_string","uri":"/algorithm_string/"},{"categories":["Coding"],"content":"前缀表统一减一之后的next数组： 时间复杂度分析： 其中n为文本串长度，m为模式串长度，因为在匹配的过程中，根据前缀表不断调整匹配的位置，可以看出匹配的过程是$O(n)$，之前还要单独生成next数组，时间复杂度是$O(m)$。所以整个KMP算法的时间复杂度是$O(n+m)$的。 暴力的解法显而易见是$O(n × m)$，所以KMP在字符串匹配中极大的提高的搜索的效率。 为了和力扣题目28.实现strStr保持一致，方便大家理解，以下文章统称haystack为文本串, needle为模式串。 都知道使用KMP算法，一定要构造next数组 构造next数组： 我们定义一个函数getNext来构建next数组，函数参数为指向next数组的指针，和一个字符串。 代码如下： void getNext(int* next, const string\u0026 s) 构造next数组其实就是计算模式串s，前缀表的过程。 主要有如下三步： 初始化 定义两个指针i和j，j指向前缀起始位置，i指向后缀起始位置。 然后还要对next数组进行初始化赋值，如下： int j = -1; next[0] = j; j 为什么要初始化为 -1呢，因为之前说过 前缀表要统一减一的操作仅仅是其中的一种实现，我们这里选择j初始化为-1，下文我还会给出j不初始化为-1的实现代码。 next[i] 表示 i（包括i）之前最长相等的前后缀长度（其实就是j） 所以初始化next[0] = j 。 处理前后缀不相同的情况 因为j初始化为-1，那么i就从1开始，进行s[i] 与 s[j+1]的比较。 所以遍历模式串s的循环下标i 要从 1开始，代码如下： for(int i = 1; i \u003c s.size(); i++) { 如果 s[i] 与 s[j+1]不相同，也就是遇到 前后缀末尾不相同的情况，就要向前回退。 怎么回退呢？ next[j]就是记录着j（包括j）之前的子串的相同前后缀的长度。 那么 s[i] 与 s[j+1] 不相同，就要找 j+1前一个元素在next数组里的值（就是next[j]）。 所以，处理前后缀不相同的情况代码如下： while (j \u003e= 0 \u0026\u0026 s[i] != s[j + 1]) { // 前后缀不相同了 j = next[j]; // 向前回退 } 处理前后缀相同的情况 如果s[i] 与 s[j + 1] 相同，那么就同时向后移动i 和j 说明找到了相同的前后缀，同时还要将j（前缀的长度）赋给next[i], 因为next[i]要记录相同前后缀的长度。 代码如下： if (s[i] == s[j + 1]) { // 找到相同的前后缀 j++; } next[i] = j; 最后整体构建next数组的函数代码如下： void getNext(int* next, const string\u0026 s){ int j = -1; next[0] = j; for(int i = 1; i \u003c s.size(); i++) { // **注意**i从1开始 while (j \u003e= 0 \u0026\u0026 s[i] != s[j + 1]) { // 前后缀不相同了 j = next[j]; // 向前回退 } if (s[i] == s[j + 1]) { // 找到相同的前后缀 j++; } next[i] = j; // 将j（前缀的长度）赋给next[i] } } 使用next数组进行匹配 在文本串s里 找是否出现过模式串t。 定义两个下标j 指向模式串起始位置，i指向文本串起始位置。 那么j初始值依然为-1，为什么呢？ 依然因为next数组里记录的起始位置为-1。 i就从0开始，遍历文本串，代码如下： for (int i = 0; i \u003c s.size(); i++) 接下来就是 s[i] 与 t[j + 1] （因为j从-1开始的） 进行比较。 如果 s[i] 与 t[j + 1] 不相同，j就要从next数组里寻找下一个匹配的位置。 代码如下： while(j \u003e= 0 \u0026\u0026 s[i] != t[j + 1]) { j = next[j]; } 如果 s[i] 与 t[j + 1] 相同，那么i 和 j 同时向后移动， 代码如下： if (s[i] == t[j + 1]) { j++; // i的增加在for循环里 } 如何判断在文本串s里出现了模式串t呢，如果j指向了模式串t的末尾，那么就说明模式串t完全匹配文本串s里的某个子串了。 本题要在文本串字符串中找出模式串出现的第一个位置 (从0开始)，所以返回当前在文本串匹配模式串的位置i 减去 模式串的长度，就是文本串字符串中出现模式串的第一个位置。 代码如下： if (j == (t.size() - 1) ) { return (i - t.size() + 1); } 那么使用next数组，用模式串匹配文本串的整体代码如下： int j = -1; // 因为next数组里记录的起始位置为-1 for (int i = 0; i \u003c s.size(); i++) { // **注意**i就从0开始 while(j \u003e= 0 \u0026\u0026 s[i] != t[j + 1]) { // 不匹配 j = next[j]; // j 寻找之前匹配的位置 } if (s[i] == t[j + 1]) { // 匹配，j和i同时向后移动 j++; // i的增加在for循环里 } if (j == (t.size() - 1) ) { // 文本串s里出现了模式串t return (i - t.size() + 1); } } 此时所有逻辑的代码都已经写出来了，力扣 28.实现strStr 题目的整体代码如下： class Solution { public: void getNext(int* next, const string\u0026 s) { int j = -1; next[0] = j; for(int i = 1; i \u003c s.size(); i++) { // **注意**i从1开始 while (j \u003e= 0 \u0026\u0026 s[i] != s[j + 1]) { // 前后缀不相同了 j = next[j]; // 向前回退 } if (s[i] == s[j + 1]) { // 找到相同的前后缀 j++; } next[i] = j; // 将j（前缀的长度）赋给next[i] } } int strStr(string haystack, string needle) { if (needle.size() == 0) { return 0; } int next[needle.size()]; getNext(next, needle); int j = -1; // // 因为next数组里记录的起始位置为-1 for (int i = 0; i \u003c haystack.size(); i++) { // **注意**i就从0开始 while(j \u003e= 0 \u0026\u0026 haystack[i] != needle[j + 1]) { // 不匹配 j = next[j]; // j 寻找之前匹配的位置 } if (haystack[i] == needle[j + 1]) { // 匹配，j和i同时向后移动 j++; // i的增加在for循环里 } if (j == (needle.size() - 1) ) { // 文本串s里出现了模式串t return (i - needle.size() + 1); } } return -1; } }; ","date":"2022-01-06 08:18:50","objectID":"/algorithm_string/:5:3","tags":["data structure"],"title":"Algorithm_string","uri":"/algorithm_string/"},{"categories":["Coding"],"content":"前缀表不减一的next数组： 直接使用前缀表可以换一种回退方式，找j=next[j-1] 来进行回退。 主要就是j=next[x]这一步最为关键！ 构建next数组： void getNext(int* next, const string\u0026 s) { int j = 0; next[0] = 0; for(int i = 1; i \u003c s.size(); i++) { while (j \u003e 0 \u0026\u0026 s[i] != s[j]) { // j要保证大于0，因为下面有取j-1作为数组下标的操作 j = next[j - 1]; // **注意**这里，是要找前一位的对应的回退位置了 } if (s[i] == s[j]) { j++; } next[i] = j; } } 使用next数组进行匹配： class Solution { public: void getNext(int* next, const string\u0026 s) { int j = 0; next[0] = 0; for(int i = 1; i \u003c s.size(); i++) { while (j \u003e 0 \u0026\u0026 s[i] != s[j]) { j = next[j - 1]; } if (s[i] == s[j]) { j++; } next[i] = j; } } int strStr(string haystack, string needle) { if (needle.size() == 0) { return 0; } int next[needle.size()]; getNext(next, needle); int j = 0; for (int i = 0; i \u003c haystack.size(); i++) { while(j \u003e 0 \u0026\u0026 haystack[i] != needle[j]) { j = next[j - 1]; } if (haystack[i] == needle[j]) { j++; } if (j == needle.size() ) { return (i - needle.size() + 1); } } return -1; } }; ","date":"2022-01-06 08:18:50","objectID":"/algorithm_string/:5:4","tags":["data structure"],"title":"Algorithm_string","uri":"/algorithm_string/"},{"categories":["Coding"],"content":"kmp总结 介绍了什么是KMP，KMP可以解决什么问题，然后分析KMP算法里的next数组，知道了next数组就是前缀表，再分析为什么要是前缀表而不是什么其他表。 接着从给出的模式串中，我们一步一步的推导出了前缀表，得出前缀表无论是统一减一还是不减一得到的next数组仅仅是kmp的实现方式的不同。 其中还分析了KMP算法的时间复杂度，并且和暴力方法做了对比。 然后先用前缀表统一减一得到的next数组，求得文本串s里是否出现过模式串t，并给出了具体分析代码。 又给出了直接用前缀表作为next数组，来做匹配的实现代码。 可以说把KMP的每一个细微的细节都扣了出来，毫无遮掩的展示给大家了 go实现： // 方法一:前缀表使用减1实现 // getNext 构造前缀表next // params: // next 前缀表数组 // s 模式串 func getNext(next []int, s string) { j := -1 // j表示 最长相等前后缀长度 next[0] = j for i := 1; i \u003c len(s); i++ { for j \u003e= 0 \u0026\u0026 s[i] != s[j+1] { j = next[j] // 回退前一位 } if s[i] == s[j+1] { j++ } next[i] = j // next[i]是i（包括i）之前的最长相等前后缀长度 } } func strStr(haystack string, needle string) int { if len(needle) == 0 { return 0 } next := make([]int, len(needle)) getNext(next, needle) j := -1 // 模式串的起始位置 next为-1 因此也为-1 for i := 0; i \u003c len(haystack); i++ { for j \u003e= 0 \u0026\u0026 haystack[i] != needle[j+1] { j = next[j] // 寻找下一个匹配点 } if haystack[i] == needle[j+1] { j++ } if j == len(needle)-1 { // j指向了模式串的末尾 return i - len(needle) + 1 } } return -1 } // 方法二: 前缀表无减一或者右移 // getNext 构造前缀表next // params: // next 前缀表数组 // s 模式串 func getNext(next []int, s string) { j := 0 next[0] = j for i := 1; i \u003c len(s); i++ { for j \u003e 0 \u0026\u0026 s[i] != s[j] { j = next[j-1] } if s[i] == s[j] { j++ } next[i] = j } } func strStr(haystack string, needle string) int { n := len(needle) if n == 0 { return 0 } j := 0 next := make([]int, n) getNext(next, needle) for i := 0; i \u003c len(haystack); i++ { for j \u003e 0 \u0026\u0026 haystack[i] != needle[j] { j = next[j-1] // 回退到j的前一位 } if haystack[i] == needle[j] { j++ } if j == n { return i - n + 1 } } return -1 } ","date":"2022-01-06 08:18:50","objectID":"/algorithm_string/:5:5","tags":["data structure"],"title":"Algorithm_string","uri":"/algorithm_string/"},{"categories":["Coding"],"content":"重复的子字符串 给定一个非空的字符串，判断它是否可以由它的一个子串重复多次构成。给定的字符串只含有小写英文字母，并且长度不超过10000。 示例 1: 输入: \"abab\" 输出: True 解释: 可由子字符串 \"ab\" 重复两次构成。 示例 2: 输入: \"aba\" 输出: False 示例 3: 输入: \"abcabcabcabc\" 输出: True 解释: 可由子字符串 \"abc\" 重复四次构成。 (或者子字符串 \"abcabc\" 重复两次构成。) 标准的KMP题目~ 数组长度减去最长相同前后缀的长度相当于是第一个周期的长度，也就是一个周期的长度，如果这个周期可以被整除，就说明整个数组就是这个周期的循环。 强烈建议大家把next数组打印出来，看看next数组里的规律，有助于理解KMP算法 代码实现： //前缀表统一减一的实现 func repeatedSubstringPattern(s string) bool { n := len(s) if n == 0 { return false } next := make([]int, n) j := -1 next[0] = j for i := 1; i \u003c n; i++ { for j \u003e= 0 \u0026\u0026 s[i] != s[j+1] { j = next[j] } if s[i] == s[j+1] { j++ } next[i] = j } // next[n-1]+1 最长相同前后缀的长度 if next[n-1] != -1 \u0026\u0026 n%(n-(next[n-1]+1)) == 0 { return true } return false } //前缀表不减一 func repeatedSubstringPattern(s string) bool { n := len(s) if n == 0 { return false } j := 0 next := make([]int, n) next[0] = j for i := 1; i \u003c n; i++ { for j \u003e 0 \u0026\u0026 s[i] != s[j] { j = next[j-1] } if s[i] == s[j] { j++ } next[i] = j } // next[n-1] 最长相同前后缀的长度 if next[n-1] != 0 \u0026\u0026 n%(n-next[n-1]) == 0 { return true } return false } ","date":"2022-01-06 08:18:50","objectID":"/algorithm_string/:6:0","tags":["data structure"],"title":"Algorithm_string","uri":"/algorithm_string/"},{"categories":["Coding"],"content":" 学习代码随想录笔记 哈希表 ","date":"2022-01-06 08:18:30","objectID":"/algorithm_hashtable/:0:0","tags":["data structure"],"title":"Algorithm_hashTable","uri":"/algorithm_hashtable/"},{"categories":["Coding"],"content":"哈希表理论基础 哈希表是根据关键码的值而直接进行访问的数据结构，比如数组、map（映射）、set（集合）。 一般用来快速判断一个元素是否出现在集合里。 比如把字符串映射为索引的例子： 通过哈希函数/hashCode将字符串转化为数值 如果得到的数值大于哈希表的大小了，取模，保证所有字符串映射到哈希表上。 如果字符串数量都大于哈希表的大小了，会出现同一索引不同字符串的情况。也称，哈希碰撞。 解决哈希碰撞： 拉链法 发生冲突的元素用链表存储 要选择适当的哈希表的大小，这样既不会因为数组空值而浪费大量内存，也不会因为链表太长而在查找上浪费太多时间。 线性探测法 保证tableSize大于dataSize，避免碰撞。 ","date":"2022-01-06 08:18:30","objectID":"/algorithm_hashtable/:1:0","tags":["data structure"],"title":"Algorithm_hashTable","uri":"/algorithm_hashtable/"},{"categories":["Coding"],"content":"有效的字母异位词 给定两个字符串 s 和 t ，编写一个函数来判断 t 是否是 s 的字母异位词。 示例 1: 输入: s = “anagram”, t = “nagaram” 输出: true 示例 2: 输入: s = “rat”, t = “car” 输出: false 说明: 你可以假设字符串只包含小写字母。 func isAnagram(s string, t string) bool { if len(s)!=len(t){ return false } exists := make(map[byte]int) for i:=0;i\u003clen(s);i++{ if v,ok:=exists[s[i]];v\u003e=0\u0026\u0026ok{ exists[s[i]]=v+1 }else{ exists[s[i]]=1 } } for i:=0;i\u003clen(t);i++{ if v,ok:=exists[t[i]];v\u003e=1\u0026\u0026ok{ exists[t[i]]=v-1 }else{ return false } } return true } ","date":"2022-01-06 08:18:30","objectID":"/algorithm_hashtable/:2:0","tags":["data structure"],"title":"Algorithm_hashTable","uri":"/algorithm_hashtable/"},{"categories":["Coding"],"content":"两个数组的交集 使用数组来做哈希的题目，是因为题目都限制了数值的大小。 而这道题目没有限制数值的大小，就无法使用数组来做哈希表了。 func intersection(nums1 []int, nums2 []int) []int { m := make(map[int]int) for _, v := range nums1 { m[v] = 1 } var res []int // 利用count\u003e0，实现重复值只拿一次放入返回结果中 for _, v := range nums2 { if count, ok := m[v]; ok \u0026\u0026 count \u003e 0 { res = append(res, v) m[v]-- } } return res } //优化版，利用set，减少count统计 func intersection(nums1 []int, nums2 []int) []int { set:=make(map[int]struct{},0) res:=make([]int,0) for _,v:=range nums1{ if _,ok:=set[v];!ok{ set[v]=struct{}{} } } for _,v:=range nums2{ //如果存在于上一个数组中，则加入结果集，并清空该set值 if _,ok:=set[v];ok{ res=append(res,v) delete(set, v) } } return res } ","date":"2022-01-06 08:18:30","objectID":"/algorithm_hashtable/:3:0","tags":["data structure"],"title":"Algorithm_hashTable","uri":"/algorithm_hashtable/"},{"categories":["Coding"],"content":"快乐数 编写一个算法来判断一个数 n 是不是快乐数。 「快乐数」定义为：对于一个正整数，每一次将该数替换为它每个位置上的数字的平方和，然后重复这个过程直到这个数变为 1，也可能是 无限循环 但始终变不到 1。如果 可以变为 1，那么这个数就是快乐数。 如果 n 是快乐数就返回 True ；不是，则返回 False 。 示例： 输入：19 输出：true 解释： 1^2 + 9^2 = 82 8^2 + 2^2 = 68 6^2 + 8^2 = 100 1^2 + 0^2 + 0^2 = 1 func isHappy(n int) bool { m := make(map[int]bool) for n != 1 \u0026\u0026 !m[n] { n, m[n] = getSum(n), true } return n == 1 } func getSum(n int) int { sum := 0 for n \u003e 0 { sum += (n % 10) * (n % 10) n = n / 10 } return sum } ","date":"2022-01-06 08:18:30","objectID":"/algorithm_hashtable/:4:0","tags":["data structure"],"title":"Algorithm_hashTable","uri":"/algorithm_hashtable/"},{"categories":["Coding"],"content":"两数之和 给定一个整数数组 nums 和一个目标值 target，请你在该数组中找出和为目标值的那 两个 整数，并返回他们的数组下标。 你可以假设每种输入只会对应一个答案。但是，数组中同一个元素不能使用两遍。 示例: 给定 nums = [2, 7, 11, 15], target = 9 因为 nums[0] + nums[1] = 2 + 7 = 9 所以返回 [0, 1] func twoSum(nums []int, target int) []int { for k1, _ := range nums { for k2 := k1 + 1; k2 \u003c len(nums); k2++ { if target == nums[k1] + nums[k2] { return []int{k1, k2} } } } return []int{} } // 使用map方式解题，降低时间复杂度 func twoSum(nums []int, target int) []int { m := make(map[int]int) for index, val := range nums { if preIndex, ok := m[target-val]; ok { return []int{preIndex, index} } else { m[val] = index } } return []int{} } ","date":"2022-01-06 08:18:30","objectID":"/algorithm_hashtable/:5:0","tags":["data structure"],"title":"Algorithm_hashTable","uri":"/algorithm_hashtable/"},{"categories":["Coding"],"content":"四数相加II 给定四个包含整数的数组列表 A , B , C , D ,计算有多少个元组 (i, j, k, l) ，使得 A[i] + B[j] + C[k] + D[l] = 0。 为了使问题简单化，所有的 A, B, C, D 具有相同的长度 N，且 0 ≤ N ≤ 500 。所有整数的范围在 -2^28 到 2^28 - 1 之间，最终结果不会超过 2^31 - 1 。 例如: 输入: A = [ 1, 2] B = [-2,-1] C = [-1, 2] D = [ 0, 2] 输出: 2 解释: 两个元组如下: (0, 0, 0, 1) -\u003e A[0] + B[0] + C[0] + D[1] = 1 + (-2) + (-1) + 2 = 0 (1, 1, 0, 0) -\u003e A[1] + B[1] + C[0] + D[0] = 2 + (-1) + (-1) + 0 = 0 func fourSumCount(nums1 []int, nums2 []int, nums3 []int, nums4 []int) int { m := make(map[int]int) count := 0 for _, v1 := range nums1 { for _, v2 := range nums2 { m[v1+v2]++ } } for _, v3 := range nums3 { for _, v4 := range nums4 { count += m[-v3-v4] } } return count } ","date":"2022-01-06 08:18:30","objectID":"/algorithm_hashtable/:6:0","tags":["data structure"],"title":"Algorithm_hashTable","uri":"/algorithm_hashtable/"},{"categories":["Coding"],"content":"赎金信 给定一个赎金信 (ransom) 字符串和一个杂志(magazine)字符串，判断第一个字符串 ransom 能不能由第二个字符串 magazines 里面的字符构成。如果可以构成，返回 true ；否则返回 false。 (题目说明：为了不暴露赎金信字迹，要从杂志上搜索各个需要的字母，组成单词来表达意思。杂志字符串中的每个字符只能在赎金信字符串中使用一次。) 注意： 你可以假设两个字符串均只含有小写字母。 canConstruct(“a”, “b”) -\u003e false canConstruct(“aa”, “ab”) -\u003e false canConstruct(“aa”, “aab”) -\u003e true func canConstruct(ransomNote string, magazine string) bool { record := make([]int, 26) for _, v := range magazine { record[v-'a']++ } for _, v := range ransomNote { record[v-'a']-- if record[v-'a'] \u003c 0 { return false } } return true } ","date":"2022-01-06 08:18:30","objectID":"/algorithm_hashtable/:7:0","tags":["data structure"],"title":"Algorithm_hashTable","uri":"/algorithm_hashtable/"},{"categories":["Coding"],"content":"三数之和 给你一个包含 n 个整数的数组 nums，判断 nums 中是否存在三个元素 a，b，c ，使得 a + b + c = 0 ？请你找出所有满足条件且不重复的三元组。 注意： 答案中不可以包含重复的三元组。 示例： 给定数组 nums = [-1, 0, 1, 2, -1, -4]， 满足要求的三元组集合为： [ [-1, 0, 1], [-1, -1, 2] ] 解法：哈希、双指针（更高效） func threeSum(nums []int)[][]int{ sort.Ints(nums) res:=[][]int{} for i:=0;i\u003clen(nums)-2;i++{ n1:=nums[i] if n1\u003e0{ break } if i\u003e0\u0026\u0026n1==nums[i-1]{ continue } l,r:=i+1,len(nums)-1 for l\u003cr{ n2,n3:=nums[l],nums[r] if n1+n2+n3==0{ res=append(res,[]int{n1,n2,n3}) for l\u003cr\u0026\u0026nums[l]==n2{ l++ } for l\u003cr\u0026\u0026nums[r]==n3{ r-- } }else if n1+n2+n3\u003c0{ l++ }else { r-- } } } return res } ","date":"2022-01-06 08:18:30","objectID":"/algorithm_hashtable/:8:0","tags":["data structure"],"title":"Algorithm_hashTable","uri":"/algorithm_hashtable/"},{"categories":["Coding"],"content":"四数之和 题意：给定一个包含 n 个整数的数组 nums 和一个目标值 target，判断 nums 中是否存在四个元素 a，b，c 和 d ，使得 a + b + c + d 的值与 target 相等？找出所有满足条件且不重复的四元组。 注意： 答案中不可以包含重复的四元组。 示例： 给定数组 nums = [1, 0, -1, 0, -2, 2]，和 target = 0。 满足要求的四元组集合为： [ [-1, 0, 0, 1], [-2, -1, 1, 2], [-2, 0, 0, 2] ] func fourSum(nums []int, target int) [][]int { if len(nums) \u003c 4 { return nil } sort.Ints(nums) var res [][]int for i := 0; i \u003c len(nums)-3; i++ { n1 := nums[i] // if n1 \u003e target { // 不能这样写,因为可能是负数 // break // } if i \u003e 0 \u0026\u0026 n1 == nums[i-1] { continue } for j := i + 1; j \u003c len(nums)-2; j++ { n2 := nums[j] if j \u003e i+1 \u0026\u0026 n2 == nums[j-1] { continue } l := j + 1 r := len(nums) - 1 for l \u003c r { n3 := nums[l] n4 := nums[r] sum := n1 + n2 + n3 + n4 if sum \u003c target { l++ } else if sum \u003e target { r-- } else { res = append(res, []int{n1, n2, n3, n4}) for l \u003c r \u0026\u0026 n3 == nums[l+1] { // 去重 l++ } for l \u003c r \u0026\u0026 n4 == nums[r-1] { // 去重 r-- } // 找到答案时,双指针同时靠近 r-- l++ } } } } return res } ","date":"2022-01-06 08:18:30","objectID":"/algorithm_hashtable/:9:0","tags":["data structure"],"title":"Algorithm_hashTable","uri":"/algorithm_hashtable/"},{"categories":["Coding"],"content":" 学习代码随想录笔记 链表 ","date":"2022-01-06 08:18:06","objectID":"/algorithm_linkedlist/:0:0","tags":["data structure"],"title":"Algorithm_linkedList","uri":"/algorithm_linkedlist/"},{"categories":["Coding"],"content":"链表理论基础 循环链表可以用来解决约瑟夫环问题。 链表和数组对比： 数组 插入删除时间复杂度：$O(n)$ 查询时间复杂度：$O(1)$ 适用场景：数据量固定，频繁查询，较少增删 链表 插入删除时间复杂度：$O(1)$ 查询时间复杂度：$O(n)$ 适用场景：数据量不固定，频繁增删，较少查询 ","date":"2022-01-06 08:18:06","objectID":"/algorithm_linkedlist/:1:0","tags":["data structure"],"title":"Algorithm_linkedList","uri":"/algorithm_linkedlist/"},{"categories":["Coding"],"content":"移除链表元素 /** * Definition for singly-linked list. * type ListNode struct { * Val int * Next *ListNode * } */ func removeElements(head *ListNode, val int) *ListNode { dummyHead := \u0026ListNode{} dummyHead.Next = head cur := dummyHead for cur != nil \u0026\u0026 cur.Next != nil { if cur.Next.Val == val { cur.Next = cur.Next.Next } else { cur = cur.Next } } return dummyHead.Next } //如果是c或者c++要在删除后free或者delete掉节点释放内存，java,python,go都会自动回收 另外，移除头节点的话，如果没有虚拟头节点，将头节点往后移一个节点，有虚拟头节点就一般删除节点即可。 ","date":"2022-01-06 08:18:06","objectID":"/algorithm_linkedlist/:2:0","tags":["data structure"],"title":"Algorithm_linkedList","uri":"/algorithm_linkedlist/"},{"categories":["Coding"],"content":"设计链表 设计五个接口： 获取链表第index个节点的数值 在链表的最前面插入一个节点 在链表的最后面插入一个节点 在链表第index个节点前面插入一个节点 删除链表的第index个节点 链表操作的两种方式： 直接使用原来的链表来进行操作。 设置一个虚拟头结点在进行操作。（更方便一点） //循环双链表 type MyLinkedList struct { dummy *Node } type Node struct { Val int Next *Node Pre *Node } //仅保存哑节点，pre-\u003e rear, next-\u003e head /** Initialize your data structure here. */ func Constructor() MyLinkedList { rear := \u0026Node{ Val: -1, Next: nil, Pre: nil, } rear.Next = rear rear.Pre = rear return MyLinkedList{rear} } /** Get the value of the index-th node in the linked list. If the index is invalid, return -1. */ func (this *MyLinkedList) Get(index int) int { head := this.dummy.Next //head == this, 遍历完全 for head != this.dummy \u0026\u0026 index \u003e 0 { index-- head = head.Next } //否则, head == this, 索引无效 if 0 != index { return -1 } return head.Val } /** Add a node of value val before the first element of the linked list. After the insertion, the new node will be the first node of the linked list. */ func (this *MyLinkedList) AddAtHead(val int) { dummy := this.dummy node := \u0026Node{ Val: val, //head.Next指向原头节点 Next: dummy.Next, //head.Pre 指向哑节点 Pre: dummy, } //更新原头节点 dummy.Next.Pre = node //更新哑节点 dummy.Next = node //以上两步不能反 } /** Append a node of value val to the last element of the linked list. */ func (this *MyLinkedList) AddAtTail(val int) { dummy := this.dummy rear := \u0026Node{ Val: val, //rear.Next = dummy(哑节点) Next: dummy, //rear.Pre = ori_rear Pre: dummy.Pre, } //ori_rear.Next = rear dummy.Pre.Next = rear //update dummy dummy.Pre = rear //以上两步不能反 } /** Add a node of value val before the index-th node in the linked list. If index equals to the length of linked list, the node will be appended to the end of linked list. If index is greater than the length, the node will not be inserted. */ func (this *MyLinkedList) AddAtIndex(index int, val int) { head := this.dummy.Next //head = MyLinkedList[index] for head != this.dummy \u0026\u0026 index \u003e 0 { head = head.Next index-- } if index \u003e 0 { return } node := \u0026Node{ Val: val, //node.Next = MyLinkedList[index] Next: head, //node.Pre = MyLinkedList[index-1] Pre: head.Pre, } //MyLinkedList[index-1].Next = node head.Pre.Next = node //MyLinkedList[index].Pre = node head.Pre = node //以上两步不能反 } /** Delete the index-th node in the linked list, if the index is valid. */ func (this *MyLinkedList) DeleteAtIndex(index int) { //链表为空 if this.dummy.Next == this.dummy { return } head := this.dummy.Next //head = MyLinkedList[index] for head.Next != this.dummy \u0026\u0026 index \u003e 0 { head = head.Next index-- } //验证index有效 if index == 0 { //MyLinkedList[index].Pre = index[index-2] head.Next.Pre = head.Pre //MyLinedList[index-2].Next = index[index] head.Pre.Next = head.Next //以上两步顺序无所谓 } } ","date":"2022-01-06 08:18:06","objectID":"/algorithm_linkedlist/:3:0","tags":["data structure"],"title":"Algorithm_linkedList","uri":"/algorithm_linkedlist/"},{"categories":["Coding"],"content":"翻转链表 //双指针 func reverseList(head *ListNode) *ListNode { var pre *ListNode cur := head for cur != nil { next := cur.Next cur.Next = pre pre = cur cur = next } return pre } //递归 func reverseList(head *ListNode) *ListNode { return help(nil, head) } func help(pre, head *ListNode)*ListNode{ if head == nil { return pre } next := head.Next head.Next = pre return help(head, next) } ","date":"2022-01-06 08:18:06","objectID":"/algorithm_linkedlist/:4:0","tags":["data structure"],"title":"Algorithm_linkedList","uri":"/algorithm_linkedlist/"},{"categories":["Coding"],"content":"两两交换链表中的节点 正常模拟，使用虚拟头节点。 func swapPairs(head *ListNode) *ListNode { dummy := \u0026ListNode{ Next: head, } //head=list[i] //pre=list[i-1] pre := dummy for head != nil \u0026\u0026 head.Next != nil { pre.Next = head.Next next := head.Next.Next head.Next.Next = head head.Next = next //pre=list[(i+2)-1] pre = head //head=list[(i+2)] head = next } return dummy.Next } // 递归版本 func swapPairs(head *ListNode) *ListNode { if head == nil || head.Next == nil { return head } next := head.Next head.Next = swapPairs(next.Next) next.Next = head return next } ","date":"2022-01-06 08:18:06","objectID":"/algorithm_linkedlist/:5:0","tags":["data structure"],"title":"Algorithm_linkedList","uri":"/algorithm_linkedlist/"},{"categories":["Coding"],"content":"删除链表的倒数第N个节点 双指针很好做： /** * Definition for singly-linked list. * type ListNode struct { * Val int * Next *ListNode * } */ func removeNthFromEnd(head *ListNode, n int) *ListNode { dummyHead := \u0026ListNode{} dummyHead.Next = head cur := head prev := dummyHead i := 1 for cur != nil { cur = cur.Next if i \u003e n { prev = prev.Next } i++ } prev.Next = prev.Next.Next return dummyHead.Next } ","date":"2022-01-06 08:18:06","objectID":"/algorithm_linkedlist/:6:0","tags":["data structure"],"title":"Algorithm_linkedList","uri":"/algorithm_linkedlist/"},{"categories":["Coding"],"content":"链表相交 func getIntersectionNode(headA, headB *ListNode) *ListNode { curA := headA curB := headB lenA, lenB := 0, 0 // 求A，B的长度 for curA != nil { curA = curA.Next lenA++ } for curB != nil { curB = curB.Next lenB++ } var step int var fast, slow *ListNode // 请求长度差，并且让更长的链表先走相差的长度 if lenA \u003e lenB { step = lenA - lenB fast, slow = headA, headB } else { step = lenB - lenA fast, slow = headB, headA } for i:=0; i \u003c step; i++ { fast = fast.Next } // 遍历两个链表遇到相同则跳出遍历 for fast != slow { fast = fast.Next slow = slow.Next } return fast } ","date":"2022-01-06 08:18:06","objectID":"/algorithm_linkedlist/:7:0","tags":["data structure"],"title":"Algorithm_linkedList","uri":"/algorithm_linkedlist/"},{"categories":["Coding"],"content":"环形链表II 第一次做有点难~ 判断是否有环：快慢指针法 如何确定环的入口：一个简单的数学题 func detectCycle(head *ListNode) *ListNode { slow, fast := head, head for fast != nil \u0026\u0026 fast.Next != nil { slow = slow.Next fast = fast.Next.Next if slow == fast { for slow != head { slow = slow.Next head = head.Next } return head } } return nil } ","date":"2022-01-06 08:18:06","objectID":"/algorithm_linkedlist/:8:0","tags":["data structure"],"title":"Algorithm_linkedList","uri":"/algorithm_linkedlist/"},{"categories":["Coding"],"content":"如何实现LRU缓存淘汰算法? 缓存是一种提高数据读取性能的技术，在硬件设计、软件开发中都有着非常广泛的应用，比如常见的 CPU 缓存、数据库缓存、浏览器缓存等等。 缓存的大小有限，当缓存被用满时，哪些数据应该被清理出去，哪些数据应该被保留？这就需要缓存淘汰策略来决定。常见的策略有三种：先进先出策略 FIFO（First In，First Out）、最少使用策略 LFU（Least Frequently Used）、最近最少使用策略 LRU（Least Recently Used）。 ","date":"2022-01-06 08:18:06","objectID":"/algorithm_linkedlist/:9:0","tags":["data structure"],"title":"Algorithm_linkedList","uri":"/algorithm_linkedlist/"},{"categories":["Coding"],"content":"链表结构 我们先从底层的存储结构上来看一看。从图中我们看到，数组需要一块连续的内存空间来存储，对内存的要求比较高。如果我们申请一个 100MB 大小的数组，当内存中没有连续的、足够大的存储空间时，即便内存的剩余总可用空间大于 100MB，仍然会申请失败。而链表恰恰相反，它并不需要一块连续的内存空间，它通过“指针”将一组零散的内存块串联起来使用，所以如果我们申请的是 100MB 大小的链表，根本不会有问题。 链表结构五花八门，今天我重点给你介绍三种最常见的链表结构，它们分别是：单链表、双向链表和循环链表。我们首先来看最简单、最常用的单链表。 其中有两个结点是比较特殊的，它们分别是第一个结点和最后一个结点。我们习惯性地把第一个结点叫作头结点，把最后一个结点叫作尾结点。其中，头结点用来记录链表的基地址。有了它，我们就可以遍历得到整条链表。而尾结点特殊的地方是：指针不是指向下一个结点，而是指向一个空地址 NULL，表示这是链表上最后一个结点。 循环链表是一种特殊的单链表。实际上，循环链表也很简单。它跟单链表唯一的区别就在尾结点。我们知道，单链表的尾结点指针指向空地址，表示这就是最后的结点了。而循环链表的尾结点指针是指向链表的头结点。从我画的循环链表图中，你应该可以看出来，它像一个环一样首尾相连，所以叫作“循环”链表。 接下来我们再来看一个稍微复杂的，在实际的软件开发中，也更加常用的链表结构：双向链表。 相比单链表，双向链表适合解决哪种问题呢？ 从结构上来看，双向链表可以支持 O(1) 时间复杂度的情况下找到前驱结点，正是这样的特点，也使双向链表在某些情况下的插入、删除等操作都要比单链表简单、高效。 对于执行较慢的程序，可以通过消耗更多的内存（空间换时间）来进行优化；而消耗过多内存的程序，可以通过消耗更多的时间（时间换空间）来降低内存的消耗 如何基于链表实现 LRU 缓存淘汰算法？我的思路是这样的：我们维护一个有序单链表，越靠近链表尾部的结点是越早之前访问的。当有一个新的数据被访问时，我们从链表头开始顺序遍历链表。 如果此数据之前已经被缓存在链表中了，我们遍历得到这个数据对应的结点，并将其从原来的位置删除，然后再插入到链表的头部。 如果此数据没有在缓存链表中，又可以分为两种情况： 如果此时缓存未满，则将此结点直接插入到链表的头部；如果此时缓存已满，则链表尾结点删除，将新的数据结点插入链表的头部。 现在我们来看下缓存访问的时间复杂度是多少。因为不管缓存有没有满，我们都需要遍历一遍链表，所以这种基于链表的实现思路，缓存访问的时间复杂度为 O(n)。实际上，我们可以继续优化这个实现思路，比如引入散列表（Hash table）来记录每个数据的位置，将缓存访问的时间复杂度降到 O(1)。因为要涉及我们还没有讲到的数据结构，所以这个优化方案，我现在就不详细说了，等讲到散列表的时候，我会再拿出来讲。 除了基于链表的实现思路，实际上还可以用数组来实现 LRU 缓存淘汰策略。如何利用数组实现 LRU 缓存淘汰策略呢？ ","date":"2022-01-06 08:18:06","objectID":"/algorithm_linkedlist/:10:0","tags":["data structure"],"title":"Algorithm_linkedList","uri":"/algorithm_linkedlist/"},{"categories":["Coding"],"content":" 学习代码随想录笔记 数组 ","date":"2022-01-06 08:17:33","objectID":"/algorithm_array/:0:0","tags":["data structure"],"title":"Algorithm_array","uri":"/algorithm_array/"},{"categories":["Coding"],"content":"数组基础 数组是存放在连续内存空间上的相同类型数据的集合。 因为数组的在内存空间的地址是连续的，所以我们在删除或者增添元素的时候，就难免要移动其他元素的地址。 数组元素无法删除，只能覆盖。 ","date":"2022-01-06 08:17:33","objectID":"/algorithm_array/:1:0","tags":["data structure"],"title":"Algorithm_array","uri":"/algorithm_array/"},{"categories":["Coding"],"content":"二分查找 有序数组、无重复元素便可想到用二分法查找。注意区间左闭右闭还是左闭右开。 简单实现： func search(nums []int, target int) int { left := 0 right := len(nums) - 1 for left \u003c= right { middle := left + (right - left)/2 if nums[middle] \u003e target { right = middle - 1 }else if nums[middle] \u003c target { left = middle + 1 }else{ return middle; } } return -1 } func search(nums []int,t int)int{ left,middle:=0 right:=len(nums) for left\u003c=right{ num=(left+right)/2 if nums[num]==t{ return num } if nums[num]\u003et{ right=num-1 }else{ left=num+1 } } } func search(nums []int,t int)int{ if middle:=len(nums)/2;nums[middle]==t{ return middle } if len(nums)==1{ return -1 } if nums[middle]\u003et{ return search(nums[:middle],t) }else{ return search(nums[middle+1:]) } } func recureionSearch(nums []int,t int) ","date":"2022-01-06 08:17:33","objectID":"/algorithm_array/:2:0","tags":["data structure"],"title":"Algorithm_array","uri":"/algorithm_array/"},{"categories":["Coding"],"content":"移除元素 双指针法（快慢指针法）： 通过一个快指针和慢指针在一个for循环下完成两个for循环的工作。 func removeElement(nums []int, val int) int { length:=len(nums) res:=0 for i:=0;i\u003clength;i++{ if nums[i]!=val { nums[res]=nums[i] res++ } } return res } func removeElement(nums []int, val int) int { num := 0 for i, v := range nums { if v == val { num++ } else { nums[i-num] = v } } return len(nums)-num } ","date":"2022-01-06 08:17:33","objectID":"/algorithm_array/:3:0","tags":["data structure"],"title":"Algorithm_array","uri":"/algorithm_array/"},{"categories":["Coding"],"content":"有序数组的平方 双指针法： func sortedSquares(nums []int) []int { n := len(nums) i, j, k := 0, n-1, n-1 ans := make([]int, n) for i \u003c= j { lm, rm := nums[i]*nums[i], nums[j]*nums[j] if lm \u003e rm { ans[k] = lm i++ } else { ans[k] = rm j-- } k-- } return ans } ","date":"2022-01-06 08:17:33","objectID":"/algorithm_array/:4:0","tags":["data structure"],"title":"Algorithm_array","uri":"/algorithm_array/"},{"categories":["Coding"],"content":"长度最小的子数组 给定一个含有 n 个正整数的数组和一个正整数 s ，找出该数组中满足其和 ≥ s 的长度最小的 连续 子数组，并返回其长度。如果不存在符合条件的子数组，返回 0。 滑动窗口 func minSubArrayLen(target int, nums []int) int { i := 0 l := len(nums) // 数组长度 sum := 0 // 子数组之和 result := l + 1 // 初始化返回长度为l+1，目的是为了判断“不存在符合条件的子数组，返回0”的情况 for j := 0; j \u003c l; j++ { sum += nums[j] for sum \u003e= target { subLength := j - i + 1 if subLength \u003c result { result = subLength } sum -= nums[i] i++ } } if result == l+1 { return 0 } else { return result } } ","date":"2022-01-06 08:17:33","objectID":"/algorithm_array/:5:0","tags":["data structure"],"title":"Algorithm_array","uri":"/algorithm_array/"},{"categories":["Coding"],"content":"螺旋矩阵II 模拟行为： func generateMatrix(n int) [][]int { top, bottom := 0, n-1 left, right := 0, n-1 num := 1 tar := n * n matrix := make([][]int, n) for i := 0; i \u003c n; i++ { matrix[i] = make([]int, n) } for num \u003c= tar { for i := left; i \u003c= right; i++ { matrix[top][i] = num num++ } top++ for i := top; i \u003c= bottom; i++ { matrix[i][right] = num num++ } right-- for i := right; i \u003e= left; i-- { matrix[bottom][i] = num num++ } bottom-- for i := bottom; i \u003e= top; i-- { matrix[i][left] = num num++ } left++ } return matrix } ","date":"2022-01-06 08:17:33","objectID":"/algorithm_array/:6:0","tags":["data structure"],"title":"Algorithm_array","uri":"/algorithm_array/"},{"categories":["Coding"],"content":"总结 ","date":"2022-01-06 08:17:33","objectID":"/algorithm_array/:7:0","tags":["data structure"],"title":"Algorithm_array","uri":"/algorithm_array/"},{"categories":["Coding"],"content":"算法性能分析 ","date":"2022-01-02 19:28:23","objectID":"/performance_analysis/:0:0","tags":["data structure"],"title":"Performance_analysis","uri":"/performance_analysis/"},{"categories":["Coding"],"content":"03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？ 复杂度分析是整个算法学习的精髓，只要掌握了它，数据结构和算法的内容基本上就掌握了一半。 ","date":"2022-01-02 19:28:23","objectID":"/performance_analysis/:1:0","tags":["data structure"],"title":"Performance_analysis","uri":"/performance_analysis/"},{"categories":["Coding"],"content":"为什么需要复杂度分析？ 你可能会有些疑惑，我把代码跑一遍，通过统计、监控，就能得到算法执行的时间和占用的内存大小。为什么还要做时间、空间复杂度分析呢？这种分析方法能比我实实在在跑一遍得到的数据更准确吗？首先，我可以肯定地说，你这种评估算法执行效率的方法是正确的。很多数据结构和算法书籍还给这种方法起了一个名字，叫事后统计法。但是，这种统计方法有非常大的局限性。 测试结果非常依赖测试环境 测试结果受数据规模的影响很大 所以，我们需要一个不用具体的测试数据来测试，就可以粗略地估计算法的执行效率的方法。这就是我们今天要讲的时间、空间复杂度分析方法。 ","date":"2022-01-02 19:28:23","objectID":"/performance_analysis/:1:1","tags":["data structure"],"title":"Performance_analysis","uri":"/performance_analysis/"},{"categories":["Coding"],"content":"时间复杂度分析 只关注循环执行次数最多的一段代码 加法法则：总复杂度等于量级最大的那段代码的复杂度 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积 ","date":"2022-01-02 19:28:23","objectID":"/performance_analysis/:1:2","tags":["data structure"],"title":"Performance_analysis","uri":"/performance_analysis/"},{"categories":["Coding"],"content":"空间复杂度分析 时间复杂度的全称是渐进时间复杂度，表示算法的执行时间与数据规模之间的增长关系。类比一下，空间复杂度全称就是渐进空间复杂度（asymptotic space complexity），表示算法的存储空间与数据规模之间的增长关系。 ","date":"2022-01-02 19:28:23","objectID":"/performance_analysis/:1:3","tags":["data structure"],"title":"Performance_analysis","uri":"/performance_analysis/"},{"categories":["Coding"],"content":"时间复杂度 时间复杂度是定性描述算法运行时间的函数。 实际情况中会因为数据用例、数据规模不同而变化，一般讨论一般情况。 时间复杂度$O(log(n))$并不以某一个确定的数为底数，因为可以通过乘以某个对数常数达到换底数的效果。 递归算法的时间复杂度：递归次数*每次递归的时间复杂度（操作的次数） ","date":"2022-01-02 19:28:23","objectID":"/performance_analysis/:2:0","tags":["data structure"],"title":"Performance_analysis","uri":"/performance_analysis/"},{"categories":["Coding"],"content":"空间复杂度分析 空间复杂度：程序运行时占用内存的大小，受很多因素的影响，比如编译器的内存对齐，编程语言容器的底层实现等 递归算法的空间复杂度：递归深度*每次递归的空间复杂度 递归所需的空间都被压到调用栈里，一次递归结束，这个栈就是就是把本次递归的数据弹出去。所以这个栈最大的长度就是递归的深度。 ","date":"2022-01-02 19:28:23","objectID":"/performance_analysis/:3:0","tags":["data structure"],"title":"Performance_analysis","uri":"/performance_analysis/"},{"categories":["Coding"],"content":"算法复杂度主方法 主方法亦可称为主定理。适用于求那些用分治法以及有递推关系式的算法的复杂度。 假设有递推关系式：$T(n)=aT(n/b)+f(n)$ n是问题规模 a为递推的子问题数量 n/b是每个子问题的规模，假设每个子问题规模一致 f(n)为递推以外进行的计算工作 T(n)为非负整数 分类讨论： 若$f(n)=O(n^{log_b(a-e)}),e\u003e0$ 则$T(n)=Θ(n^{log_b(a)})$ 若$f(n)=Θ(n^{log_b(a)})$ 则$T(n)=Θ(n^{log_b(a)}log(n))$ 若$f(n)=Ω(n^{log_b(a+e)}),e\u003e0$，且对于某个常数c \u003c 1和所有充分大的n有$af(n/b)\u003c=cf(n)$， 则$T(n)=Θ(f(n))$ 不是很容易记忆。下面有一种简化的版本： 若算法运行时间$T(n)\u003c=aT(n/b)+O(n^d)$ a\u003e=1是子问题的个数，b\u003e=1是输入规模减小的倍数，d\u003e=0是递归过程之外的步骤的时间复杂度指数，则： ","date":"2022-01-02 19:28:23","objectID":"/performance_analysis/:4:0","tags":["data structure"],"title":"Performance_analysis","uri":"/performance_analysis/"},{"categories":["Coding"],"content":"代码的内存消耗 每种语言都有着自己的内存管理方式。 ","date":"2022-01-02 19:28:23","objectID":"/performance_analysis/:5:0","tags":["data structure"],"title":"Performance_analysis","uri":"/performance_analysis/"},{"categories":["Coding"],"content":"内存对齐 对于各种基本数据类型来说，它的变量的内存地址值必须是其类型本身大小的整数倍。在go里面，对于结构体而言，它的变量的内存地址，只要是它最长字段长度与系统对齐系数两者之间较小的那个的整数倍就可以了。但对于结构体类型来说，我们还要让它每个字段的内存地址都严格满足内存对齐要求。 举个例子： type T struct { b byte i int64 u uint16 } 64bit平台系统对齐系数是8 计算过程：sum=1+7+8+2+6 第一个阶段是对齐结构体的各个字段: 首先，我们看第一个字段 b 是长度 1 个字节的 byte 类型变量，这样字段 b 放在任意地址上都可以被 1 整除，所以我们说它是天生对齐的。我们用一个 sum 来表示当前已经对齐的内存空间的大小，这个时候 sum=1； 接下来，我们看第二个字段 i，它是一个长度为 8 个字节的 int64 类型变量。按照内存对齐要求，它应该被放在可以被 8 整除的地址上。但是，如果把 i 紧邻 b 进行分配，当 i 的地址可以被 8 整除时，b 的地址就无法被 8 整除。这个时候，我们需要在 b 与 i 之间做一些填充，使得 i 的地址可以被 8 整除时，b 的地址也始终可以被 8 整除，于是我们在 i 与 b 之间填充了 7 个字节，此时此刻 sum=1+7+8； 再下来，我们看第三个字段 u，它是一个长度为 2 个字节的 uint16 类型变量，按照内存对其要求，它应该被放在可以被 2 整除的地址上。有了对其的 i 作为基础，我们现在知道将 u 与 i 相邻而放，是可以满足其地址的对齐要求的。i 之后的那个字节的地址肯定可以被 8 整除，也一定可以被 2 整除。于是我们把 u 直接放在 i 的后面，中间不需要填充，此时此刻，sum=1+7+8+2。 结构体 T 的所有字段都已经对齐了，开始第二个阶段，也就是对齐整个结构体: 结构体的内存地址为 min（结构体最长字段的长度，系统内存对齐系数）的整数倍，那么这里结构体 T 最长字段为 i，它的长度为 8，而 64bit 系统上的系统内存对齐系数一般为 8，两者相同，我们取 8 就可以了。那么整个结构体的对齐系数就是 8。 在尾部填充6字节原因： 结构体 T 的对齐系数是 8，那么我们就要保证每个结构体 T 的变量的内存地址，都能被 8 整除。如果我们只分配一个 T 类型变量，不再继续填充，也可能保证其内存地址为 8 的倍数。但如果考虑我们分配的是一个元素为 T 类型的数组，数组是元素连续存储的一种类型，元素 T[1]的地址为 T[0]地址 +T 的大小 (18)，显然无法被 8 整除，这将导致 T[1]及后续元素的地址都无法对齐，这显然不能满足内存对齐的要求。 所以，定义结构体时，一定要注意结构体中字段顺序，尽量合理排序，降低结构体对内存空间的占用。 前面例子中的内存填充部分，是由编译器自动完成的。不过，有些时候，为了保证某个字段的内存地址有更为严格的约束，我们也会做主动填充。比如 runtime 包中的 mstats 结构体定义就采用了主动填充： // $GOROOT/src/runtime/mstats.go type mstats struct { ... ... // Add an uint32 for even number of size classes to align below fields // to 64 bits for atomic operations on 32 bit platforms. _ [1 - _NumSizeClasses%2]uint32 // 这里做了主动填充,通常我们会通过空标识符来进行主动填充 last_gc_nanotime uint64 // last gc (monotonic time) last_heap_inuse uint64 // heap_inuse at mark termination of the previous GC ... ... } 为什么会有内存对齐？ 平台原因：不是所有的硬件平台都能访问任意内存地址上的任意数据，某些硬件平台只能在某些地址处取某些特定类型的数据，否则抛出硬件异常。为了同一个程序可以在多平台运行，需要内存对齐。 硬件原因：经过内存对齐后，CPU访问内存的速度大大提升 CPU读取内存不是一次读取单个字节，而是一块一块的来读取内存，块的大小可以是2，4，8，16个字节，具体取多少个字节取决于硬件。 只要可以跨平台的编程语言都需要做内存对齐，不做内存对齐会使运行速度下降，因为寻址访存次数多了。现在的编译器一般都会做内存对齐的优化操作，也就是说当考虑程序真正占用的内存大小的时候，也需要认识到内存对齐的影响。 ","date":"2022-01-02 19:28:23","objectID":"/performance_analysis/:5:1","tags":["data structure"],"title":"Performance_analysis","uri":"/performance_analysis/"},{"categories":["Coding"],"content":"go语言的内存管理 显然，go的内存管理内部机制建立于操作系统以及机器硬件如何管理内存之上的。尽可能扬长避短。 介绍一下和开发者关系较大的操作系统内存管理机制。 暂停 ","date":"2022-01-02 19:28:23","objectID":"/performance_analysis/:5:2","tags":["data structure"],"title":"Performance_analysis","uri":"/performance_analysis/"},{"categories":["Coding"],"content":"编程相关 ","date":"2022-01-02 18:57:57","objectID":"/programming_literacy/:0:0","tags":["data structure"],"title":"Programming_literacy","uri":"/programming_literacy/"},{"categories":["Coding"],"content":"代码风格与规范 go其实没有什么要说的。。 ","date":"2022-01-02 18:57:57","objectID":"/programming_literacy/:1:0","tags":["data structure"],"title":"Programming_literacy","uri":"/programming_literacy/"},{"categories":["Coding"],"content":"变量命名 主要以团队风格为主； 主流有如下三种变量规则： 小驼峰、大驼峰(帕斯卡命名法)命名法（java,go） 下划线命名法(python,linux下的c/c++编程) 匈牙利命名法 该命名规范，要求前缀字母用变量类型的缩写，其余部分用变量的英文或英文的缩写，单词第一个字母大写。（很少用，在windows下的c/c++编程有时会用,没有IDE的时代挺好） int iMyAge; // \"i\": int char cMyName[10]; // \"c\": char float fManHeight; // \"f\": float ","date":"2022-01-02 18:57:57","objectID":"/programming_literacy/:1:1","tags":["data structure"],"title":"Programming_literacy","uri":"/programming_literacy/"},{"categories":["Coding"],"content":"核心代码模式和ACM模式 核心代码模式： 把要处理的数据都已经放入容器里，可以直接写逻辑 ACM输入模式呢： 自己构造输入数据格式，把要需要处理的容器填充好，不会给你任何代码，包括include哪些函数都要自己写，最后也要自己控制返回数据的格式。 ","date":"2022-01-02 18:57:57","objectID":"/programming_literacy/:1:2","tags":["data structure"],"title":"Programming_literacy","uri":"/programming_literacy/"},{"categories":["Advanced learning"],"content":" 极客时间学习笔记 MySQL基础 ","date":"2021-12-01 21:31:10","objectID":"/mysql_advanced_01/:0:0","tags":["mysql"],"title":"Mysql_advanced_01","uri":"/mysql_advanced_01/"},{"categories":["Advanced learning"],"content":"一条sql查询语句 mysql\u003e select * from T where ID=10； 一条简单的查询语句，MYSQL内部发生了什么？ 大体来说，MySQL 可以分为 Server 层和存储引擎层两部分。 Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。 存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。可以在 create table 语句中使用 engine=memory, 来指定使用内存引擎创建表。 不同的存储引擎共用一个 Server 层，也就是从连接器到执行器的部分。 ","date":"2021-12-01 21:31:10","objectID":"/mysql_advanced_01/:1:0","tags":["mysql"],"title":"Mysql_advanced_01","uri":"/mysql_advanced_01/"},{"categories":["Advanced learning"],"content":"连接器 连接器负责跟客户端建立连接、获取权限、维持和管理连接。 mysql -h$ip -P$port -u$user -p 如果把密码直接写在-p后面容易导致密码泄露 连接命令中的 mysql 是客户端工具，用来跟服务端建立连接。在完成经典的 TCP 握手后，连接器就要开始认证你的身份，这个时候用的就是你输入的用户名和密码： 如果用户名或密码不对，你就会收到一个\"Access denied for user\"的错误，然后客户端程序结束执行。 如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限（注意修改权限后下次登录才生效）。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。 连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，你可以在 show processlist 命令中看到该连接的command是sleep的。show processlist 是显示用户正在运行的线程，需要注意的是，除了 root 用户能看到所有正在运行的线程外，其他用户都只能看到自己正在运行的线程，看不到其它用户正在运行的线程。除非单独个这个用户赋予了PROCESS 权限。 客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数 wait_timeout 控制的，默认值是 8 小时。 mysql\u003e show variables like 'wait_timeout'; 长连接和短连接： 长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。（推荐，因为建立连接的过程通常是比较复杂的） 短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。 但是全部使用长连接后，有些时候 MySQL 占用内存涨得特别快，这是因为 **MySQL 在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。**所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是 MySQL 异常重启了。 解决方法： 定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。 如果你用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。 mysql_reset_connection：重置连接以清除会话状态。（将句柄都给置空，并且清理掉了预处理语句、结果集） mysql_reset_connection()的作用类似于mysql_change_user()或自动重新连接，除了未关闭并重新打开连接且未完成重新身份验证外。 与连接有关的状态受到以下影响： 回滚所有活动的事务，并重置自动提交模式。 所有 table 锁均已释放。 所有TEMPORARYtable 均已关闭(并删除)。 会话系统变量将重新初始化为相应的全局系统变量的值，包括由诸如SET NAMES之类的语句隐式设置的系统变量。 用户变量设置丢失。 准备好的语句被释放。 HANDLER个变量已关闭。 LAST_INSERT_ID()的值重置为 0. 用GET_LOCK()获取的锁被释放。 Return Values 零成功。如果发生错误，则为非零值。 查询缓存 MySQL 拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。key 是查询的语句，value 是查询的结果。如果你的查询能够直接在这个缓存中找到 key，那么这个 value 就会被直接返回给客户端。 如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。 查询缓存的弊端： 查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。 可以将参数 query_cache_type 设置成 DEMAND，这样对于默认的 SQL 语句都不使用查询缓存。而对于确定要使用查询缓存的语句，可以用 SQL_CACHE 显式指定： mysql\u003e select SQL_CACHE * from T where ID=10； MySQL 8.0 版本直接将查询缓存的整块功能删掉了。 分析器 分析器对 SQL 语句做解析让mysql知道你要做什么： 词法分析 你输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是什么，代表什么。 MySQL 从你输入的\"select\"这个关键字识别出来，这是一个查询语句。它也要把字符串“T”识别成“表名 T”，把字符串“ID”识别成“列 ID” 语法分析 根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。 如果你的语句不对，就会收到“You have an error in your SQL syntax”的错误提醒，比如你的查询语句 select 少打了开头的字母“s”。 优化器 执行前，需经过优化器的处理： 优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。比如你执行下面这样的语句，这个语句是执行两个表的 join： mysql\u003e select * from t1 join t2 using(ID) where t1.c=10 and t2.d=20; 既可以先从表 t1 里面取出 c=10 的记录的 ID 值，再根据 ID 值关联到表 t2，再判断 t2 里面 d 的值是否等于 20。 也可以先从表 t2 里面取出 d=20 的记录的 ID 值，再根据 ID 值关联到 t1，再判断 t1 里面 c 的值是否等于 10。 逻辑结果是一样的，但是执行的效率会有不同，而优化器的作用就是决定选择使用哪一个方案。 执行器 执行语句： 先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误，如下所示 (在工程实现上，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。查询也会在优化器之前调用 precheck 验证权限)。 mysql\u003e select * from T where ID=10; ERROR 1142 (42000): SELECT command denied to user 'b'@'localhost' for table 'T' 如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。 比如我们这个例子中的表 T 中，ID 字段没有索引，那么执行器的执行流程是这样的： 调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如果是则将这行存在结果集中； 调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。 对于有索引的表，执行的逻辑也差不多。第一次调用的是“取满足条件的第一行”这个接口，之后循环取“满足条件的下一行”这个接口，这些接口都是引擎中已经定义好的。 你会在数据库的慢查询日志中看到一个 rows_examined 的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。 在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟 rows_examined 并不是完全相同的。 ","date":"2021-12-01 21:31:10","objectID":"/mysql_advanced_01/:1:1","tags":["mysql"],"title":"Mysql_advanced_01","uri":"/mysql_advanced_01/"},{"categories":["Advanced learning"],"content":"一条sql更新语句 日志系统：一条SQL更新语句是如何执行的? mysql\u003e create table T(ID int primary key, c int); mysql\u003e update T set c=c+1 where ID=2; 查询语句的那一套流程，更新语句也是同样会走一遍。 执行语句前要先连接数据库，这是连接器的工作。 在一个表上有更新的时候，跟这个表有关的查询缓存会失效，所以这条语句就会把表 T 上所有缓存结果都清空。 分析器会通过词法和语法解析知道这是一条更新语句。优化器决定要使用 ID 这个索引。然后，执行器负责具体执行，找到这一行，然后更新。 与查询流程不一样的是，更新流程还涉及两个重要的日志模块，redo log（重做日志）和 binlog（归档日志）。redo log 和 binlog 在设计上有很多有意思的地方。 ","date":"2021-12-01 21:31:10","objectID":"/mysql_advanced_01/:2:0","tags":["mysql"],"title":"Mysql_advanced_01","uri":"/mysql_advanced_01/"},{"categories":["Advanced learning"],"content":"重要的日志模块：redo log 如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高。 WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘 具体来说，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。 InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB。从头开始写，写到末尾就又回到开头循环写。 write pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。 write pos 和 checkpoint 之间的还空着的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，表示日志满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。 有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为 crash-safe。 redo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这个参数我建议你设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。 ","date":"2021-12-01 21:31:10","objectID":"/mysql_advanced_01/:2:1","tags":["mysql"],"title":"Mysql_advanced_01","uri":"/mysql_advanced_01/"},{"categories":["Advanced learning"],"content":"重要的日志模块 MySQL 整体来看，其实就有两块：一块是 Server 层，它主要做的是 MySQL 功能层面的事情；还有一块是引擎层，负责存储相关的具体事宜。上面的 redo log 是 InnoDB 引擎特有的日志，而 Server 层也有自己的日志，称为 binlog（归档日志）。 最开始 MySQL 里并没有 InnoDB 引擎。MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB 使用另外一套日志系统——也就是 redo log 来实现 crash-safe 能力。 两种日志的不同： redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。 redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1”。 redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。 执行器和 InnoDB 引擎在执行这个简单的 update 语句时的内部流程： 执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。 执行器生成这个操作的 binlog，并把 binlog 写入磁盘。 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。 注：redo log 的写入拆成了两个步骤：prepare 和 commit，这就是\"两阶段提交”。 sync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。这个参数我也建议你设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。 ","date":"2021-12-01 21:31:10","objectID":"/mysql_advanced_01/:2:2","tags":["mysql"],"title":"Mysql_advanced_01","uri":"/mysql_advanced_01/"},{"categories":["Advanced learning"],"content":"两阶段提交 两阶段提交是为了让两份日志之间的逻辑一致。 binlog 会记录所有的逻辑操作，并且是采用“追加写”的形式。如果你的 DBA 承诺说半个月内可以恢复，那么备份系统中一定会保存最近半个月的所有 binlog，同时系统会定期做整库备份。这里的“定期”取决于系统的重要性，可以是一天一备，也可以是一周一备。 当需要恢复到指定的某一秒时，比如某天下午两点发现中午十二点有一次误删表，需要找回数据，那你可以这么做： 首先，找到最近的一次全量备份，如果你运气好，可能就是昨天晚上的一个备份，从这个备份恢复到临时库； 然后，从备份的时间点开始，将备份的 binlog 依次取出来，重放到中午误删表之前的那个时刻。 为什么日志需要“两阶段提交”？ 由于 redo log 和 binlog 是两个独立的逻辑，如果不用两阶段提交，要么就是先写完 redo log 再写 binlog，或者采用反过来的顺序。这两种方式的问题： 先写 redo log 后写 binlog。假设在 redo log 写完，binlog 还没有写完的时候，MySQL 进程异常重启。由于我们前面说过的，redo log 写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行 c 的值是 1。但是由于 binlog 没写完就 crash 了，这时候 binlog 里面就没有记录这个语句。因此，之后备份日志的时候，存起来的 binlog 里面就没有这条语句。然后你会发现，如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 binlog 丢失，这个临时库就会少了这一次更新，恢复出来的这一行 c 的值就是 0，与原库的值不同。 先写 binlog 后写 redo log。如果在 binlog 写完之后 crash，由于 redo log 还没写，崩溃恢复以后这个事务无效，所以这一行 c 的值是 0。但是 binlog 里面已经记录了“把 c 从 0 改成 1”这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务出来，恢复出来的这一行 c 的值就是 1，与原库的值不同。 即，如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。 不只是误操作后需要用这个过程来恢复数据。当你需要扩容的时候，也就是需要再多搭建一些备库来增加系统的读能力的时候，现在常见的做法也是用全量备份加上应用 binlog来实现的，这个“不一致”就会导致你的线上出现主从数据库不一致的情况。 ","date":"2021-12-01 21:31:10","objectID":"/mysql_advanced_01/:2:3","tags":["mysql"],"title":"Mysql_advanced_01","uri":"/mysql_advanced_01/"},{"categories":["Advanced learning"],"content":"一天一备份和一周一备份的区别 一天一备份“最长恢复时间”更短。 频繁全量备份需要消耗更多存储空间，所以这个 RTO 是成本换来的，就需要你根据业务重要性来评估了。 ","date":"2021-12-01 21:31:10","objectID":"/mysql_advanced_01/:2:4","tags":["mysql"],"title":"Mysql_advanced_01","uri":"/mysql_advanced_01/"},{"categories":["Advanced learning"],"content":"事务隔离 转账过程具体到程序里会有一系列的操作，比如查询余额、做加减法、更新余额等，这些操作必须保证是一体的，不然等程序查完之后，还没做减法之前，你这 100 块钱，完全可以借着这个时间差再查一次，然后再给另外一个朋友转账，如果银行这么整，不就乱了么？这时就要用到“事务”这个概念了。 简单来说，事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在 MySQL 中，事务支持是在引擎层实现的。你现在知道，MySQL 是一个支持多引擎的系统，但并不是所有的引擎都支持事务。比如 MySQL 原生的 MyISAM 引擎就不支持事务，这也是 MyISAM 被 InnoDB 取代的重要原因之一。 以下会以 InnoDB 为例，剖析 MySQL 在事务支持方面的特定实现。 ","date":"2021-12-01 21:31:10","objectID":"/mysql_advanced_01/:3:0","tags":["mysql"],"title":"Mysql_advanced_01","uri":"/mysql_advanced_01/"},{"categories":["Advanced learning"],"content":"隔离性与隔离级别 事务：ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性） 当数据库上有多个事务同时执行的时候，就可能出现脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）的问题，为了解决这些问题，就有了“隔离级别”的概念。 隔离做得越好，往往效率越低，所以需要互相平衡。 SQL 标准的事务隔离级别包括：读未提交（read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（serializable ）。 读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。 读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。 可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。(事务在执行期间看到的数据前后必须是一致的。) 串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。 Oracle 数据库的默认隔离级别其实就是“读提交”，因此对于一些从 Oracle 迁移到 MySQL 的应用，为保证数据库隔离级别的一致，一定要记得将 MySQL 的隔离级别设置为“读提交”。 配置的方式是，将启动参数 transaction-isolation 的值设置成 READ-COMMITTED。你可以用 show variables 来查看当前的值: mysql\u003e show variables like 'transaction_isolation'; +-----------------------+----------------+ | Variable_name | Value | +-----------------------+----------------+ | transaction_isolation | READ-COMMITTED | +-----------------------+----------------+ 应用案例： 假设你在管理一个个人银行账户表。一个表存了账户余额，一个表存了账单明细。到了月底你要做数据校对，也就是判断上个月的余额和当前余额的差额，是否与本月的账单明细一致。你一定希望在校对过程中，即使有用户发生了一笔新的交易，也不影响你的校对结果。 使用“可重复读”隔离级别就很方便。事务启动时的视图可以认为是静态的，不受其他事务更新的影响。 ","date":"2021-12-01 21:31:10","objectID":"/mysql_advanced_01/:3:1","tags":["mysql"],"title":"Mysql_advanced_01","uri":"/mysql_advanced_01/"},{"categories":["Advanced learning"],"content":"事务隔离的实现 可重复读： 在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。 假设一个值从 1 被按顺序改成了 2、3、4，在回滚日志里面就会保存相应记录。 当前值是 4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的 read-view(eg:将2改成1)。 同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC） 系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。 什么时候才不需要了呢？就是当系统里没有比这个回滚日志更早的 read-view 的时候。 为什么建议你尽量不要使用长事务？ 长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。 在 MySQL 5.5 及以前的版本，回滚日志是跟数据字典一起放在 ibdata 文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小。数据只有 20GB，但回滚段可能有 200GB 的库。最终只好为了清理回滚段，重建整个库。 除了对回滚段的影响，长事务还占用锁资源，也可能拖垮整个库。 很多时候业务开发同学并不是有意使用长事务，通常是由于误用所致。 ","date":"2021-12-01 21:31:10","objectID":"/mysql_advanced_01/:3:2","tags":["mysql"],"title":"Mysql_advanced_01","uri":"/mysql_advanced_01/"},{"categories":["Advanced learning"],"content":"事务的启动方式 MySQL 的事务启动方式有以下几种： 显式启动事务语句， begin 或 start transaction。配套的提交语句是 commit，回滚语句是 rollback。 set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。 有些客户端连接框架会默认连接成功后先执行一个 set autocommit=0 的命令。这就导致接下来的查询都在事务中，如果是长连接，就导致了意外的长事务。 因此，建议总是使用 set autocommit=1, 通过显式语句的方式来启动事务。 若考虑到交互次数的增加，建议使用 commit work and chain 语法。 在 autocommit 为 1 的情况下，用 begin 显式启动的事务，如果执行 commit 则提交事务。如果执行 commit work and chain，则是提交事务并自动启动下一个事务，这样也省去了再次执行 begin 语句的开销。同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。 你可以在 information_schema 库的 innodb_trx 这个表中查询长事务，比如下面这个语句，用于查找持续时间超过 60s 的事务： select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))\u003e60 ","date":"2021-12-01 21:31:10","objectID":"/mysql_advanced_01/:3:3","tags":["mysql"],"title":"Mysql_advanced_01","uri":"/mysql_advanced_01/"},{"categories":["Advanced learning"],"content":"索引 索引的出现就是为了提高数据查询的效率，就像书的目录一样。 索引常见模型（数据结构）： 哈希表 一般用拉链法解决哈希等值数据的存储，适用于只有等值查询的场景。范围查询则需要全部扫描一遍。 比如 Memcached 及其他一些 NoSQL 引擎。 有序数组 有序数组在等值查询和范围查询场景中的性能就都非常优秀。 查询效率最好的数据结构，更新数据效率低下。 只适用于静态存储引擎 搜索树 查询的时候当然要控制尽量少地读磁盘，查询的时候尽量少地访问数据块（树根的数据块一般都在内存中，而其余节点的数据块大概率都需要访问磁盘），二叉搜索树理论上搜索效率虽高，但实际应用时都是用 N 叉树，N 取决于数据块的大小 N 叉树由于在读写上的性能优点，以及适配磁盘的访问模式，已经被广泛应用在数据库引擎中了。 在 MySQL 中，索引是在存储引擎层实现的，所以并没有统一的索引标准，即不同存储引擎的索引的工作方式并不一样。而即使多个存储引擎支持同一种类型的索引，其底层的实现也可能不同 ","date":"2021-12-01 21:31:10","objectID":"/mysql_advanced_01/:4:0","tags":["mysql"],"title":"Mysql_advanced_01","uri":"/mysql_advanced_01/"},{"categories":["Advanced learning"],"content":"InnoDB的索引模型 在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。 InnoDB 使用了 B+ 树索引模型，所以数据都是存储在 B+ 树中的。 主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引（secondary index）。 mysql\u003e create table T( id int primary key, k int not null, name varchar(16), index (k))engine=InnoDB; 表中 R1~R5 的 (ID,k) 值分别为 (100,1)、(200,2)、(300,3)、(500,5) 和 (600,6)，两棵树的示例示意图如下。 如果语句是 select * from T where ID=500（ID是主键），即主键查询方式，则只需要搜索 ID 这棵 B+ 树；如果语句是 select * from T where k=5，即普通索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为 500，再到 ID 索引树搜索一次。这个过程称为回表。也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。 索引维护 B+ 树为了维护索引有序性，在插入新值的时候需要做必要的维护。否则需要挪动插入索引位置后的数据甚至导致页分裂，性能下降，空间利用率也下降。 哪些场景下应该使用自增主键，而哪些场景下不应该？ 自增主键是指自增列上定义的主键，在建表语句中一般是这么定义的： NOT NULL PRIMARY KEY AUTO_INCREMENT。 有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高 主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小 所以，从性能和存储空间方面考量，自增主键往往是更合理的选择。 用业务字段直接做主键：比如，有些业务的场景需求是这样的：（典型的KV场景） 只有一个索引； 该索引必须是唯一索引。 由于没有其他索引，所以也就不用考虑其他索引的叶子节点大小的问题。这时候我们就要优先考虑上一段提到的“尽量使用主键查询”原则，直接将这个索引设置为主键，可以避免每次查询需要搜索两棵树。 重建索引：索引可能因为删除，或者页分裂等原因，导致数据页有空洞，重建索引的过程会创建一个新的索引，把数据按顺序插入，这样页面的利用率最高，也就是索引更紧凑、更省空间。 ","date":"2021-12-01 21:31:10","objectID":"/mysql_advanced_01/:4:1","tags":["mysql"],"title":"Mysql_advanced_01","uri":"/mysql_advanced_01/"},{"categories":["Advanced learning"],"content":"索引2 在下面这个表 T 中，如果我执行 select * from T where k between 3 and 5，需要执行几次树的搜索操作，会扫描多少行？下面是这个表的初始化语句。 mysql\u003e create table T ( ID int primary key, k int NOT NULL DEFAULT 0, s varchar(16) NOT NULL DEFAULT '', index k(k)) engine=InnoDB; insert into T values(100,1, 'aa'),(200,2,'bb'),(300,3,'cc'),(500,5,'ee'),(600,6,'ff'),(700,7,'gg'); 在 k 索引树上找到 k=3 的记录，取得 ID = 300；再到 ID 索引树查到 ID=300 对应的 R3；在 k 索引树取下一个值 k=5，取得 ID=500；再回到 ID 索引树查到 ID=500 对应的 R4；在 k 索引树取下一个值 k=6，不满足条件，循环结束。 回到主键索引树搜索的过程，我们称为回表。有没有可能经过索引优化，避免回表过程呢？ ","date":"2021-12-01 21:31:10","objectID":"/mysql_advanced_01/:5:0","tags":["mysql"],"title":"Mysql_advanced_01","uri":"/mysql_advanced_01/"},{"categories":["Advanced learning"],"content":"覆盖索引 如果执行的语句是 select ID from T where k between 3 and 5，这时只需要查 ID 的值，而 ID 的值已经在 k 索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引 k 已经“覆盖了”我们的查询需求，我们称为覆盖索引。 需要注意的是，在引擎内部使用覆盖索引在索引 k 上其实读了三个记录，R3~R5（对应的索引 k 上的记录项），但是对于 MySQL 的 Server 层来说，它就是找引擎拿到了两条记录，因此 MySQL 认为扫描行数是 2。 在一个市民信息表上，是否有必要将身份证号和名字建立联合索引？假设这个市民表的定义是这样的： CREATE TABLE `tuser` ( `id` int(11) NOT NULL, `id_card` varchar(32) DEFAULT NULL, `name` varchar(32) DEFAULT NULL, `age` int(11) DEFAULT NULL, `ismale` tinyint(1) DEFAULT NULL, PRIMARY KEY (`id`), KEY `id_card` (`id_card`), KEY `name_age` (`name`,`age`) ) ENGINE=InnoDB 如果现在有一个高频请求，要根据市民的身份证号查询他的姓名，这个联合索引就有意义了。它可以在这个高频请求上用到覆盖索引，不再需要回表查整行记录，减少语句的执行时间。当然，索引字段的维护总是有代价的。因此，在建立冗余索引来支持覆盖索引时就需要权衡考虑了。这正是业务 DBA，或者称为业务数据架构师的工作。 ","date":"2021-12-01 21:31:10","objectID":"/mysql_advanced_01/:5:1","tags":["mysql"],"title":"Mysql_advanced_01","uri":"/mysql_advanced_01/"},{"categories":["Advanced learning"],"content":"最左前缀原则 B+ 树这种索引结构，可以利用索引的“最左前缀”，来定位记录，加速检索。这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符。 在建立联合索引的时候，如何安排索引内的字段顺序。这里我们的评估标准是，索引的复用能力。因为可以支持最左前缀，所以当已经有了 (a,b) 这个联合索引后，一般就不需要单独在 a 上建立索引了。因此，第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。 如果既有联合查询，又有基于 a、b 各自的查询呢？查询条件里面只有 b 的语句，是无法使用 (a,b) 这个联合索引的，这时候你不得不维护另外一个索引，也就是说你需要同时维护 (a,b)、(b) 这两个索引。这时候，我们要考虑的原则就是空间了。比如上面这个市民表的情况，name 字段是比 age 字段大的 ，那我就建议你创建一个（name,age) 的联合索引和一个 (age) 的单字段索引。 ","date":"2021-12-01 21:31:10","objectID":"/mysql_advanced_01/:5:2","tags":["mysql"],"title":"Mysql_advanced_01","uri":"/mysql_advanced_01/"},{"categories":["Advanced learning"],"content":"索引下推 如果现在有一个需求：检索出表中“名字第一个字是张，而且年龄是 10 岁的所有男孩”。那么，SQL 语句是这么写的： mysql\u003e select * from tuser where name like '张%' and age=10 and ismale=1; 这个语句在搜索索引树的时候，只能用 “张”，找到第一个满足条件的记录 ID3 判断其他条件是否满足: 在 MySQL 5.6 之前，只能从 ID3 开始一个个回表。到主键索引上找出数据行，再对比字段值。而 MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。 图三： 图四：索引下推 图 4 跟图 3 的区别是，InnoDB 在 (name,age) 索引内部就判断了 age 是否等于 10，对于不等于 10 的记录，直接判断并跳过。 ","date":"2021-12-01 21:31:10","objectID":"/mysql_advanced_01/:5:3","tags":["mysql"],"title":"Mysql_advanced_01","uri":"/mysql_advanced_01/"},{"categories":["Advanced learning"],"content":"全局锁和表锁 数据库资源需要被并发访问，锁是为了合理地控制资源的访问规则。 根据加锁的范围，MySQL 里面的锁大致可以分成全局锁、表级锁和行锁三类。 ","date":"2021-12-01 21:31:10","objectID":"/mysql_advanced_01/:6:0","tags":["mysql"],"title":"Mysql_advanced_01","uri":"/mysql_advanced_01/"},{"categories":["Advanced learning"],"content":"全局锁 顾名思义，全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。 全局锁的典型使用场景是，做全库逻辑备份。也就是把整库每个表都 select 出来存成文本。 如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆；如果你在从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致主从延迟。 在前面讲事务隔离的时候，其实是有一个方法能够拿到一致性视图的，就是在可重复读隔离级别下开启一个事务。 官方自带的逻辑备份工具是 mysqldump。当 mysqldump 使用参数–single-transaction 的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的。 有了这个功能，为什么还需要 FTWRL 呢？一致性读是好，但前提是引擎要支持这个隔离级别。比如，对于 MyISAM 这种不支持事务的引擎，如果备份过程中有更新，总是只能取到最新的数据，那么就破坏了备份的一致性。这时，我们就需要使用 FTWRL 命令了。 所以，single-transaction 方法只适用于所有的表使用事务引擎的库。如果有的表使用了不支持事务的引擎，那么备份就只能通过 FTWRL 方法。这往往是 DBA 要求业务开发人员使用 InnoDB 替代 MyISAM 的原因之一。 不用set global readonly=true而用 FTWRL 方式设置全库只读的原因： 一是，在有些系统中，readonly 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改 global 变量的方式影响面更大，我不建议你使用。 二是，在异常处理机制上有差异。如果执行 FTWRL 命令之后由于客户端发生异常断开，那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高。 ","date":"2021-12-01 21:31:10","objectID":"/mysql_advanced_01/:6:1","tags":["mysql"],"title":"Mysql_advanced_01","uri":"/mysql_advanced_01/"},{"categories":["Advanced learning"],"content":"表级锁 MySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。表锁的语法是 lock tables … read/write。与 FTWRL 类似，可以用 unlock tables 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。 举个例子, 如果在某个线程 A 中执行 lock tables t1 read, t2 write; 这个语句，则其他线程写 t1、读写 t2 的语句都会被阻塞。同时，线程 A 在执行 unlock tables 之前，也只能执行读 t1、读写 t2 的操作。连写 t1 都不允许，自然也不能访问其他表。 在还没有出现更细粒度的锁的时候，表锁是最常用的处理并发的方式。而对于 InnoDB 这种支持行锁的引擎，一般不使用 lock tables 命令来控制并发，毕竟锁住整个表的影响面还是太大。 另一类表级的锁是 MDL（metadata lock)。MDL 不需要显式使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性。你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。 因此，在 MySQL 5.5 版本中引入了 MDL，当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。 读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。 虽然 MDL 锁是系统默认会加的，但却是你不能忽略的一个机制。比如下面这个例子，我经常看到有人掉到这个坑里：给一个小表加个字段，导致整个库挂了。 你肯定知道，给一个表加字段，或者修改字段，或者加索引，需要扫描全表的数据。在对大表操作的时候，你肯定会特别小心，以免对线上服务造成影响。而实际上，即使是小表，操作不慎也会出问题。我们来看一下下面的操作序列，假设表 t 是一个小表。 我们可以看到 session A 先启动，这时候会对表 t 加一个 MDL 读锁。由于 session B 需要的也是 MDL 读锁，因此可以正常执行。之后 session C 会被 blocked，是因为 session A 的 MDL 读锁还没有释放，而 session C 需要 MDL 写锁，因此只能被阻塞。 如果只有 session C 自己被阻塞还没什么关系，但是之后所有要在表 t 上新申请 MDL 读锁的请求也会被 session C 阻塞。前面我们说了，所有对表的增删改查操作都需要先申请 MDL 读锁，就都被锁住，等于这个表现在完全不可读写了。 如果某个表上的查询语句频繁，而且客户端有重试机制，也就是说超时后会再起一个新 session 再请求的话，这个库的线程很快就会爆满。 你现在应该知道了，事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放。 基于上面的分析，我们来讨论一个问题，如何安全地给小表加字段？ 首先我们要解决长事务，事务不提交，就会一直占着 MDL 锁。在 MySQL 的 information_schema 库的 innodb_trx 表中，你可以查到当前执行中的事务。如果你要做 DDL 变更的表刚好有长事务在执行，要考虑先暂停 DDL，或者 kill 掉这个长事务。 但考虑一下这个场景。如果你要变更的表是一个热点表，虽然数据量不大，但是上面的请求很频繁，而你不得不加个字段，你该怎么做呢？ 这时候 kill 可能未必管用，因为新的请求马上就来了。比较理想的机制是，在 alter table 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者 DBA 再通过重试命令重复这个过程。 MariaDB 已经合并了 AliSQL 的这个功能，所以这两个开源分支目前都支持 DDL NOWAIT/WAIT n 这个语法。 ALTER TABLE tbl_name NOWAIT add column ... ALTER TABLE tbl_name WAIT N add column ... ","date":"2021-12-01 21:31:10","objectID":"/mysql_advanced_01/:6:2","tags":["mysql"],"title":"Mysql_advanced_01","uri":"/mysql_advanced_01/"},{"categories":["Advanced learning"],"content":"小结 全局锁主要用在逻辑备份过程中。对于全部是 InnoDB 引擎的库，我建议你选择使用–single-transaction 参数，对应用会更友好。表锁一般是在数据库引擎不支持行锁的时候才会被用到的。如果你发现你的应用程序里有 lock tables 这样的语句，你需要追查一下，比较可能的情况是：要么是你的系统现在还在用 MyISAM 这类不支持事务的引擎，那要安排升级换引擎；要么是你的引擎升级了，但是代码还没升级。我见过这样的情况，最后业务开发就是把 lock tables 和 unlock tables 改成 begin 和 commit，问题就解决了。MDL 会直到事务提交才释放，在做表结构变更的时候，你一定要小心不要导致锁住线上查询和更新。 ","date":"2021-12-01 21:31:10","objectID":"/mysql_advanced_01/:6:3","tags":["mysql"],"title":"Mysql_advanced_01","uri":"/mysql_advanced_01/"},{"categories":["Advanced learning"],"content":"行锁 MySQL 的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如 MyISAM 引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。InnoDB 是支持行锁的，这也是 MyISAM 被 InnoDB 替代的重要原因之一。 了解行锁，以及如何通过减少锁冲突来提升业务并发度。 ","date":"2021-12-01 21:31:10","objectID":"/mysql_advanced_01/:7:0","tags":["mysql"],"title":"Mysql_advanced_01","uri":"/mysql_advanced_01/"},{"categories":["Advanced learning"],"content":"从两阶段说起 ","date":"2021-12-01 21:31:10","objectID":"/mysql_advanced_01/:7:1","tags":["mysql"],"title":"Mysql_advanced_01","uri":"/mysql_advanced_01/"},{"categories":["Advanced learning"],"content":"事务要不要隔离？ ","date":"2021-12-01 21:31:10","objectID":"/mysql_advanced_01/:8:0","tags":["mysql"],"title":"Mysql_advanced_01","uri":"/mysql_advanced_01/"},{"categories":["School courses"],"content":" 2022春JOANNA老师的软件体系结构 topics 1.Introduction to Software Architecture Why is Software Architecture Important? The Many Contexts of Software Architecture 2.Architecture modelling and representation: Architectural structures and views 3.Quality attributes :Understanding quality attributes and availability Availability Quality attributes: interoperability and modifiability Interoperability Quality attributes: Modifiability Quality attributes: Performance, Security Quality attributes: Security Patterns and Tactics Quality Attribute Modelling and Analysis Designing for architecturally significant requirements Designing and evaluating an architecture Exercise 1 Capturing ASR in practice . exercise2 exercise3 10%+30%+60% ","date":"2021-11-25 08:44:33","objectID":"/sek_base_07/:0:0","tags":["software engineering knowledge"],"title":"SEK_base_07","uri":"/sek_base_07/"},{"categories":["School courses"],"content":"topics Introduction to the subject: objectives, plan, assessment.Introduction to software architecture: concept and importance of software architecture Architecture modelling and representation: architectural structures and views, UML Quality attributes: Understanding quality attributes and availability Quality attributes: interoperability and modifiability Quality attributes: performance and security Quality attributes: testability, usability and other quality attributes Achieving quality attribute through tactics and patterns: architectural tactics and patterns Achieving quality attribute through tactics and patterns: architectural tactics and patterns Achieving quality attribute through tactics and patterns: quality attribute modelling and analysis Achieving quality attribute through tactics and patterns: designing for architecturally significant requirements Designing and evaluating an architecture: TOGAF, ADD and ATAM Architecture reuse: software product lines, frameworks and middleware Capturing ASR in practice (practical exercises) Designing an architecture in practice (practical exercises) Documenting software architecture in practice (practical exercises) Architecture evaluation in practice (practical exercises) ","date":"2021-11-25 08:44:33","objectID":"/sek_base_07/:1:0","tags":["software engineering knowledge"],"title":"SEK_base_07","uri":"/sek_base_07/"},{"categories":["School courses"],"content":"1.Introduction to Software Architecture The software architecture of a system is the set of structures needed to reason about the system, which comprise software elements, relations among them, and properties of both. We can say that architecture is an abstraction. What does it mean that architecture is an abstraction? If the information about element is no useful for reasoning about the system, architecture will omit it. Architecture shows the system in an abstract way - in terms of its elements and their relationships. The architects design structures – make decisions on what architectural elements should be used in a system to solve the problems that the system will face. Some compositions of architectural elements that solve particular problems may be used again in different systems facing similar problems. If a certain composition of architectural elements that solves a particular problem was found useful over time and over many domains, has been documented and disseminated, it may become a/an…. Architectural pattern Architecture Is a Set of Software Structures : A structure is a set of elements held together by a relation. Software systems are composed of many structures, and no single structure holds claim to being the architecture. There are three important categories of architectural structures. Module Component and Connector Allocation Architecture vs Design The architecture - the selection of architectural elements, their interaction and the restrictions on those elements and their interactions. The design - modularization and the detailed interfaces of the elements of the system, their algorithms and procedures, and the kinds of data needed to support the architecture and satisfy the requirements. Architecture is an Abstraction An architecture specifically omits certain information about elements that is not useful for reasoning about the system. The architectural abstraction lets us look at the system in terms of its elements, how they are arranged, how they interact, how they are composed, and so forth. This abstraction is essential to taming the complexity of an architecture. Every System has a Software Architecture But the architecture may not be known to anyone. Perhaps all of the people who designed the system are long gone Perhaps the documentation has vanished (or was never produced) Perhaps the source code has been lost (or was never delivered) An architecture can exist independently of its description or specification Structures and Views A view is a representation of a coherent set of architectural elements, as written by and read by system stakeholders. A structure is the set of elements itself, as they exist in software or hardware. In short, a view is a representation of a structure. For example, a module structure is the set of the system’s modules and their organization. A module view is the representation of that structure, documented according to a template in a chosen notation, and used by some system stakeholders. Architects design structures. They document views of those structures. Architects design structures. Architects document views of those structures. What is a view? a representation of a coherent set of architectural elements is written by the architects may be read by the testers or the project clients Architectural Patterns Architectural elements can be composed in ways that solve particular problems. The compositions have been found useful over time, and over many different domains They have been documented and disseminated. These compositions of architectural elements, called architectural patterns. Patterns provide packaged strategies for solving some of the problems facing a system. An architectural pattern delineates the element types and their forms of interaction used in solving the problem. What Makes a “Good” Architecture? There is no such thing as an inherently good or bad architecture. Architectures can be evaluated but only in the context of specific stated goals. Architec","date":"2021-11-25 08:44:33","objectID":"/sek_base_07/:2:0","tags":["software engineering knowledge"],"title":"SEK_base_07","uri":"/sek_base_07/"},{"categories":["School courses"],"content":"Why is Software Architecture Important? Inhibiting or Enabling System’s Quality Attributes Whether a system will be able to exhibit its desired (or required) quality attributes is substantially determined by its architecture. Performance Modifiability Security Scalability Reusability Reasoning About and Managing Change About 80 percent of a typical software system’s total cost occurs after initial deployment accommodate new features adapt to new environments, fix bugs, and so forth. Every architecture partitions possible changes into three categories A local change can be accomplished by modifying a single element. A nonlocal change requires multiple element modifications but leaves the underlying architectural approach intact. An architectural change affects the fundamental ways in which the elements interact with each other and will require changes all over the system. Obviously, local changes are the most desirable A good architecture is one in which the most common changes are local, and hence easy to make. Which kind of a change in the system is most desirable?(1 answer) A local change that can be accomplished by modifying a single element. A nonlocal change that requires multiple element modifications but leaves the underlying architectural approach intact. An architectural change that affects the fundamental ways in which the elements interact with each other and will require changes all over the system. Predicting System Qualities When we examine an architecture we can confidently predict that the architecture will exhibit the associated qualities. The earlier you can find a problem in your design, the cheaper, easier, and less disruptive it will be to fix. Enhancing Communication Among Stakeholders The architecture—or at least parts of it—is sufficiently abstract that most nontechnical people can understand it. Most of the system’s stakeholders can use as a basis for creating mutual understanding, negotiating, forming consensus, and communicating with each other. Each stakeholder of a software system is concerned with different characteristics of the system Users, client, manager, architect Earliest Design Decisions Software architecture is a manifestation of the earliest design decisions about a system. These early decisions affect the system’s remaining development, its deployment, and its maintenance life. Earliest Design Decisions What are these early design decisions? Will the system run on one processor or be distributed across multiple processors? Will the software be layered? If so, how many layers will there be? What will each one do? Will components communicate synchronously or asynchronously? What communication protocol will we choose? Will the system depend on specific features of the operating system or hardware? Will the information that flows through the system be encrypted or not? Defining Constraints on an Implementation An implementation exhibits an architecture if it conforms to the design decisions prescribed by the architecture. The implementation must be implemented as the set of prescribed elements These elements must interact with each other in the prescribed fashion Each of these prescriptions is a constraint on the implementer. Influencing the Organizational Structure Architecture prescribes the structure of the system being developed. The architecture is typically used as the basis for the work-breakdown structure. The work-breakdown structure in turn dictates units of planning, scheduling, and budget interteam communication channels configuration and file-system organization integration and test plans and procedures; the maintenance activity Enabling Evolutionary Prototyping Once an architecture has been defined, it can be prototyped as a skeletal system. A skeletal system is one in which at least some of the infrastructure is built before much of the system’s functionality has been created. The fidelity of the system increases as prototype parts are replaced with complete versions of these","date":"2021-11-25 08:44:33","objectID":"/sek_base_07/:2:1","tags":["software engineering knowledge"],"title":"SEK_base_07","uri":"/sek_base_07/"},{"categories":["School courses"],"content":"The Many Contexts of Software Architecture Contexts of Software Architecture We put software architecture in its place relative to four contexts: Technical. What technical role does the software architecture play in the system? Project life cycle. How does a software architecture relate to the other phases of a software development life cycle? Business. How does the presence of a software architecture affect an organization’s business environment? Professional. What is the role of a software architect in an organization or a development project? Technical Context The most important technical context factor is the set of quality attributes that the architecture can help to achieve. The architecture’s current technical environment is also an important factor. Standard industry practices Software engineering techniques prevalent in the architect’s professional community. Project Life-cycle Context Software development processes are standard approaches for developing software systems. They tell the members of the team what to do next. There are four dominant software development processes: Waterfall Iterative Agile Model-driven development Architecture Activities Architecture is a special kind of design, so architecture finds a home in each process of software development. There are activities involved in creating a software architecture, using it to realize a complete design, and then implementing Understanding the architecturally significant requirements Creating or selecting the architecture Documenting and communicating the architecture Analyzing or evaluating the architecture Implementing and testing the system based on the architecture Ensuring that the implementation conforms to the architecture Business Context Systems are created to satisfy the business goals of one or more organizations. Development organizations: e.g., make a profit, or capture market, or help their customers do their jobs better, or keep their staff employed, or make their stockholders happy Customers have their own goals: e.g. ,make their lives easier or more productive. Other organizations, such as subcontractors or government regulatory agencies, have their own goals Architects need to understand the goals. Many of these goals will influence the architecture. Architecture and business goals: Professional Context Architects need more than just technical skills. Architects need diplomatic, negotiation, and communication skills. Architects need the ability to communicate ideas clearly Architects need up-to-date knowledge. Know about (for example) patterns, or database platforms, or web services standards. Know about business considerations. Stakeholders A stakeholder is anyone who has a stake in the success of the system Stakeholders typically have different specific concerns on the system Early engagement of stakeholders to understand the constraints of the task, manage expectations, negotiate priorities, and make tradeoffs. How is Architecture Influenced? Technical requirements Architects Business, social, and technical environment What Do Architectures Influence? Technical context The architecture can affect stakeholder’s requirements for the next system A customer may relax some of their requirements to gain these economies. Shrinkwrapped software has affected people’s requirements, as it is inexpensive and of high quality. Project context The architecture affects the structure of the developing organization. An architecture prescribes the units of software to be implemented and integrated to the system. These units are the basis for the development project’s structure. the development, test, and integration activities all revolve around the units. Business context The architecture can affect the business goals of the developing organization. The architecture can provide opportunities for the efficient production and deployment of similar systems, and the organization may adjust its goals to take advantage of its newfound expertise. Professional co","date":"2021-11-25 08:44:33","objectID":"/sek_base_07/:2:2","tags":["software engineering knowledge"],"title":"SEK_base_07","uri":"/sek_base_07/"},{"categories":["School courses"],"content":"2.Architecture modelling and representation: Architectural structures and views Intended Learning Outcomes By the end of this lesson you will be able to: differentiate between structures and views list useful structures and views and understand how they relate to each other choose the relevant structure and views combine views use UML to express the views Architecture Is a Set of Software Structures A structure is a set of elements held together by a relation. Software systems are composed of many structures, and no single structure holds claim to being the architecture. There are three important categories of architectural structures. Module Component and Connector Allocation Module Structures Some structures partition systems into implementation units, which we call modules. Modules are assigned specific computational responsibilities, and are the basis of work assignments for programming teams. In large projects, these elements (modules) are subdivided for assignment to sub-teams. Component-and-connector Structures Other structures focus on the way the elements interact with each other at runtime to carry out the system’s functions. We call runtime structures component-and-connector (C\u0026C) structures. In our use, a component is always a runtime entity. In SOA, the system is to be built as a set of services. These services are made up of (compiled from) the programs in the various implementation units – modules. Allocation Structures Allocation structures describe the mapping from software structures to the system’s environments For example Modules are assigned to teams to develop, and assigned to places in a file structure for implementation, integration, and testing. Components are deployed onto hardware in order to execute. Which Structures are Architectural? A structure is architectural if it supports reasoning about the system and the system’s properties. The reasoning should be about an attribute of the system that is important to some stakeholder. These include functionality achieved by the system the availability of the system in the face of faults the difficulty of making specific changes to the system the responsiveness of the system to user requests, many others. Programming team developing our cafeteria system wants to know what units of implementation will be assigned with functional responsibilities. Which structures can help reason about that? Module structures Structures and Views A structure is the set of elements itself, as they exist in software or hardware. In short, a view is a representation of a structure. Architects design structures. They document views of those structures. Physiological Structures The neurologist, the orthopedist, the hematologist, and the dermatologist all have different views of the structure of a human body. Ophthalmologists, cardiologists, and podiatrists concentrate on specific subsystems. The kinesiologist and psychiatrist are concerned with different aspects of the entire arrangement’s behavior. Although these views are pictured differently and have different properties, all are inherently related, interconnected. Together they describe the architecture of the human body. So it is with software! Module Structures Module structures embody decisions as to how the system is to be structured as a set of code or data units In any module structure, the elements are modules of some kind (perhaps classes, or layers, or merely divisions of functionality, all of which are units of implementation). Modules are assigned areas of functional responsibility. Component-and-connector Structures Component-and-connector structures embody decisions as to how the system is to be structured as a set of elements that have runtime behavior (components) and interactions (connectors). Elements are runtime components such as services, peers, clients, servers, or many other types of runtime element) Connectors are the communication vehicles among components, such as call-return, process synchronization o","date":"2021-11-25 08:44:33","objectID":"/sek_base_07/:3:0","tags":["software engineering knowledge"],"title":"SEK_base_07","uri":"/sek_base_07/"},{"categories":["School courses"],"content":"3.Quality attributes :Understanding quality attributes and availability Intended Learning Outcomes By the end of this lesson you will be able to: specify a quality attribute requirement understand quality design decisions apply the design decision categories to different quality attributes Architecture and Requirements System requirements can be categorized as: Functional requirements state what the system must do, how it must behave or react to run-time stimuli. Quality attribute requirements qualify functional requirements, e.g., how fast the function must be performed, how resilient it must be to erroneous input, etc. Constraints. A constraint is a design decision with zero degrees of freedom. Which of the above system requirements will have an impact on the architecture of the system?（1 answer） Functional requirements Quality attributes requirements Constraints Functionality Functionality is the ability of the system to do the work for which it was intended. Functionality has a strange relationship to architecture: functionality does not determine architecture; Quality Attribute Considerations If a functional requirement is “when the user presses the green button the Options dialog appears”: a performance qualification might describe how quickly the dialog will appear; an availability qualification might describe how often this function will fail, and how quickly it will be repaired; a usability qualification might describe how easy it is to learn this function. Two Categories of Quality Attributes The ones that describe some properties of the system at runtime Availability, performance, usability, security The ones that describe some properties of the development of system Modifiability Testability Quality Attribute Considerations There are problems with previous discussions of quality attributes: Untestable definitions. The definitions provided for an attribute are not testable. It is meaningless to say that a system will be “modifiable” Overlapping concerns. Is a system failure due to a denial of service attack an aspect of availability, performance, security, or usability? A solution to the problems (untestable definitions and overlapping concerns) is to use quality attribute scenarios as a means of characterizing quality attributes. Specifying Quality Attribute Requirements We use a common form to specify all quality attribute requirements as scenarios. Our representation of quality attribute scenarios has these parts: Stimulus Stimulus source Response Response measure Environment Artifact Specifying Quality Attribute Requirements Stimulus. he stimulus is a condition that requires a response when it arrives at a system. Source of stimulus. his is some entity (a human, a computer system, or any other actuator) that generated the stimulus. Response. he response is the activity undertaken as the result of the arrival of the stimulus. Response measure. hen the response occurs, it should be measurable in some fashion so that the requirement can be tested. Environment. he stimulus occurs under certain conditions. The system may be in an overload condition or in normal operation, or some other relevant state. Artifact. his may be a collection of systems, the whole system, or some piece or pieces of it. Some artifact is stimulated. Specifying Quality Attribute Requirements General quality attribute scenarios are system independent and can, potentially, pertain to any system Concrete quality attribute scenarios are specific to the particular system under consideration. Specifying Quality Attribute Requirements Example general scenario for availability: Achieving Quality Attributes Through Tactics There are a collection of primitive design techniques that an architect can use to achieve a quality attribute response. We call these architectural design primitives tactics. Tactics, like design patterns, are techniques that architects have been using for years. We do not invent tactics, we simply capture what architects do in pract","date":"2021-11-25 08:44:33","objectID":"/sek_base_07/:4:0","tags":["software engineering knowledge"],"title":"SEK_base_07","uri":"/sek_base_07/"},{"categories":["School courses"],"content":"Availability What is Availability? Availability refers to a property of software that it is there and ready to carry out its task when you need it to be. Availability refers to the ability of a system to mask or repair faults such that the cumulative service outage period does not exceed a required value over a specified time interval. Availability is about minimizing service outage time by mitigating faults Availability Availability v.s. reliability or dependability Availability encompasses what is normally called reliability. Availability encompasses other consideration such as service outage due to period maintenance Availability is closely related to security, e..g, denial-of-service performance … Availability General Scenario Stimulus … … … … … … ? Stimulus source … … … ? Response … … … … … …? Response measure … …? Environment … … … … .? Artifact … … … … … … ..? Specifying Quality Attribute Requirements Stimulus. he stimulus is a condition that requires a response when it arrives at a system. Source of stimulus. his is some entity (a human, a computer system, or any other actuator) that generated the stimulus. Response. he response is the activity undertaken as the result of the arrival of the stimulus. Response measure. hen the response occurs, it should be measurable in some fashion so that the requirement can be tested. Environment. he stimulus occurs under certain conditions. The system may be in an overload condition or in normal operation, or some other relevant state. Artifact. his may be a collection of systems, the whole system, or some piece or pieces of it. Some artifact is stimulated. Availability General Scenario: Sample Concrete Availability Scenario The heartbeat monitor determines that the server is nonresponsive during normal operations. The system informs the operator and continues to operate with no downtime. The heartbeat monitor determines that the server is nonresponsive during normal operations. The system informs the operator and continues to operate with no downtime. Let us analyze if this scenario is complete Specifying Quality Attribute Requirements Stimulus. he stimulus is a condition that requires a response when it arrives at a system. Source of stimulus. his is some entity (a human, a computer system, or any other actuator) that generated the stimulus. Response. he response is the activity undertaken as the result of the arrival of the stimulus. Response measure. hen the response occurs, it should be measurable in some fashion so that the requirement can be tested. Environment. he stimulus occurs under certain conditions. The system may be in an overload condition or in normal operation, or some other relevant state. Artifact. his may be a collection of systems, the whole system, or some piece or pieces of it. Some artifact is stimulated. Sample Concrete Availability Scenario The heartbeat monitor determines that the server is nonresponsive during normal operations. The system informs the operator and continues to operate with no downtime. Stimulus: ??? The stimulus is a condition that requires a response when it arrives at a system. Sample Concrete Availability Scenario The heartbeat monitor determines that the server is nonresponsive during normal operations. The system informs the operator and continues to operate with no downtime. Stimulus: non-responsiveness Response: inform the operator Response measure: no downtime, or 100 availability percentages Environment: normal operation Artifact: heartbeat monitor Stimulus source: server We will continue this topic on Monday Which statement is NOT true?（The last one） A stakeholder is anyone who has a stake in the success of the system Stakeholders typically have different specific concerns on the system Stakeholders participate in some parts of the design process. Architect is the only stakeholder of the system Recall our earlier example University Town, has directed its software development subsidiary, Campus Software, to develop a cafeteria s","date":"2021-11-25 08:44:33","objectID":"/sek_base_07/:4:1","tags":["software engineering knowledge"],"title":"SEK_base_07","uri":"/sek_base_07/"},{"categories":["School courses"],"content":"Quality attributes: interoperability and modifiability ","date":"2021-11-25 08:44:33","objectID":"/sek_base_07/:5:0","tags":["software engineering knowledge"],"title":"SEK_base_07","uri":"/sek_base_07/"},{"categories":["School courses"],"content":"Interoperability Intended Learning Outcomes By the end of this lesson you will be able to: apply the design decision categories to interoperability What is Interoperability? Interoperability is about the degree to which two or more systems can usefully exchange meaningful information via interfaces in a particular context. Any discussion of a system’s interoperability needs to identify with whom, and under what circumstance. Syntactic interoperability is the ability to exchange data. Semantic interoperability is the ability to interpret the data being exchanged. Two perspectives for achieving interoperability With the knowledge about the interfaces of external systems, design that knowledge into the system Without the knowledge about other systems, design the system to interoperate in a more general fashion Motivation The system provides a service to be used by a collection of unknown systems, eg., GoogleMaps The system is constructed from existing systems, for example Producing a representation of what was sensed Interpreting the data Processing the raw data Sensing the environment Two Important Aspects of Interoperability Discovery. The consumer of a service must discover the location, identity, and interface of service Handling the response. Three possibilities: The service reports back to the requester The service sends its response on to another system The service broadcasts its response to any interested parties Example Will this system need to provide services to other system(s)? What do we know about these systems? Will this system be constructed by combining capabilities from other systems? Example - a traffic sensing system where the input comes from individual vehicles, the raw data is processed into common units of measurement, is interpreted and fused, and traffic congestion information is broadcast one of the existing systems is responsible for sensing its environment another one is responsible for processing the raw data a third is responsible for interpreting the data a final one is responsible for producing and distributing a representation of what was sensed Intelligent transportation system Interoperability General Scenario Sample Concrete Interoperability Scenario Our vehicle information system sends our current location to the traffic monitoring system. The traffic monitoring system combines our location with other information, overlays this information on a Google Map, and broadcasts it. Our location information is correctly included with a probability of 99.9%. Sample Concrete Interoperability Scenario Goal of Interoperability Tactics For two or more systems to usefully exchange information they must Know about each other. That is the purpose behind the locate tactics. Exchange information in a semantically meaningful fashion. That is the purpose behind the manage interfaces tactics. Two aspects of the exchange are Provide services in the correct sequence Modify information produced by one actor to a form acceptable to the second actor. Goal of Interoperability Tactics Interoperability Tactics Locate Service Discovery : Locate a service through searching There are many service discovery mechanisms: UDDI for Webservices Jini for Jave objects Simple Service Discovery Protocol (SSDP) as used in Universal plug-and-play (UPnP) DNS Service Discovery (DNS-SD) Bluetooth Service Discovery Protocol (SDP) Service Discovery – Necessary conditions The searcher wants to find the searched entity and the searched entity wants to be found The searched entity must have identifiers The searcher must acquire sufficient identifiers to identify the searched entity Searching Method – Searcher’s initiative Flood/Broadcast request Ask every entity and wait for answer Examples Paging in the location area to find the mobile terminal DHCP discover: the client broadcasts on the local subnet to find available servers to ask for IP address Efficient and less resource consuming for the searcher Low resource consuming for the searched B","date":"2021-11-25 08:44:33","objectID":"/sek_base_07/:5:1","tags":["software engineering knowledge"],"title":"SEK_base_07","uri":"/sek_base_07/"},{"categories":["School courses"],"content":"Quality attributes: Modifiability Intended Learning Outcomes By the end of this lesson you will be able to: apply the design decision categories to modifiability What is Modifiability? Modifiability is about change and our interest in it is in the cost and risk of making changes. To plan for modifiability, an architect has to consider four questions: What can change? What is the likelihood of the change? When is the change made and who makes it? What is the cost of the change? Recall our earlier example University Town, has directed its software development subsidiary, Campus Software, to develop a cafeteria system that supports a network of cafeteria Kiosks and POSs (points of sale). Kiosks are distributed in diverse locations of University Town near cafeterias and POSs are located near meal serving stations inside of cafeterias. The users are students, faculty and other employees of University Town. They use Kiosks to make queries, and funds transfers from their bank accounts to their cafeteria accounts. They use POSs to pay for their meals. What can change? The functions of the system computers The platforms, i.e., the hardware, operating system, middleware The environment in which the system operates The systems with which it must interoperate The protocols it uses to communicate The capacity Number of users supported Number of simultaneous operations When is the change made and who makes it? Changes can be made during implementation by modifying the source code build by choice of libraries execution by parameter setting, plugins, etc Changes can also be made by a developer an end user a system administrator What is the cost of the change? Involving two types of cost The cost of introducing the mechanisms to make the system more modifiable The cost of making the modification using the mechanisms Example User interface builder Example You are an architect on the Campus Software team. There is a possibility that in the future, the client will request changes to be made to the user interface. Your team is considering two ways to handle this problem Do nothing for now. Wait for a change request to come in, then change the source code to accommodate request. Add additional component to the system now – user interface builder. When there is a change request, the designer will use a drag-and-drop editor to design a new interface, and the user interface builder will produce the new source code directly Let us consider what is the cost of each option Considering the differences in cost between these options, which one will be a better choice? Which option will be a better choice if the chance of the need to make a change is not high?（1 answer） Do nothing for now. Add user interface builder to the system. Which option will be a better choice if there is a chance that the changes in the interface will be requested many times??(1 answer) Do nothing for now. Add user interface builder to the system. Modifiability General Scenario Sample Concrete Modifiability Scenario The developer wishes to change the user interface by modifying the code at design time. The modifications are made with no side effects within three hours. Stimulus – Wishes to change UI Artifact – Code Environment: Design time Response – Change made Response measure – No side effects in three hours Source - Developer Goal of Modifiability Tactics Goal of modifiability controlling the complexity of making changes, controlling the time and cost to make changes. Modifiability Tactics Design 1 – the module includes a great deal of capability Design B – the module is refined into several smaller modules (each capability is represented in a separate module) If there is a chance needed in this module, which design will have smaller modification cost?(Second one is right) Reduce Size of a Module Split Module: If the module being modified includes a great deal of capability, the modification costs will likely be high. Refining the module into several smaller modules should reduce","date":"2021-11-25 08:44:33","objectID":"/sek_base_07/:5:2","tags":["software engineering knowledge"],"title":"SEK_base_07","uri":"/sek_base_07/"},{"categories":["School courses"],"content":"Quality attributes: Performance, Security Intended Learning Outcomes By the end of this lesson you will be able to: apply the design decision categories to diverse quality attributes What is Performance? It is about time Performance is about time and the software system’s ability to meet timing requirements When events occur, the system must respond to them in time Events include interrupts, messages, requests from users or other systems, or clock events marking the passage of time Performance General Scenario Performance concrete scenario - example You are an architect on the Campus Software team and you are designing the system for performance In the requirements document you have found this requirement: The system should process the transactions with an average latency of two seconds Is this description complete, is it clear enough for the architect to make good design decisions? Which parts are missing? Which parts are missing in the performance concrete scenario example we discussed? Source Stimulus Artifact Environment Response Response measure Sample Concrete Performance Scenario – not complete The system processes the transactions with an average latency of two seconds. Stimulus: transaction arrivals Source: ??? Artifact: the system Response: process the transactions Response measure: average latency of two seconds Environment: ??? This scenario is not complete, source and environment parts are missing How to add the remaining parts? We can use the general scenario to help us look for ideas Then, clarify with the stakeholders about the details of the requirement Performance General Scenario Sample Concrete Performance Scenario - complete Users initiate transactions under normal operations. The system processes the transactions with an average latency of two seconds. Stimulus: transaction arrivals Source: users Artifact: the system Response: process the transactions Response measure: average latency of two seconds Environment: under normal operations Sample Concrete Performance Scenario Users initiate transactions under normal operations. The system processes the transactions with an average latency of two seconds. Stimulus: transaction arrivals Source: users Artifact: the system Response: process the transactions Response measure: average latency of two seconds Environment: under normal operations Performance Modeling Two basic contributors to the response time Processing time is the time that the system is working to respond Blocked time is the time that the system is unable to respond Blocked time is caused by Contention for resources Availability of resources Dependency on other computations Goal of Performance Tactics To generate a response to an event arriving the system within some time-based constraint The event can be single or a stream, and is the trigger to perform computation First, lets consider an example not related to the computing You are an owner of the noodle shop. You hired one cook who is able to cook 100 bowls during lunch time Your restaurant has 20 seats On the first day, there were over 200 people lining up for your noodles You want to improve the performance of your noodle shop to make sure you serve as many customers as possible during the day. Give examples of the tactics that you could use Two Tactic Categories Control resource demand To produce smaller demand on the resources Operate on the demand side Manage resources To make the resources at hand work more effectively in handling the demands Operate on the response side Resources Hardware resources, e.g., CPU, data stores, network bandwidth, and memory Software resources, e.g., buffers, or critical sections Performance Tactics Control Resource Demand Manage Sampling Rate: to reduce the sampling frequency at which a stream of data is captured Prioritize Events: to impose a priority scheme that ranks events according to the importance Ignore low-priority events when resources are not enough Reduce Overhead: The use of intermediaries increas","date":"2021-11-25 08:44:33","objectID":"/sek_base_07/:6:0","tags":["software engineering knowledge"],"title":"SEK_base_07","uri":"/sek_base_07/"},{"categories":["School courses"],"content":"Quality attributes: Security What is Security? Security is a measure of the system’s ability to protect data and information from unauthorized access while still providing access to people and systems that are authorized An action taken against a computer system with the intention of doing harm is called an attack Attack can be in different forms unauthorized attempt to access/modify data or service intended to deny services to legitimate users What is Security? Security has three main characteristics, called CIA: Confidentiality is the property that data or services are protected from unauthorized access. For example, a hacker cannot access your income tax returns on a government computer. Integrity is the property that data or services are not subject to unauthorized manipulation. For example, your grade has not been changed since your instructor assigned it. Availability is the property that the system will be available for legitimate use. For example, a denial-of-service attack prevent you from ordering a book from an online bookstore. What is Security? Other characteristics that support CIA are Authentication verifies the identities of the parties to a transaction and checks if they are truly who they claim to be. Authorization grants a user the privileges to perform a task. Nonrepudiation guarantees that the sender/recipient of a message cannot later deny having sent/received the message Sample Concrete Security Scenario A disgruntled employee from a remote location attempts to modify the pay rate table during normal operations. The system maintains an audit trail and the correct data is restored within a day. Stimulus: unauthorized attempts to modify the pay rate table Stimulus source: a disgruntled employee Artifact: the system with pay rate table Environment: during normal operation Response: maintains an audit trail Response measure: correct data is restored within a day Security Tactics Detect Attacks Detect Intrusion: compare network traffic or service request patterns within a system to a set of signatures or known patterns of malicious behavior stored in a database. Detect Service Denial: comparison of the pattern or signature of network traffic coming into a system to historic profiles of known Denial of Service (DoS) attacks. Denial of Service Attack Ping of Death UDP Flood TCP SYN Detect Attacks Verify Message Integrity: use techniques such as checksums or hash values to verify the integrity of messages, resource files, deployment files, and configuration files. Detect Attacks Detect Message Delay: checking the time that it takes to deliver a message, it is possible to detect suspicious timing behavior, i.e., man-in-the-middle attack Resist Attacks Identify Actors: identify the source of any external input to the system. Authenticate Actors: ensure that a user or remote computer is actually who or what it purports to be. Authorize Actors: ensuring that an authenticated actor has the rights to access and modify either data or services. Limit Access: limiting access to resources such as memory, network connections, or access points. Resist Attacks Limit Exposure: minimize the attack surface of a system by having the fewest possible number of access points. E.g., firewall is a single point of access to the intranet E.g., closing a port Passive defense – no human analysis or interaction - limiting security gaps and exposure to threats through firewalls, antimalware systems, intrusion prevention systems, antivirus protection, intrusion detection systems… Resist Attacks Encrypt Data: apply some form of encryption to data and to communication. Symmetric encryption： asymmetric encryption： Resist Attacks Separate Entities: can be done through physical separation on different servers, the use of virtual machines Change Default Settings: Force the user to change settings assigned by default. React to Attacks Revoke Access: limit access to sensitive resources, even for normally legitimate users and uses, if an attack is s","date":"2021-11-25 08:44:33","objectID":"/sek_base_07/:6:1","tags":["software engineering knowledge"],"title":"SEK_base_07","uri":"/sek_base_07/"},{"categories":["School courses"],"content":"Patterns and Tactics Intended Learning Outcomes By the end of this lesson you will be able to: Understand how patterns achieve quality attributes Understand relation between tactics and patterns Know how to use tactics together What is a Pattern? An architecture pattern is a package of design decisions that is found repeatedly in practice has known properties that permits reuse, and describes a class of architectures Architectural Patterns Module patterns Layered pattern Component-and-Connector patterns Broker pattern Model-View-Controller pattern Pipe-and-Filter pattern Client-Server pattern Peer-to-Peer pattern Service-Oriented Architecture (SOA) pattern Publish-Subscribe pattern Shared-Data pattern Allocation patterns Map-Reduce pattern Multi-tier Pattern Layer Pattern Context: Modules of the system may be independently developed and maintained. Problem: To minimize the interaction among the different development organizations, and support portability, modifiability, and reuse. Layer Pattern Solution: the layered pattern divides the software into units called layers. Each layer is a grouping of modules that offers a cohesive set of services. Each layer is exposed through a public interface. The usage must be unidirectional. Layer Pattern Example Layer Pattern Solution The layered pattern defines layers and a unidirectional allowed-to-use relation among the layers. Elements: Layer, a kind of module. Relations: Allowed to use. Constraints: Every piece of software is allocated to exactly one layer. There are at least two layers The allowed-to-use relations should not be circular Weaknesses: The addition of layers adds up cost and complexity to a system. Layers contribute a performance penalty. Three layered applications Architectural Patterns Module patterns Layered pattern Component-and-Connector patterns Broker pattern Model-View-Controller pattern Pipe-and-Filter pattern Client-Server pattern Peer-to-Peer pattern Service-Oriented Architecture (SOA) pattern Publish-Subscribe pattern Shared-Data pattern Allocation patterns Map-Reduce pattern Multi-tier Pattern Architectural Patterns Component-and-Connector patterns Broker pattern Model-View-Controller pattern Pipe-and-Filter pattern Client-Server pattern Peer-to-Peer pattern Service-Oriented Architecture (SOA) pattern Publish-Subscribe pattern Shared-Data pattern Broker Pattern Context: Many systems are constructed from a collection of services distributed across multiple servers Problem: How do we structure distributed software so that service users do not need to know the nature and location of service providers? Solution: The broker pattern separates clients from providers servers by inserting an intermediary, called a broker. When a client needs a service, it queries a broker via a service interface. The broker then forwards the client’s service request to a server, which processes the request. Broker Solution Overview: The broker pattern defines a runtime component, called a broker, that mediates the communication between a number of clients and servers. Elements: Client, a requester of services Server, a provider of services Broker, an intermediary that locates an appropriate server to fulfill a client’s request, forwards the request to the server, and returns the results to the client Broker Solution Constraints: The client can only attach to a broker. The server can only attach to a broker. Weaknesses: Brokers add latency between clients and servers, and it may be a communication bottleneck. …. Consider there is one broker that mediates the communication between a large number of clients and servers. What happens when the broker fails? Nothing happens, the clients can start communicating directly with the servers All the clients and server are not able to communicate in this situation Broker Solution Constraints: The client can only attach to a broker. The server can only attach to a broker. Weaknesses: Brokers add latency between clients and servers, and it may be a ","date":"2021-11-25 08:44:33","objectID":"/sek_base_07/:7:0","tags":["software engineering knowledge"],"title":"SEK_base_07","uri":"/sek_base_07/"},{"categories":["School courses"],"content":"Quality Attribute Modelling and Analysis Intended Learning Outcomes By the end of this lesson you will be able to: Model architectures to enable quality attribute analysis Use quality attribute checklists Generate and carry out a thought experiment to perform early analysis Analyse architectures using alternative ways: experiments, simulations and prototypes Analyse at different stages of the life cycle How do we know the quality attributes of a software? Analytic model Experiment and measurement Simulations Modeling Architectures to Enable Quality Attribute Analysis Some quality attributes, most notably performance and availability, have well-understood, time-tested analytic models that can be used to assist in an analysis. By analytic model, we mean one that supports quantitative analysis. Let us first consider performance. Performance Models Parameters: arrival rate of events, chosen queuing discipline, chosen scheduling algorithm, service time for events, network topology, network bandwidth, routing algorithm chosen Allocation Model for MVC Queuing Model for MVC Arrivals View sends requests to Controller Actions returned to View Actions returned to model Model sends actions to View Parameters To solve a queuing model for MVC performance, the following parameters must be known or estimated: The frequency of arrivals from outside the system The queuing discipline used at the view queue The time to process a message within the view The number and size of messages that the view sends to the controller The bandwidth of the network that connects the view and the controller The queuing discipline used by the controller The time to process a message within the controller The number and size of messages that the controller sends back to the view The bandwidth of the network from the controller to the view The number and size of messages that the controller sends to the model The queuing discipline used by the model The time to process a message within the model The number and size of messages the model sends to the view The bandwidth of the network connecting the model and the view Parameters To solve a queuing model for MVC performance, the following parameters must be known or estimated: The frequency of arrivals from outside the system The queuing discipline used at the view queue The time to process a message within the view The number and size of messages that the view sends to the controller The bandwidth of the network that connects the view and the controller The queuing discipline used by the controller The time to process a message within the controller The number and size of messages that the controller sends back to the view The bandwidth of the network from the controller to the view The number and size of messages that the controller sends to the model The queuing discipline used by the model The time to process a message within the model The number and size of messages the model sends to the view The bandwidth of the network connecting the model and the view Cost/benefit of Performance Modeling Cost: determining the parameters previously mentioned Benefit: estimate of the latency The more accurately the parameters can be estimated, the better the predication of latency. This is worthwhile when latency is important and questionable. This is not worthwhile when it is obvious there is sufficient capacity to satisfy the demand. Availability Modeling Another quality attribute with a well-understood analytic framework is availability. Modeling an architecture for availability—or to put it more carefully, modeling an architecture to determine the availability of a system based on that architecture—is a matter of determining the failure rates and the recovery times of the components. Example Just as for performance, to model an architecture for availability, we need an architecture to analyze. Suppose we want to increase the availability of a system that uses the Broker pattern, by applying redundancy tactics. Availability M","date":"2021-11-25 08:44:33","objectID":"/sek_base_07/:8:0","tags":["software engineering knowledge"],"title":"SEK_base_07","uri":"/sek_base_07/"},{"categories":["School courses"],"content":"Designing for architecturally significant requirements Intended Learning Outcomes By the end of this lesson you will be able to: understand the concept of ASR identify and capture ASR design for ASR Architecturally Significant Requirement Architectures exist to build systems that satisfy requirements. But, to an architect, not all requirements are created equal. An Architecturally Significant Requirement (ASR) is a requirement that will have a profound effect on the architecture. How do we find those? Approaches to Capture ASRs From Requirements Document By Interviewing Stakeholders By Understanding the Business Goals In Utility Tree ASRs and Requirements Documents An obvious location to look for candidate ASRs is in the requirements documents Requirements should be in requirements documents! Unfortunately, this is not usually the case. Don’t Get Your Hopes Up Many projects don’t create or maintain the detailed, high-quality requirements documents. Standard requirements pay more attention to functionality than quality attributes. The architecture is driven by quality attribute requirements rather than functionalities Most requirements specification does not affect the architecture. Don’t Get Your Hopes Up Quality attributes are often captured poorly, e.g. “The system shall be modular” “The system shall exhibit high usability” “The system shall meet users’ performance expectations” Much of what is useful to an archit ect is not in even the best requirements document ASRs often derive from business goals in the development organization itself Gathering ASRs from Stakeholders Stakeholders often have no idea what QAs they want in a system if you insist on quantitative QA requirements, you’re likely to get numbers that are arbitrary. at least some of those requirements will be very difficult to satisfy. Architects often have very good ideas about what QAs are reasonable to provide. Interviewing the stakeholders is the surest way to learn what they know and need. “The system shall meet users’ performance expectations”- this is an example of a poorly captured quality attribute requirement. Do you know a tool to help us express quality requirements in a better way? No, there is no better way. There should be a better way, but I do not know how Yes – use a quality attribute scenario and make sure all 6 parts are included Gathering ASRs from Stakeholders The results of stakeholder interviews should include a list of architectural drivers a set of QA scenarios that the stakeholders (as a group) prioritized. This information can be used to: refine system and software requirements understand and clarify the system’s architectural drivers provide rationale for why the architect subsequently made certain design decisions guide the development of prototypes and simulations influence the order in which the architecture is developed. Quality Attribute Scenario: Example Our vehicle information system sends our current location to the traffic monitoring system. The traffic monitoring system combines our location with other information, overlays this information on a Google Map, and broadcasts it. Our location information is correctly included with a probability of 99.9%. Quality Attribute Scenario: Example The developer wishes to change the user interface by modifying the code at design time. The modifications are made with no side effects within three hours. Stimulus – Wishes to change UI Artifact – Code Environment: Design time Response – Change made Response measure – No side effects in three hours Source - Developer Quality Attribute Scenario: Example Users initiate transactions under normal operations. The system processes the transactions with an average latency of two seconds. Stimulus: transaction arrivals Source: users Artifact: the system Response: process the transactions Response measure: average latency of two seconds Environment: under normal operation Quality Attribute Scenario: Example A disgruntled employee from a remote location","date":"2021-11-25 08:44:33","objectID":"/sek_base_07/:9:0","tags":["software engineering knowledge"],"title":"SEK_base_07","uri":"/sek_base_07/"},{"categories":["School courses"],"content":"Designing and evaluating an architecture Intended Learning Outcomes By the end of this lesson you will be able to: design a software architecture using ADD approach evaluate an architecture using ATAM method Design Strategy Decomposition Designing to Architecturally Significant Requirements Generate and Test The Attribute-Driven Design Method An iterative method. At each iteration you combine the 3 design strategies we studied earlier Choose a part of the system to design. Marshal all the architecturally significant requirements for that part. Generate and test a design for that part. ADD does not result in a complete design Set of containers with responsibilities Interactions and information flow among containers Does not produce an API for containers. ADD Inputs Requirements Functional, quality, constraints A context description What are the boundary of the system being designed? What are the external systems, devices, users and environment conditions with which the system being designed must interact? ADD Outputs Architectural elements and their relationship Responsibility of elements Interactions Information flow among the elements The Steps of ADD Choose an element of the system to design. Identify the ASRs for the chosen element. Generate a design solution for the chosen element. Inventory remaining requirements and select the input for the next iteration. Repeat steps 1–4 until all the ASRs have been satisfied. Step 1: Choose an Element of the System to Design For green field designs, the element chosen is usually the whole system. For legacy designs, the element is the portion to be added. After the first iteration: Step 1 example We want to design a system for online travel agency Step 1 example In iteration #1, we decide to apply SOA pattern (Service Oriented Architecture, where functions of the system will become services) We decompose our system into necessary components based on SOA pattern Step 1 example Then, we need to choose which part of the system to design next, In iteration #2, we choose to further design SOA infrastructure components element We decide to decompose it into 3 components Step 1 example Then, we need to choose which part of the system to design next, In iteration #3, which element should we choose to design? Refine one of the remaining SOA elements? Refine one of the SOA infrastructure components? Which Element Comes Next? Two basic refinement strategies: Breadth first Depth first Which one to choose? If using new technology =\u003e depth first: explore the implications of using that technology. If a team needs work =\u003e depth first: generate requirements for that team. Otherwise =\u003e breadth first. Step 2: Identify the ASRs for the Chosen Element If the chosen element is the whole system, then use a utility tree (as described earlier). If the chosen element is further down the decomposition tree, then generate a utility tree from the requirements for that element. Step 3: Generate a Design Solution for the Chosen Element Apply generate and test to the chosen element with its ASRs Step 4 Inventory remaining requirements and select the input for the next iteration We need to consider 3 kinds of requirements Functional requirements Quality attribute requirements Constraints Step 4: Select the Input for the Next Iteration For each functional requirement Ensure that requirement has been satisfied. If not, then add responsibilities to satisfy the requirement. Add them to container with similar requirements If no such container, may need to create new one or add to container with dissimilar responsibilities (coherence) If container has too many requirements for a team, split it into two portions. Try to achieve loose coupling when splitting. Quality Attribute Requirements If the quality attribute requirement has been satisfied, it does not need to be further considered. If the quality attribute requirement has not been satisfied then either Delegate it to one of the child elements Split it among the child e","date":"2021-11-25 08:44:33","objectID":"/sek_base_07/:10:0","tags":["software engineering knowledge"],"title":"SEK_base_07","uri":"/sek_base_07/"},{"categories":["School courses"],"content":"Exercise 1 Capturing ASR in practice . Intended Learning Outcomes By the end of this lesson you will be able to: Specify concrete scenarios for a real system Create a utility tree for the real system Our system – ATM network Please check our WeChat group – I have sent a document The document in front of you describes the requirements for the system, including functional requirements and known quality attribute requirements Activity: Scenario Brainstorming (1) Based on the received document, express scenarios representing your concerns with respect to the system. Describe your scenarios in as many details as you can (do NOT use the concrete scenario form yet) Pick one of the scenarios and submit as an answer to the question. Activity: Scenario Brainstorming (2) Read scenarios of other participants, while reading, you can write more scenarios Your new scenarios can be inspired by what the other participant shared, but not the same Submit a new scenario you have wrote, inspired by scenarios of other participants Next steps Scenarios consolidation Participants discuss and consolidate the scenarios where reasonable. Scenario Prioritization - voting Each participants receives a number of votes equal to 30 percent of the total number of scenarios Each participant allocates their votes to scenarios Refine and elaborate the top scenarios Put the scenarios in the six-part scenario form (concrete scenario) Specifying Quality Attribute Requirements Stimulus. he stimulus is a condition that requires a response when it arrives at a system. Source of stimulus. his is some entity (a human, a computer system, or any other actuator) that generated the stimulus. Response. he response is the activity undertaken as the result of the arrival of the stimulus. Response measure. hen the response occurs, it should be measurable in some fashion so that the requirement can be tested. Environment. he stimulus occurs under certain conditions. The system may be in an overload condition or in normal operation, or some other relevant state. Artifact. his may be a collection of systems, the whole system, or some piece or pieces of it. Some artifact is stimulated. Quality Attribute Scenario: Example Our vehicle information system sends our current location to the traffic monitoring system. The traffic monitoring system combines our location with other information, overlays this information on a Google Map, and broadcasts it. Our location information is correctly included with a probability of 99.9%. Quality Attribute Scenario: Example The developer wishes to change the user interface by modifying the code at design time. The modifications are made with no side effects within three hours. Stimulus – Wishes to change UI Artifact – Code Environment: Design time Response – Change made Response measure – No side effects in three hours Source - Developer Quality Attribute Scenario: Example Users initiate transactions under normal operations. The system processes the transactions with an average latency of two seconds. Stimulus: transaction arrivals Source: users Artifact: the system Response: process the transactions Response measure: average latency of two seconds Environment: under normal operation Quality Attribute Scenario: Example A disgruntled employee from a remote location attempts to modify the pay rate table during normal operations. The system maintains an audit trail and the correct data is restored within a day. Stimulus: unauthorized attempts to modify the pay rate table Stimulus source: a disgruntled employee Artifact: the system with pay rate table Environment: during normal operation Response: maintains an audit trail Response measure: correct data is restored within a day Quality Attribute Scenario: Example The user downloads a new application and is using it productively after two minutes of experimentation. Source: user Stimulus: download a new application Artifact: system Environment: runtime Response: user uses application productively Response ","date":"2021-11-25 08:44:33","objectID":"/sek_base_07/:11:0","tags":["software engineering knowledge"],"title":"SEK_base_07","uri":"/sek_base_07/"},{"categories":["School courses"],"content":"exercise2 Please comply with epidemic prevention and control policies Choose the seat that you will use during the whole semester and register your information in the system. Make sure to take the same seat during every lecture. Intended Learning Outcomes By the end of this lesson you will be able to: Create a design for a real system using the ADD method employing and instantiating a pattern ASRs We will add/expand the following ASRs to our utility tree Modifiability Performance Modifiability The system must be easily modified to take advantage of new platform capabilities (for example, it must not be tied to a single database or to a single kind of client hardware or software) and that it must be extensible to allow the addition of new functions and new business rules. Modifiability scenarios A developer wishes to add a new auditing business rule at design time and makes the modification, without affecting other functionality, in 10 person-days. A developer wishes to change the relational schema to add a new view to the database, without affecting other functionality, in 30 person-days. A system administrator wishes to employ a new database and makes the modification, without affecting other functionality, in 18 person-months. A developer wishes to add a new function to a client menu, without side effects, in 15 person-days. A developer needs to add a Web-based client to the system, without affecting the functionality of the existing ATM client, in 90 person-days. Performance Latency of an operation (such as an ATM withdrawal) Performance scenario “The user can withdraw a limit of $300 from an account that has sufficient funds in less than 10 seconds.” There are two functional requirements and one performance requirement in this scenario. One function is a withdrawal Another function is a limit (a constraint of $300 if it is in the account) Performance constraint/quality attribute - “less than 10 seconds” ADD method The ADD method defines a software architecture by basing the design process on the quality attribute requirements of the system. The ADD approach follows a recursive decomposition process where, at each stage in the decomposition, architectural tactics and patterns are selected to satisfy a chosen set of high-priority quality scenarios. ADD: The Steps of ADD Choose an element of the system to design. Identify the ASRs for the chosen element. Generate a design solution for the chosen element. Inventory remaining requirements and select the input for the next iteration. Repeat steps 1–4 until all the ASRs have been satisfied. Step 1: Choose an Element of the System to Design For green field designs, the element chosen is usually the whole system. For legacy designs, the element is the portion to be added. After the first iteration: Step 2: Identify the ASRs for the Chosen Element If the chosen element is the whole system, then use a utility tree (as described earlier). Let us first look at our modifiability scenarios Modifiability scenarios A developer wishes to add a new auditing business rule at design time and makes the modification, without affecting other functionality, in 10 person-days. A developer wishes to change the relational schema to add a new view to the database, without affecting other functionality, in 30 person-days. A system administrator wishes to employ a new database and makes the modification, without affecting other functionality, in 18 person-months. A developer wishes to add a new function to a client menu, without side effects, in 15 person-days. A developer needs to add a Web-based client to the system, without affecting the functionality of the existing ATM client, in 90 person-days. Step 3: Generate a Design Solution for the Chosen Element Apply generate and test to the chosen element with its ASRs Activity: Use patterns and tactics Based on the modifiability scenarios, generate a candidate design employing and instantiating a pattern. Which tactics are you going to use? Tips (1) In or","date":"2021-11-25 08:44:33","objectID":"/sek_base_07/:12:0","tags":["software engineering knowledge"],"title":"SEK_base_07","uri":"/sek_base_07/"},{"categories":["School courses"],"content":"exercise3 Please comply with epidemic prevention and control policies Choose the seat that you will use during the whole semester and register your information in the system. Make sure to take the same seat during every lecture. Intended Learning Outcomes By the end of this lesson you will be able to: Create a documentation for a real system Structures and Views Architecture Is a Set of Software Structures A structure is the set of elements itself, as they exist in software or hardware. In short, a view is a representation of a structure. Architects design structures. They document views of those structures. Architecture Documentation Even the best architecture will be useless if the people who need it do not know what it is; cannot understand it well enough to use, build, or modify it; misunderstand it and apply it incorrectly. All of the effort, analysis, hard work, and insightful design on the part of the architecture team will have been wasted. Architecture Documentation and Stakeholders Education Introducing people to the system New members of the team External analysts or evaluators New architect Primary vehicle for communication among stakeholders Especially architect to developers Especially architect to future architect! Basis for system analysis and construction Architecture tells implementers what to implement. Each module has interfaces that must be provided and uses interfaces from other modules. Documentation can serve as a receptacle for registering and communicating unresolved issues. Architecture documentation serves as the basis for architecture evaluation. Views Principle of architecture documentation: Documenting an architecture is a matter of documenting the relevant views and then adding documentation that applies to more than one view. Which Views? The Ones You Need! Different views support different goals and uses. The views you should document depend on the uses you expect to make of the documentation. Each view has a cost and a benefit; you should ensure that the benefits of maintaining a view outweigh its costs. Building the Documentation Package Documentation package consists of Views Documentation beyond views View Template Implementation View Describes the static organization of the software in its development environment. Viewer Programmers and Software Managers Considers Software module organization - Hierarchy of layers, software management, reuse, constraints of tools Style layered style Notation Activity For our simple ATM network, with additional database servers deployed, create an implementation view Implementation and deployment views Implementation view Deployment View Describes the mapping(s) of the software onto the hardware and reflects its distributed aspect. Viewer System Engineers Considers Non-functional requirement (reliability, availability and performance) regarding to underlying hardware. Deployment view example Activity For our simple ATM network, with additional database servers deployed, create a deployment view Implementation and deployment views Implementation view Deployment view Use Case View Captures system functionality as seen by users Built in early stages of development Developed by analysts and domain experts System behavior, that is what functionality it must provide, is documented in a use case model. Use Case Model Illustrates the system’s intended functions (use cases), its surroundings (actors), and relationships between the use cases and actors (use case diagrams). provides a vehicle used by the customers or end users and the developers to discuss the system’s functionality and behavior. starts in the Inception phase with the identification of actors and principal use cases for the system, and is then matured in the elaboration phase, by adding more details and additional use cases. Graphical Constructs Actors represent anyone or anything that must interact with the system: they are not part of the system. may: only input information to the system only recei","date":"2021-11-25 08:44:33","objectID":"/sek_base_07/:13:0","tags":["software engineering knowledge"],"title":"SEK_base_07","uri":"/sek_base_07/"},{"categories":["School courses"],"content":"系统模型 ","date":"2021-11-17 08:45:55","objectID":"/distributedsystem_base_02/:0:0","tags":["distributed system"],"title":"DistributedSystem_base_02","uri":"/distributedsystem_base_02/"},{"categories":["School courses"],"content":"简介 物理模型是描述系统的-个最显式的方法，它从计算机(和其他设备，例如移动电话)及其互联的网络方面考虑系统的硬件组成。 体系结构模型从系统的计算元素执行的计算和通信任务方面来描述系统。 基础模型采用抽象的观点描述分布式系统的某个方面。本章介绍考察分布式系统三个重要方面的基础模型: 交互模型，它考虑在系统元素之间通信的结构和顺序; 故障模型，它考虑一个系统可能不能正确操作的方式; 安全模型，它考虑如何保护系统使其不受到正确操作的干扰或不被窃取数据。 ","date":"2021-11-17 08:45:55","objectID":"/distributedsystem_base_02/:1:0","tags":["distributed system"],"title":"DistributedSystem_base_02","uri":"/distributedsystem_base_02/"},{"categories":["School courses"],"content":"物理模型 物理模型是从计算机和所用网络技术的特定细节中抽象出来的分布式系统底层硬件元素的表示。 ","date":"2021-11-17 08:45:55","objectID":"/distributedsystem_base_02/:2:0","tags":["distributed system"],"title":"DistributedSystem_base_02","uri":"/distributedsystem_base_02/"},{"categories":["School courses"],"content":"体系结构模型 本节采取一种三阶段方法: 首先，描述支撑现代分布式系统的核心基本体系结构元素，重点展示现在已有方法的不同; 考察能在开发复杂分布式系统解决方案中单独使用或组合使用的复合体系结构模式; 最后，对于以上体系结构风格中出现的不同编程风格，考虑可用于支持它们的中间件平台。 注意，有许多与本章中介绍的体系结构模型相关的权衡，其中涉及采用的系统体系结构元素、所采用的模式和(在合适的地方)使用的中间件，它们会影响结果系统的性能和有效性。理解这样的权衡可以说是分布式系统设计中的关键技能。 ","date":"2021-11-17 08:45:55","objectID":"/distributedsystem_base_02/:3:0","tags":["distributed system"],"title":"DistributedSystem_base_02","uri":"/distributedsystem_base_02/"},{"categories":["School courses"],"content":"体系结构元素 通信实体：从系统的观点，回答通常是非常清楚的,这是因为在一个分布式系统中通信的实体通常是进程，这导致普遍地把分布式系统看成是带有恰当进程间通信范型的多个进程(如在第4章中讨论的)，有两个注意事项: 在一些原始环境中，例如传感器网络,基本的操作系统可能不支持进程抽象(或甚至任何形式的隔离)，因此在这些系统中通信的实体是结点。 在大多数分布式系统环境中，用线程补充进程，所以，严格说来，通信的末端是线程。 对象：对象已被引人以便在分布式系统中使用面向对象的方法(包括面向对象的设计和面向对象的编程语言)。在分布式面向对象的方法中，-个计算由若千交互的对象组成，这些对象代表分解给定问题领域的自然单元。对象通过接口被访问，用一个相关的接口定义语言(IDL) 提供定义在一个对象上的方法的规约。分布式对象已经成为分布式系统研究的一个主要领域，第5章和第8章将进一步讨论这个话题。 组件:因为对象的引入，许多重要的问题已被认为与分布式对象有关，组件技术的出现及使用是对这些弱点的一个直接响应。组件类似于对象，因为它们为构造分布式系统提供面向问题的抽象，也是通过接口被访问。关键的区别在于组件不仅指定其(提供的)接口而且给出关于其他组件/接口的假设，其他组件/接口是组件完成它的功能必须有的。换句话说,组件使得所有依赖显式化，为系统的构造提供一个更完整的合约。这个合约化的方法鼓励和促进第三方开发组件，也通过去除隐含的依赖 提升了一个更纯粹的组合化方法来构造分布式系统。基于组件的中间件经常对关键领域如部署和服务器方编程支持提供额外的支持[ Heineman and Councill 2001]。关于基于组件方法的进一步细节请参见第8章。 Web服务: Web 服务代表开发分布式系统的第三种重要的范型[Alonso et al. 2004]。Web 服务与对象和组件紧密相关，也是采取基于行为封装和通过接口访问的方法。但是，相比而言，通过利用Web标准表示和发现服务，Web 服务本质上是被集成到万维网(即W3C)的。W3C ( World WideWeb)联盟把Web服务定义成： 一个软件应用，通过URI被辨识，它的接口和绑定能作为XML制品被定义描述和发现。一个Web服务通过在基于互联网的协议上利用基于XML的消息交换支持与其他软件代理的直接交互。 换句话说，Web服务采用的基于Web的技术在-定程度上定义了Web服务。另一个重要的区别来源于技术使用的风格。对象和组件经常在一个组织内部使用，用于开发紧耦合的应用，但Web服务本身通常被看成完整的服务，它们可以组合起来获得增值服务，它们经常跨组织边界，因此可以实现业 务到业务的集成。Web服务可以由不同的提供商用不同的底层技术实现。Web服务将在第9章做进一步的探讨。 通信范型我们现在转向在分 布式系统中实体如何通信,考虑三种通信范型: 进程间通信; 远程调用; 间接通信。 进程间通信指的是用于分布式系统进程之间通信的相对底层的支持，包括消息传递原语、直接访问由互联网协议提供的API (套接字编程)和对多播通信的支持。第4章将详细讨论这样的服务。 远程调用代表分布式系统中最常见的通信范型，覆盖一系列分布式系统中通信实体之间基于双向交换的技术，包括调用远程操作、过程或方法。进一步的定义参见下面内容(详细讨论见第5章): 请求-应答协议是一个有效的模式，它加在一个底层消息传递服务之上，用于支持客户-服务器计算。特别的，这样的协议通常涉及一对消息的交换，消息从客户到服务器，接着从服务器返回客户，第一个消息包含在服务器端执行的操作的编码，然后是保存相关参数的字节数组，第二个消息包含操作的结果，它也被编码成字节数组。这种范型相对原始，实际上仅被用于嵌人式系统，对嵌人式系统来说性能是至关重要的。这个方法也被用在5.2节描述的HTTP协议中。正如下面讨论的，大多数分布式系统将选择使用远程过程调用或者远程方法调用，但注意底层的请求-应答交换支持两种方法。 远程过程调用( Remote Procedure Call, RPC)的概念，最初由Birell 和Nelson [1984] 提出，代表了分布式计算中的一个主要突破。在RPC中,远程计算机上进程中的过程能被调用，好像它们是在本地地址空间中的过程一样。底层RPC系统隐藏了分布的重要方面，包括参数和结果的编码和解码、消息的传递和保持过程调用所要求的语义。这个方法直接而且得体地支持了客户-服务器计算，其中,服务器通过一个服务接口提供一套操作, 当这些操作本地可用时客户直接调用这些操作。因此，RPC系统(在最低程度上)提供访问和位置透明性。 远程方法调用( Remote Method Invocation, RMI) 非常类似于远程过程调用，但它应用于分布式对象的环境。用这种方法，-个发起调用的对象能调用一个远程对象中的方法。与RPC一样，底层的细节都对用户隐藏。不过，通过支持对象标识和在远程调用中传递对象标识符作为参数，RMI 实现做得更多。它们也从与面向对象语言(见第5章相关讨论)的紧密集成中获得更多的好处。 上述技术具有一个共同点:通信代表发送者和接收者之间的双向关系，其中，发送者显式地把消息/调用送往相关的接收者。接收者通常了解发送者的标识，在大多数情况下，双方必须在同时存在。相比而言，已经出现若千技术，这些技术支持间接通信,通过第三个实体，允许在发送者和接收者之间的深度解耦合。尤其是: 发送者不需要知道他们正在发送给谁(空间解耦合)。 发送者和接收者不需要同时存在(时间解耦合)。 第6章将详细讨论间接通信。 间接通信的关键技术包括: 组通信:组通信涉及消息传递给若干接收者，因此是支持一对多通信的多方通信范型。组通信依赖组抽象，-一个组在系统中用-一个组标识符表示。接收方通过加人组，就能选择性接收发送到组的消息。发送者通过组标识符发送消息给组，因此，不需要知道消息的接收者。组通常也要维护组成员,具有处理组成员故障的机制。 发布-订阅系统:许多系统，例如第1章中金融贸易的例子，被归类于信息分发系统，其中，大量生产者(或发布者)为大量的消费者(或订阅者)发布他们感兴趣的信息项(事件)。采用前述的任-核心通信范型来实现这个需求是复杂且低效的，因此，出现了发布-订阅系统(有时也叫分布式基于事件的系统)用于满足此项重要需求[ Muhl et al. 2006]。发布-订阅系统共享同一个关键的特征，即提供-一个中间服务,有效确保由生产者生成的信息被路由到需要这个信息的消费者。 消息队列:虽然发布-订阅系统提供一种一对多风格的通信,但消息队列提供了点对点服务,其中生产者进程能发送消息到一个指定的队列，消费者进程能从队列中接收消息，或被通知队列里有新消息到达。因此，队列是生产者和消费者进程的中介。 元组空间:元组空间提供了进-步的间接通信服务，并支持这样的模型一进程 能把任意的结构化数据项( 称为元组)放到一个持久元组空间，其他进程可以指定感兴趣的模式，从而可以在元组空间读或者删除元组。因为元组空间是持久的，读操作者和写操作者不需要同时存在。这种风格的编程，也被称为生成通信，由Gelemter [ 1985]作为一种并行编程范型引人。已经开发了不少分布式实现，采用了客户-服务器-风格的实现或采用了更分散的对等方法。 分布式共享内存:分布式共享内存(Distributed Shared Memory, DSM)系统提供一种抽象，用于支持在不共享物理(内存的进程之间共享数据。提供给程序员的是-套熟悉的读或写(共享)数据结构的抽象，就好像这些数据在程序员自已本地的地址空间一样,从而提供了高层的分布透明性。基本的基础设施必须确保以及时的方式提供副本，也必须处理与数据同步和一致性相关的问题。分布式共享内存的概述在第6章中介绍。 到目前为止讨论的体系结构 角色和责任，在一个分布式系统中, 进程，或者说，对象、组件、服务，包括Web服务(为简单起见，我们在本节中使用术语“进程”)相互交互完成一个有用的活动，例如支持一次聊天会话。在这样做的时候，进程扮演给定的角色，在建立所采用的整体体系结构时，这些角色是基本的。本节我们考察两种起源于单个进程角色的体系结构风格:客户-服务器风格和对等风格。 客户-服务器:这是讨论分布式系统时最常引用的体系结构。它是历史上最重要的体系结构，现在仍被广泛地使用。图2-3 给出了一个简单的结构，其中，进程扮演服务器和客户的角色。特别是,为了访问服务器管理的共享资源，客户进程可以与不同主机上的服务器进程交互。如图2-3所示，一台服务器也可以是其他服务器的客户。例如，Web服务器通常是管理存储Web页面文件的本地文件服务器的客户。Web 服务器和大多数其他互联网服务是DNS服务的客户，DNS服务用于将互联网域名翻译成网络地址。另一个与Web相关的例子是搜索引擎,搜索引擎能让用户通过互联网查看Web页面上可用的信息汇总。这些信息汇总通过称为“Web 抓取”的程序形成，该程序在搜索引擎站点以后台方式运行，利用HTTP请求访问互联网上的Web服务器。因此，搜索引擎既是服务器又是客户:它回答来自浏览器客户的查询，并且运行作为其他Web服务器客户的Web抓取程序。在这个例子中，服务器任务(对用户查询的回答)和Web抓取的任务( 向其他Web服务器发送请求)是完全独立的，很少需要同步它们，它们可以并行运行。事实上,一个典型的搜索引擎正常情况下包含许多并发执行的线程，一些线程为它的客户服务，另一些线程运行Web抓取程序。 对等体系结构:在这种体系结构中,涉及一项任务或活动的所有进程扮演相同的角色，作为对","date":"2021-11-17 08:45:55","objectID":"/distributedsystem_base_02/:3:1","tags":["distributed system"],"title":"DistributedSystem_base_02","uri":"/distributedsystem_base_02/"},{"categories":["School courses"],"content":"体系结构模式 我们给出分布式系统中几个关键的体系结构模型，包括分层体系结构( layering architecture)、层次化体系结构( tiered ar-chitecture)和瘦客户相关的概念(包括虚拟网络计算的特定机制)。我们也把Web服务当做一个体系结构模式进行了考察，给出了其他可以应用在分布式系统中的模式。 分层，分层的概念是-一个熟悉的概念，与抽象紧密相关。在分层方法中，一个复杂的系统被分成若干层，每层利用下层提供的服务。因此，一个给定的层提供-一个软件抽象，更高的层不清楚实现细节，或不清楚在它下面的其他层。就分布式系统而言，这等同于把服务垂直组织成服务层。一个分布式服务可由一个或多个服务器进程提供，这些进程相互交互，并与客户进程交互，维护服务中的资源在系统范围内的-致视图。 层次化体系结构层次化体系结构 与分层体系结构是互补的。分层将服务垂直组织成抽象层，而层次化是一项组织给定层功能的技术，它把这个功能放在合适的服务器上，或者作为第二选择放在物理结点上。 AJAX的作用:在1.6节中，我们介绍了AJAX ( Asynchronous Javascript And XML)是Web所使用的标准客户-服务器交互方式的扩展。AJAX满足了Javascript 前端程序( 运行在Web浏览器中)和基于服务器的后端程序(拥有描述应用状态的数据)之间的细粒度通信的需要。概括而言，在标准的Web交互方式中，浏览器发送HTTP请求给服务器，请求给定URL的页面、图像或其他资源。服务器发送整个页面作为应答，这个页面或者从服务器上的-一个文件中读取，或者由一个程序生成，取决于 URL中可识别的资源类型。当客户收到内容时，浏览器根据其MIME类型( text/html、image/jpg 等)相关的显示方式呈现它。虽然Web页面由不同类型的内容项组成，但是整个页面以它在html页面定义中指定的方式由浏览器组合并呈现。 瘦客户，分布式计算的趋势是将复杂性从最终用户设备移向互联网服务。这点在向云计算(见第1章)发展的趋势中最明显，在上面讨论的层次化体系结构中也能看到。这个趋势导致了对瘦客户概念的兴趣，它使得能以很少的对客户设备的假设或需求，获得对复杂网络化服务的访问，这些服务可以通过云解决方案提供。更具体来说，术语瘦客户指的是一个软件层，在执行一个应用程序或访问远程计算机上的服务时，由该软件层提供一个基于窗口的本地用户界面。 其他经常出现的模式： 代理 代理(proxy) 模式是分布式系统中经常出现的模式，其主要用于支持远程过程调用或远程方法调用的位置透明性。用这种方法，一个代理在本地地址空间中被创建，用于代表远程对象。这个代理提供与远程对象-样的接口，程序员调用这个代理对象，因此无须了解交互的分布式特性。在RPC和RMI中，代理支持位置透明性的作用将在第5章做进一步的讨论。 注意代理也被用于封装其他的功能( 诸如复制或缓存的放置策略等)。 web服务中的业务代理 Web服务中的业务代理(brokerage)的使用能被看成是一个在可能很复杂的分布式基础设施中支持互操作性的体系结构模式。特别地，这个模式是由服务提供商、服务请求者和服务代理(提供与请求的服务-致的服务)三部分组成，如图2-11所示。这个业务代理模式在分布式系统的多个领域被多次应用，例如Java RMI中的注册服务、CORBA中的名字服务( 分别参见第5章和第8章的讨论)。 反射 反射( reflection)模式在分布式系统中作为支持内省(系统的动态发现的特性)和从中调停(动态修改结构或行为的能力)的手段而被持续地使用。.例如，Java的内省能力被用于RMI的实现中，提供通用的分发(参见5.4.2节的讨论)。在一个反射系统中，标准的服务接口在基础层可供使.用，但元层接口也可以提供对涉及服务实现的组件及组件参数的访问。许多技术在元层可用，包括截获到达的消息或调用、动态发现由给定对象提供的接口、发现和适应系统底层体系结构的能力。反射被应用于分布式系统中的多个领域，特别是反射中间件领域，例如，可以用于支持更多的可配置及重配置中间件体系结构[Kon et al. 2001]。与分布式系统相关的体系结构模式更多的例子可以在Bushmann等人[2007] 的著作中找到。. ","date":"2021-11-17 08:45:55","objectID":"/distributedsystem_base_02/:3:2","tags":["distributed system"],"title":"DistributedSystem_base_02","uri":"/distributedsystem_base_02/"},{"categories":["School courses"],"content":"相关的中间件解决方案 第1章引入了中间件，在2.3.2节讨论分层体系结构时又重温了中间件。中间件的任务是为分布式系统的开发提供-一个高层的编程抽象，并且通过分层，对底层基础设施中的异构性提供抽象，从而提升互操作性和可移植性。中间件解决方案是基于2. 3. 1节引人的体系结构模型，也支持更复杂的体系结构模式。本节我们简要回顾一下现在存在的中间件类别，为在本书的其他部分进-步研究这 些解决方案做好准备。 中间件的类别 远程过程调用包, (如Sun RPC,第5章)和组通信(如ISIS,第6章和第18章)属于最早的中间件实例。从那以后，出现了大量不同风格的中间件，大部分都基于上面介绍的体系结构模型。我们在图2-12中给出了中间件平台的分类，其中交叉引用了其他章,那些章更详细地讨论了不同种类的中间件。需要强调的是分类并不精确，现代中间件平台试图提供混合的解决方案。例如，许多分布式对象平台提供分布式事件服务，来补充传统的对远程方法调用的支持。类似地，出于互操作性的原因,许多基于组件的平台(和平台的其他分类)也支持Web服务和标准。从中间件标准和今天可用的技术的角度来看,还应该强调这个分类并不完整，其目的在于给出中间件的主要类别。其他(未给出的)解决方案是比较特定的，例如，特定于提供某-通信范型，如消息传递、远程过程调用、分布式共享内存、元组空间或组通信。 图2-12中的中间件的顶层分类是根据通信实体和相关通信范型而确定的，遵循五个主要的体系结构模型:分布式对象、分布式组件、发布-订阅系统、消息队列和Web服务。对等系统是这些类别的补充，基于2.3. 1节讨论的协作方法，对等系统是中间件-一个相当独立的分支。应用服务器，显示为分布式组件的子类，也提供对三层体系结构的直接支持。特别地，应用服务器提供了结构以支持应用逻辑和数据存储的分离，以及对其他特性( 如安全性和可靠性)的支持。详细细节将延后到第8章讨论。 除了编程抽象之外，中间件也能提供分布式系统的基础设施服务,供应用程序或其他服务使用。这些基础设施服务与中间件提供的分布式编程模式是紧密绑定的。例如，CORBA (第8章)提供给应用一系列的CORBA服务，包括对程序安全和可靠的支持。如上所述和在第8章中的进-一步讨论，应用服务器也提供对这些服务的内在支持。 中间件的限制 许多分布式应用完全依赖中间件提供的服务来支持应用的通信和数据共享需求。例如，一个适合客户-服务器模型的应用，如一个名字和地址的数据库，可以依赖只提供远程方法调用的中间件。 通过依靠中间件支持的开发，能大大简化分布式系统的编程，但系统可依赖性的一些方面要求应用层面的支持。 考虑从发送者的邮件主机传递大量的电子邮件消息到接收者的邮件主机。乍一看，这是一个TCP数据传输协议的简单应用( 见第3章的相关讨论)。但考虑这样的问题:用户试图在一个可能不可靠的网络上传递非常大的文件。TCP提供一些错误检测和更正， 但它不能从严重的网络中断中恢复。因此，邮件传递服务增加了另一层次的容错，维护一个进展记录，如果原来的TCP连接断开了，用一个新的TCP连接继续传递。 Saltzer、Reed 和Clarke的一篇经典论文[Saltzer et al. 1984]对分布式系统的设计给出了类似的、有价值的观点，他们称之为“端到端争论”。可将他们的陈述表述为: 一些与通信相关的功能，可以只依靠通信系统终点(end point)的应用的知识和帮助，即可完整、可靠地实现。因此，将这些功能作为通信系统的特征不总是明智的(虽然由通信系统提供一个不完全版本的功能有时对性能提高是有用的)。可以看出他们的论点与通过引人适当的中间件层将所有通信活动从应用编程中抽象出来的观点是相反的。 争论的关键是分布式程序正确的行为在很多层面上依赖检查、错误校正机制和安全手段，其中有些要求访问应用的地址空间的数据。任何企图在通信系统中单独完成的检查将只能保证部分正确性。因此，可能在应用程序中重复同样的任务,降低了编程效率,更重要的是增加了不必要的复杂性并要执行冗余的计算。 这里不进一步介绍他们的争论细节,强烈推荐读者阅读前面提到的那篇论文一那里有许多说明的实例。原文作者之一最近指出:争论给互联网设计带来的实质性好处最近面临着为满足当前应用需求而转向网络服务专门化的危险[ www. reed. com]。 这个争论给中间件设计者带来一个实际的两难困境，而且给定当代分布式系统中种类繁多的应用(和相关的环境条件) (见第1章)，这些困难与日俱增。本质上，底层中间件行为与一个给定应用或应用集的需求和相关环境上下文(如底层网络的状态和风格)有关。这个看法推动了对上下文感知和中间件自适应解决方案的兴趣，见Kon等人的讨论[2002] 。 ","date":"2021-11-17 08:45:55","objectID":"/distributedsystem_base_02/:3:3","tags":["distributed system"],"title":"DistributedSystem_base_02","uri":"/distributedsystem_base_02/"},{"categories":["School courses"],"content":"基础模型 上面的各种系统模型完全不同，但具有一些基本特性。特别是，所有的模型都由若干进程组成,这些进程通过在计算机网络上发送消息而相互通信，所有的模型都共享下列设计需求:实现进程及网络的性能和可靠性特征，确保系统中资源的安全性。本节给出基于基本特性的模型，利用这些模型，我们能更详细地描述系统可能展示的特征、故障和安全风险。 通常，为了理解和推理系统行为的某些方面，一个基础模型应该仅包含我们要考虑的实质性成分。这样一个模型的目的是: 显式地表示有关我们正在建模的系统的假设。 给定这些假设，就什么是可能的、什么是不可能的给出结论。结论以通用算法或要确保的特性 的形式给出。特性成立的保证依赖于逻辑分析和(适当时候的)数学证明。 了解设计依赖什么、不依赖什么，我们就能从中获益。如果在一个特定系统中实现-个设计，这个设计能否运作，我们只需询向在那个系统中假设是否成立。通过清晰、显式地给出我们的假设，就能利用数学技巧证明系统的特征，这些特征对任何满足假设的系统都成立。最后，通过从细节(如硬件)中抽象系统的基本实体和特性，我们就能阐明对系统的理解。 我们希望在我们的基本模型中提取的分布式系统情况能解决下列问题: 交互:计算在进程中发生，进程通过传递消息交互，并引发进程之间的通信(信息流)和协调(活动的同步和排序)。在分布式系统的分析和设计中,我们特别关注这些交互。交互模型必须反映通信带来的延迟，这些延迟的持续时间会比较长，交互模型必须反映独立进程相互配合的准确性受限于这些延迟，受限于在分布式系统中很难跨所有计算机维护同一时间概念。 故障:只要分布式系统运行的任-计算机上出现故障(包括软件故障)或连接它们的网络出现故障，分布式系统的正确操作就会受到威胁。我们的模型将对这些故障进行定义和分类。这为分析它们潜在效果以及设计能容忍每种类型故障的系统奠定了基础。 安全:分布式系统的模块特性和开放性将其暴露在外部代理和内部代理的攻击下。我们的安全模型对发生这种攻击的形式给出了定义并进行了分类，为分析对系统的威胁以及设计能抵御这些威胁的系统奠定了基础。为了帮助讨论和推理，我们对本章介绍的模型进行了必要的简化，省略了许多真实系统中的细节。 它们与真实系统的关系，以及在模型帮助下揭示的问题环境中的解决方案是本书讨论的主题。 ","date":"2021-11-17 08:45:55","objectID":"/distributedsystem_base_02/:4:0","tags":["distributed system"],"title":"DistributedSystem_base_02","uri":"/distributedsystem_base_02/"},{"categories":["School courses"],"content":"交互模型 体系结构模型对系统体系结构的讨论表明分布式系统由多个以复杂方式进行交互的进程组成。例如: 多个服务器进程能相互协作提供服务，前面提到的例子有域名服务(它将数据分区并复制到互联网中的服务器上)和Sun的网络信息服务(它在局域网的几个服务器上保存口令文件的复制版本)。 对等进程能相互协作获得一个共同的目标。例如，一个语音会议系统，它以类似的方式分布音频数据流，但它有严格的实时限制。 大多数程序员非常熟悉算法的概念一采取一系列步骤以执行期望的计算。简单的程序由算法控制，算法中的每一步都有严格的顺序。由算法决定程序的行为和程序变量的状态。这样的程序作为一个进程执行。由多个上面所说的进程组成的分布式系统是很复杂的。它们的行为和状态能用分布式算法描述一分布式算法定 义了组成系统的每个进程所采取的步骤，包括它们之间消息的传递。消息在进程之间传递以便在它们之间传递信息并协调它们的活动。每个进程执行的速率和进程之间消息传递的时限通常是不能预测的。要描述分布式算法的所有状态也非常困难，因为它必须处理所涉及的一个或多个进程的故障或消息传递的故障。 进程交互完成了分布式系统中所有的活动。每个进程有它自已的状态，该状态由进程能访问和更新的数据集组成，包括程序中的变量。属于每个进程的状态完全是私有的一也就是说， 它不能被其他进程访向或更新。 本节讨论分布式系统中影响进程交互的两个重要因素: 通信性能经常是一个限制特性。 不可能维护-个全局时间概念。 通信通道的性能。在我们的模型中， 通信通道在分布式系统中可用许多方法实现，例如，通过计算机网络上的流或简单消息传递来实现。计算机网络上的通信有下列与延迟(lateney)、 带宽( band-widh)和抖动(itter) 有关的性能特征: 从一个进程开始发送消息到另–个进程开始接收消息之间的间隔时间称为延迟。延迟包括: 第一串比特通过网络传递到目的地所花费的时间。例如，通过卫星链接传递消息的延迟是无线电信号到达卫星并返回的时间。 访问网络的延迟，当网络负载很重时，延迟增长很快。例如，对以太网传送而言，发送站点要等待网络空闲。 操作系统通信服务在发送进程和接收进程上所花费的时间，这个时间会随操作系统当前的负载的变化而变化。 计算机网络的带寬是指在给定时间内网络能传递的信息总量。当大量通信通道使用同-一个网络时，它们就不得不共享可用的带宽。 抖动是传递一系列消息所花费的时间的变化值。抖动与多媒体数据有关。例如，如果音频数据 的连续采样在不同的时间间隔内播放，那么声音将严重失真。 计算机时钟和时序事件。分布式系统中的每台计算机有自己的内部时钟,本地进程用这个时钟获得当前时间值。因此，在不同计算机上运行的两个进程能将时间戳与它们的事件关联起来。但是，即使两个进程在同时读它们的时钟,它们各自的本地时钟也会提供不同的时间值。这是因为计算机时钟和绝对时间之间有偏移，更重要的是，它们的漂移率互不相同。术语时钟漂移率( clock drit rate)指的是计算机时钟偏离绝对参考时钟的比率。即使分布式系统中所有计算机的时钟在初始情况下都设置成相同的时间，它们的时钟最后也会相差巨大，除非进行校正。 有几种校正计算机时钟的时间的方法。例如，计算机可使用无线电接收器从全球定位系统( GPS)以大约1μs的精度接收时间读数。但GPS接收器不能在建筑物内工作，同时，为每一台计算机增加GPS在费用上也不合理。相反，具有精确时间源(如GPS)的计算机可发送时序消息给网络中的其他计算机。在两个本地时钟时间之间进行协商当然会受消息延迟的影响。有关时钟漂移和时钟同步的更详细的讨论见第14章。 交互模型的两个变体。在分布式系统中，很难对进程执行、消息传递或时钟漂移所花的时间设置时间限制。两种截然相反的观点提供了一对简单模型:第一个模型对时间有严格的假设，第二个模型对时间没有假设。 同步分布式系统: Hadzilacos 和Toueg [1994] 定义了一个同步分布式系统，它满足下列约束: 进程执行每一步的时间有一个上限和下限。 通过通道传递的每个消息在一个已知的时间范围内接收到。 每个进程有一个本地时钟，它与实际时间的偏移率在一个已知的范围内。 对于分布式系统，建议给出合适的关于进程执行时间、消息延迟和时钟漂移率的上界和下界是可能的。但是达到实际值并对所选值提供保证是比较困难的。除非能保证上界和下界的值，否则任何基于所选值的设计都不可靠。但是，按同步系统构造算法，可以对算法在实际分布式系统的行为提供一些想法。例如，在同步系统中，可以使用超时来检测进程的故障，参见下面的2.4.2节。 同步分布式系統是能够被构造出来的。所要求的是进程用已知的资源需求完成任务，这些资源需求保证有足够的处理器周期和网络能力;还有要为进程提供漂移率在一定范围内的时钟。 异步分布式系统:许多分布式系统，例如互联网，是非常有用的，但它们不具备同步系统的资格。 因此我们需要另一个模型。异步分布式系统是对下列因素没有限制的系统: 进程执行速度 例如， 进程的一步可能只花费亿万分之一秒，而进程的另一步要花费一个世纪的时间，也就是说，每一步能花费任意长的时间。 消息传递延迟 例如， 从进程A到进程B传递一个消息的时间可能快得可以忽略，也可能要花费几年时间。换句话说，消息可在任意长时间后接收到。 时钟漂移率 时钟漂移率可以是任意的。 异步模型对执行的时间间隔没有任何假设。这正好与互联网一致，在互联网中,服务器或网络负载没有内在的约束，对像用FTP传输文件要花费多长时间也没有限制。有时电子邮件消息要花几天时间才能到达。下面的“Pepperland协定”部分说明在异步分布式系统中达成协定的困难性。即使有这些假设，有些设计问题也能得到解决。例如，虽然Web并不总能在一个合理的时间限制内提供特定的响应，但浏览器的设计可以做到让用户在等待时做其他事情。对异步分布式系统有效的任何解决方案对同步系统同样有效。 实际的分布式系统经常是异步的，因为进程需要共享处理器，而通信通道需要共享网络。例如，如果有太多特性未知的进程共享一个处理器，那么任何一个进程的性能都不能保证。但是，有许多不能在异步系统中解决的设计问题,在使用时间的某些特征后就能解决。在最终期限之前传递多媒体数据流的每个元素就是这样-个问题。对这样的问题，可使用同步模型。 事件排序。在许多情况下， 我们有兴趣知道一个进程中的一个事件(发送或接收一个消息)是发生在另一个进程中的另一个事件之前、之后或同时。尽管缺乏精确的时钟，但系统的执行仍能用事件和它们的顺序来描述。 ","date":"2021-11-17 08:45:55","objectID":"/distributedsystem_base_02/:4:1","tags":["distributed system"],"title":"DistributedSystem_base_02","uri":"/distributedsystem_base_02/"},{"categories":["School courses"],"content":"故障模型 在分布式系统中，进程和通信通道都有可能出故障，即它们可能偏离被认为是正确或所期望的行为。故障模型定义了故障可能发生的方式，以便理解故障所产生的影响。Hadzilacos 和Toueg [ 1994]提供了一种分类法，用于区分进程故障和通信通道故障。这些故障将分别在下面的“ 遗漏故障”、“随机故障”和“时序故障”部分介绍。 本书将贯穿使用故障模型。例如: 第4章给出数据报和流通信的Java接口，它们分别提供不同程度的可靠性。 第5章给出支持RMI的请求-应答协议。它的故障特征取决于进程和通信通道两者的故障特征。该协议能用数据报或流通信实现。可根据实现的简单性、性能和可靠性作出决定。 第17章给出事务的两阶段的提交协议。它用于在面对进程和通信通道的确定性故障时完成事务。 遗漏故障。遗漏故障类错误指的是进程或通信通道不能完成它应该做的动作。 进程遗漏故障:进程主要的遗漏故障是崩溃。当我们说进程崩溃了，意为进程停止了，将不再执行程序的任何步骤。能在故障面前存活的服务,如果假设该服务所依赖的服务能干净利落地崩溃，即进程仍能正确运行或者停止运行,那么它的设计能被简化。其他进程通过下列事实能检测到这种进程崩溃:这个进程一再地不能对调用消息进行应答。然而，这种崩溃检测的方法依赖超时的使用，即进程用一段固定时间等待某个事件的发生。在异步系统中，超时只能表明进程没有响应一它 可能是崩溃了，也可能是执行速度慢，或者是消息还没有到达。如果其他进程能确切检测到进程已经崩溃，那么这个进程崩溃称为故障-停止。在同步系统中, 如果确保消息已被传递，而其他进程又没有响应时，进程使用超时来检测，那么就会产生故障–停止 行为。 通信遗漏故障:考虑通信原语send和re-ceive。进程p通过将消息m插人到它的外发消息缓冲区来执行send。通信通道将m传输到q的接收消息缓冲区。进程q通过将m从它的接收消息缓冲区取走并完成传递来执行receive ( 见图2-14)。通常由操作系统提供外发消息缓冲区和接收消息缓冲区。 随机故障术语随机故障或拜占庭故障用于描述可能出现的最坏的故障，此时可能发生任何类型的错误。 时序故障时序故障适用于同步分布式系统。在这样的系统中，对进程执行时间、消息传递时间和时钟漂移率均有限制。时序故障见图2-16的列表。这些故障中的任何一个均可导致在指定时间间隔内对客户没有响应。 故障屏蔽分布式系统中的每个组件通常是基于其他一组组件构造的。利用存在故障的组件构造可靠的服务是可能的。例如，保存有数据副本的多个服务器在其中一个服务器崩溃时能继续提供服务。 一对一通信的可靠性虽然基本的通信通道可能出现前面描述的遗漏故障，但用它来构造一个能屏蔽某些故障的通信服务是可能的。 术语可靠通信可从下列有效性和完整性的角度来定义: 有效性:外发消息缓冲区中的任何消息最终能传递到接收消息缓冲区。 完整性:接收到的消息与发送的消息一致，没有消息被传递两次。 对完整性的威胁来自两个方面: 任何重发消息但不拒绝到达两次的消息的协议。要检测消息是否到达了两次，可以在协议中给消息附加序号。 心怀恶意的用户，他们可能插人伪造的消息、重放旧的消息或篡改消息。在面对这种攻击时为维护完整性要采取相应的安全措施。 ","date":"2021-11-17 08:45:55","objectID":"/distributedsystem_base_02/:4:2","tags":["distributed system"],"title":"DistributedSystem_base_02","uri":"/distributedsystem_base_02/"},{"categories":["School courses"],"content":"安全模型 在第1章中，我们识别出资源共享是分布式系统的一个激发因素。 在2.3节中，我们用进程来描述分布式系统的体系结构，其中可能封装了如对象、组件或服务等的高层抽象，而且，我们通过与其他进程的交互来访问系统。那个体系结构模型为我们的安全模型提供了基础: 通过保证进程和用于进程交互的通道的安全以及保护所封装的对象免遭未授权访问可实现分布式系统的安全。 保护对象。用户运行客户程序，由客户程序向服务器发送调用以完成在对象上的操作。服务器完成每个调用指定的操作并将结果发给客户。 保护进程和它们的交互进程通过发送消息进行交互。消息易于受到攻击，因为它们所使用的网络和通信服务是开放的，以使得任一对进程可以进行交互。服务器和对等进程暴露它们的接口，使得任何其他进程能给它们发送调用。 敌人。为了给安全威胁建模，我们假定敌人(有时也称为对手)能给任何进程发送任何消息，并读取或复制一对进程之间的任何消息，如图2-18所示。这种攻击能很简单地实现，它利用连接在网上的计算机运行一个程序读取那些发送给网络上其他计算机的网络消息，或是运行一个程序生成假的服务请求消息并声称来自授权的用户。攻击可能来自合法连接到网络的计算机或以非授权方式连接到网络的计算机。来自一个潜在敌人的威胁包括对进程的威胁和对通信通道的威胁。 对进程的威胁:在分布式系统中,一个用于处理到达的请求的进程可以接收来自其他进程的消息，但它未必能确定发送方的身份。通信协议(如IP)确实在每个消息中包括了源计算机的地址，但对一个敌人而言，用一个假的源地址生成一个消息并不困难。缺乏消息源的可靠的知识对服务器和客户的正确工作而言是一个威胁，具体解释如下: 服务器:因为服务器能接收来自许多不同客户的调用，所以它未必能确定进行调用的主体的身份。即使服务器要求在每个调用中加入主体的身份，敌人也可能用假的身份生成一个调用。在没有关于发送方身份的可靠知识时，服务器不能断定应执行操作还是拒绝执行操作。例如，邮件服务器不知道从指定邮箱中请求一个邮件的用户是否有权限这样做，或者它是否为来自一个敌人的请求。 客户:当客户接收到服务器的调用结果时，它未必能区分结果消息来自预期的服务器还是来自一个“哄骗”邮件服务器的敌人。因此，客户可能接收到一个与原始调用无关的结果，如一个假的邮件(不在用户邮箱中的邮件)。 对通信通道的威胁:一个敌人在网络和网关上行进时能复制、改变或插人消息。当信息在网络上传递时，这种攻击会对信息的私密性和完整性构成威胁，对系统的完整性也会构成威胁。例如，包含用户邮件的结果消息可能泄露给另-一个用户或者可能被改变成完全不同的东西。另一种形式的攻击是试图保存消息的拷贝并在以后重放这个消息，这使得反复重用同一消息成为可能。例如，有些人通过重发请求从一个银行账户转账到另一个银行账户的调用消息而受益。利用安全通道可解除这些威胁，安全通道是基于密码学和认证的，详细内容见下面的描述。 解除安全威胁。下面将介绍安全系统所基于的主要技术。 第11章将详细讨论安全的分布式系统的设计和实现。 密码学和共享秘密:假设一对进程(例如某个客户和某个服务器)共享一个秘密，即它们两个知道秘密但分布式系统中的其他进程不知道这个秘密。如果由一对进程交换的消息包括证明发送方共享秘密的信息，那么接收方就能确认发送方是一对进程中的另一个进程。当然，必须小心以确保共享的秘密不泄露给敌人。 密码学是保证消息安全的科学,加密是将消息编码以隐藏其内容的过程。现代密码学基于使用密钥(很难猜测的大数)的加密算法来传输数据，这些数据只能用相应的解密密钥恢复。 认证:共享秘密和加密的使用为消息的认证(证明由发送方提供的身份)奠定了基础。基本的认证技术是在消息中包含加密部分，该部分中包含足够的消息内容以保证它的真实性。对文件服务器的一个读取部分文件的请求，其认证部分可能包括请求的主体身份的表示、文件的标识、请求的日期和时间，所有内容都用一个在文件服务器和请求的进程之间共享的密钥加密。服务器能解密这个请求并检查它是否与请求中指定的未加密细节相对应。 安全通道:加密和认证用于构造安全通道，安全通道作为已有的通信服务层之上的服务层。安全通道是连接一对进程的通信通道，每个进程代表一个主体行事，如图2- 19所示。- 一个安全通道有下列特性: 每个进程确切知道其他正在执行的进程所代表的主体身份。因此，如果客户和服务器通过安全通道通信，那么服务器要知道发起调用的主体身份，并能在执行操作之前检查它们的访向权限。这使得服务器能正确地保护它的对象，以便客户相信它是从真实的服务器上接收到的结果。 安全通道确保在其上传送的数据的私密性和完整性(防止篡改)。 每个消息包括一个物理的或逻辑的时间戳以防消息被重放或重排序。 其他可能的来自敌人的威胁。1.5.3 节简要介绍了两个安全威胁一拒绝服 务攻击和移动代码的部署。作为敌人破坏进程活动的可能的机会，我们要再介绍一下这两个安全威胁。 拒绝服务:在这种攻击形式下，敌人通过超量地、无意义地调用服务或在网络上进行消息传送，干扰授权用户的活动，导致物理资源( 网络带宽、服务器处理能力)的过载。这种攻击通常意在延迟或阻碍其他用户的动作。例如，建筑物中的电子门锁可能由于受到对计算机控制的电子锁的过多非法请求而失效。 移动代码:如果进程接收和执行来自其他地方的程序代码(如1. 5.3节提到的邮件附件)，那么这些移动代码就会带来新的、有趣的安全问题。这样的代码很容易扮演特洛伊木马的角色，声称完成的是无害的事情但事实上包括了访问或修改资源的代码，这些资源对宿主进程是合法可用的但对代码的编写者是不合法的。实现这种攻击有多种不同的方法，因此必须非常小心地构造宿主环境以避免攻击。其中的大多数问题已在Java和其他移动代码系统中解决了，但从最近的一段历史看，移动代码问题暴露了一些让人窘迫的弱点。这-点也很好地说明了所有安全系统的设计都需要严格的分析。 安全模型的使用。有人认为, 在分布式系统中获得安全是件简单的事，即根据预定义的访问权限控制对象的访问以及通信的安全通道的使用，但是通常却不是这样。安全技术(如加密)和访问控制的使用会产生实质性的处理和管理开销。前面概述的安全模型提供了分析和设计安全系统的基础，其中这些开销保持最少,但对分布式系统的威胁会在许多地方出现，需要对系统网络环境、物理环境和人际环境中所有可能引发的威胁进行仔细的分析。这种分析涉及构造威胁模型，由它列出系统会遭遇 的各种形式的攻击、风险评估和每个威胁所造成的后果。要在抵御威胁所需的安全技术的有效性和开销之间做出权衡。 ","date":"2021-11-17 08:45:55","objectID":"/distributedsystem_base_02/:4:3","tags":["distributed system"],"title":"DistributedSystem_base_02","uri":"/distributedsystem_base_02/"},{"categories":["School courses"],"content":"小结 如2.2节所展示的，从底层物理特性角度，例如，系统的规模、系统内在的异构性、从特性角度(如安全)提供端到端解决方案的实际需求等，分布式系统的复杂性正在增加。这使得从模型角度理解和探讨分布式系统显得更加重要。本章考虑了底层物理模型，并深度考察了支撑分布式系统的体系结构模型和基础模型。 本章从所包含的体系结构模型角度给出了描述分布式系统的方法，明晰了这个设计空间的内涵，包括查看什么在通信以及这些实体如何通信等核心问题，以及基于给定物理基础设施，考虑每个元素可以扮演的角色与合适的放置策略，并把它们补充到设计中去。 本章还介绍了体系结构模式在由底层核心元素(例如上述的客户-服务器模型)构造复杂设计中发挥的关键作用,给出了支持分布式系统的中间件解决方案的主要类型，包括基于分布式对象、组件、Web服务和分布式事件的解决方案。从体系结构模型角度看，客户-服务器方法是一种常见的体系结构模型一 Web 和其他互联网服务(如FIP、新闻和邮件以及Web服务和DNS)均基于这个模型，文件归档和其他本地服务也是如此。像DNS这种有大量的用户并管理大量信息的服务是基于多个服务器的，并使用数据分区和复制来提高可用性和容错能力。客户和代理服务器上的缓存得到广泛使用以提高服务的性能。不过，现在有许多方法对分布式系统进行建模，包括各种可替代的观点，如对等计算和更多的面向问题的抽象(如对象、组件或服务)。 基础棋型补充了体系结构模型，它们帮助从诸如性能、可靠性和安全角度对分布式系统的特性进行推理。特别地，我们给出了交互模型、故障模型和安全模型。它们识别出构造分布式系统的基本组件的共同特征。交互模型关注进程和通信通道的性能以及全局时钟的缺乏。它将同步系统看成在进程执行时间、消息传递时间和时钟漂移上有已知范围的系统，将异步系统看成在进程执行时间、消息传递时间和时钟漂移上没有限制的系统一这是对互联网行为的描述。 故障模型将分布式系统中的进程故障和基本的通信通道故障进行了分类。屏蔽是一项技术，依靠它，可将不太可靠的服务中的故障加以屏蔽，并基于此构造出较可靠的服务。特别是，通过屏蔽基本的通信通道的故障，可从基本的通信通道构造出可靠的通信服务。例如，遗漏故障可通过重传丢失的消息加以屏蔽。完整性是可靠通信的一个性质一它要求接收到的消息 与发送的消息一致，并且没有消息被发送两次。有效性是可靠通信的另一个性质一它要求发送消息缓冲区中的任何消息最终都能传递到接收消息缓冲区。 安全模型可识别出在一个开放的分布式系统中对进程和通信通道可能的威胁。有些威胁与完整性有关:恶意用户可能篡改消息或重放消息。其他的威胁则会损害私密性。另一个安全问题是发送消息所代表的主体(用户或服务器)的认证。安全通道使用密码技术来确保消息的完整性和私密性，并使得相互通信的主体可以进行验证。 ","date":"2021-11-17 08:45:55","objectID":"/distributedsystem_base_02/:5:0","tags":["distributed system"],"title":"DistributedSystem_base_02","uri":"/distributedsystem_base_02/"},{"categories":["School courses"],"content":"分布式系统的特征 ","date":"2021-11-10 10:24:24","objectID":"/distributedsystem_base_01/:0:0","tags":["distributed system"],"title":"DistributedSystem_base_01","uri":"/distributedsystem_base_01/"},{"categories":["School courses"],"content":"简介 我们把分布式系统定义成一个其硬件或软件组件分布在联网的计算机上，组件之间通过传递消息进行通信和动作协调的系统。 我们定义的分布式系统具有如下的具体特征： 并发：在一个计算机网络中，执行并发程序是常见的行为。用户可以在各自的计算机上工作，在必要时共享诸如Web页面或文件之类的资源。系统处理共享资源的能力会随着网络资源（例如，计算机）的增加而提高。 缺乏全局时钟：在程序需要协作时，它们通过交换消息来协调它们的动作。密切的协作通常取决于对程序动作发生的时间的共识。但是，事实证明，网络上的计算机与时钟同步所达到的准确性是有限的，即没有一个正确时间的全局概念。原因也很简单，因为基于网络的通信天然存在时延，而这个时延可能会由于网络状态等条件而不断发生变化，这么一来，就会导致各项动作没办法按照原定的时间来工作，反而会出现一些不好的影响。 故障独立性：所有的计算机系统都可能会出现故障，一般由系统设计者负责为可能的故障设计结果。分布式系统可能会以新的方式出现故障。网络故障导致网上互联的计算机的隔离，但这并不意味着它们停止运行，事实上，计算机上的程序不能检测到网络是出现故障还是网络运行得比通常慢。类似的，计算机的故障或系统中程序得异常终止（崩溃），并不能让与它通信的其他组件了解。系统的每个组件会单独地出现故障，而其他组件还在运行。 ","date":"2021-11-10 10:24:24","objectID":"/distributedsystem_base_01/:1:0","tags":["distributed system"],"title":"DistributedSystem_base_01","uri":"/distributedsystem_base_01/"},{"categories":["School courses"],"content":"分布式系统的例子 ","date":"2021-11-10 10:24:24","objectID":"/distributedsystem_base_01/:2:0","tags":["distributed system"],"title":"DistributedSystem_base_01","uri":"/distributedsystem_base_01/"},{"categories":["School courses"],"content":"web搜索 Web搜索引擎的任务是为万维网的所有内容建立索引，其中包含各种信息类型，例如Web页面、多媒体资源和扫描后的书。考虑到大多数搜索引擎是分析整个Web内容，并在这个巨大的数据库上完成复杂的处理，那么这个任务自身就是对分布式系统涉及的一个巨大挑战。 Google，Web搜索技术上的市场领导者，在支持用于搜索（与其他Google应用和服务，如Google Earth）的复杂的分布式系统基础设施上做出了巨大努力。该设施最突出的亮点包括： 一个底层物理设施：它由超大数目的位于全世界多个数据中心的连网计算机组成。 一个分布式文件系统：支持超大文件，并根据搜索和其他Google应用的使用方式（特别是在文件中以快速而持久的速度读取）进行了深度优化 一个相关的结构化分布式存储系统：它提供了对超大数据集的快速访问 一个锁服务：它提供了诸如分布式加锁和协定等分布式系统功能。 一个编程模式：它支持对底层物理基础设施上的超大并行和分布式计算的管理。 ","date":"2021-11-10 10:24:24","objectID":"/distributedsystem_base_01/:2:1","tags":["distributed system"],"title":"DistributedSystem_base_01","uri":"/distributedsystem_base_01/"},{"categories":["School courses"],"content":"大型多人在线游戏 大型多人在线游戏（Massively Multiplayer Online Game,MMOG）提供了一种身临其境的体验，超大数目用户通过互联网在一个持久的虚拟世界中交互。这类游戏的主要例子是Sony的EverQuest Ⅱ和芬兰公司CCP Games公司的EVE Online。 MMOG工程体现了分布式系统技术面临的巨大挑战，尤其是它对快速响应时间的需求。其他挑战包括事件实时传播给多个玩家和维护对共享世界的一个一致的视图。 针对大型多人在线游戏，提出了许多解决方案： 可能有点出乎意料，最大的在线游戏EVE Online，采用了CS体系结构，在一个集中式服务器上维护了游戏世界状态的单个拷贝，供运行在玩家终端或其他设备上的客户程序访问。为了支持大量客户，服务器自身是一个复杂的实体，拥有上百个计算机节点组成的集群结构。从虚拟世界的管理看，集中式体系结构有极大的益处，单个拷贝也简化了一致性问题。接着，目标是用过优化网络协议和快速响应到达事件来确保快速的响应。为了支持这点，对负载进行分区，把单个“星系”分配给集群中指定的计算机，这样，高负载星系会拥有自己的专用计算机，而其他星系则共享一台计算机。通过跟踪王家在i星系之间的移动，到达事件会被导向集群中正确的计算机上。 其他MMOG采用更多的分布式体系结构，宇宙被划分到大量（可能是超多）服务器上，这些服务器可能地理上分散部署。接着，用户基于当前的使用模式和到服务器的网络延迟（基于地理最近）被动态地分配到一个特定的服务器。这种体系结构风格被EverQuest采用，它通过增加新的服务器，可自然地扩展。 大多数商业系统采用上述两个模型中的一个，但研究者现在也在寻找更极端的体系结构，即不基于客户-服务器原理而是基于对等技术采用完全分散的方法。采用对等技术，意味着每个参与者贡献（存储和处理）资源来容纳游戏。 ","date":"2021-11-10 10:24:24","objectID":"/distributedsystem_base_01/:2:2","tags":["distributed system"],"title":"DistributedSystem_base_01","uri":"/distributedsystem_base_01/"},{"categories":["School courses"],"content":"金融交易 金融行业以其需求一直处在分布式系统技术的最前沿，特别是在实时访问大范围的信息源方面（例如，当前股票价格和趋势，经济和政治发展）。金融行业采用自动监控和交易应用。 此类系统的重点是对感兴趣数据项的通信和处理。感兴趣数据项在分布式系统中称为事件，在金融行业中的需求是可靠和及时地传递事件给可能是大量对此信息有兴趣地客户。这要求底层地体系结构具有与前述风格（例如CS）完全不同的风格，这样的系统通常采用分布式基于事件的系统。 下图说明了一个典型的金融交易的例子。它显示了一系列事件进入一个指定的金融机构。这样的事件输入具有下列特征。（图片来自分布式系统：概念与设计（原书第五版） by George Coulouris Jean Dollimore Tim Kindberg Gordon Blair (z-lib.org)） 首先，事件源通常具有多种格式，例如路透社的市场数据事件和FIX事件（符合金融信息交换协议特定格式的事件），事件源还来自不同的事件技术，这说明了在大多数分布式系统中回到异构性问题。图中使用了适配器，它把异构性格式转换成一个公共的内部格式。 其次交易系统必须处理各种各样的事件流，这些事件流高速到达，经常需要实时处理来检测表示交易机会的模式。这在过去曾今是手工处理的，但在竞争压力下变成自动处理，这就是所谓的复杂事件处理（Complex Event Processing，CEP），它提供了一种方法来将一起发生的事件组成逻辑的、时序的或空间的模式。 ","date":"2021-11-10 10:24:24","objectID":"/distributedsystem_base_01/:2:3","tags":["distributed system"],"title":"DistributedSystem_base_01","uri":"/distributedsystem_base_01/"},{"categories":["School courses"],"content":"分布式系统的趋势 分布式系统正在经历巨大的变化，这可追溯到一系列有影响力的趋势： 出现了泛在联网技术 出现了无处不在计算，它伴随着分布式系统中支持用户移动性的意愿 对多媒体设备的需求 把分布式系统作为一个设施 ","date":"2021-11-10 10:24:24","objectID":"/distributedsystem_base_01/:3:0","tags":["distributed system"],"title":"DistributedSystem_base_01","uri":"/distributedsystem_base_01/"},{"categories":["School courses"],"content":"泛在联网和现代互联网 互联网上的计算机程序通过传递消息进行交互，采用了一种公共的通信手段。互联网通信机制（互联网协议）的设计和构造是一项重大的技术成果，它使得一个在某处运行的程序能给另一个地方的程序发送消息。 互联网是一个超大的分布式系统。互联网和其支持得服务的实现，使得必须开发实用解决方案来解决分布式系统中的许多问题。 ","date":"2021-11-10 10:24:24","objectID":"/distributedsystem_base_01/:3:1","tags":["distributed system"],"title":"DistributedSystem_base_01","uri":"/distributedsystem_base_01/"},{"categories":["School courses"],"content":"移动和无处不在计算 设备小型化和无线网络方面的技术进步已经逐渐使得小型和便携式计算设备集成到分布式系统中。这些设备包括： 笔记本电脑 手持设备（包括移动电话、智能电话、GPS设备、摄像机等） 可穿戴设备 嵌入式家电 这些设备大多具有可便携性，再加上它们可以在不同的地方方便地连接到网络的能力，使得移动计算成为可能。移动计算是指用户在移动或访问某个非常规环境时执行计算任务的性能。 无处不在计算是指对用户的的物理环境（包括家庭、办公室和其他自然环境）中存在的多个小型、便宜的计算设备的利用。 移动和无处不在计算是一个热门的研究领域。 ","date":"2021-11-10 10:24:24","objectID":"/distributedsystem_base_01/:3:2","tags":["distributed system"],"title":"DistributedSystem_base_01","uri":"/distributedsystem_base_01/"},{"categories":["School courses"],"content":"分布式多媒体系统 另一个重要趋势是在分布式系统中支持多媒体服务的需求。多媒体支持可以定义为以集成的方式支持多种媒体类型的能力。人们可以期望分布式多媒体系统支持离散型媒体（如图片或正文消息）的存储、传输和展示。分布式多媒体系统应该能对连续类型媒体（如音频和视频）完成相同的功能，即它应该能存储和定位音频或视频文件，并通过网络传输它们（可能需要以实时的方式，因为流来自摄像机），从而能给用户展示多种媒体类型，以及在一组用户中共享多种类型的媒体。 连续媒体的重要特点时它们包括一个时间维度，媒体类型的完整性从根本上依赖于在媒体类型的元素之间保持实时关系。 分布式多媒体计算的好处时相当大的，因为能在桌面环境提供大量的新（多媒体）服务和应用，包括访问实况或预先录下的电视广播、访问提供视屏点播服务的电影资料库、访问音乐资料库、提供音频和视频会议设施、提供集成的电话功能。 网络播放（webcasting） 是分布式多媒体技术的应用。网络播放是在互联网上广播连续媒体（典型是音频和视频）的能力，现在常见以这种方式广播主要的体育或音乐事件。 分布式多媒体应用（例如网络播放）对底层的分布式基础设施提出了大量的要求，包括： 提供对一系列（可扩展的）编码和加密格式的支持，例如MPEG系列标准（包括如流行的MP3标准，也称MPEG-1音频第三层）和HDTV 提供一系列机制来保障所需的服务质量能够得到满足 提供相关的资源管理策略，包括合适的调度策略，来支持所需的服务质量 提供适配策略类处理在开放系统中不可避免的场景，即服务质量不能得到满足或维持 ","date":"2021-11-10 10:24:24","objectID":"/distributedsystem_base_01/:3:3","tags":["distributed system"],"title":"DistributedSystem_base_01","uri":"/distributedsystem_base_01/"},{"categories":["School courses"],"content":"把分布式计算作为一个公共设施 随着分布式下基础设施的不断成熟，不少公司在推广这样的观点：把分布式资源看作一个商品或公共设施，把分布式资源和其他公共设施进行类比。采用这种模型，资源通过合适的服务提供者提供，能被最终用户有效地租赁而不是拥有。这种模型可以应用到物理资源和更多的逻辑服务上。 联网的计算机可用诸如存储和处理这样的物理资源，从而无需自己拥有这样的资源。从一个维度来看，用户可以为其文件存储需求和文件备份需求选择一个远程存储设施。类似的，利用这个方法，用户能租到一个或多个计算结点，从而满足他们的基本计算需求或者完成分布式计算。从另一个维度来看，用户现在能用像Amazon和Google之类的公司提供的服务访问复杂的数据中心或计算基础设施。操作系统虚拟化时该方法关键的使能技术，它意味着实际上可以通过一个虚拟的而不是物理的结点为用户提供服务。这从资源管理角度给服务提供者提供了更大的灵活性。 用这种方法，软件服务也能跨全球互联网使用。 关于计算作为公共设施，术语云计算（cloud computi）被用来刻画其前景。云被定义成一组基于互联网的应用，并且足以满足大多数用户需求的存储和计算服务的集合，这使得用户能大部分或全部免于本地数据存储和应用软件的使用。该术语也推广“把每个事物看成一个服务”的观点。 通常，云实现在集群计算机上，从而提供每个服务所要求的必须的伸缩性和性能。**集群计算机（cluster computer）**是互联的计算机集合，它们密切协作提供单一的、集成的高性能计算能力。 集群服务器的总目的时提供一系列的云服务，包括高性能计算能力、大容量存储能力（例如通过数据中心）、丰富的应用服务（如Web搜索——Google依赖大容量集群计算机体系结构来实现其搜索引擎和其他服务） 网格计算也能被看作时一种云计算。但网格计算通常被看作时云计算这种更通用模式的先驱，它只是偏重于支持科学计算。 ","date":"2021-11-10 10:24:24","objectID":"/distributedsystem_base_01/:3:4","tags":["distributed system"],"title":"DistributedSystem_base_01","uri":"/distributedsystem_base_01/"},{"categories":["School courses"],"content":"关注资源共享 从硬件资源来看，大家共享设备可以减少花费，但对用户具用更大意义的是共享与用户应用、日常工作和社会活动有关的更高层的资源。例如用户惯性以共享数据库或Web页面集方式出现的共享数据，而不是实现上述服务的硬盘和处理器。类似的，用户关心诸如搜索引擎或货币换算器之类的共享资源，而不关心提供这些服务的服务器。 实际上，资源共享的模式随着其工作范围和与用户工作的密切程度的不同而不同。一种极端是，Web上的搜索引擎是给全世界的用户提供工具，而用户之间并不需要直接接触；另一种极端是，在计算机支持协调工作（Computer Supported Working。CSCW） 中，若干直接进行合作的用户在一个小型封闭的小组中共享诸如文档之类的资源。用户在地理上的分布以及用户之间进行共享的模式决定了系统必须提供协调用户动作的机制。 我们使用属于服务表示计算机系统中管理相关资源并提供功能给用户和应用的一个单独的部分。 服务将资源访问限制为一组定义良好的操作，这在某种程度上属于标准的软件工程实践。同时它也反映出分布式系统的物理组织。分布式相同的资源是物理地封装在计算机内，其他计算机只能通过通信访问。为了实现有效的共享，每个资源必须由一个程序管理，这个程序提供通信接口使得对资源进行可靠和一致的访问和更新。 ","date":"2021-11-10 10:24:24","objectID":"/distributedsystem_base_01/:4:0","tags":["distributed system"],"title":"DistributedSystem_base_01","uri":"/distributedsystem_base_01/"},{"categories":["School courses"],"content":"挑战 随着分布式系统的应用范围和规模扩大，可能会遇到相同的和其他的挑战。 ","date":"2021-11-10 10:24:24","objectID":"/distributedsystem_base_01/:5:0","tags":["distributed system"],"title":"DistributedSystem_base_01","uri":"/distributedsystem_base_01/"},{"categories":["School courses"],"content":"异构性 互联网使得用户能在大量异构计算机和网络上访问服务和运行应用程序。 下面这些均存在异构性（即存在多样性和差别）： 网络 计算机硬件 操作系统 编程语言 由不同开发者完成的软件实现 中间件：指一个软件层，它提供了一个编程抽象，同时屏蔽了底层网络、硬件、操作系统和编程语言的异构性。有些中间件。如Java远程方法调用（Remote Method Invocation,RMI）,仅支持一种编程语言。大多数中间件在互联网协议上实现，由这些协议屏蔽了底层网路的差异，但所有的中间件要解决操作系统和硬件的不同。 处理解决异构性问题之外，中间件为服务器和分布式应用的程序员提供了一致的计算模型。这些模型包括远程方法调用、远程时间通知、远程SQL访问和分布式事务处理。 异构性和移动代码中移动代码是指能从一台计算机发送到另一台计算机发送到另一台计算机，并在目的计算机上执行的代码，Java applet是一个例子。适合在一种计算机上运行的代码未必适合在另一种计算机上运行，因为可执行程序通常依赖于计算机的指令集和操作系统。 虚拟机方法提供了一种使代码可在任何计算机上运行的方法：某种语言的编译器生成一台虚拟机的代码而不是某种硬件代码，例如，Java编译器生成Java虚拟机的代码，虚拟机通过解释的方法来执行它。为了使Java程序嫩个运行，要在每种计算机上实现一次Java虚拟机。 今天，最常使用的移动代码是将一些Web页面的JavaScript程序装载到客户端浏览器中。 ","date":"2021-11-10 10:24:24","objectID":"/distributedsystem_base_01/:5:1","tags":["distributed system"],"title":"DistributedSystem_base_01","uri":"/distributedsystem_base_01/"},{"categories":["School courses"],"content":"开放性 计算机系统的开放性是决定系统能否以不同的方式被扩展和重新实现的特征。分布式系统的开放性主要取决于新的资源共享服务能被增加和供多种客户程序使用的程度。 除非软件开发者能获得系统组件的关键软件接口的规范和文档，否则无法实现开放性。一句话发布关键接口。这个过程类似接口的标准化，但它进程避开官方的标准化过程，官方的标准化过程非常繁琐且进度缓慢。 然而发布接口仅是分布式系统增加和扩展服务的起点。设计者所面临的挑战是解决由不同人构造的由许多组件组成的分布式系统的复杂性。 互联网协议的设计者引入了一系列称为“征求意见文档”（Requests For Comments，RFC）的文档，每个文档有一个编号。 按这种方式支持资源共享的系统之所以被称为开放的分布式系统，主要是强调它们是可扩展的。它们通过在网络中增加计算机实现在硬件层次上的扩展，通过引入新的服务、重新实现旧的服务实现在软件层次上的扩展，最终使得应用程序能够共享资源。开放系统常被提到的好处是它们与销售商无关。 开放的分布式系统的特征总结如下： 发布系统的关键接口是开放系统的特征 开放的分布式系统是基于一致的通信机制和发布接口访问共享资源的。 开放的分布式系统能用不同销售商提供的异构硬件和软件构造，但如果想让系统正确工作，就要仔细测试和验证每个组件与发布的标准之间的一致性。 ","date":"2021-11-10 10:24:24","objectID":"/distributedsystem_base_01/:5:2","tags":["distributed system"],"title":"DistributedSystem_base_01","uri":"/distributedsystem_base_01/"},{"categories":["School courses"],"content":"安全性 分布式系统中维护和使用的众多信息资源对用户具有很高的内在价值，因此它们的安全相当重要。信息资源的安全性包括三个部分：机密性（防止泄露给未授权的个人）、完整性（防止被改变或被破坏）、可用性（防止对访问资源的手段的干扰）。 安全性不止涉及对消息的内容保密，还涉及确切知道用户或代表用户发送消息的其他代理的身份。利用机密技术可满足这两个挑战。 然而，下面两个安全方面所面临的挑战目前还没有完美解决： 拒绝服务攻击：另一个安全问题是处于某些用户可能希望中断服务。可用下面的方法实现这个目的：用大量无意义的请求攻击服务器，使得重要的用户不能使用它。这称为拒绝服务攻击。现在通过在世间发生后抓获和惩罚犯罪者来解决这种攻击，但这不是解决这种问题的通用方法。 移动代码的安全性：移动代码需要小心处理。因为有些程序表面上可能一副有意思的画，但实际上却在访问本地资源，或者可能是拒绝服务攻击的一部分。 ","date":"2021-11-10 10:24:24","objectID":"/distributedsystem_base_01/:5:3","tags":["distributed system"],"title":"DistributedSystem_base_01","uri":"/distributedsystem_base_01/"},{"categories":["School courses"],"content":"可伸缩性 分布式系统可在不同的规模（从小型企业内部网到互联网）下有效且高效地运转。如果资源数量和用户数量激增，系统仍能保持其有效性，那么该系统就被称为可伸缩性。 可伸缩性分布式系统的设计面临下列挑战： 控制物理资源的开销 控制性能损耗 防止软件资源用尽：例如IP地址 避免性能瓶颈：通常，算法应该是分散型，以避免性能瓶颈。例如域名系统的前身，那时名字表被保存在一个主文件中，可被任何需要它的计算机下载。当互联网中只有几百个计算机时，这是可以的，但这不久就变成了一个严重的性能和管理瓶颈。现在，域名系统将名字表分区，分散到互联网中的服务器上，并采用本地管理的方式，从而解决了这个瓶颈。 ","date":"2021-11-10 10:24:24","objectID":"/distributedsystem_base_01/:5:4","tags":["distributed system"],"title":"DistributedSystem_base_01","uri":"/distributedsystem_base_01/"},{"categories":["School courses"],"content":"故障处理 计算机系统有时会出现故障。当硬件或软件发生故障时，程序可能会产生不正确的结果或者在它们完成应该进行的计算之前就停止了。 分布式系统的故障时部分的，也就是说，有些组件出了故障而有些组件运行正常。因此故障的处理相当困难。接下来我们讨论一下处理故障的技术： 检测故障：有些故障能被检测到。例如，校验和可用于检测消息或文件中出现的错误。而有些故障时很难甚至不能被检测到的。面临的挑战是如何在有故障出现的情况下进行管理，这些故障不能被检测到但可以被猜到。 掩盖故障：有些被检测到的故障能被隐藏起来或降低她的严重程度。下面是隐藏故障的两个例子 ： 1）消息在不能到达时重传。 2）将文件数据写入两个磁盘，如果一个磁盘损坏，那么另一个磁盘的数据仍是正确的。 降低故障严重程度的例子是丢掉被损坏的消息。这样，该消息可以被重传。读者可能意识到，隐藏故障的技术不能保证在最坏情况下有效。例如，第二个磁盘上的数据可能也坏了，或消息无论怎样重传都不能在合理的时间到达。 容错：互联网上的大多服务确实可能发生故障，试图检测并隐藏在这样大的网络、这么多的组件中发生的所有故障是不太实际的。服务的客户能被设计成容错的，这通常也涉及用户要容忍错误。例如，当Web浏览器不能与Web服务器连接时，它不会让用户一直等待它与服务器建立连接，而是通知用户这个问题，让用户自由选择是否尝试稍后再连接。 故障恢复：恢复涉及软件的设计，以便在服务器崩溃后，永久数据的状态能被恢复或“回滚”。通常再出现错误时，程序完成的计算是不完整的，被更新的永久数据（文件和其他保存在永久存储介质中的资料）可能处在不一致的状态。 冗余：利用冗余组件，服务可以实现容错。考虑下面的例子： 1）在互联网的任意两个路由器之间，至少存在两个不同的路由。 2）在域名系统中，每个名字表至少被复制到两个不同的服务器上。 3）数据库可以被复制到几个服务器上，以保证在任何一个服务器上有错误时，客户就被重定向到剩下的服务器上。 ","date":"2021-11-10 10:24:24","objectID":"/distributedsystem_base_01/:5:5","tags":["distributed system"],"title":"DistributedSystem_base_01","uri":"/distributedsystem_base_01/"},{"categories":["School courses"],"content":"并发性 在分布式系统中，服务和应用均提供可被客户共享的资源。因此，可能有几个客户同时试图访问一个共享资源的情况。 管理共享资源的进程可以一次接受一个客户请求，但这种方法限制了吞吐量。因此，服务和应用通常被允许并发地处理多个客户请求。 在分布式系统中，代表共享资源的任何一个对象必须负责确保它在并发环境中操作正确，这不仅适用于服务器，也适用于服务器，也适用于应用中的对象。因此，持有未打算用于分布式系统的对象实现的程序员必须做一些事情，使得对象在并发环境中能安全使用。 为了使对象在并发环境中能安全使用，它的操作必须在数据一致的基础上同步。者可通过标准的技术（如大多数操作系统所采用的信号量）来实现。 ","date":"2021-11-10 10:24:24","objectID":"/distributedsystem_base_01/:5:6","tags":["distributed system"],"title":"DistributedSystem_base_01","uri":"/distributedsystem_base_01/"},{"categories":["School courses"],"content":"透明性 透明性被定义成对用户和应用程序员屏蔽分布式系统的组件的分离性，使系统被认为是一个整体，而不是独立组件的集合。 ANSA参考手册和国际化标准化组织的开放分布式处理的参考模型（RM-ODP）识别出八种透明性（并用范围更广的移动透明性替换迁移透明性）： 访问透明性：用相同的操作访问本地资源和远程资源。 位置透明性：不需要知道资源的物理或网络位置就能访问它们 并发透明性：几个进程能并发地使用共享资源进行操作且互不干扰 复制透明性：使用资源的多个实例提升可靠性和性能，而用户和应用程序员无需知道副本的相关信息 故障透明性：屏蔽错误，不论是硬件组件故障还是软件组件故障，用户和应用程序员能够完成他们的任务 移动透明性：资源和客户能够在系统内移动而不会影响用户或程序的操作 性能透明性：当负载发生变化时，系统能被重新配置以提高性能 伸缩透明性：系统和应用能够进行扩展而不改变系统结构或应用算法 最重要的两个透明性是访问透明性和位置透明性，它们的有无对分布式资源的利用有很大影响，又是它们被统一称为网络透明性。 ","date":"2021-11-10 10:24:24","objectID":"/distributedsystem_base_01/:5:7","tags":["distributed system"],"title":"DistributedSystem_base_01","uri":"/distributedsystem_base_01/"},{"categories":["School courses"],"content":"服务质量 一旦提供给用户他们要求的功能，例如在一个分布式系统中的文件服务，我们就能继续探寻所提供的服务质量。系统的主要的非功能特性，即影响客户和用户体验的服务质量是可靠性、安全性和性能。满足变化的系统配置和资源可用性的适用性已被公认为服务质量的一个重要方面。 可靠性和安全性问题再设计大多是计算机系统时时关键的。服务质量的性能源于及时性和计算吞吐量，但它已被重新定义成满足及时性保证的能力。 一些应用，包括多媒体应用，处理时间关键性数据，这些数据是要求以固定速度处理或从一个进程传送到另一个进程的数据流。例如，一个电影服务可能由一个客户程序组成，该程序从一个视频服务器中检索电影并把它呈现到用户的屏幕上。该视频的连续帧在指定时间限制内显示给用户，才算是一个满意的结果。 ","date":"2021-11-10 10:24:24","objectID":"/distributedsystem_base_01/:5:8","tags":["distributed system"],"title":"DistributedSystem_base_01","uri":"/distributedsystem_base_01/"},{"categories":["School courses"],"content":"实例研究：万维网 在1989年3月，互联网还只属于少数人。在这一互联网的黎明期，HTTP诞生了。 蒂姆·伯纳斯-李博士提出了一种让远隔两地的研究者们共享知识的设想，这一最初设想的基本理念是：借助多文档之间相互关联形成的超文本（HyperText），连成可相互参阅的WWW（World Wide Web,万维网）。 超文本（Hypertext）：在互联网早期的时候，我们输入的信息只能保存在本地，无法和其他电脑交互。我们保存的信息通常都以文本即简单字符的形式存在，文本是一种能够被计算机解析的有意义的二进制数据包。而随着互联网的高速发展，两台电脑之间能够进行数据的传输后，人们不再满足只能在两台电脑之间传输文字，还想要传输图片、音频、视频，甚至是超链接，那么文本的语义就被扩大了，这种语义扩大后的文本就被称为超文本（HyperText）。 而为了实现这一理念，现在已经提出了3项WWW构建技术，分别是： 把SGML（Standard Generalized Markup Langrage，标准通用标记语言）作为页面的文本标记语言的HTML（HyperText Markup Language，超文本标记语言） 作为文档传输协议的HTTP（HyperText Transfer Protocol,超文本传输协议） 指定文档所在地址的URL（Uniform Resource Locator，统一资源定位符） WWW这一名称，是Web浏览器当年用来浏览超文本的客户端应用程序是的名称。现在则用来表示这一系列的集合，也可简称为Web。 除了这三样技术外，还有Javascript，提供比HTML标准化窗口部件质量更好的用户交互，用于更新Web页面的部分内容而不必取得该页面的全新版本并重新显示。AJAX处理异步情况等等技术。 Web之所以取得巨大的成功，是因为许多个人或机构能比较容易地发布资源，它的超文本结构适合组织多种类型的信息，而且Web体系结构具有开放性。Web体系结构所基于的标准很简单，且早被广泛发布。它使得许多新的资源类型和服务可以集成到一起。 Web成功的背后也存在一些设计问题，首先，它的超文本模型再某些方面有所欠缺。如果删除或移动了一个资源，那么就会存在对资源所谓“悬空”链接，会使用户请求落空。此外，还存在用户“在超空间迷失”这个常见的问题。用户经常发现自己处于混乱状态下，跟随许多无关的链接打开完全不同的页面，使得有些情况下可靠性值得怀疑。 在Web上查找信息的另一种方法是使用搜索引擎，但这种方法在满足用户真正需求方面是相当不完美的。要解决这个问题，资源描述框架[www.w3.org V]中介绍过,一种方法是生成标准的表达事务元数据的词汇、语法和语义，并将元数据封装在相应的Web资源中供程序访问。除了查找Web页面中出现的词组外，从原理上讲，程序可以完成对针对元数据的搜索，然后，根据语义匹配编译相关的链接列表。总而言之，由互连的元数据资源组成的Web就是语义Web。 作为一个系统体系结构，Web面临规模的问题。常见的Web服务器会在一秒中有很多点击量，结果导致对用户的应答变慢。 ","date":"2021-11-10 10:24:24","objectID":"/distributedsystem_base_01/:6:0","tags":["distributed system"],"title":"DistributedSystem_base_01","uri":"/distributedsystem_base_01/"},{"categories":["School courses"],"content":"小结 分布式系统无处不在。 资源共享是构造分布式系统的主要因素。 分布式系统的构造面临许多挑战： 异构性 开放性 安全性 可伸缩性 故障处理 透明性 服务质量 ","date":"2021-11-10 10:24:24","objectID":"/distributedsystem_base_01/:7:0","tags":["distributed system"],"title":"DistributedSystem_base_01","uri":"/distributedsystem_base_01/"},{"categories":["Advanced learning"],"content":"1. Linux 背景知识 Linux 有两种含义： 一种是 Linus 编写的开源操作系统的内核 另一种是广义的操作系统 执行环境 云主机 虚拟机（较推荐） 无数据的 PC（不推荐多系统混跑） linux版本： 内核版本 内核版本分为三个部分 主版本号、次版本号、末版本号 次版本号是奇数为开发版，偶数为稳定版（但从2.6开始就不这样了） 发行版本（因为linux是开源的）5种 Redhat Enterprise Linux:RedHat公司发行，软件经过专业人员的测试，非常稳定，但是需要付费。 Fedora发行版本，也是RadHat发行，组建一个社区免费提供这个操作系统，软件较新，但未经过RedHat的专业测试，稳定性较差。 centos，是基于Enterprise Linux 的源代码经行编译的，把RedHad的商标和字样去掉了，故免费。 Debian和Ubuntu 不是字符桌面，有图形界面。 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:1:0","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"2. 系统操作 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:2:0","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"帮助命令man help info manual: man ls;man 章节号 man；man -a passwd help: 内部命令(命令解释器shell自带的命令 type cd查看cd命令类型)：help cd 外部命令：ls –help info：比help 更详细，可以作为help的补充，全英文。 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:2:1","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"linux文件管理 一切皆文件 windows里有注册表，资源管理器等组件，控制linux自身的统统都是文件，linux文件管理非常重要 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:2:2","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"文件查看 tab可以进行目录补全 pwd cd cd - 回到上次目录 cd ..(/)回到上一级目录 cd /path/to/…. 绝对路径 cd ./path/to/… 相对路径（./可以省略） ls -l长格式显示（显示大小单位为Mb时可用-lh） -a显示隐藏文件 -r逆序显示 -t时间顺序显示 -R递归显示 -F把文件按照类型归类，主要区分目录文件、可执行文件、链接文件，并且在末尾加上 / 、*、@符号标识 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:2:3","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"目录文件的创建和删除 只列出了少量命令 mkdir mkdir a b c mkdir /a/b /a目录已存在 mkdir -p /a/b/c/d 无需a b c等目录存在 mkdir a b c -p 忽略已存在a b c 的报错 rmdir 删除空目录，目录下有空目录也不行，体现了“一切皆文件” rm -r -f（/rf） 可以删除非空目录，不去进行提示删除目录，具有一定危险性 eg: rm -r -f / a 不小心在/a之间加空格会导致删除所有目录且不提示 -i 删除前逐一询问确认 -f 即使原档案属性设为唯读，亦直接删除，无需逐一确认 -r 将目录及以下之档案亦逐一删除 cp -r 复制⽬录 -p 保留访问权限、修改时间 -a 等同于 -dpR（保留权限、属组、修改时间） -v 显示复制过程 -i 会在复制文件的时候给提示 如果复制的目标文件存在 会给你提示是否要覆盖如果目标文件不存在那么就直接复制了 mv mv /a /b将a改名为b（可与移动同时进行），在linux底层操作即进行了一个移动 更多命令见命令大全 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:2:4","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"通配符（通用的匹配符号） 是shell内建的符号，用于多个相似的文件进行操作 *匹配任何字符串 ？匹配单个字符 [abc]匹配abc任意一个字符 [a-z]匹配一个范围 [!xyz]或[^xyz] 不匹配 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:2:5","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"文件操作 文本内容查看 cat ⽂本内容显示到终端 head 查看⽂件开头（默认10行，-5可显示5行） tail 查看⽂件结尾（行数同head）(-f可进行跟踪) eg:tail -10 /etc/passwd 查看psaawd文件中倒数十行 常⽤参数 -f ⽂件内容更新后，显示信息同步更新 wc 统计⽂件内容信息（-l查看行数） more 分行显示 （空格继续显示） less more和less: less:由于more不能后退，就取more的反义词less加上后退功能 所以Linux里流传着这样一句话：“less is more”. 总结下more 和 less的区别: less可以按键盘上下方向键显示上下内容,more不能这样 less不必读整个文件，加载速度会比more更快 less退出后shell不会留下刚显示的内容,而more退出后会在shell上留下刚显示的内容 打包压缩解压 最早的 Linux 备份介质是磁带，使⽤的命令是 tar 可以打包后的磁带⽂件进⾏压缩储存，压缩的命令是 gzip 和 bzip2 经常使⽤的扩展名是 .tar.gz .tar.bz2 .tgz tar 打包命令 c 打包(cf .tar) x 解包 f 指定操作类型为⽂件 可以使⽤ gzip 和 bzip2 命令单独操作通常和 tar 命令配合操作 -z gzip 格式压缩和解压缩(czf .tar.gz) -j bzip2 格式压缩和解压缩(cjf .tar.bz2)，压缩比例更高，执行时间更慢。 vim的四种模式 vim是一个vi向上兼容的文本编辑器，vim写的时候实际上是先复制一个隐藏文件，写入其中，保存退出时再用隐藏文件替换目的文件。 正常模式 正常模式下输入： i:进入插入模式光标位置不动 I:进入插入模式光标移到行首 a:进入插入模式光标移到下一位 A:进入插入模式光标移到行末 o:进入插入模式光标在原来那一行的下一行，另起一行 O:进入插入模式光标在原来那一行的上一行，另起一行 ::进入命令模式 hjkl:正常模式下光标上下左右移动 复制剪切粘贴输入错误进行重做 y: yy:光标在某一行输入n(不输入时默认为1，作为从当前行开始要复制的行数) yy，粘贴用p y$:复制当前字符到行末的字符 d:剪切 dd d$ u:撤销 ctrl+r:重做 x:单个字符删除 r:替换当前字符 n(你要移动光标到哪一行)+G g到第一行 G到最后一行 ^到当前行的开头 $到当前行的结尾 命令模式 文件的保存、退出、查找、替换，在正常模式下输入： w /test.txt 将文本保存到新文件，w直接保存到原始文件 wq保存并推出 q!不保存退出 ！执行linux命令，有时候在打开vim的同时需要临时执行一条命令，eg:!ifconfig(查看ip地址) /查找eg:/x+enter光标自动移到第一个x,按n可以移动到下一个x，按N可以移到上一个x s/old/new 在光标所在行，将第一个旧的字符替换成新的字符 %s/old/new 所有行，将第一个旧的字符替换成新的字符 %s/old/new/g 所有行，将所有旧的字符替换成新的字符、 n,m+前三个命令是在[n,m]行进行替换，左闭右闭 set nohlsearch去除高亮显示 set nu:显示行数 set nonu:不显示行数 修改vim配置在/etc/vimrc文件里操作 比如在最后一行添加set nu则以后每次打开文件都会显示行号 可视模式 用于对文件进行重复的大量操作可以一次性执行完成 v 字符可视模式 V 行可视模式 ctrl+v 块可视模式（用的最多） 配合d和I可以进行块的便利操作 eg:进入块可视模式，用hjkl选择一个块，I可以在块头插入比如abc再按两次esc可见每行都被插入了abc；选中一个块，按d直接删除块 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:2:6","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"用户和用户组管理及密码管理 windows linux都是多用户操作系统。只是windows的用户一般只有一个。 多用户操作系统的目的是隔离 用户权限隔离 系统资源隔离 root 用户与普通用户的区别 用户管理常用命令 useradd 新建用户 id+用户名 可显示相关信息（uid gid 以及组号） userdel 删除用户 一般会加-r选项，因为如果不加，用户的家目录就会被保留下来，防止误删数据，加-r后都会删除 可查看/etc/passwd /etc/shadow passwd 修改用户密码 usermod 修改用户属性 可接很多属性如-a -c -d -e -g……。经常使用的一个属性是-d（用户的新登陆目录，家目录） 修改用户组 eg: usermod -g group1 user1 chage 修改用户属性 change age的缩写，可更改用户密码过期信息 组管理命令 groupadd 新建用户组 新建用户加入组有两种方法： 先新建用户再用usermod -g 直接useradd -g group1 user1 groupdel 删除用户组 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:2:7","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"su和sudo 用户切换 su 切换用户 su - USERNAME 使用 login shell 方式切换用户 -的作用是在用户切换的同时将运行环境也变更为目标用户的运行环境 不带 - 为不完全切换，只切换了身份，需要额外切换目录 sudo 以其他用户身份执行命令 visudo 设置需要使用 sudo 的用户（组） #30分钟后关闭主机，需要管理员权限 shutdown -h 30 #停止关闭主机命令 shutdown -c vi sudo后可手动添加某用户权限eg:(A B=C )=(user1 ALL=/sbin/shutdown -c) 字符终端时B可以是localhost C是命令，在命令模式输入!which shutdown可得到shutdown命令的位置 user1就被临时赋予了使用shutdown -c的权限 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:2:8","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"用户和用户组的配置文件介绍 用户配置文件 /root root 用户的家目录 /home/USERNAME 普通用户默认家目录位置 /etc/passwd 用户配置文件 /etc/shadow 用户密码相关配置文件 /etc/group 用户组配置文件 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:2:9","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"文件和目录权限的表示方法 文件类型： - 普通⽂件 d ⽬录⽂件 b 块特殊⽂件（块设备） c 字符特殊⽂件（字符设备） l 符号链接（快捷方式） f 命名管道 s 套接字⽂件 字符权限表示方法 r 读 w 写 x 执行 数字权限的表示方法 r = 4 w = 2 x = 1 - rw- r-x r- - 1 userame groupname mtime filename 第一列：文件类型加权限。 第一个字符为文件类型，d表示目录，l表示软连接，-表示文件，c表示字符设备文件。后面的字符分为三组，所有者u，所属组g,其它人o. r表示可读，w表示可写，x表示可执行。 第2列是硬链接的引用次数。 第3列是文件的拥有者账户。只能有一个。 第4列是文件的拥有者账户所在组名。只能有一个。 第5列是文件所占有的字节数。 第6列是文件最后修改时间。 第7列是文件名。 创建文件有默认权限，根据 umask 值计算 目录权限： x 进入目录 rx 显示目录内的文件名 wx 修改目录内的文件名 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:2:10","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"文件权限的修改方法和数字表示方法 修改权限： chmod 修改文件、目录权限 u/g/o/a 前三个分别对应属主、属组、其他用户的权限，a代表所有的权限 chmod u+/-/= rwx file 数字权限表示：chmod 446 file 一个新建文件的默认权限是644，即666-0022（umask） chown 更改属主、属组 chown user /dir改属主 chown :group1 /dir改属组 或者 chown user1:group1 /dir chgrp 可以单独更改属组，不常用 chgrp group1 /dir ctrl+r搜索之前出现的命令 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:2:11","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"权限管理和文件的特殊权限 echo 123 \u003e file 将123输出到file，\u003e是输出重定向符号，会将file先清空。 注意：如果一个文件的属主权限和其属组的权限有冲突，以属主的权限为准。 对于目录来说，x执行就是进入目录,rx是可以进入查看，wx是可以进入修改，只给r权限只能看到文件名。。 特殊权限： SUID 用于二进制可执行文件，执行命令时取得文件属主权限 如/usr/bin/passwd，执行passwd自动获取到root身份，只有root能改/etc/shadow （/etc/shadow里边是用户密码） chmod 4755 /test/b 755是目的文件属性 SGID 用于目录，在该目录下创建新的文件和目录，权限自动更改为该目录的属组，文件共享会用到 SBIT 用于目录，该目录下新建的文件和目录，仅 root 和自己可以删除，用sbit位进行标记 chmod 1777 /test 777是目的文件夹属性 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:2:12","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"3. 服务管理 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:3:0","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"网络管理 ⽹络状态查看 ： net-tools （centos7以前） ifconfig eth0 第⼀块⽹卡（⽹络接⼝） 第⼀个⽹络接⼝可能叫做下⾯的名字 eno1 板载⽹卡 ens33 PCI-E⽹卡 enp0s3 ⽆法获取物理信息的 PCI-E ⽹卡 CentOS 7 使⽤了⼀致性⽹络设备命名，以上都不匹配则使⽤ eth0 ⽹络接⼝命名修改 ⽹卡命名规则受 biosdevname 和 net.ifnames 两个参数影响 编辑 /etc/default/grub ⽂件，在GRUB_COMMIT_LINUX项中增加 biosdevname=0 net.ifnames=0 （grub是系统刚开始启动的时候，引导内核需要一个工具，类似于启动菜单，这个启动菜单可以设置一些参数，传递到内核，真正启动时读取到的文件是/boot/grub2/grub.cfg） 更新 grub grub2-mkconfig -o /boot/grub2/grub.cfg 重启后网卡生效 reboot route netstat iproute2（centos7、8） ip ss 查看⽹卡物理连接情况 mii-tool eth0 当网卡通信需要连接其他网络地址范围的时候，需要配置一个网关路由，查看⽹关 route -n 使⽤ -n 参数不解析主机名 [test@Centos8 workspace]$ route Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface default _gateway 0.0.0.0 UG 100 0 0 eth0 172.17.0.0 0.0.0.0 255.255.0.0 U 0 0 0 docker0 172.25.208.0 0.0.0.0 255.255.240.0 U 100 0 0 eth0 [test@Centos8 workspace]$ route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 172.25.223.253 0.0.0.0 UG 100 0 0 eth0 172.17.0.0 0.0.0.0 255.255.0.0 U 0 0 0 docker0 172.25.208.0 0.0.0.0 255.255.240.0 U 100 0 0 eth0 ⽹络配置修改、路由命令 ifconfig \u003c接⼝\u003e \u003cIP地址\u003e [netmask ⼦⽹掩码 ]（云主机会立即生效）eg:ifconfig eth0 10.211.55.4 ifup \u003c接⼝\u003e （启动） ifdown \u003c接⼝\u003e 添加⽹关（删除del） route add default gw \u003c⽹关ip\u003e route add -host \u003c指定ip\u003e gw \u003c⽹关ip\u003e route add -net \u003c指定⽹段\u003e netmask \u003c⼦⽹掩码\u003e gw \u003c⽹关ip\u003e ip命令 ip addr ls ifconfig ip link set dev eth0 up ifup eth0 ip addr add 10.0.0.1/24 dev eth1 ifconfig eth1 10.0.0.1 netmask 255.255.255.0 ip route add 10.0.0/24 via 192.168.0.1 route add -net 10.0.0.0 netmask 255.255.255.0 gw 192.168.0. ⽹络故障排除 从上到下依次排除： ping：检查到目标主机是否畅通 traceroute： Ping有效，但网络依旧异常，可追踪服务器每一跳服务质量，显示数据包到主机间的路径 eg:traceroute -w 1（指1秒） www.baidu.com mtr：检查到目标主机中间是否有数据报丢失，更详细 nslookup：查看域名对应的IP eg:nslookup www.baidu.com telnet：查看端口连接状态 eg:telnet www.baidu.com 80 tcpdump：抓取分析数据包 eg:tcpdump -i any -n port 80(任意网卡、80端口数据包、以IP形式进行显示)（捕获主机的话用host eg: ~-i any host 10.0.0.1）（两者都要可用and eg: ~host 10.0.0.1 and port 80）（~ -w /filename保存到文件中） netstat：服务的监听地址范围 netstat -ntpl n显示IP不显示域名 t 以TCP方式截取要显示的内容，非UDP（UDP是-p） p 显示进程，除了显示端口之外，还要显示端口对应哪一个进程 l TCP的一个状态，叫做listen，监听服务 [test@Centos8 workspace]$ netstat -ntpl (Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.) Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:5355 0.0.0.0:* LISTEN - tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN - tcp6 0 0 :::5355 :::* LISTEN - ss：服务的监听地址范围，参数和netstat基本相同 ⽹络服务管理 : ⽹络服务管理程序分为两种，分别为SysV和systemd service network start|stop|restart|status chkconfig -list network chkconfig –level 2345 network off禁用2345network systemctl list-unit-files NetworkManager.service systemctl start|stop|restart NetworkManger systemctl enable|disable NetworkManger 常⽤⽹络配置⽂件: ifcfg-eth0 /etc/hosts /etc/sysconfig/network-scripts/下每个ifcfg开头的文件都对应着一个网络接口，可以配置这些网卡。 route -n可以查看网关 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:3:1","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"软件包管理器的使用及软件包的安装 包管理器是⽅便软件安装、卸载，解决软件依赖关系的重要⼯具 CentOS、RedHat 使⽤ yum 包管理器，软件安装包格式为 rpm Debian、Ubuntu 使⽤ apt 包管理器，软件安装包格式为 deb rpm命令 rpm 包格式 vim-common-7.4.10-5.el7.x86_64.rpm 软件名称 软件版本 系统版本 平台 rpm 命令常⽤参数 -q 查询软件包 -i 安装软件包（要加软件包完整名称） -e 卸载软件包 rpm -qa | more查看所有安装的软件包 rpm -q vim-common查看某个软件包 yum包管理器也叫yum仓库 rpm 包的问题 需要⾃⼰解决依赖关系 软件包来源不可靠 CentOS yum 源 http://mirror.centos.org/centos/7/ 国内镜像 https://opsx.alibaba.com/mirror yum makecache切换镜像后更新缓存 常⽤选项 install 安装软件包 remove 卸载软件包 list| grouplist 查看软件包 update 升级软件包 源代码编译安装 ⼆进制安装 源代码编译安装 wget https://openresty.org/download/openresty-1.15.8.1.tar.gz tar -zxf openresty-VERSION.tar.gz cd openresty-VERSION/ ./configure –prefix=/usr/local/openresty指定安装目录 make -j2 指定两个内核 make install ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:3:2","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"内核升级 rpm 格式内核（不能获得最新稳定版内核） 查看内核版本 uname –r 升级内核版本 yum install kernel-3.10.0 升级已安装的其他软件包和补丁 yum update 源代码编译安装内核： 安装依赖包 yum install gcc gcc-c++ make ncurses-devel openssl-devel elfutils-libelf-devel 下载并解压缩内核 https://www.kernel.org tar xvf linux-5.1.10.tar.xz -C /usr/src/kernels 配置内核编译参数 cd /usr/src/kernels/linux-5.1.10/ make menuconfig | allyesconfig | allnoconfig 使⽤当前系统内核配置 cp /boot/config-kernelversion.platform /usr/src/kernels/ linux-5.1.10/.config 查看 CPU lscpu 编译 make -j2 all 安装内核 make modules_install make install ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:3:3","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"grub配置文件介绍 启动引导软件grub grub 配置⽂件 /etc/default/grub（主要关注：grub_default和grub_cmdline_linux） /etc/grub.d/ /boot/grub2/grub.cfg grub2-mkconfig -o /boot/grub2/grub.cfg 使⽤单⽤户进⼊系统（忘记 root 密码） 重设root密码~ ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:3:4","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"ps top查看进程 查看命令 ps （ps -e , ps -e | more,ps -ef | more,ps -eLf可查看线程数） pstree top（top -p 18746） 结论： 进程也是树形结构 进程和权限有着密不可分的关系 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:3:5","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"进程的控制、关联、通信 调整优先级 nice 范围从-20 到 19 ，值越⼩优先级越⾼，抢占资源就越多 renice 重新设置优先级（已经运行的程序更改优先级 renice -n 15 19314） 进程的作业控制（前后台切换） jobs \u0026 符号 ctrl+z暂停 ctrl+c终止 进程通信：（比如管道、socket） 信号是进程间通信⽅式之⼀，典型⽤法是：终端⽤户输⼊中断命令，通过信号机制停⽌⼀个程序的运⾏。 使⽤信号的常⽤快捷键和命令 kill -l SIGINT 通知前台进程组终⽌进程 ctrl + c SIGKILL ⽴即结束程序，不能被阻塞和处理 kill -9 pid ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:3:6","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"守护进程 如何使你关掉终端也不杀死进程？ 使⽤ nohup 与 \u0026 符号配合运⾏⼀个命令 nohup 命令使进程忽略 hangup（挂起）信号 把输出追加到nohup.out文件中 关掉终端后，继续执行的进程a的父进程–也就是终端结束，进程a成了孤儿进程，会被1号进程收留 守护进程(daemon)和⼀般进程有什么差别呢？（开机自启，输出会打印到socket通信程序，socket通过套接字与系统日志进行通讯。daemon进程占用的目录是根目录）(/var/log系统日志) ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:3:7","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"screen和系统日志 使⽤ screen 命令 screen 进⼊ screen 环境 ctrl+a d 退出 (detached) screen 环境 screen -ls 查看 screen 的会话 screen -r sessionid 恢复会话 常⻅的系统⽇志/var/log（系统日志） message（常规日志） dmesg（内核运行相关信息） cron（周期性、计划任务日志信息） secur（安全日志） ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:3:8","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"服务管理工具systemctl 服务（提供常⻅功能的守护进程）集中管理⼯具 service /etc/init.d/ systemctl systemctl 常⻅操作 systemctl start | stop | restart | reload | enable(随开机运行) | disable |status 服务名称 软件包安装的服务单元 /usr/lib/systemd/system/ systemctl 的服务配置 [Unit] Requires = 新的依赖服务 After = 新的依赖服务 [Service] [Install] 安装到哪个默认启动级别 /lib/systemd/system systemctl get-default | set-default ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:3:9","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"SElinux 安全组件，安全但复杂，且会降低服务器的性能，生产环境下一般被关闭 MAC（强制访问控制）与 DAC（⾃主访问控制） 查看 SELinux 的命令 getenforce /usr/sbin/sestatus ps -Z and ls -Z and id -Z 关闭 SELinux setenforce 0 vim /etc/selinux/sysconfig ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:3:10","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"内存和磁盘管理 内存和磁盘使⽤率查看 free 如果不设swap分区，也就是虚拟内存，那当内存不足时，linux内核会随机杀掉占用内存较大的进程。一旦发现swap被占用了，尽量增大内存。 top fdisk -l df du du 与 ls 的区别 ext4 ⽂件系统 Linux ⽀持多种⽂件系统，常⻅的有 ext4 xfs NTFS（需安装额外软件） ext4 ⽂件系统基本结构⽐较复杂 超级块 超级块副本 i 节点(inode) 数据块(datablock) ext4 ⽂件系统深⼊理解 执⾏ mkdir 、touch、 vi 等命令后的内部操作 符号链接与硬链接 facl 磁盘配额的使⽤ ⽤户磁盘配额 xfs⽂件系统的⽤户磁盘配额 quota mkfs.xfs /dev/sdb1 mkdir /mnt/disk1 mount -o uquota,gquota /dev/sdb1 /mnt/disk1 chmod 1777 /mnt/disk1 xfs_quota -x -c ‘report -ugibh’ /mnt/disk1 xfs_quota -x -c ‘limit -u isoft=5 ihard=10 user1’ /mnt/disk1 磁盘的分区与挂载 常⽤命令 fdisk mkfs parted mount 常⻅配置⽂件 /etc/fstab 交换分区（虚拟内存）的查看与创建 增加交换分区的⼤⼩ mkswap swapon 使⽤⽂件制作交换分区 dd if=/dev/zero bs=4M count=1024 of=/swapfile 软件 RAID 的使⽤ RAID 与软件 RAID 技术 RAID 的常⻅级别及含义 RAID 0 striping 条带⽅式，提⾼单盘吞吐率 RAID 1 mirroring 镜像⽅式，提⾼可靠性 RAID 5 有奇偶校验 RAID 10 是RAID 1 与 RAID 0 的结合 软件 RAID 的使⽤ 逻辑卷管理 逻辑卷和⽂件系统的关系 为 Linux 创建逻辑卷 动态扩容逻辑卷 系统综合状态查看 使⽤ sar 命令查看系统综合状态 使⽤第三⽅命令查看⽹络流量 yum install epel-release yum install iftop iftop -P ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:3:11","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"4. Shell ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:4:0","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"什么是shell Shell 是命令解释器，用于解释用户对操作系统的操作 • Shell 有很多 • cat /etc/shells • CentOS 7 默认使用的 Shell 是 bash ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:4:1","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"linux的启动过程 BIOS-MBR-BootLoader(grub)-kernel-init-系统初始化-shell ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:4:2","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"shell脚本 UNIX 的哲学：一条命令只做一件事 • 为了组合命令和多次执行，使用脚本文件来保存需要执行的命令 • 赋予该文件执行权限（chmod u+rx filename） 标准的 Shell 脚本要包含哪些元素 • Sha-Bang • 命令 • “#”号开头的注释 • chmod u+rx filename 可执行权限 • 执行命令 • bash ./filename.sh. • ./filename.sh • source ./filename.sh • . filename.sh 内建命令和外部命令的区别 • 内建命令不需要创建子进程 • 内建命令对当前 Shell 生效 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:4:3","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"管道 管道与管道符 • 管道和信号一样，也是进程通信的方式之一 • 匿名管道（管道符）是 Shell 编程经常用到的通信工具 • 管道符是“|”，将前一个命令执行的结果传递给后面的命令 • ps | cat • echo 123 | ps 子进程与子 Shell • 子进程是 Shell 程序，称作子 Shell • 内部命令的结果不会传递给子 Shell ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:4:4","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"重定向 重定向符号 • 一个进程默认会打开标准输入、标准输出、错误输出三个文件描述符 • 输入重定向符号 “ \u003c” • 输出重定向符号 “\u003e” “»” “2\u003e” “\u0026\u003e” ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:4:5","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"变量查看 变量的查看方法 • echo • ${变量名} 在部分情况下可以省略为 $变量名 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:4:6","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"变量作用范围 • 变量的默认作用范围 • 变量的导出 • export ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:4:7","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"环境变量、预定义变量与位置变量 系统环境变量 • 环境变量：每个 Shell 打开都可以获得到的变量 • set 和 env 命令 • $? • $! • $$ $0 • $PATH • $PS1 环境变量配置文件 • 配置文件 • /etc/profile • /etc/bashrc • ~/.bashrc • ~/.bash_profile ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:4:8","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"环境变量配置文件 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:4:9","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"数组 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:4:10","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"转义和引用 特殊字符 • 特殊字符：一个字符不仅有字面意义，还有元意（meta-meaning） • # 注释 • ; 分号 • \\ 转义符号 • “和’ 引号 转义符号 • 单个字符前的转义符号 • \\n \\r \\t 单个字母的转义 • $ \\” \\ 单个非字母的转义 引用 • 常用的引用符号 • “ 双引号 • ‘ 单引号 • ` 反引号 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:4:11","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"运算符 运算符 • 赋值运算符 • 算数运算符 • 数字常量 • 双圆括号 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:4:12","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"特殊字符大全 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:4:13","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"test比较 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:4:14","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"if判断的使用 if-else判断的使用 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:4:15","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"嵌套if的使用 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:4:16","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"case分支 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:4:17","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"for的基本使用 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:4:18","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"c语言风格的for ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:4:19","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"while循环和until循环 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:4:20","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"循环的嵌套和break、continue语句 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:4:21","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"使用循环处理位置参数 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:4:22","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"自定义参数 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:4:23","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"系统函数库介绍 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:4:24","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"脚本资源控制 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:4:25","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"信号 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:4:26","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"一次性计划任务 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:4:27","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"周期性计划任务 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:4:28","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"为脚本加锁 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:4:29","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"5. 文本操作 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:5:0","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"元字符介绍 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:5:1","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"find演示 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:5:2","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"sed和awk介绍 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:5:3","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"sed替换命令讲解 加强版 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:5:4","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"sed的其他常用命令 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:5:5","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"sed多行模式空间 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:5:6","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"什么是sed的保持空间 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:5:7","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"awk ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:5:8","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"6. 服务 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:6:0","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"防火墙概述 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:6:1","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"iptables iptables规则的基本使用演示 iptables过滤规则的使用 iptables nat表的使用 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:6:2","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"firewalld ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:6:3","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"SSH SSH介绍之Telent明文漏洞 SSH服务演示 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:6:4","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"FTP服务器vsftpd介绍与软件包安装 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:6:5","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"vsftpd配置文件介绍 vsftp虚拟用户 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:6:6","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"sanba服务演示 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:6:7","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"NFS服务 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:6:8","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"Nginx基本配置文件 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:6:9","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"使用Nginx配置域名虚拟主机 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:6:10","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"LNMP环境搭建 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:6:11","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"DNS服务原理 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:6:12","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":["Advanced learning"],"content":"NAS演示 ","date":"2021-11-08 15:34:58","objectID":"/linux_base_01/:6:13","tags":["linux"],"title":"Linux_base_01","uri":"/linux_base_01/"},{"categories":null,"content":"关于网站 个人博客,学习笔记 ","date":"2021-11-06 00:00:00","objectID":"/about/:1:0","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"作者简介 哈尔滨工业大学（深圳）19 级计算机本科生，01 年出生，籍贯江西，共青团员，目前坐标深圳。 ","date":"2021-11-06 00:00:00","objectID":"/about/:2:0","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"关于博客 目前输出的博客很少，很多都是学习笔记，日后会改善。 ","date":"2021-11-06 00:00:00","objectID":"/about/:3:0","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"致谢 本站所有文章受创作共享 署名-非商业性 4.0 许可协议 / CC BY-NC 4.0 保护。 本站图片部分来自互联网以及哈尔滨工业大学（深圳）教学课件，仅供公益性的学习参考，在此表示感谢！此类图片的原版权所有者可在任何时候、以任何理由要求本站停止使用有关图片，其中包括被本站编辑（比如加注中文说明）过的图片， 联系方式见本站首页。 转载注明来源为本站首页网址 qizhengzou.github.io，或所转内容在本站的完整网址 ","date":"2021-11-06 00:00:00","objectID":"/about/:4:0","tags":null,"title":"About","uri":"/about/"}]