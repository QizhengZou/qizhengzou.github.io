---
title: "CN_HTTP"
date: 2022-01-24T20:52:12+08:00
lastmod: 2022-01-24
tags: [computer network]
categories: [Advanced learning]
slug: HTTP
draft: false
---
> 部分来自极客时间学习笔记
# HTTP
## 前言
**因特网、互联网、万维网**：
- 互联网 > 因特网 > 万维网
- 凡是能彼此通信的设备组成的网络就叫互联网
- 因特网是网络与网络之间所串连成的庞大网络，这些网络以一组标准的网络TCP/IP协议族相连
- 万维网是文件、图片、多媒体和其他资源的集合，资源通过超链接互相连接形成网络，并使用统一资源标志符（URL）标识。HTTP是万维网的主要访问协议。

据 NetCraft 公司统计，目前全球至少有 16 亿个网站、2 亿多个独立域名，而这个庞大网络世界的底层运转机制就是 HTTP。

HTTP 不就是请求 / 响应、GET/POST、Header/Body 吗？好像是哎，但又简略了点。

本文内容：
- 广度上从 HTTP 尽量向外扩展，不只讲协议本身，与它相关的 TCP/IP、DNS、SSL/TLS、Web Server 等
- 基于最新RFC标准文档

分析 HTTPS时用 Wireshark 从建立 TCP 连接时就开始抓包，从二进制最底层来分析里面的 Record、Cipher Suite、Extension，讲 ECDHE、AES、SHA384，再画出详细的流程图，做到“一览无余”

学习网络协议最重要的就是实践，咱们会用 Nginx 搭建一个“麻雀虽小，五脏俱全”的实验环境（**自身就是一个完整的网络环境，即使不联网也能够在里面收发 HTTP 消息。**）

## 破冰
### 历史
20 世纪 60 年代，美国国防部高等研究计划署（ARPA）建立了 ARPA 网，它有四个分布在各地的节点，被认为是如今互联网的“始祖”。

然后在 70 年代，基于对 ARPA 网的实践和思考，研究人员发明出了著名的 TCP/IP 协议。由于具有良好的分层结构和稳定的性能，TCP/IP 协议迅速战胜其他竞争对手流行起来，并在 80 年代中期进入了 UNIX 系统内核，促使更多的计算机接入了互联网。

1989 年，任职于欧洲核子研究中心（CERN）的蒂姆·伯纳斯 - 李（Tim Berners-Lee）发表了一篇论文，提出了在互联网上构建超链接文档系统的构想。这篇论文中他确立了三项关键技术。
- URI：即统一资源标识符，作为互联网上资源的唯一身份；
- HTML：即超文本标记语言，描述超文本文档；
- HTTP：即超文本传输协议，用来传输超文本。
（超文本有超链接，是网状结构，而普通文本是线性结构。）

蒂姆把这个系统称为“万维网”（World Wide Web），也就是我们现在所熟知的 Web。

20 世纪 90 年代初期的互联网世界非常简陋，计算机处理能力低，存储容量小，网速很慢。网络上绝大多数的资源都是纯文本，很多通信协议也都使用纯文本。这一时期的 HTTP 被定义为 0.9 版，结构比较简单，为了便于服务器和客户端处理，它也采用了纯文本格式。蒂姆·伯纳斯 - 李最初设想的系统里的文档都是只读的，所以只允许用“GET”动作从服务器上获取 HTML 文档，并且在响应请求之后立即关闭连接，功能非常有限。

1993 年，NCSA（美国国家超级计算应用中心）开发出了 Mosaic，是第一个可以图文混排的浏览器，随后又在 1995 年开发出了服务器软件 Apache，简化了 HTTP 服务器的搭建工作。同一时期，计算机多媒体技术也有了新的发展：1992 年发明了 JPEG 图像格式，1995 年发明了 MP3 音乐格式。HTTP/1.0 版本在 1996 年正式发布。它在多方面增强了 0.9 版，形式上已经和我们现在的 HTTP 差别不大了，例如：
- 增加了 HEAD、POST 等新方法；
- 增加了响应状态码，标记可能的错误原因；
- 引入了协议版本号概念；
- 引入了 HTTP Header（头部）的概念，让 HTTP 处理请求和响应更加灵活；
- 传输的数据不再仅限于文本。
但 HTTP/1.0 并不是一个“标准”，只是记录已有实践和模式的一份参考文档，不具有实际的约束力，相当于一个“备忘录”。

1995 年，网景的 Netscape Navigator 和微软的 Internet Explorer 开始了著名的“浏览器大战”，都希望在互联网上占据主导地位。最终微软的 IE 取得了决定性的胜利，而网景则“败走麦城”（但后来却凭借 Mozilla Firefox 又扳回一局）

在“浏览器大战”结束之后的 1999 年，HTTP/1.1 发布了 RFC 文档，编号为 2616，正式确立了延续十余年的传奇。

HTTP/1.1 与 HTTP/1.0 的一个重要的区别是：它是一个“正式的标准”，而不是一份可有可无的“参考文档”。这意味着今后互联网上所有的浏览器、服务器、网关、代理等等，只要用到 HTTP 协议，就必须严格遵守这个标准，相当于是互联网世界的一个“立法”。

HTTP/1.1 主要的变更点有：
- 增加了 PUT、DELETE 等新的方法；
- 增加了缓存管理和控制；
- 明确了连接管理，允许持久连接；
- 允许响应数据分块（chunked），利于传输大文件；
- 强制要求 Host 头，让互联网主机托管成为可能

只要是HTTP/1.1，就都是文本格式，虽然里面的数据可能是二进制，但分隔符还是文本。

现在许多的知名网站都是在HTTP/1.1这个时间点左右创立的，例如 Google、新浪、搜狐、网易、腾讯等，互联网开始爆发式增长。不过由于 HTTP/1.1 太过庞大和复杂，所以在 2014 年又做了一次修订，原来的一个大文档被拆分成了六份较小的文档，编号为 7230-7235，优化了一些细节，但此外没有任何实质性的改动。

当时也有一些弊病：主要是连接慢。但标准固定人们只能耍技巧，比如切图、js合并等网页优化手段。

Google 首先开发了自己的浏览器 Chrome，然后推出了新的 SPDY 协议，并在 Chrome 里应用于自家的服务器，如同十多年前的网景与微软一样，从实际的用户方来“倒逼”HTTP 协议的变革，这也开启了第二次的“浏览器大战”。

历史再次重演，不过这次的胜利者是 Google，Chrome 目前的全球的占有率超过了 60%。Google 借此顺势把 SPDY 推上了标准的宝座，互联网标准化组织以 SPDY 为基础开始制定新版本的 HTTP 协议，最终在 2015 年发布了 HTTP/2，RFC 编号 7540。

HTTP/2 的制定充分考虑了现今互联网的现状：宽带、移动、不安全，在高度兼容 HTTP/1.1 的同时在性能改善方面做了很大努力，主要的特点有：
- 二进制协议，不再是纯文本；
- 可发起多个请求，废弃了 1.1 里的管道；
- 使用专用算法压缩头部，减少数据传输量；
- 允许服务器主动向客户端推送数据；
- 增强了安全性，“事实上”要求加密通信。

在 HTTP/2 还处于草案之时，Google 又发明了一个新的协议，叫做 QUIC，而且还是相同的“套路”，继续在 Chrome 和自家服务器里试验着“玩”，依托它的庞大用户量和数据量，持续地推动 QUIC 协议成为互联网上的“既成事实”。

2018 年，互联网标准化组织 IETF 提议将“HTTP over QUIC”更名为“HTTP/3”并获得批准，HTTP/3 正式进入了标准化制订阶段。HTTP/3 现在还没正式推出，不过自 2017 年起， HTTP/3 已经更新到 30 多个草案了。

### HTTP的定义
HyperText Transfer Protocol。

协议意味着有**多个参与者为了达成某个共同的目的而站在了一起**，除了要无疑义地沟通交流之外，还必须明确地规定各方的“责、权、利”，约定该做什么不该做什么，先做什么后做什么，做错了怎么办，有没有补救措施等等。

**HTTP 是一个用在计算机世界里的协议。它使用计算机能够理解的语言确立了一种计算机之间交流通信的规范，以及相关的各种控制和错误处理方式。**

**HTTP 是一个在计算机世界里专门用来在两点之间传输数据的约定和规范**

最终定义：
**HTTP 是一个在计算机世界里专门在两点之间传输超文本数据的约定和规范”**

互联网（Internet）是遍布于全球的许多网络互相连接而形成的一个巨大的国际网络，在它上面存放着各式各样的资源，也对应着各式各样的协议，例如超文本资源使用 HTTP，普通文件使用 FTP，电子邮件使用 SMTP 和 POP3 等。

HTML 是超文本的载体，是一种标记语言，使用各种标签描述文字、图片、超链接等资源，并且可以嵌入 CSS、JavaScript 等技术实现复杂的动态效果。

在互联网世界里，HTTP 通常跑在 TCP/IP 协议栈之上，依靠 IP 协议实现寻址和路由、TCP 协议实现可靠数据传输、DNS 协议实现域名查找、SSL/TLS 协议实现安全通信。此外，还有一些协议依赖于 HTTP，例如 WebSocket、HTTPDNS 等。这些协议相互交织，构成了一个协议网，而 HTTP 则处于中心地位。

与HTTP相关的协议与技术（左边偏理论，右边偏应用）总图：![](https://raw.githubusercontent.com/QizhengZou/Image_hosting_rep/main/20220124232208.png)
### HTTP相关的概念
见总图右边部分。

#### **网络世界**：
- 实际的互联网是由许许多多个规模略小的网络连接而成的，这些“小网络”可能是只有几百台电脑的局域网，可能是有几万、几十万台电脑的广域网，可能是用电缆、光纤构成的固定网络，也可能是用基站、热点构成的移动网络……
- 我们通常所说的“上网”实际上访问的只是互联网的一个子集“万维网”（World Wide Web），它基于 HTTP 协议，传输 HTML 等超文本资源，能力也就被限制在 HTTP 协议之内。
- 互联网上还有许多万维网之外的资源，例如常用的电子邮件、BT（BitTorrent，一种内容分发协议，上传速度越快，下载速度越快；但BT下载速度不够稳定，当中断时则无法完整下载。） 和 Magnet（磁力链接，磁力链接是一种特殊链接，但是它与传统基于文件的位置或名称的普通链接（如http://xxx）不一样，它只是通过不同文件内容的Hash结果生成一个纯文本的“数字指纹”，并用它来识别文件。） 点对点下载、FTP 文件下载、SSH 安全登录、各种即时通信服务等等，它们需要用各自的专有协议来访问。
- 由于 HTTP 协议非常灵活、易于扩展，而且“超文本”的表述能力很强，所以**很多其他原本不属于 HTTP 的资源也可以“包装”成 HTTP 来访问**，这就是我们为什么能够总看到各种“网页应用”——例如“微信网页版”“邮箱网页版”——的原因。

#### **浏览器**：
- Google 的 Chrome、Mozilla 的 Firefox、Apple 的 Safari、Microsoft 的 IE 和 Edge（后者是前者的替代品，Edge是win10正式推出的，支持更多插件拓展，而IE在16年停止了更新），还有小众的 Opera 以及国内的各种“换壳”的“极速”“安全”浏览器。
- 浏览器本质上是一个 HTTP 协议中的请求方，使用 HTTP 协议获取网络上的各种资源。当然，为了让我们更好地检索查看网页，它还集成了很多额外的功能。（例如，HTML 排版引擎用来展示页面，JavaScript 引擎用来实现动态化效果，甚至还有开发者工具用来调试网页，以及五花八门的各种插件和扩展。）
- 在 HTTP 协议里，浏览器的角色被称为“User Agent”即“用户代理”，意思是作为访问者的“代理”来发起 HTTP 请求。不过在不引起混淆的情况下，我们通常都简单地称之为“客户端”。

#### **web服务器**：
- 作为HTTP 协议里响应请求的主体，通常也把控着绝大多数的网络资源
- web服务器的组成：硬件、软件
    - 硬件含义就是物理形式或“云”形式的机器，在大多数情况下它可能不是一台服务器，而是利用反向代理、负载均衡等技术组成的庞大集群。但从外界看来，它仍然表现为一台机器，但这个形象是“虚拟的”。
    - 软件含义的 Web 服务器可能我们更为关心，它就是提供 Web 服务的应用程序，通常会运行在硬件含义的服务器上。它利用强大的硬件能力响应海量的客户端 HTTP 请求，处理磁盘上的网页、图片等静态文件，或者把请求转发给后面的 Tomcat、Node.js 等业务应用，返回动态的信息。
- Apache成熟且适合入门。Nginx作为后起之秀，具备高性能、高稳定性、易拓展等优势，受高流量网站的青睐。此外，还有 Windows 上的 IIS、Java 的 Jetty/Tomcat 等，因为性能不是很高，所以在互联网上应用得较少。

#### **CDN**:
- 浏览器和服务器是 HTTP 协议的两个端点。但浏览器通常不会直接连到服务器，中间会经过“重重关卡”，其中的一个重要角色就叫做 CDN。
- **CDN，全称是“Content Delivery Network”，翻译过来就是“内容分发网络”。它应用了 HTTP 协议里的缓存和代理技术，代替源站响应客户端的请求。**
- 可以缓存源站的数据，让浏览器的请求不用“千里迢迢”地到达源站服务器，直接在“半路”就可以获取响应。如果 CDN 的调度算法很优秀，更可以找到离用户最近的节点，大幅度缩短响应时间。
- 除了基本的网络加速外，还提供负载均衡、安全防护、边缘计算、跨运营商网络等功能，能够成倍地“放大”源站服务器的服务能力，很多云服务商都把 CDN 作为产品的一部分。
- 作为透明代理与反向代理。

#### **爬虫**：
- 自动访问web资源的应用程序
- 据估计，互联网上至少有 50% 的流量都是由爬虫产生的，某些特定领域的比例还会更高
- 绝大多数爬虫是由各大搜索引擎“放”出来的，抓取网页存入庞大的数据库，再建立关键字索引，这样我们才能够在搜索引擎中快速地搜索到互联网角落里的页面
- **不好的地方**：过度消耗网络资源，占用服务器和带宽，影响网站对真实数据的分析，甚至导致敏感信息泄漏
- 反爬虫：网站自身的反爬机制以及“君子协定”robots.txt（约定哪些该爬，哪些不该爬）等。
- 爬与反爬都只用到了两个技术：HTTP,HTML
### HTTP相关的协议
见总图左边部分。

#### **TCP/IP**：
- TCP/IP 协议实际上是一系列网络通信协议的统称，其中最核心的两个协议是 TCP 和 IP，其他的还有 UDP、ICMP、ARP 等等，共同构成了一个复杂但有层次的协议栈。
- **这个协议栈有四层，最上层是“应用层”，最下层是“链接层”，TCP 和 IP 则在中间：TCP 属于“传输层”，IP 属于“网际层”。协议的层级关系模型非常重要。**
- IP 协议是“Internet Protocol”的缩写，主要目的是解决寻址和路由问题，以及如何在两点间传送数据包。IP 协议使用“IP 地址”的概念来定位互联网上的每一台计算机。
- 现在我们使用的 IP 协议大多数是 v4 版，地址是四个用“.”分隔的数字，例如“192.168.0.1”，总共有 2^32，大约 42 亿个可以分配的地址。看上去好像很多，但互联网的快速发展让地址的分配管理很快就“捉襟见肘”。所以，就又出现了 v6 版，使用 8 组“:”分隔的数字作为地址，容量扩大了很多，有 2^128 个，在未来的几十年里应该是足够用了。
- TCP 协议是“Transmission Control Protocol”的缩写，意思是“传输控制协议”，它位于 IP 协议之上，基于 IP 协议提供可靠的、字节流形式的通信，是 HTTP 协议得以实现的基础。**“可靠”是指保证数据不丢失，“字节流”是指保证数据完整**，所以在 TCP 协议的两端可以如同操作文件一样访问传输的数据，就像是读写在一个密闭的管道里“流动”的字节。
- 因此，HTTP协议运行在TCP/IP之上。

#### **DNS**：
- 域名系统”（Domain Name System）
- 在 DNS 中，“域名”（Domain Name）又称为“主机名”（Host），为了更好地标记不同国家或组织的主机，让名字更好记，所以被设计成了一个有层次的结构。
- 域名用“.”分隔成多个单词，级别从左到右逐级升高，最右边的被称为“顶级域名”。对于顶级域名，可能你随口就能说出几个，例如表示商业公司的“com”、表示教育机构的“edu”，表示国家的“cn”“uk”等
- 目前全世界有 13 组根 DNS 服务器，下面再有许多的顶级 DNS、权威 DNS 和更小的本地 DNS，逐层递归地实现域名查询。
- HTTP 协议中并没有明确要求必须使用 DNS，但实际上为了方便访问互联网上的 Web 服务器，通常都会使用 DNS 来定位或标记主机名，间接地把 DNS 与 HTTP 绑在了一起。

#### **URI、URL**：
- DNS 和 IP 地址只是标记了互联网上的主机，并没有确定要访问的资源。
- URI（Uniform Resource Identifier），中文名称是 统一资源标识符，使用它就能够唯一地标记互联网上资源。
- URI 另一个更常用的表现形式是 URL（Uniform Resource Locator）， 统一资源定位符，也就是我们俗称的“网址”，它实际上是 URI 的一个子集，不过因为这两者几乎是相同的，差异不大，所以通常不会做严格的区分。
- http://nginx.org/en/download.html URI 主要有三个基本部分构成：
    - **协议名**：即访问该资源应当使用的协议，在这里是“http”；
    - **主机名**：即互联网上主机的标记，可以是域名或 IP 地址，在这里是“nginx.org”；
    - **路径**：即资源在主机上的位置，使用“/”分隔多级目录，在这里是“/en/download.html”。

#### **HTTPS**（HTTP over SSL/TLS）：
- SSL/TLS是负责加密通信的安全协议，可以被用作HTTP的下层
- SSL 的全称是 **“Secure Socket Layer”** ，由网景公司发明，当发展到 3.0 时被标准化，改名为 TLS，即“Transport Layer Security”，但由于历史的原因还是有很多人称之为 SSL/TLS，或者直接简称为 SSL。
- SSL 使用了许多密码学最先进的研究成果，综合了对称加密、非对称加密、摘要算法、数字签名、数字证书等技术，能够在不安全的环境中为通信的双方创建出一个秘密的、安全的传输通道。
- 浏览器地址栏，如果有一个小锁头标志，那就表明网站启用了安全的 HTTPS 协议，而 URI 里的协议名，也从“http”变成了“https”

#### **代理**：
- 代理（Proxy）是 HTTP 协议中请求方和应答方中间的一个环节，作为“中转站”，既可以转发客户端的请求，也可以转发服务器的应答。
- 常见的代理：
    - 匿名代理：完全“隐匿”了被代理的机器，外界看到的只是代理服务器；
    - 透明代理：顾名思义，它在传输过程中是“透明开放”的，外界既知道代理，也知道客户端；
    - 正向代理：靠近客户端，代表客户端向服务器发送请求；
    - 反向代理：靠近服务器端，代表服务器响应客户端的请求；
- **由于代理在传输过程中插入了一个“中间层”，所以可以在这个环节做很多有意思的事情，比如：**
    - **负载均衡**：把访问请求均匀分散到多台机器，实现访问集群化；
    - **内容缓存**：暂存上下行的数据，减轻后端的压力；
    - **安全防护**：隐匿 IP, 使用 WAF 等工具抵御网络攻击，保护被代理的机器；
    - **数据处理**：提供压缩、加密等额外的功能。
- 关于 HTTP 的代理还有一个特殊的“代理协议”（proxy protocol），它由知名的代理软件 HAProxy 制订，但并不是 RFC 标准。
### 四层？七层？
什么四层负载均衡”“七层负载均衡”，什么“二层转发”“三层路由”  都是啥？

#### **TCP/IP网络分层模型**：
- 把复杂的网络通信划分出多个层次，再给每一个层次分配不同的职责，层次内只专心做自己的事情就好，典型的分而治之的思想。
- **TCP/IP协议栈层次图**：
```
----------------------
application layer /HTTP       ----OSI:L5,L6,L7
----------------------
transport layer /TCP/UDP      ----OSI:L4
----------------------
internet layer /IP            ----OSI:L3
----------------------
link layer /MAC (first layer) ----OSI:L2
----------------------
```
- 第一层叫“链接层”（link layer），负责在以太网、WiFi 这样的底层网络上发送原始数据包，工作在网卡这个层次，使用 MAC 地址（MAC地址（英语：Media Access Control Address），直译为媒体存取控制位址，也称为局域网地址（LAN Address），MAC位址，以太网地址（Ethernet Address）或物理地址（Physical Address），它是一个用来确认网络设备位置的位址。在OSI模型中，第三层网络层负责IP地址，第二层数据链路层则负责MAC位址 。MAC地址用于在网络中唯一标示一个网卡，一台设备若有一或多个网卡，则每个网卡都需要并会有一个唯一的MAC地址，摘自百度百科）来标记网络上的设备，所以有时候也叫 MAC 层。
- 第二层叫“网际层”或者“网络互连层”（internet layer），IP 协议就处在这一层。因为 IP 协议定义了“IP 地址”的概念，所以就可以在“链接层”的基础上，用 IP 地址取代 MAC 地址，把许许多多的局域网、广域网连接成一个虚拟的巨大网络，在这个网络里找设备时只要把 IP 地址再“翻译”成 MAC 地址就可以了。
- 第三层叫“传输层”（transport layer），这个层次协议的职责是保证数据在 IP 地址标记的两点之间“可靠”地传输，是 TCP 协议工作的层次，另外还有它的一个“小伙伴”UDP。（User Datagram Protocol） ，都是二进制协议。
    - TCP 是一个有状态的协议，需要先与对方建立连接然后才能发送数据，而且保证数据不丢失不重复。而 UDP 则比较简单，它无状态，不用事先建立连接就可以任意发送数据，但不保证数据一定会发到对方。两个协议的另一个重要区别在于数据的形式。TCP 的数据是连续的“字节流”，有先后顺序，而 UDP 则是分散的小数据包，是顺序发，乱序收。
    - 关于 TCP 和 UDP 可以展开讨论的话题还有很多，比如最经典的“三次握手”和“四次挥手”，一时半会很难说完，好在与 HTTP 的关系不是太大，以后遇到了再详细讲解。
- 协议栈的第四层叫“应用层”（application layer），由于下面的三层把基础打得非常好，所以在这一层就“百花齐放”了，有各种面向具体应用的协议。例如 Telnet、SSH、FTP、SMTP 等等，当然还有我们的 HTTP。
- **MAC 层的传输单位是帧（frame），IP 层的传输单位是包（packet），TCP 层的传输单位是段（segment），HTTP 的传输单位则是消息或报文（message）。但这些名词并没有什么本质的区分，可以统称为数据包。**

#### **OSI网络分层模型**：
- OSI，全称是“开放式系统互联通信参考模型”（Open System Interconnection Reference Model）。
- 背景：TCP/IP 发明于 1970 年代，当时除了它还有很多其他的网络协议，整个网络世界比较混乱。这个时候国际标准组织（ISO）注意到了这种现象，就想要来个“大一统”。于是设计出了一个新的网络分层模型，想用这个新框架来统一既存的各种网络协议。
- OSI层次模型：
```
------------------
application layer L7
------------------
presentation layer L6
------------------
session layer L5
------------------
transport layer L4
------------------
network layer L3
------------------
data link layer L2
------------------
physical layer L1
------------------
```
- 第一层：物理层，网络的物理形式，例如电缆、光纤、网卡、集线器等等；
- 第二层：数据链路层，它基本相当于 TCP/IP 的链接层；
- 第三层：网络层，相当于 TCP/IP 里的网际层；
- 第四层：传输层，相当于 TCP/IP 里的传输层；
- 第五层：会话层，维护网络中的连接状态，即保持会话和同步；
- 第六层：表示层，把数据转换为合适、可理解的语法和语义；
- 第七层：应用层，面向具体的应用传输数据。
- 对比一下就可以看出，TCP/IP 是一个纯软件的栈，没有网络应有的最根基的电缆、网卡等物理设备的位置。而 OSI 则补足了这个缺失，在理论层面上描述网络更加完整。
- **OSI 的分层模型在四层以上分的太细，而 TCP/IP 实际应用时的会话管理、编码转换、压缩等和具体应用经常联系的很紧密，很难分开。例如，HTTP 协议就同时包含了连接管理和数据格式定义。**


**所谓的“四层负载均衡”就是指工作在传输层上，基于 TCP/IP 协议的特性，例如 IP 地址、端口号等实现对后端服务器的负载均衡。**

**所谓的“七层负载均衡”就是指工作在应用层上，看到的是 HTTP 协议，解析 HTTP 报文里的 URI、主机名、资源类型等数据，再用适当的策略转发给后端服务器。**

#### TCP/IP协议栈的工作方式
HTTP 协议的传输过程就是通过协议栈逐层向下，每一层都添加本层的专有数据，层层打包，然后通过下层发送出去。

接收数据则是相反的操作，从下往上穿过协议栈，逐层拆包，每层去掉本层的专有头，上层就会拿到自己的数据。

但下层的传输过程对于上层是完全“透明”的，上层也不需要关心下层的具体实现细节，所以就 HTTP 层次来看，它不管下层是不是 TCP/IP 协议，看到的只是一个可靠的传输链路，只要把数据加上自己的头，对方就能原样收到。

### 域名相关
IP 协议的职责是“网际互连”，它在 MAC 层之上，使用 IP 地址把 MAC 编号转换成了四位数字，这就对物理网卡的 MAC 地址做了一层抽象，发展出了许多的“新玩法”。

但IP地址难记忆，从而发展出了DNS域名系统。

域名是一个有层次的结构，是一串用“.”分隔的多个单词，最右边的被称为“顶级域名”，然后是“二级域名”，层级关系向左依次降低。最左边的是主机名，通常用来表明主机的用途，比如“www”表示提供万维网服务、“mail”表示提供邮件服务，不过这也不是绝对的，名字的关键是要让我们容易记忆。

域名除了代替IP地址的其他用途：
- 在 Apache、Nginx 这样的 Web 服务器里，域名可以用来标识虚拟主机，决定由哪个虚拟主机来对外提供服务，比如在 Nginx 里就会使用“server_name”指令：
```
server {
    listen 80;                       #监听80端口
    server_name  www.baidu.com;  #主机名是www.baidu.com
    ... 
}
```
域名本质上还是个名字空间系统，使用多级域名就可以划分出不同的国家、地区、组织、公司、部门，每个域名都是独一无二的，可以作为一种身份的标识。
#### 域名解析
就像 IP 地址必须转换成 MAC 地址才能访问主机一样，域名也必须要转换成 IP 地址，这个过程就是“域名解析”。

DNS 的核心系统是一个三层的树状、分布式服务，基本对应域名的结构：
- 根域名服务器（Root DNS Server）：管理顶级域名服务器，返回“com”“net”“cn”等顶级域名服务器的 IP 地址；（目前全世界共有 13 组根域名服务器，又有数百台的镜像，10个在美国，2个在欧洲，1个在日本。而中国只有3个根域名镜像服务器，DNS解析的结果最终还会汇总到根域名服务器上。）
- 顶级域名服务器（Top-level DNS Server）：管理各自域名下的权威域名服务器，比如 com 顶级域名服务器可以返回 apple.com 域名服务器的 IP 地址；
- 权威域名服务器（Authoritative DNS Server）：管理自己域名下主机的 IP 地址，比如 apple.com 权威域名服务器可以返回 www.apple.com 的 IP 地址。

例如，你要访问“www.apple.com”，就要进行下面的三次查询：访问根域名服务器，它会告诉你“com”顶级域名服务器的地址；访问“com”顶级域名服务器，它再告诉你“apple.com”域名服务器的地址；最后访问“apple.com”域名服务器，就得到了“www.apple.com”的地址。

减轻域名解析的压力：
- 缓存
    - 许多大公司、网络运行商都会建立自己的 DNS 服务器，作为用户 DNS 查询的代理，代替用户访问核心 DNS 系统。这些“野生”服务器被称为“非权威域名服务器”，可以缓存之前的查询结果，如果已经有了记录，就无需再向根服务器发起查询，直接返回对应的 IP 地址。
        - 这些 DNS 服务器的数量要比核心系统的服务器多很多，而且大多部署在离用户很近的地方。比较知名的 DNS 有 Google 的“8.8.8.8”，Microsoft 的“4.2.2.1”，还有 CloudFlare 的“1.1.1.1”等等。
    - 操作系统里也会对 DNS 解析结果做缓存，如果你之前访问过“www.apple.com”，那么下一次在浏览器里再输入这个网址的时候就不会再跑到 DNS 那里去问了，直接在操作系统里就可以拿到 IP 地址。
    - 操作系统里还有一个特殊的“主机映射”文件，通常是一个可编辑的文本，在 Linux 里是“/etc/hosts”，在 Windows 里是“C:\WINDOWS\system32\drivers\etc\hosts”，如果操作系统在缓存里找不到 DNS 记录，就会找这个文件。

在 Nginx 里有这么一条配置指令“resolver”，它就是用来配置 DNS 服务器的，如果没有它，那么 Nginx 就无法查询域名对应的 IP，也就无法反向代理到外部的网站。
```
resolver 8.8.8.8 valid=30s;  #指定Google的DNS，缓存30秒
```
#### 域名新玩法
- 重定向
    - 当主机有情况需要下线、迁移时，可以更改 DNS 记录，让域名指向其他的机器。比如，你有一台“buy.tv”的服务器要临时停机维护，那你就可以通知 DNS 服务器：“我这个 buy.tv 域名的地址变了啊，原先是 1.2.3.4，现在是 5.6.7.8，麻烦你改一下。”DNS 于是就修改内部的 IP 地址映射关系，之后再有访问 buy.tv 的请求就不走 1.2.3.4 这台主机，改由 5.6.7.8 来处理，这样就可以保证业务服务不中断。
- 搭建内部DNS
    - 因为域名是一个名字空间，所以可以使用 bind9 等开源软件搭建一个在内部使用的 DNS，作为名字服务器。这样我们开发的各种内部服务就都用域名来标记，比如数据库服务都用域名“mysql.inner.app”，商品服务都用“goods.inner.app”，发起网络通信时也就不必再使用写死的 IP 地址了，可以直接用域名，而且这种方式也兼具了第一种“玩法”的优势。
- 基于域名实现的负载均衡
    - 包含前两种玩法，有两种方式，且可以混用
        - 第一种方式，因为域名解析可以返回多个 IP 地址，所以一个域名可以对应多台主机，客户端收到多个 IP 地址后，就可以自己使用轮询算法依次向服务器发起请求，实现负载均衡
        - 第二种方式，域名解析可以配置内部的策略，返回离客户端最近的主机，或者返回当前服务质量最好的主机，这样在 DNS 端把请求分发到不同的服务器，实现负载均衡。

恶意DNS:
- “域名屏蔽”，对域名直接不解析，返回错误，让你无法拿到 IP 地址，也就无法访问网站；
- “域名劫持”，也叫“域名污染”，你要访问 A 网站，但 DNS 给了你 B 网站。

比如你有一个网站要上线，你在域名注册商那里申请了abc.com,那么你的域名A记录就保存在这个域名注册商的DNS服务器上，该DNS服务器称为权威域名服务器。当客户端访问abc.com时，先查找浏览器DNS缓存，没有则查找操作系统DNS缓存，在这一阶段是操作系统dnscache clinet 服务进行DNS缓存的（你在任务管理器里面可以看到一个dns客户端进程，就是这玩意实现缓存的），如果还是没有则查找hosts文件中的域名记录。**然后依然没有的话则访问电脑上设置的DNS服务器IP，比如三大营运商的dns服务器或者谷歌的8.8.8.8，此时这一层的DNS服务器称为“野生DNS缓存服务器”，也就是非权威域名服务器**。

如果还是没有则非权威域名服务器会去查找 根域名服务器-顶级域名服务器-二级域名服务器-权威域名服务器 ，这样客户端就在权威域名服务器上找到了abc.com对应的IP了，这个IP可以是多个，每次客户端请求的时候域名服务器会根据负载均衡算法分配一个IP给你。当DNS缓存失效了，则重新开始新一轮的域名请求。

总结如下：
浏览器缓存->操作系统dnscache ->hosts文件->非权威域名服务器->根域名服务器->顶级域名服务器->（二级域名服务器）->权威域名服务器。

其中非权威域名服务器还包括LDNS（企业内网DNS服务器），三大营运商DNS，谷歌公开的DNS，微软公开的DNS等。
### 搭建HTTP实验环境

- Wireshark
    - 著名的网络抓包工具，能够截获在 TCP/IP 协议栈中传输的所有流量，并按协议类型、地址、端口等任意过滤，功能非常强大，是学习网络协议的必备工具。
- Chrome
    - 它不仅上网方便，也是一个很好的调试器，对 HTTP/1.1、HTTPS、HTTP/2、QUIC 等的协议都支持得非常好，用 F12 打开“开发者工具”还可以非常详细地观测 HTTP 传输全过程的各种数据。不能观测 HTTP 传输的过程，只能看到结果。
- Telnet
    - 一个经典的虚拟终端，基于 TCP 协议远程登录主机，我们可以使用它来模拟浏览器的行为，连接服务器后手动发送 HTTP 请求，把浏览器的干扰也彻底排除，能够从最原始的层面去研究 HTTP 协议。
- OpenResty
    - 它是基于 Nginx 的一个“强化包”，里面除了 Nginx 还有一大堆有用的功能模块，不仅支持 HTTP/HTTPS，还特别集成了脚本语言 Lua 简化 Nginx 二次开发，方便快速地搭建动态网关，更能够当成应用容器来编写业务逻辑。它相当于 Nginx 的“超集”，功能更丰富，安装部署更方便。可以用 Lua 编写一些服务端脚本，实现简单的 Web 服务器响应逻辑，方便实验。



## 基础
### 在浏览器上访问网址
![](https://raw.githubusercontent.com/QizhengZou/Image_hosting_rep/main/20220401112727.png)
- 解析域名
- 浏览器从地址栏的输入中获得服务器的 IP 地址和端口号；
- 浏览器用 TCP 的三次握手与服务器建立连接；
- 浏览器向服务器发送拼好的报文；
- 服务器收到报文后处理请求，同样拼好报文再发给浏览器；
- 浏览器解析报文，渲染输出页面。

域名解析的过程中会有多级的缓存，浏览器首先看一下自己的缓存里有没有，如果没有就向操作系统的缓存要，还没有就检查本机域名解析文件 hosts

真实网络场景：
![](https://raw.githubusercontent.com/QizhengZou/Image_hosting_rep/main/20220401115712.png)
CDN 会在 DNS 的解析过程中“插上一脚”。DNS 解析可能会给出 CDN 服务器的 IP 地址，这样你拿到的就会是 CDN 服务器而不是目标网站的实际地址。因为 CDN 会缓存网站的大部分资源，比如图片、CSS 样式表。由 PHP、Java 等后台服务动态生成的页面属于“动态资源”，CDN 无法缓存，只能从目标网站获取。

目标网站的服务器对外表现的是一个 IP 地址，但为了能够扛住高并发，在内部也是一套复杂的架构。通常在入口是负载均衡设备，例如四层的 LVS 或者七层的 Nginx，在后面是许多的服务器，构成一个更强更稳定的集群。

负载均衡设备会先访问系统里的缓存服务器，通常有 memory 级缓存 Redis 和 disk 级缓存 Varnish，它们的作用与 CDN 类似，不过是工作在内部网络里，把最频繁访问的数据缓存几秒钟或几分钟，减轻后端应用服务器的压力。

如果缓存服务器里也没有，那么负载均衡设备就要把请求转发给应用服务器了。这里就是各种开发框架大显神通的地方了，例如 Java 的 Tomcat/Netty/Jetty，Python 的 Django，还有 PHP、Node.js、Golang 等等。它们又会再访问后面的 MySQL、PostgreSQL、MongoDB 等数据库服务，实现用户登录、商品查询、购物下单、扣款支付等业务操作，然后把执行的结果返回给负载均衡设备，同时也可能给缓存服务器里也放一份

应用服务器的输出到了负载均衡设备这里，请求的处理就算是完成了，就要按照原路再走回去，还是要经过许多的路由器、网关、代理。如果这个资源允许缓存，那么经过 CDN 的时候它也会做缓存，这样下次同样的请求就不会到达源站了

最后网站的响应数据回到了你的设备，它可能是 HTML、JSON、图片或者其他格式的数据，需要由浏览器解析处理才能显示出来，如果数据里面还有超链接，指向别的资源，那么就又要重走一遍整个流程，直到所有的资源都下载完。

### HTTP报文
HTTP协议的核心部分在于它传输的报文内容。
#### 报文结构
TCP 报文在实际要传输的数据之前附加了一个 20 字节的头部数据，存储 TCP 协议必须的额外信息，例如发送方的端口号、接收方的端口号、包序号、标志位等等。有了这个附加的 TCP 头，数据包才能够正确传输，到了目的地后把头部去掉，就可以拿到真正的数据。
![](https://raw.githubusercontent.com/QizhengZou/Image_hosting_rep/main/20220401143047.png)
HTTP 协议也是与 TCP/UDP 类似，同样也需要在实际传输的数据前附加一些头数据，不过与 TCP/UDP 不同的是，它是一个“纯文本”的协议，所以头数据都是 ASCII 码的文本，可以很容易地用肉眼阅读

HTTP 协议的请求报文和响应报文的结构基本相同，由三大部分组成：
- 起始行（start line）：描述请求或响应的基本信息；
- 头部字段集合（header）：使用 key-value 形式更详细地说明报文；
- 消息正文（entity）：实际传输的数据，它不一定是纯文本，可以是图片、视频等二进制数据。

这其中前两部分起始行和头部字段经常又合称为“请求头”或“响应头”，消息正文又称为“实体”，但与“header”对应，很多时候就直接称为“body”

HTTP 协议规定报文必须有 header，但可以没有 body，而且在 header 之后必须要有一个“空行”，也就是“CRLF”，十六进制的“0D0A”。
![](https://raw.githubusercontent.com/QizhengZou/Image_hosting_rep/main/20220401143714.png)
![](https://raw.githubusercontent.com/QizhengZou/Image_hosting_rep/main/20220401144156.png)
#### 请求行
请求行简要地描述了客户端想要如何操作服务器端的资源。

构成：
- 请求方法：是一个动词，如 GET/POST，表示对资源的操作；
- 请求目标：通常是一个 URI，标记了请求方法要操作的资源；
- 版本号：表示报文使用的 HTTP 协议版本。
- 这三个部分通常使用空格（space）来分隔，最后要用 CRLF 换行表示结束
#### 状态行
状态行，顾名思义，服务器响应的状态。

构成：
- 版本号：表示报文使用的 HTTP 协议版本；
- 状态码：一个三位数，用代码的形式表示处理的结果，比如 200 是成功，500 是服务器错误，详细见文章附录；
- 原因：作为数字状态码补充，是更详细的解释文字，帮助人理解原因。
- 以空格分割，CRLF换行结束。

#### 头部字段
请求行或状态行再加上头部字段集合就构成了 HTTP 报文里完整的请求头或响应头

头部字段是 key-value 的形式，key 和 value 之间用“:”分隔，最后用 CRLF 换行表示字段结束

HTTP 头字段非常灵活，不仅可以使用标准里的 Host、Connection 等已有头，也可以任意添加自定义头

使用头字段需要注意下面几点：
- 字段名不区分大小写，例如“Host”也可以写成“host”，但首字母大写的可读性更好；
- 字段名里不允许出现空格，可以使用连字符“-”，但不能使用下划线“_”。例如，“test-name”是合法的字段名，而“test name”“test_name”是不正确的字段名；
- 字段名后面必须紧接着“:”，不能有空格，而“:”后的字段值前可以有多个空格；
- 字段的顺序是没有意义的，可以任意排列不影响语义；
- 字段原则上不能重复，除非这个字段本身的语义允许，例如 Set-Cookie。
#### 常用头字段
基本上可以分为四大类：
- 通用字段：在请求头和响应头里都可以出现；
- 请求字段：仅能出现在请求头里，进一步说明请求信息或者额外的附加条件；
- 响应字段：仅能出现在响应头里，补充说明响应报文的信息；
- 实体字段：它实际上属于通用字段，但专门描述 body 的额外信息。

对 HTTP 报文的解析和处理实际上主要就是对头字段的处理，理解了头字段也就理解了 HTTP 报文。

- Host字段
    - 属于请求字段，只能出现在请求头里，它同时也是唯一一个 HTTP/1.1 规范里要求必须出现的字段。Host 字段告诉服务器这个请求应该由哪个主机来处理，当一台计算机上托管了多个虚拟主机的时候，服务器端就需要用 Host 字段来选择，有点像是一个简单的“路由重定向”
- User-Agent
    - 是请求字段，只出现在请求头里。它使用一个字符串来描述发起 HTTP 请求的客户端，服务器可以依据它来返回最合适此浏览器显示的页面。“诚实”的爬虫会在 User-Agent 里用“spider”标明自己是爬虫，所以可以利用这个字段实现简单的反爬虫策略
- Date 字段
    - 是一个通用字段，但通常出现在响应头里，表示 HTTP 报文创建的时间，客户端可以使用这个时间再搭配其他字段决定缓存策略。
- Server 字段
    - 是响应字段，只能出现在响应头里。它告诉客户端当前正在提供 Web 服务的软件名称和版本号 
    - Server 字段也不是必须要出现的，因为这会把服务器的一部分信息暴露给外界，如果这个版本恰好存在 bug，那么黑客就有可能利用 bug 攻陷服务器
    - 比如 GitHub，它的 Server 字段里就看不出是使用了 Apache 还是 Nginx，只是显示为“GitHub.com”。
- Content-Length
    - 实体字段，它表示报文里 body 的长度，也就是请求头或响应头空行后面数据的长度。服务器看到这个字段，就知道了后续有多少数据，可以直接接收。如果没有这个字段，那么 body 就是不定长的，需要使用 chunked 方式分段传输


### 请求方法
目前 HTTP/1.1 规定了八种方法，前四个比较常用，单词都必须是大写的形式：
- GET：获取资源，可以理解为读取或者下载数据；
    - 请求从服务器获取资源，这个资源既可以是静态的文本、页面、图片、视频，也可以是由 PHP、Java 动态生成的页面或者其他格式的数据
    - 搭配 URI 和其他头字段就能实现对资源更精细的操作：
        - 在 URI 后使用“#”，就可以在获取页面后直接定位到某个标签所在的位置；使用 If-Modified-Since 字段就变成了“有条件的请求”，仅当资源被修改时才会执行获取动作；使用 Range 字段就是“范围请求”，只获取资源的一部分数据。
- HEAD：获取资源的元信息；
    - 服务器不会返回请求的实体数据，只会传回响应头，也就是资源的“元信息”
    - 比如，想要检查一个文件是否存在，只要发个 HEAD 请求就可以了，没有必要用 GET 把整个文件都取下来。再比如，要检查文件是否有最新版本，同样也应该用 HEAD，服务器会在响应头里把文件的修改时间传回来。
- POST：向资源提交数据，相当于写入或上传数据；
    - 只要向服务器发送数据，用的大多数都是 POST
- PUT：类似 POST，但较少使用；
    - 与 POST 存在微妙的不同，通常 POST 表示的是“新建”“create”的含义，而 PUT 则是“修改”“update”的含义。
- DELETE：删除资源；
    - 这个动作危险性太大，所以通常服务器不会执行真正的删除操作，而是对资源做一个删除标记。当然，更多的时候服务器就直接不处理 DELETE 请求。
- CONNECT：建立特殊的连接隧道；
    - 要求服务器为客户端和另一台远程服务器建立一条特殊的连接隧道，这时 Web 服务器在中间充当了代理的角色。
- OPTIONS：列出可对资源实行的方法；
    - 要求服务器列出可对资源实行的操作方法，在响应头的 Allow 字段里返回。它的功能很有限，用处也不大，有的服务器（例如 Nginx）干脆就没有实现对它的支持。
- TRACE：追踪请求 - 响应的传输路径。
    - 多用于对 HTTP 链路的测试或诊断，可以显示出请求 - 响应的传输路径。它的本意是好的，但存在漏洞，会泄漏网站的信息，所以 Web 服务器通常也是禁止使用。

也可以自定义请求方法。

在 HTTP 协议里，所谓的“安全”是指请求方法不会“破坏”服务器上的资源，即不会对服务器上的资源造成实质的修改。只有GET/HEAD是安全的。

所谓的“幂等”实际上是一个数学用语（一个运算*，如果对任意元x，x与自身运算等于自身，即x * x=x,则称该运算*满足幂等律），被借用到了 HTTP 协议里，意思是多次执行相同的操作，结果也都是相同的，即多次“幂”后结果“相等”。GET可以多次请求同一个资源，DELETE可以多次删除同一个资源，所以它们都是幂等的。POST不是幂等的，而PUT是幂等的。

### 正确的网址
URI最常用形式：
![](https://raw.githubusercontent.com/QizhengZou/Image_hosting_rep/main/20220402103018.png)
- scheme，“方案名”或者“协议名”，表示资源应该使用哪种协议来访问。
- ://
- “authority”，表示资源所在的主机名，通常的形式是“host:port”，即主机名加端口号
- 标记资源所在位置的 path
- /是UNIX的目录风格，也是path的一部分，Win的目录风格是\
- 客户端和服务器看到的URI是不一样的。客户端看到的必须是完整的 URI，使用特定的协议去连接特定的主机，而服务器看到的只是报文请求行里被删除了协议名和主机名的 URI。
- query，用一个“?”开始，但不包含“?”，表示对资源附加的额外要求
    - 查询参数 query 有一套自己的格式，是多个“key=value”的字符串，这些 KV 值用字符“&”连接，浏览器和服务器都可以按照这个格式把长串的查询参数解析成可理解的字典或关联数组形式。

URI完整格式：![](https://raw.githubusercontent.com/QizhengZou/Image_hosting_rep/main/20220402110440.png)
- 协议名之后、主机名之前的身份信息“user:passwd@”，表示登录主机时的用户名和密码，但现在已经不推荐使用这种形式了（RFC7230），不安全
- 查询参数后的片段标识符“#fragment”，它是 URI 所定位的资源内部的一个“锚点”或者说是“标签”，浏览器可以在获取资源后直接跳转到它指示的位置。
    - 片段标识符仅能由浏览器这样的客户端使用，服务器是看不到的

URI会把ASCII 码以外的字符集和特殊字符进行转义，将其转换成十六进制字节值，然后前面再加上一个“%”。
- eg: 空格被转义成“%20”，“?”被转义成“%3F”。而中文、日文等则通常使用 UTF-8 编码后再转义，例如“银河”会被转义成“%E9%93%B6%E6%B2%B3”

### 响应状态码
RFC 标准把状态码分成了五类，用数字的第一位表示分类，而 0~99 不用，这样状态码的实际可用范围就大大缩小了，由 000~999 变成了 100~599。
- 1××：
    - 1××类状态码属于提示信息，是协议处理的中间状态，实际能够用到的时候很少。
    - 我们偶尔能够见到的是“101 Switching Protocols”。它的意思是客户端使用 Upgrade 头字段，要求在 HTTP 协议的基础上改成其他的协议继续通信，比如 WebSocket。而如果服务器也同意变更协议，就会发送状态码 101，但这之后的数据传输就不会再使用 HTTP 了。
- 2××：
    - 2××类状态码表示服务器收到并成功处理了客户端的请求。
    - “200 OK”是最常见的成功状态码，表示一切正常，如果是非 HEAD 请求，通常在响应头后都会有 body 数据。
    - “204 No Content”是另一个很常见的成功状态码，它的含义与“200 OK”基本相同，但响应头后没有 body 数据。所以对于 Web 服务器来说，正确地区分 200 和 204 是很必要的。
    - “206 Partial Content”是 HTTP 分块下载或断点续传的基础，在客户端发送“范围请求”、要求获取资源的部分数据时出现，它与 200 一样，也是服务器成功处理了请求，但 body 里的数据不是资源的全部，而是其中的一部分。
    - 状态码 206 通常还会伴随着头字段“Content-Range”，表示响应报文里 body 数据的具体范围，供客户端确认，例如“Content-Range: bytes 0-99/2000”，意思是此次获取的是总计 2000 个字节的前 100 个字节。
- 3××：
    - 3××类状态码表示客户端请求的资源发生了变动，客户端必须用新的 URI 重新发送请求获取资源，也就是通常所说的“重定向”，包括著名的 301、302 跳转。
    - “301 Moved Permanently”俗称“永久重定向”，含义是此次请求的资源已经不存在了，需要改用新的 URI 再次访问。
    - 与它类似的是“302 Found”，曾经的描述短语是“Moved Temporarily”，俗称“临时重定向”，意思是请求的资源还在，但需要暂时用另一个 URI 来访问。
    - 301 和 302 都会在响应头里使用字段 Location 指明后续要跳转的 URI，最终的效果很相似，浏览器都会重定向到新的 URI。两者的根本区别在于语义，一个是“永久”，一个是“临时”，所以在场景、用法上差距很大。
    - 比如，你的网站升级到了 HTTPS，原来的 HTTP 不打算用了，这就是“永久”的，所以要配置 301 跳转，把所有的 HTTP 流量都切换到 HTTPS。
    - 再比如，今天夜里网站后台要系统维护，服务暂时不可用，这就属于“临时”的，可以配置成 302 跳转，把流量临时切换到一个静态通知页面，浏览器看到这个 302 就知道这只是暂时的情况，不会做缓存优化，第二天还会访问原来的地址。
    - “304 Not Modified” 是一个比较有意思的状态码，它用于 If-Modified-Since 等条件请求，表示资源未修改，用于缓存控制。它不具有通常的跳转含义，但可以理解成“重定向已到缓存的文件”（即“缓存重定向”）。
    - 301、302 和 304 分别涉及了 HTTP 协议里重要的“重定向跳转”和“缓存控制”
- 4××：
    - 4××类状态码表示客户端发送的请求报文有误，服务器无法处理，它就是真正的“错误码”含义了。
    - “400 Bad Request”是一个通用的错误码，表示请求报文有错误，但具体是数据格式错误、缺少请求头还是 URI 超长它没有明确说，只是一个笼统的错误，客户端看到 400 只会是“一头雾水”“不知所措”。所以，在开发 Web 应用时应当尽量避免给客户端返回 400，而是要用其他更有明确含义的状态码。
    - “403 Forbidden”实际上不是客户端的请求出错，而是表示服务器禁止访问资源。原因可能多种多样，例如信息敏感、法律禁止等，如果服务器友好一点，可以在 body 里详细说明拒绝请求的原因，不过现实中通常都是直接给一个“闭门羹”。
    - “404 Not Found”可能是我们最常看见也是最不愿意看到的一个状态码，它的原意是资源在本服务器上未找到，所以无法提供给客户端。但现在已经被“用滥了”，只要服务器“不高兴”就可以给出个 404，而我们也无从得知后面到底是真的未找到，还是有什么别的原因，某种程度上它比 403 还要令人讨厌。
    - 4××里剩下的一些代码较明确地说明了错误的原因，都很好理解，开发中常用的有：
        - 405 Method Not Allowed：不允许使用某些方法操作资源，例如不允许 POST 只能 GET；
        - 406 Not Acceptable：资源无法满足客户端请求的条件，例如请求中文但只有英文；
        - 408 Request Timeout：请求超时，服务器等待了过长的时间；
        - 409 Conflict：多个请求发生了冲突，可以理解为多线程并发时的竞态；
        - 413 Request Entity Too Large：请求报文里的 body 太大；
        - 414 Request-URI Too Long：请求行里的 URI 太大；
        - 429 Too Many Requests：客户端发送了太多的请求，通常是由于服务器的限连策略；
        - 431 Request Header Fields Too Large：请求头某个字段或总体太大；
- 5××：
    - 表示客户端请求报文正确，但服务器在处理时内部发生了错误，无法返回应有的响应数据，是服务器端的“错误码”。
    - “500 Internal Server Error”与 400 类似，也是一个通用的错误码，服务器究竟发生了什么错误我们是不知道的。不过对于服务器来说这应该算是好事，通常不应该把服务器内部的详细信息，例如出错的函数调用栈告诉外界。虽然不利于调试，但能够防止黑客的窥探或者分析。
    - “501 Not Implemented”表示客户端请求的功能还不支持，这个错误码比 500 要“温和”一些，和“即将开业，敬请期待”的意思差不多，不过具体什么时候“开业”就不好说了。
    - “502 Bad Gateway”通常是服务器作为网关或者代理时返回的错误码，表示服务器自身工作正常，访问后端服务器时发生了错误，但具体的错误原因也是不知道的。
    - “503 Service Unavailable”表示服务器当前很忙，暂时无法响应服务，我们上网时有时候遇到的“网络服务正忙，请稍后重试”的提示信息就是状态码 503。
    - 503 是一个“临时”的状态，很可能过几秒钟后服务器就不那么忙了，可以继续提供服务，所以 503 响应报文里通常还会有一个“Retry-After”字段，指示客户端可以在多久以后再次尝试发送请求。

目前 RFC 标准里总共有 41 个状态码，但状态码的定义是开放的，允许自行扩展。所以 Apache、Nginx 等 Web 服务器都定义了一些专有的状态码。

### HTTP/1.1的特点
- 灵活可拓展
    - 比如自定义头部字段、传输的实体数据可缓存可压缩、可分段获取数据、支持身份认证、支持国际化语言等
- 可靠传输
    - HTTP是基于TCP/IP的，TCP是可靠的
    - 具体做法与 TCP/UDP 差不多，都是对实际传输的数据（entity）做了一层包装，加上一个头，然后调用 Socket API，通过 TCP/IP 协议栈发送或者接收。
- 应用层协议
    - 自TCP/IP诞生后，出现了不少应用较为局限的应用层协议，如FTP 只能传输文件、SMTP 只能发送邮件、SSH 只能远程登录等
    - HTTP 凭借着可携带任意头字段和实体数据的报文结构，以及连接控制、缓存代理等方便易用的特性，在通用数据传输方面技压群雄
- 请求-应答
    - 这是HTTP最根本的通信模型，契合了传统的 C/S（Client/Server）系统架构以及后来的B/S架构。
    - 请求 - 应答模式也完全符合 RPC（Remote Procedure Call）的工作模式，可以把 HTTP 请求处理封装成远程函数调用，导致了 WebService、RESTful 和 gRPC 等的出现。
- 无状态
    - 客户端和服务器永远是处在一种“无知”的状态。建立连接前两者互不知情，每次收发的报文也都是互相独立的，没有任何的联系
    - “没有记忆能力”,不需要额外的资源来记录状态信息，能减轻服务器的负担
        - 不能记忆，就无法支持需要连续多个步骤的“事务”操作。例如电商购物，首先要登录，然后添加购物车，再下单、结算、支付，这一系列操作都需要知道用户的身份才行，但“无状态”服务器是不知道这些请求是相互关联的，每次都得问一遍身份信息，不仅麻烦，而且还增加了不必要的数据传输量，当然现在以及有好些解决方式了。
    - “无状态”也表示服务器都是相同的，没有“状态”的差异，所以可以很容易地组成集群，让负载均衡把请求转发到任意一台服务器
    - 对比一下 UDP 协议，不过它是无连接也无状态的，顺序发包乱序收包，数据包发出去后就不管了，收到后也不会顺序整理。而 HTTP 是有连接无状态，顺序发包顺序收包，按照收发的顺序管理报文。
- 明文
    - 协议里的报文（准确地说是 header 部分）不使用二进制数据，而是用简单可阅读的文本形式。对比 TCP、UDP 这样的二进制协议，它的优点显而易见，不需要借助任何外部工具，用浏览器、Wireshark 或者 tcpdump 抓包后，直接用肉眼就可以很容易地查看或者修改
    - HTTP 报文的所有信息会暴露。免费WIFI陷阱，一旦你连上了这个 WiFi 热点，所有的流量都会被截获保存。
- 不安全
    - 与明文有重合
    - 明文只是“机密”方面的一个缺点，在“身份认证”和“完整性校验”这两方面 HTTP 也是欠缺的。
    - 为了解决 HTTP 不安全的缺点，所以就出现了 HTTPS
- 性能
    - “队头阻塞”（Head-of-line blocking），当顺序发送的请求序列中的一个请求因为某种原因被阻塞时，在后面排队的所有请求也一并被阻塞，会导致客户端迟迟收不到数据。解决方案：HTTP/2 和 HTTP/3
## 进阶
### HTTP的实体数据
#### 数据类型与编码
TCP、UDP 是传输层的协议，它们不会关心 body 数据是什么，只要把数据发送到对方就算是完成了任务。

HTTP作为应用层的协议需要告诉上层接收到的是什么数据。HTTP 协议诞生之前就已经有了针对这种问题的解决方案，不过它是用在电子邮件系统里的，让电子邮件可以发送 ASCII 码以外的任意数据，方案的名字叫做“多用途互联网邮件扩展”（Multipurpose Internet Mail Extensions），简称为 **MIME**。MIME 把数据分成了八大类，每个大类下再细分出多个子类，形式是“type/subtype”的字符串。

HTTP取了MIME标准规范中的一部分，用来标记 body 的数据类型，这就是我们平常总能听到的“MIME type”。

在 HTTP 里经常遇到的几个类别：
- text：即文本格式的可读数据，我们最熟悉的应该就是 text/html 了，表示超文本文档，此外还有纯文本 text/plain、样式表 text/css 等。
- image：即图像文件，有 image/gif、image/jpeg、image/png 等。
- audio/video：音频和视频数据，例如 audio/mpeg、video/mp4 等。
- application：数据格式不固定，可能是文本也可能是二进制，必须由上层应用程序来解释。常见的有 application/json，application/javascript、application/pdf 等，另外，如果实在是不知道数据是什么类型，就会是 application/octet-stream，即不透明的二进制数据。

HTTP 在传输时为了节约带宽，有时候还会压缩数据，需要有一个“Encoding type”，告诉数据是用的什么编码格式，这样对方才能正确解压缩，还原出原始的数据。

比MIME type要少，常用的Encoding type只有下面三种：
- gzip：GNU zip 压缩格式，也是互联网上最流行的压缩格式；
- deflate：zlib（deflate）压缩格式，流行程度仅次于 gzip；
- br：一种专门为 HTTP 优化的新压缩算法（Brotli）。

#### 数据类型使用的头字段
HTTP 协议定义了两个 Accept 请求头字段和两个 Content 实体头字段，用于客户端和服务器进行“内容协商”。也就是说，客户端用 Accept 头告诉服务器希望接收什么样的数据，而服务器用 Content 头告诉客户端实际发送了什么样的数据。

Accept 字段标记的是客户端可理解的 MIME type，可以用“,”做分隔符列出多个类型，让服务器有更多的选择，例如:
```
Accept: text/html,application/xml,image/webp,image/png
```
服务器会在响应报文里用头字段 Content-Type 告诉实体数据的真实类型：（注意：content-type是通用字段，请求头也可以用，比如post时会用）
```
Content-Type: text/html
Content-Type: image/png
```
浏览器看到报文里的类型是“text/html”就知道是 HTML 文件，会调用排版引擎渲染出页面，看到“image/png”就知道是一个 PNG 文件，就会在页面上显示出图像

Accept-Encoding 字段标记的是客户端支持的压缩格式，例如上面说的 gzip、deflate 等，同样也可以用“,”列出多个，服务器可以选择其中一种来压缩数据，实际使用的压缩格式放在响应头字段 Content-Encoding 里。这两个字段是可以省略的，如果请求报文里没有 Accept-Encoding 字段，就表示客户端不支持压缩数据；如果响应报文里没有 Content-Encoding 字段，就表示响应数据没有被压缩。
#### 语言类型与编码
en 表示任意的英语，en-US 表示美式英语，en-GB 表示英式英语，而 zh-CN 表示汉语。

遵循 UTF-8 字符编码方式的 Unicode 字符集是互联网上的标准字符集。

Accept-Language 字段标记了客户端可理解的自然语言，也允许用“,”做分隔符列出多个类型，例如：
```
Accept-Language: zh-CN, zh, en
```
同样的（一般不会发，因为语言完全可以由字符集推断出来）：
```
Content-Language: zh-CN
```
需要注意的是，字符集在 HTTP 里使用的请求头字段是 Accept-Charset（虽然这个头字段基本用不着，现在浏览器基本支持多种字符集），但响应头里却没有对应的 Content-Charset，而是在 Content-Type 字段的数据类型后面用“charset=xxx”来表示：
```
Accept-Charset: gbk, utf-8
Content-Type: text/html; charset=utf-8
```
用以上请求头请求头字段进行**内容协商**的时候，还可以用一种特殊的“q”参数表示权重来设定优先级，这里的“q”是“**quality factor**”的意思。最大值是 1，最小值是 0.01，默认值是 1，如果值是 0 就表示拒绝。具体的形式是在数据类型或语言代码后面加一个“;”，然后是“q=value”

**注意**：在大多数编程语言里“;”的断句语气要强于“,”，而在 HTTP 的内容协商里却恰好反了过来，“;”的意义是小于“,”的。
```
Accept: text/html,application/xml;q=0.9,*/*;q=0.8
```
#### 内容协商的结果
内容协商的过程是不透明的，每个 Web 服务器使用的算法都不一样。

服务器可以在响应头里多加一个 Vary 字段，记录服务器在内容协商时参考的请求头字段，给出一点信息，例如：
```
Vary: Accept-Encoding,User-Agent,Accept
```

### HTTP传输大文件的方法
数据压缩：
- 有个缺点，gzip 等压缩算法通常只对文本文件有较好的压缩率，而图片、音频视频等多媒体数据本身就已经是高度压缩的，再用 gzip 处理也不会变小（甚至还有可能会增大一点），所以它就失效了
- 压缩文本效果不错，在 Nginx 里就会使用“gzip on”指令，启用对“text/html”的压缩。

分块传输：
- HTTP 协议里的“chunked”分块传输编码，在响应报文里用头字段“Transfer-Encoding: chunked”来表示（注意：和和“Content-Length”不能同时出现），意思是报文里的 body 部分不是一次性发过来的，而是分成了许多的块（chunk）逐个发送。
- 分块传输也可以用于“流式数据”，例如由数据库动态生成的表单页面，这种情况下 body 数据的长度是未知的，无法在头字段“Content-Length”里给出确切的长度，所以也只能用 chunked 方式分块发送。

分块传输的编码规则：
![](https://raw.githubusercontent.com/QizhengZou/Image_hosting_rep/main/20220403143209.png)

分块传输也有局限性，用看视频快进来理解就明白了。为了满足需求，HTTP协议提出了“**范围请求**”（这个功能是非必须的，web服务器支持范围请求便需要在响应头里添加字段“Accept-Ranges: bytes”，不支持可以用“Accept-Ranges: none”或者不用该字段），允许客户端在请求头里使用专用字段来表示只获取文件的一部分

请求头 Range 是 HTTP 范围请求的专用字段，格式是“bytes=x-y”，其中的 x 和 y 是以字节为单位的数据范围。（也可以请求多个范围，即多个x-y，见后文）

关于Range的格式：假设文件是 100 个字节，那么：
- “0-”表示从文档起点到文档终点，相当于“0-99”，即整个文件；
- “10-”是从第 10 个字节开始到文档末尾，相当于“10-99”；
- “-1”是文档的最后一个字节，相当于“99-99”；
- “-10”是从文档末尾倒数 10 个字节，相当于“90-99”

服务器收到 Range 字段后，需要做四件事:
- 检查范围是否合法
- 范围正确，服务器就可以根据 Range 头计算偏移量，读取文件的片段了，返回状态码“206 Partial Content”，和 200 的意思差不多，但表示 body 只是原数据的一部分。
- 添加一个响应头字段 Content-Range，告诉片段的实际偏移量和资源的总大小，格式是“bytes x-y/length”，与 Range 头区别在没有“=”，范围后多了总长度。例如，对于“0-10”的范围请求，值就是“bytes 0-10/100”。
- 发送数据，直接把片段用 TCP 发给客户端

除了视频拖拽，常用的下载工具里的多段下载、断点续传也是基于范围请求实现的。

**多范围请求**要使用一种特殊的 MIME 类型：“multipart/byteranges”，表示报文的 body 是由多段字节序列组成的，并且还要用一个参数“boundary=xxx”给出段之间的分隔标记。见下图：
![](https://raw.githubusercontent.com/QizhengZou/Image_hosting_rep/main/20220403145726.png)
比如：
```
……
Range: bytes=0-9, 20-29
```
```
……

--00000000001
Content-Type: text/plain
Content-Range: bytes 0-9/96

// this is
--00000000001
Content-Type: text/plain
Content-Range: bytes 20-29/96

ext json d
--00000000001--
```

### HTTP的连接管理

短连接：
- 早期的HTTP（0.9/1.0）是短连接的，数据传输基于 TCP/IP，每次发送请求前需要先与服务器建立连接，收到响应报文后会立即关闭连接。
- 在 TCP 协议里，建立连接和关闭连接都是非常“昂贵”的操作。TCP 建立连接要有“三次握手”，发送 3 个数据包，需要 1 个 RTT；关闭连接是“四次挥手”，4 个数据包需要 2 个 RTT（RTT（round-trip time）：一个小的分组从客户端到服务器，在回到客户端的时间（传输时间忽略））

长连接：
- 也叫“持久连接”（persistent connections）、“连接保活”（keep alive）、“连接复用”（connection reuse）。
- 在 HTTP/1.1 中的连接都会默认启用长连接。不需要用什么特殊的头字段指定，只要向服务器发送了第一次请求，后续的请求都会重复利用第一次打开的 TCP 连接，也就是长连接，在这个连接上收发数据。
- 也可以在请求头里明确地要求使用长连接机制，使用的字段是 Connection，值是“keep-alive”。
- 如果服务器支持长连接，它总会在响应报文里放一个“Connection: keep-alive”字段
- 关闭连接：在客户端，可以在请求头里加上“Connection: close”字段，服务端看到后在响应报文里也加上这个字段，发送之后就调用 Socket API 关闭 TCP 连接。
- 服务器端通常不会主动关闭连接，拿 Nginx 来举例，它有两种方式关闭连接：
    - 使用“keepalive_timeout”指令，设置长连接的超时时间，如果在一段时间内连接上没有任何数据收发就主动断开连接
    - 使用“keepalive_requests”指令，设置长连接上可发送的最大请求次数。

队头阻塞：head-of-line blocking
-   与短连接和长连接无关，而是由 HTTP 基本的“请求 - 应答”模型所导致的。
- HTTP 规定报文必须是“一发一收”，这就形成了一个先进先出的“串行”队列。队列里的请求没有轻重缓急的优先级，只有入队的先后顺序，排在最前面的请求被最优先处理。
- 性能优化：
    - “并发连接”（concurrent connections），也就是同时对一个域名发起多个长连接
        - 缺陷：每个客户端都建立多个连接，会将资源服务器榨干，或者“拒绝服务”
        - RFC2616 里明确限制每个客户端最多并发 2 个连接。不过实践证明这个数字实在是太小了，众多浏览器都无视标准，把这个上限提高到了 6~8。后来修订的 RFC7230 也就取消了这个“2”的限制。
    - “域名分片”（domain sharding）
        - 多个域名指向同一个服务器。避免被HTTP和浏览器限制，但依旧在增加服务器负担。

**注意**：上面是指HTTP层次的队首阻塞，而tcp层次的队首阻塞的原因：引自《web性能权威指南》
```
每个 TCP 分组都会带着一个唯一的序列号被发出，而所有分组必须按顺序传送到接收端。如果中途有一个分组没能到达接收端，那么后续分组必须保存到接收端的 TCP 缓冲区，等待丢失的分组重发并到达接收端。这一切都发生在 TCP 层，应用程序对 TCP 重发和缓冲区中排队的分组一无所知，必须等待分组全部到达才能访问数据。在此之前，应用程序只能在通过套接字读数据时感觉到延迟交互。这种效应称为 TCP 的队首阻塞。
```
### HTTP的重定向以及跳转

- 主动跳转：点击文档里的一个链接
    - 浏览器发起，浏览器首先要解析链接文字里的 URI
    - 再用这个 URI 发起一个新的 HTTP 请求，获取响应报文后就会切换显示内容，渲染出新 URI 指向的页面。
- 被动跳转：
    - 服务器发起，在HTTP里也叫做“重定向”（Redirection）
    - 重定向是“用户无感知”的。

重定向：
- “Location”字段属于响应字段，必须出现在响应报文里。但只有配合 301/302 状态码才有意义，它标记了服务器要求重定向的 URI，这里就是要求浏览器跳转到“index.html”。
- 浏览器收到 301/302 报文，会检查响应头里有没有“Location”。如果有，就从字段值里提取出 URI，发出新的 HTTP 请求
- 在“Location”里的 URI 既可以使用绝对 URI，也可以使用相对 URI（如果是站内跳转的话），相对 URI 从从请求上下文里计算得到。

重定向状态码：
- 内部重定向对用户来说是透明的，所以HTTP状态码是200
- 301
    - 永久重定向（Moved Permanently），意思是原 URI 已经“永久”性地不存在了，今后的所有请求都必须改用新的 URI。
- 302
    - 临时重定向
- 其他
    - 303 See Other：类似 302，但要求重定向后的请求改为 GET 方法，访问一个结果页面，避免 POST/PUT 重复操作；
    - 307 Temporary Redirect：类似 302，但重定向后请求里的方法和实体不允许变动，含义比 302 更明确；
    - 308 Permanent Redirect：类似 307，不允许重定向后的请求变动，但它是 301“永久重定向”的含义。

重定向应用场景：
- “资源不可用”，需要用另一个新的 URI 来代替。例如域名变更、服务器变更、网站改版、系统维护，这些都会导致原 URI 指向的资源无法访问，为了避免出现 404，就需要用重定向跳转到新的 URI。
- “避免重复”，让多个网址都跳转到一个 URI，增加访问入口的同时还不会增加额外的工作量。
- 永久和临时的选择。


重定向的一些问题：
- “性能损耗”。重定向的机制决定了一个跳转会有两次请求 - 应答，比正常的访问多了一次。（这里默认了外部重定向，内部重定向只有一次）
- “循环跳转”
    - HTTP 协议特别规定，浏览器必须具有检测“循环跳转”的能力，在发现这种情况时应当停止发送请求并给出错误提示。

### HTTP的cookie机制
Cookie的工作过程：
- 响应头字段 Set-Cookie 和请求头字段 Cookie
- 当用户通过浏览器第一次访问服务器的时候，要创建一个独特的身份标识数据，格式是“key=value”，然后放进 Set-Cookie 字段里，随着响应报文一同发给浏览器
- 浏览器收到响应报文，看到里面有 Set-Cookie，知道这是服务器给的身份标识，保存起来，下次再请求的时候就自动把这个值放进 Cookie 字段里发给服务器
- 第二次请求里面有了 Cookie 字段，就可以拿出 Cookie 里的值，识别出用户的身份

服务器有时会在响应头里添加多个 Set-Cookie，存储多个“key=value”。浏览器发送时不需要用多个 Cookie 字段，只要在一行里用“;”隔开就行。

Cookie 是由浏览器负责存储的。

可见，**Cookie 就是服务器委托浏览器存储在客户端里的一些数据，而这些数据通常都会记录用户的关键识别信息**。

设置Cookie属性：
- 设置 Cookie 的生存周期
    - 使用 Expires 和 Max-Age 两个属性来设置。
    - “Expires”俗称“过期时间”，用的是绝对时间点，可以理解为“截止日期”（deadline）。“Max-Age”用的是相对时间，单位是秒，浏览器用收到报文的时间点再加上 Max-Age，就可以得到失效的绝对时间。二者可以同时出现，浏览器会优先采用 Max-Age 计算失效期。
- 设置 Cookie 的作用域
    - “Domain”和“Path”指定了 Cookie 所属的域名和路径，浏览器在发送 Cookie 前会从 URI 中提取出 host 和 path 部分，对比 Cookie 的属性。如果不满足条件，就不会在请求头里发送 Cookie。
- Cookie 的安全性
    - 属性“HttpOnly”会告诉浏览器，此 Cookie 只能通过浏览器 HTTP 协议传输，禁止其他方式访问，浏览器的 JS 引擎就会禁用 document.cookie 等一切相关的 API。
    - 属性“SameSite”可以防范“跨站请求伪造”（XSRF）攻击，设置成“SameSite=Strict”可以严格限定 Cookie 不能随着跳转链接跨站发送，而“SameSite=Lax”则略宽松一点，允许 GET/HEAD 等安全方法，但禁止 POST 跨站发送。
    - “Secure”，表示这个 Cookie 仅能用 HTTPS 协议加密传输，明文的 HTTP 协议会禁止发送。但 Cookie 本身不是加密的，浏览器里还是以明文的形式存在

Cookie应用：
- 身份识别
- 广告跟踪
    - 一些网站的页面里会嵌入很多广告代码，里面就会访问广告商，传给浏览器的cookie都带有一定的行为分析，从而你访问其他网站时，那些广告商网站也能拿到你具有行为分析的的Cookie，从而个性化广告。

虽然现在已经出现了多种 Local Web Storage 技术，能够比 Cookie 存储更多的数据，但 Cookie 仍然是**最通用、兼容性最强**的客户端数据存储手段。

### HTTP的缓存控制
### HTTP的代理服务
### HTTP的缓存代理
## 安全
### HTTPS? SSL/TLS?
### 对称加密与非对称加密
### 数字签名与证书
### TLS1.2连接过程解析
### TLS1.3特性解析
### HTTPS的优化
### 该不该迁移到HTTPS
## 飞翔
### HTTP/2特性概览
### HTTP/2内核剖析
### HTTP/3展望
### 该不该迁移到HTTP/2
## 探索
### Nginx：高性能web服务器
### OpenResty：更灵活的web服务器
### WAF：保护我们的网络服务
### CDN：加速我们的网络服务
### WebSocket：沙盒里的TCP
## 总结
### HTTP性能优化

## 附录
[HTTP错误状态码](https://zhuanlan.zhihu.com/p/86603617)：
```
HTTP 400 – 请求无效
HTTP 401.1 – 未授权：登录失败
HTTP 401.2 – 未授权：服务器配置问题导致登录失败
HTTP 401.3 – ACL 禁止访问资源
HTTP 401.4 – 未授权：授权被筛选器拒绝
HTTP 401.5 – 未授权：ISAPI 或 CGI 授权失败
HTTP 403 – 禁止访问
HTTP 403 – 对 Internet 服务管理器 的访问仅限于 Localhost
HTTP 403.1 禁止访问：禁止可执行访问
HTTP 403.2 – 禁止访问：禁止读访问
HTTP 403.3 – 禁止访问：禁止写访问
HTTP 403.4 – 禁止访问：要求 SSL
HTTP 403.5 – 禁止访问：要求 SSL 128
HTTP 403.6 – 禁止访问：IP 地址被拒绝
HTTP 403.7 – 禁止访问：要求客户证书
HTTP 403.8 – 禁止访问：禁止站点访问
HTTP 403.9 – 禁止访问：连接的用户过多
HTTP 403.10 – 禁止访问：配置无效
HTTP 403.11 – 禁止访问：密码更改
HTTP 403.12 – 禁止访问：映射器拒绝访问
HTTP 403.13 – 禁止访问：客户证书已被吊销
HTTP 403.15 – 禁止访问：客户访问许可过多
HTTP 403.16 – 禁止访问：客户证书不可信或者无效
HTTP 403.17 – 禁止访问：客户证书已经到期或者尚未生效 HTTP 404.1 -

无法找到 Web 站点
HTTP 404- 无法找到文件
HTTP 405 – 资源被禁止
HTTP 406 – 无法接受
HTTP 407 – 要求代理身份验证
HTTP 410 – 永远不可用
HTTP 412 – 先决条件失败
HTTP 414 – 请求 – URI 太长

HTTP 500 – 内部服务器错误
HTTP 500.100 – 内部服务器错误 – ASP 错误
HTTP 500-11 服务器关闭
HTTP 500-12 应用程序重新启动
HTTP 500-13 – 服务器太忙
HTTP 500-14 – 应用程序无效
HTTP 500-15 – 不允许请求 global.asa
Error 501 – 未实现
HTTP 502 – 网关错误
```